{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "toc": {
      "nav_menu": {
        "height": "318px",
        "width": "252px"
      },
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "name": "Aula 5 - Exercício - Marcus Borela",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcusborela/Aprendizado-Profundo-Unicamp/blob/main/main/ex05/Marcus_Vinicius_Borela_de_Castro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nome = 'Marcus Vinícius Borela de CAstro'\n",
        "\n",
        "print(f'Meu nome é {nome}')"
      ],
      "metadata": {
        "id": "CdORg7oe68oq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bb071ae-aa4d-4069-fd75-90fd8741dabb"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meu nome é Marcus Vinícius Borela de CAstro\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkfGTqMVQT1u"
      },
      "source": [
        "Este exercicío consiste em treinar no MNIST um modelo de duas camadas, sendo a primeira uma camada convolucional e a segunda uma camada linear de classificação.\n",
        "\n",
        "Não podemos usar as funções torch.nn.Conv{1,2,3}d"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inicializações"
      ],
      "metadata": {
        "id": "GRNH4EGz8t-T"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFNf4RPxQT1w"
      },
      "source": [
        "## Importação das bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-21T14:08:14.033692Z",
          "start_time": "2018-08-21T14:08:11.179981Z"
        },
        "id": "-fLUSHaCQT1x"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision.datasets import MNIST"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "QRHim2GTA1wh"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fixando as seeds"
      ],
      "metadata": {
        "id": "achvQ78sa3p3"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkETIyWGkbOf"
      },
      "source": [
        "def inicializa_seed(num_semente:int=123):\n",
        "  \"\"\"\n",
        "  É recomendado reiniciar as seeds antes de inicializar o modelo, pois assim\n",
        "  garantimos que os pesos vao ser sempre os mesmos.\n",
        "  fontes de apoio: \n",
        "      http://nlp.seas.harvard.edu/2018/04/03/attention.html\n",
        "      https://github.com/CyberZHG/torch-multi-head-attention/blob/master/torch_multi_head_attention/multi_head_attention.py#L15\n",
        "  \"\"\"\n",
        "  random.seed(num_semente)\n",
        "  np.random.seed(num_semente)\n",
        "  torch.manual_seed(num_semente)\n",
        "  #torch.cuda.manual_seed(num_semente)\n",
        "  #Cuda algorithms\n",
        "  #torch.backends.cudnn.deterministic = True "
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViMcw_kVkbOf"
      },
      "source": [
        "inicializa_seed(123)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define pesos iniciais"
      ],
      "metadata": {
        "id": "fzurMVpHxcNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "in_channels = 1\n",
        "out_channels = 2\n",
        "kernel_size = 5\n",
        "stride = 3\n",
        "\n",
        "# Input image size\n",
        "height_in = 28  \n",
        "width_in = 28\n",
        "\n",
        "# Image size after the first convolutional layer.\n",
        "height_out = (height_in - kernel_size - 1) // stride + 1\n",
        "width_out = (width_in - kernel_size - 1) // stride + 1\n",
        "\n",
        "initial_conv_weight = torch.FloatTensor(out_channels, in_channels, kernel_size, kernel_size).uniform_(-0.01, 0.01)\n",
        "initial_conv_bias = torch.FloatTensor(out_channels,).uniform_(-0.01, 0.01)\n",
        "\n",
        "initial_classification_weight = torch.FloatTensor(10, out_channels * height_out * width_out).uniform_(-0.01, 0.01)\n",
        "initial_classification_bias = torch.FloatTensor(10,).uniform_(-0.01, 0.01)"
      ],
      "metadata": {
        "id": "9a6jQJLLlfF3"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\" height_out {height_out}, width_out {width_out}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Y2-ILXqbE1d",
        "outputId": "da30f8dc-7a1b-4836-f37c-132f8fe26957"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " height_out 8, width_out 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEMUsfJpQT11"
      },
      "source": [
        "# Dataset e dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHoQjDs_QT12"
      },
      "source": [
        "### Definição do tamanho do minibatch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-21T14:08:20.282474Z",
          "start_time": "2018-08-21T14:08:20.275450Z"
        },
        "id": "tEQYUr4TQT13"
      },
      "source": [
        "batch_size = 50"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc7Rv_2BQT16"
      },
      "source": [
        "### Carregamento, criação dataset e do dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-21T14:10:45.430605Z",
          "start_time": "2018-08-21T14:10:04.953051Z"
        },
        "id": "G0dEKCn-QT17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e86df164-f738-425b-c3aa-ee901245b771"
      },
      "source": [
        "dataset_dir = '../data/'\n",
        "\n",
        "dataset_train_full = MNIST(dataset_dir, train=True, download=True,\n",
        "                           transform=torchvision.transforms.ToTensor())\n",
        "print(dataset_train_full.data.shape)\n",
        "print(dataset_train_full.targets.shape)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([60000, 28, 28])\n",
            "torch.Size([60000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rOy9ntrQT2D"
      },
      "source": [
        "### Usando apenas 1000 amostras do MNIST\n",
        "\n",
        "Neste exercício utilizaremos 1000 amostras de treinamento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNF2XjLBWWe7"
      },
      "source": [
        "indices = torch.randperm(len(dataset_train_full))[:1000]\n",
        "dataset_train = torch.utils.data.Subset(dataset_train_full, indices)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSNLD2JyA2e-"
      },
      "source": [
        "loader_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-21T13:30:35.209157Z",
          "start_time": "2018-08-21T13:30:34.757103Z"
        },
        "id": "w52KGYlIQT2A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c17ebef-1b99-4c33-ed4a-55fc4c61f836"
      },
      "source": [
        "print('Número de minibatches de trenamento:', len(loader_train))\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de minibatches de trenamento: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train = next(iter(loader_train))\n",
        "print(\"\\nDimensões dos dados de um minibatch:\", x_train.size())\n",
        "print(\"Valores mínimo e máximo dos pixels: \", torch.min(x_train), torch.max(x_train))\n",
        "print(\"Tipo dos dados das imagens:         \", type(x_train))\n",
        "print(\"Tipo das classes das imagens:       \", type(y_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7vPdWoIbwht",
        "outputId": "f945580d-1108-4b3f-ecd4-5eee45960914"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dimensões dos dados de um minibatch: torch.Size([50, 1, 28, 28])\n",
            "Valores mínimo e máximo dos pixels:  tensor(0.) tensor(1.)\n",
            "Tipo dos dados das imagens:          <class 'torch.Tensor'>\n",
            "Tipo das classes das imagens:        <class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape, y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYw9dR89b3Is",
        "outputId": "e056a01f-a37f-4030-cf80-32729dfd652c"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([50, 1, 28, 28]), torch.Size([50]))"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[0, 0, 0, ] # 1a linha da 1a amostra"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6g_7GhLcJak",
        "outputId": "cb6622dc-9ee5-4c21-96f3-ee452173e32c"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[0, 0,] # 28 linhas da 1a amostra"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7J64G0oDcYed",
        "outputId": "2d355f07-9a2b-4029-cf6a-d260e96e7ca1"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2980, 0.9922, 0.9922, 0.6235,\n",
              "         0.3373, 0.0431, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0667, 0.0196, 0.0353, 0.3608, 0.4824, 0.8745,\n",
              "         0.9882, 0.7569, 0.1490, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.3255, 0.8196, 0.4196, 0.0000, 0.0000, 0.0000, 0.0980,\n",
              "         0.6784, 0.9922, 0.9412, 0.3216, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0667, 0.8196, 0.6902, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.4588, 0.9882, 0.9412, 0.1451, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.2902, 0.9176, 0.9882, 0.4235, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0118, 0.4588, 0.9882, 0.7529, 0.0431, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4980,\n",
              "         1.0000, 0.9765, 0.4510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.1686, 0.9686, 0.9922, 0.3373, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9569,\n",
              "         0.9765, 0.4588, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.4353, 0.9882, 0.5373, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3255, 0.9412, 0.9882,\n",
              "         0.4510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0745, 0.8588, 0.8667, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1490, 0.9412, 0.9882, 0.6157,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.8118, 0.9882, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5922, 0.9882, 0.9882, 0.1255,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.8118, 0.9882, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.3412, 0.9922, 0.9922, 0.1804, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.2745, 0.9922, 0.9529, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.5412, 0.9882, 0.8157, 0.0667, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.3569, 0.9882, 0.5373, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.5412, 0.9882, 0.5922, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.1333, 0.9176, 0.9882, 0.4157, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.5412, 0.9882, 0.2706, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0353, 0.4784, 0.9882, 0.8549, 0.0549, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.9529, 0.8235, 0.0235, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.5020, 0.9882, 0.9882, 0.2196, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.8275, 0.0275, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0353,\n",
              "         0.5020, 1.0000, 0.9765, 0.4510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.7059, 0.9882, 0.6039, 0.0353, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2588, 0.7608,\n",
              "         0.9882, 0.8941, 0.4588, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.3961, 0.8902, 0.9882, 0.6039, 0.2745,\n",
              "         0.2510, 0.1255, 0.2000, 0.2745, 0.2745, 0.5176, 0.7216, 0.9176, 0.9882,\n",
              "         0.7412, 0.1255, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1961, 0.6275, 0.9255, 0.9882,\n",
              "         0.9765, 0.8941, 0.9412, 0.9882, 0.9882, 0.9922, 0.9216, 0.6275, 0.2588,\n",
              "         0.0157, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0745, 0.0863,\n",
              "         0.5373, 0.5373, 0.6588, 0.8235, 0.5373, 0.2941, 0.0706, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape[1] # canais"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yo8ov5QdUNk",
        "outputId": "e3efe735-6fec-43cf-dea4-cecbb7be563c"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementando Conv2d com for na imagem de saída"
      ],
      "metadata": {
        "id": "hp4eoVD77ubG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inicializa_seed(123)"
      ],
      "metadata": {
        "id": "OhhVYR-M7ubH"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.cat((saida[0,0,0], torch.tensor([[12]])), dim=-1)"
      ],
      "metadata": {
        "id": "-FebDt7c__d1"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saida"
      ],
      "metadata": {
        "id": "1Qi-eoW97Sp_"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyConv2dForSaida(torch.nn.Module):\n",
        "  \"\"\"\n",
        "  Versão com for sobre as dimensões do filtro de saída\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int, verbose:bool = False):\n",
        "    super(MyConv2dForSaida, self).__init__()\n",
        "\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.kernel_size = kernel_size  # The same for height and width.\n",
        "    self.stride = stride  # The same for height and width.\n",
        "    self.weight = torch.nn.Parameter(torch.FloatTensor(out_channels, in_channels, kernel_size, kernel_size).uniform_(-0.01, 0.01))\n",
        "    self.bias = torch.nn.Parameter(torch.FloatTensor(out_channels,).uniform_(-0.01, 0.01))\n",
        "    self.verbose = verbose\n",
        "    if self.verbose:\n",
        "      print(f\"Inicializado MyConv2dForSaida\")\n",
        "      print(f\"in_channels: {self.in_channels} \")\n",
        "      print(f\"out_channels: {self.out_channels} \")\n",
        "      print(f\"kernel_size: {self.kernel_size} \")\n",
        "      print(f\"stride: {self.stride} \")\n",
        "      print(f\"weight.shape: {self.weight.shape} \")\n",
        "      print(f\"weight: {self.weight} \")\n",
        "      print(f\"bias.shape: {self.bias.shape} \")\n",
        "      print(f\"bias: {self.bias} \")\n",
        "\n",
        "  def forward(self, x):\n",
        "    assert x.dim() == 4, f'x must have 4 dimensions, not {x.shape}'\n",
        "    assert x.shape[1] == 1, f'x must have only 1 channel, not {x.shape[1]}' # Num_canais sempre 1 (mnist, preto/branco)\n",
        "\n",
        "    # print(f\"kernel.shape: {self.weight.shape}, kernel: {self.weight}\")\n",
        "    # Escreva seu código aqui.\n",
        "    # versão com for nas dimensões de X\n",
        "    num_amostras = x.shape[0]\n",
        "    num_linhas_entrada = x.shape[2]\n",
        "    num_colunas_entrada = x.shape[3]\n",
        "    num_linhas_saida = (num_linhas_entrada - self.kernel_size) // self.stride + 1\n",
        "    num_colunas_saida = (num_colunas_entrada - self.kernel_size) // self.stride + 1\n",
        "    saida = torch.zeros((num_amostras,self.out_channels,num_linhas_saida,num_colunas_saida), dtype=torch.float, requires_grad=False)        \n",
        "    if self.verbose:\n",
        "      print(f\" num_amostras: {num_amostras}, self.out_channels: {self.out_channels}, num_linhas_entrada: {num_linhas_entrada}, num_colunas_entrada: {num_colunas_entrada}, num_linhas_saida: {num_linhas_saida}, num_colunas_saida: {num_colunas_saida}\")\n",
        "      print(f\"saida.shape: {saida.shape}\")\n",
        "    for ndx_amostra in range(num_amostras):\n",
        "      if self.verbose:\n",
        "        print(f\"\\nndx_amostra: {ndx_amostra}\")\n",
        "      # for ndx_out_channels in range(self.out_channels):\n",
        "      #   print(f\"\\nndx_out_channels: {ndx_out_channels}\")\n",
        "      for ndx_in_channels in range(self.in_channels):\n",
        "        if self.verbose:\n",
        "          print(f\"\\nndx_in_channels: {ndx_in_channels}\")\n",
        "        ndx_linhas_entrada = 0\n",
        "        for ndx_linhas_saida in range(num_linhas_saida):\n",
        "          ndx_colunas_entrada = 0\n",
        "          for ndx_colunas_saida in range(num_colunas_saida):\n",
        "            produto = torch.mul(x[ndx_amostra, ndx_in_channels, ndx_linhas_entrada:ndx_linhas_entrada+self.kernel_size, ndx_colunas_entrada:ndx_colunas_entrada+self.kernel_size], self.weight)\n",
        "            soma = torch.sum(produto, dim=(2,3), keepdim=True )\n",
        "            valor_soma = soma.squeeze()\n",
        "            if self.verbose:\n",
        "              print(f\"\\nndx_linhas_saida, ndx_colunas_saida: {ndx_linhas_saida}, {ndx_colunas_saida}\")\n",
        "              print(f\" alvo do kernel em x: x[{ndx_amostra},{ndx_in_channels},{ndx_linhas_entrada}:{ndx_linhas_entrada+self.kernel_size}, {ndx_colunas_entrada}:{ndx_colunas_entrada+self.kernel_size}]\")\n",
        "              print(f\" \\n {x[ndx_amostra, ndx_in_channels, ndx_linhas_entrada:ndx_linhas_entrada+self.kernel_size, ndx_colunas_entrada:ndx_colunas_entrada+self.kernel_size]}\")\n",
        "              print(f\" produto: {produto}\")\n",
        "              print(f\" soma: {soma}\")\n",
        "              print(f\" valor_soma: {valor_soma}\")\n",
        "            # saida = torch.cat((saida, soma))\n",
        "            if self.out_channels > 1:  # soma é um com dimensões, como em torch.tensor([[[[ 46.]], [[134.]]]])\n",
        "              for ndx_out_channels in range(self.out_channels):\n",
        "                saida[ndx_amostra, ndx_out_channels, ndx_linhas_saida, ndx_colunas_saida] += valor_soma[ndx_out_channels]\n",
        "                if self.verbose:\n",
        "                  print(f\" somado na saída em [{ndx_amostra}, {ndx_out_channels}, {ndx_linhas_saida}, {ndx_colunas_saida}] = {saida[ndx_amostra, ndx_out_channels, ndx_linhas_saida, ndx_colunas_saida]}\")\n",
        "            else: # soma é um tensor escalar, como em tensor(34.)\n",
        "                saida[ndx_amostra, 0, ndx_linhas_saida, ndx_colunas_saida] += valor_soma\n",
        "                if self.verbose:\n",
        "                  print(f\" somado na saída em [{ndx_amostra}, 0, {ndx_linhas_saida}, {ndx_colunas_saida}] = {saida[ndx_amostra, 0, ndx_linhas_saida, ndx_colunas_saida]}\")\n",
        "            ndx_colunas_entrada += self.stride\n",
        "          ndx_linhas_entrada += self.stride\n",
        "    if self.verbose:\n",
        "      print(f\" saida: {saida}\")\n",
        "    # somando bias\n",
        "    for ndx_amostra in range(num_amostras):\n",
        "      if self.verbose:\n",
        "        print(f\"\\nndx_amostra: {ndx_amostra}\")\n",
        "      for ndx_out_channels in range(self.out_channels):\n",
        "        saida[ndx_amostra, ndx_out_channels] += self.bias[ndx_out_channels]\n",
        "    if self.verbose:\n",
        "      print(f\" saida apos somar bias: {saida}\")\n",
        "    # versão com for no kernel\n",
        "\n",
        "    return saida"
      ],
      "metadata": {
        "id": "urzHK0QB_hyY"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare se sua implementação está igual à do pytorch usando um exemplo simples"
      ],
      "metadata": {
        "id": "ROizI33sqE79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "in_channels_dummy = 1\n",
        "out_channels_dummy = 1\n",
        "kernel_size_dummy = 2\n",
        "stride_dummy = 1\n",
        "x = torch.arange(30).float().reshape(1, 1, 5, 6)"
      ],
      "metadata": {
        "id": "i1TuxWbkqMJc"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-FSsEC9icLX",
        "outputId": "3857b6de-31d5-43c8-a68d-ff112a18bfca"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[ 0.,  1.,  2.,  3.,  4.,  5.],\n",
            "          [ 6.,  7.,  8.,  9., 10., 11.],\n",
            "          [12., 13., 14., 15., 16., 17.],\n",
            "          [18., 19., 20., 21., 22., 23.],\n",
            "          [24., 25., 26., 27., 28., 29.]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0,0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ko7dGDl66A8k",
        "outputId": "ec0ca5f2-5bcc-4b1f-cc62-e767d7baf332"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.,  1.,  2.,  3.,  4.,  5.],\n",
              "        [ 6.,  7.,  8.,  9., 10., 11.],\n",
              "        [12., 13., 14., 15., 16., 17.],\n",
              "        [18., 19., 20., 21., 22., 23.],\n",
              "        [24., 25., 26., 27., 28., 29.]])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "conv_layer = MyConv2dForSaida( in_channels=in_channels_dummy,out_channels=out_channels_dummy, kernel_size=kernel_size_dummy, stride=stride_dummy, verbose=True)\n",
        "\n",
        "# Usa os mesmos pesos para minha implementação e a do pytorch\n",
        "initial_weights_dummy = torch.arange(in_channels_dummy * out_channels_dummy * kernel_size_dummy * kernel_size_dummy).float()\n",
        "initial_weights_dummy = initial_weights_dummy.reshape(in_channels_dummy, out_channels_dummy, kernel_size_dummy, kernel_size_dummy)\n",
        "initial_bias_dummy = torch.arange(out_channels_dummy,).float()\n",
        "\n",
        "conv_layer.weight.data = initial_weights_dummy\n",
        "conv_layer.bias.data = initial_bias_dummy\n",
        "\n",
        "out = conv_layer(x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASbzrpDHiaxm",
        "outputId": "fa78a414-1edd-4ff9-8ca6-05ecec30d440"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inicializado MyConv2dForSaida\n",
            "in_channels: 1 \n",
            "out_channels: 1 \n",
            "kernel_size: 2 \n",
            "stride: 1 \n",
            "weight.shape: torch.Size([1, 1, 2, 2]) \n",
            "weight: Parameter containing:\n",
            "tensor([[[[-0.0041,  0.0003],\n",
            "          [-0.0050,  0.0038]]]], requires_grad=True) \n",
            "bias.shape: torch.Size([1]) \n",
            "bias: Parameter containing:\n",
            "tensor([-0.0085], requires_grad=True) \n",
            " num_amostras: 1, self.out_channels: 1, num_linhas_entrada: 5, num_colunas_entrada: 6, num_linhas_saida: 4, num_colunas_saida: 5\n",
            "saida.shape: torch.Size([1, 1, 4, 5])\n",
            "\n",
            "ndx_amostra: 0\n",
            "\n",
            "ndx_in_channels: 0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 0\n",
            " alvo do kernel em x: x[0,0,0:2, 0:2]\n",
            " \n",
            " tensor([[0., 1.],\n",
            "        [6., 7.]])\n",
            " produto: tensor([[[[ 0.,  1.],\n",
            "          [12., 21.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[34.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 34.0\n",
            " somado na saída em [0, 0, 0, 0] = 34.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 1\n",
            " alvo do kernel em x: x[0,0,0:2, 1:3]\n",
            " \n",
            " tensor([[1., 2.],\n",
            "        [7., 8.]])\n",
            " produto: tensor([[[[ 0.,  2.],\n",
            "          [14., 24.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[40.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 40.0\n",
            " somado na saída em [0, 0, 0, 1] = 40.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 2\n",
            " alvo do kernel em x: x[0,0,0:2, 2:4]\n",
            " \n",
            " tensor([[2., 3.],\n",
            "        [8., 9.]])\n",
            " produto: tensor([[[[ 0.,  3.],\n",
            "          [16., 27.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[46.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 46.0\n",
            " somado na saída em [0, 0, 0, 2] = 46.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 3\n",
            " alvo do kernel em x: x[0,0,0:2, 3:5]\n",
            " \n",
            " tensor([[ 3.,  4.],\n",
            "        [ 9., 10.]])\n",
            " produto: tensor([[[[ 0.,  4.],\n",
            "          [18., 30.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[52.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 52.0\n",
            " somado na saída em [0, 0, 0, 3] = 52.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 4\n",
            " alvo do kernel em x: x[0,0,0:2, 4:6]\n",
            " \n",
            " tensor([[ 4.,  5.],\n",
            "        [10., 11.]])\n",
            " produto: tensor([[[[ 0.,  5.],\n",
            "          [20., 33.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[58.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 58.0\n",
            " somado na saída em [0, 0, 0, 4] = 58.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 0\n",
            " alvo do kernel em x: x[0,0,1:3, 0:2]\n",
            " \n",
            " tensor([[ 6.,  7.],\n",
            "        [12., 13.]])\n",
            " produto: tensor([[[[ 0.,  7.],\n",
            "          [24., 39.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[70.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 70.0\n",
            " somado na saída em [0, 0, 1, 0] = 70.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 1\n",
            " alvo do kernel em x: x[0,0,1:3, 1:3]\n",
            " \n",
            " tensor([[ 7.,  8.],\n",
            "        [13., 14.]])\n",
            " produto: tensor([[[[ 0.,  8.],\n",
            "          [26., 42.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[76.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 76.0\n",
            " somado na saída em [0, 0, 1, 1] = 76.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 2\n",
            " alvo do kernel em x: x[0,0,1:3, 2:4]\n",
            " \n",
            " tensor([[ 8.,  9.],\n",
            "        [14., 15.]])\n",
            " produto: tensor([[[[ 0.,  9.],\n",
            "          [28., 45.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[82.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 82.0\n",
            " somado na saída em [0, 0, 1, 2] = 82.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 3\n",
            " alvo do kernel em x: x[0,0,1:3, 3:5]\n",
            " \n",
            " tensor([[ 9., 10.],\n",
            "        [15., 16.]])\n",
            " produto: tensor([[[[ 0., 10.],\n",
            "          [30., 48.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[88.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 88.0\n",
            " somado na saída em [0, 0, 1, 3] = 88.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 4\n",
            " alvo do kernel em x: x[0,0,1:3, 4:6]\n",
            " \n",
            " tensor([[10., 11.],\n",
            "        [16., 17.]])\n",
            " produto: tensor([[[[ 0., 11.],\n",
            "          [32., 51.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[94.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 94.0\n",
            " somado na saída em [0, 0, 1, 4] = 94.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 0\n",
            " alvo do kernel em x: x[0,0,2:4, 0:2]\n",
            " \n",
            " tensor([[12., 13.],\n",
            "        [18., 19.]])\n",
            " produto: tensor([[[[ 0., 13.],\n",
            "          [36., 57.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[106.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 106.0\n",
            " somado na saída em [0, 0, 2, 0] = 106.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 1\n",
            " alvo do kernel em x: x[0,0,2:4, 1:3]\n",
            " \n",
            " tensor([[13., 14.],\n",
            "        [19., 20.]])\n",
            " produto: tensor([[[[ 0., 14.],\n",
            "          [38., 60.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[112.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 112.0\n",
            " somado na saída em [0, 0, 2, 1] = 112.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 2\n",
            " alvo do kernel em x: x[0,0,2:4, 2:4]\n",
            " \n",
            " tensor([[14., 15.],\n",
            "        [20., 21.]])\n",
            " produto: tensor([[[[ 0., 15.],\n",
            "          [40., 63.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[118.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 118.0\n",
            " somado na saída em [0, 0, 2, 2] = 118.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 3\n",
            " alvo do kernel em x: x[0,0,2:4, 3:5]\n",
            " \n",
            " tensor([[15., 16.],\n",
            "        [21., 22.]])\n",
            " produto: tensor([[[[ 0., 16.],\n",
            "          [42., 66.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[124.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 124.0\n",
            " somado na saída em [0, 0, 2, 3] = 124.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 4\n",
            " alvo do kernel em x: x[0,0,2:4, 4:6]\n",
            " \n",
            " tensor([[16., 17.],\n",
            "        [22., 23.]])\n",
            " produto: tensor([[[[ 0., 17.],\n",
            "          [44., 69.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[130.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 130.0\n",
            " somado na saída em [0, 0, 2, 4] = 130.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 0\n",
            " alvo do kernel em x: x[0,0,3:5, 0:2]\n",
            " \n",
            " tensor([[18., 19.],\n",
            "        [24., 25.]])\n",
            " produto: tensor([[[[ 0., 19.],\n",
            "          [48., 75.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[142.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 142.0\n",
            " somado na saída em [0, 0, 3, 0] = 142.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 1\n",
            " alvo do kernel em x: x[0,0,3:5, 1:3]\n",
            " \n",
            " tensor([[19., 20.],\n",
            "        [25., 26.]])\n",
            " produto: tensor([[[[ 0., 20.],\n",
            "          [50., 78.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[148.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 148.0\n",
            " somado na saída em [0, 0, 3, 1] = 148.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 2\n",
            " alvo do kernel em x: x[0,0,3:5, 2:4]\n",
            " \n",
            " tensor([[20., 21.],\n",
            "        [26., 27.]])\n",
            " produto: tensor([[[[ 0., 21.],\n",
            "          [52., 81.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[154.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 154.0\n",
            " somado na saída em [0, 0, 3, 2] = 154.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 3\n",
            " alvo do kernel em x: x[0,0,3:5, 3:5]\n",
            " \n",
            " tensor([[21., 22.],\n",
            "        [27., 28.]])\n",
            " produto: tensor([[[[ 0., 22.],\n",
            "          [54., 84.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[160.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 160.0\n",
            " somado na saída em [0, 0, 3, 3] = 160.0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 4\n",
            " alvo do kernel em x: x[0,0,3:5, 4:6]\n",
            " \n",
            " tensor([[22., 23.],\n",
            "        [28., 29.]])\n",
            " produto: tensor([[[[ 0., 23.],\n",
            "          [56., 87.]]]], grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[166.]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: 166.0\n",
            " somado na saída em [0, 0, 3, 4] = 166.0\n",
            " saida: tensor([[[[ 34.,  40.,  46.,  52.,  58.],\n",
            "          [ 70.,  76.,  82.,  88.,  94.],\n",
            "          [106., 112., 118., 124., 130.],\n",
            "          [142., 148., 154., 160., 166.]]]], grad_fn=<CopySlices>)\n",
            "\n",
            "ndx_amostra: 0\n",
            " saida apos somar bias: tensor([[[[ 34.,  40.,  46.,  52.,  58.],\n",
            "          [ 70.,  76.,  82.,  88.,  94.],\n",
            "          [106., 112., 118., 124., 130.],\n",
            "          [142., 148., 154., 160., 166.]]]], grad_fn=<CopySlices>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pytorch_conv_layer = torch.nn.Conv2d(out_channels=out_channels_dummy, in_channels=in_channels_dummy, kernel_size=kernel_size_dummy, stride=stride_dummy, padding=0)\n",
        "pytorch_conv_layer.load_state_dict(dict(weight=initial_weights_dummy, bias=initial_bias_dummy))\n",
        "target_out = pytorch_conv_layer(x)"
      ],
      "metadata": {
        "id": "xN--jid1fn-p"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blRMn_9hgIGZ",
        "outputId": "70c7e9e5-78c3-457a-89a3-b22b8e9f23c6"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 4, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert torch.allclose(out, target_out, atol=1e-6)"
      ],
      "metadata": {
        "id": "FUgUwtXPgGaD"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare se sua implementação está igual à do pytorch usando um exemplo aleatório"
      ],
      "metadata": {
        "id": "_75UnRhdd_MW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(2, in_channels, height_in, width_in)\n",
        "print(f\"x.shape: {x.shape}, x:{x}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7X_A2jeDs4f",
        "outputId": "2947a5af-dce7-43a2-8f04-63420808fde6"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x.shape: torch.Size([2, 1, 28, 28]), x:tensor([[[[0.3153, 0.6871, 0.0756,  ..., 0.4340, 0.0772, 0.3565],\n",
            "          [0.1479, 0.5331, 0.4066,  ..., 0.1634, 0.3009, 0.5201],\n",
            "          [0.3834, 0.4451, 0.0126,  ..., 0.8858, 0.6568, 0.8459],\n",
            "          ...,\n",
            "          [0.0697, 0.6010, 0.1875,  ..., 0.1904, 0.0051, 0.0117],\n",
            "          [0.6601, 0.6034, 0.5058,  ..., 0.1765, 0.4007, 0.9541],\n",
            "          [0.8567, 0.4604, 0.2238,  ..., 0.0509, 0.9271, 0.2894]]],\n",
            "\n",
            "\n",
            "        [[[0.8272, 0.9483, 0.8171,  ..., 0.5849, 0.4149, 0.2594],\n",
            "          [0.1849, 0.2540, 0.4626,  ..., 0.1202, 0.6813, 0.3728],\n",
            "          [0.8571, 0.0257, 0.7619,  ..., 0.0264, 0.0534, 0.0903],\n",
            "          ...,\n",
            "          [0.4493, 0.0843, 0.3308,  ..., 0.9408, 0.3042, 0.3526],\n",
            "          [0.9909, 0.5564, 0.9295,  ..., 0.0156, 0.8797, 0.2511],\n",
            "          [0.0361, 0.4623, 0.8646,  ..., 0.4430, 0.6219, 0.1061]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_layer = MyConv2dForSaida(out_channels=out_channels, in_channels=in_channels, kernel_size=kernel_size, stride=stride, verbose=True)\n",
        "conv_layer.weight.data = initial_conv_weight\n",
        "conv_layer.bias.data = initial_conv_bias\n",
        "print(f\"conv_layer.weight.data.shape: {conv_layer.weight.data.shape}, conv_layer.bias.data.shape: {conv_layer.bias.data.shape}\")\n",
        "print(f\"conv_layer.weight.data: {conv_layer.weight.data}, conv_layer.bias.data: {conv_layer.bias.data}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPL18MC-Ed9x",
        "outputId": "625e423c-4039-4e04-e691-9cae1674f474"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inicializado MyConv2dForSaida\n",
            "in_channels: 1 \n",
            "out_channels: 2 \n",
            "kernel_size: 5 \n",
            "stride: 3 \n",
            "weight.shape: torch.Size([2, 1, 5, 5]) \n",
            "weight: Parameter containing:\n",
            "tensor([[[[ 6.6078e-06, -9.2485e-03, -9.2362e-03,  1.8061e-04,  1.3908e-03],\n",
            "          [ 1.8874e-03, -3.6917e-03, -1.0977e-03, -1.1083e-03, -3.3335e-04],\n",
            "          [-6.4626e-03,  2.1828e-03,  3.0981e-03,  2.8529e-04, -8.1157e-04],\n",
            "          [ 4.8421e-03,  6.7688e-03, -1.2534e-04, -7.5895e-03, -6.9633e-03],\n",
            "          [-1.9524e-04, -9.1405e-03, -7.5606e-03, -2.4248e-03, -3.9989e-03]]],\n",
            "\n",
            "\n",
            "        [[[-1.2834e-03,  2.4163e-03,  6.8450e-03,  9.9526e-03, -3.9993e-03],\n",
            "          [-9.7703e-03,  6.6395e-03,  8.7120e-03,  9.5413e-03,  2.2681e-03],\n",
            "          [ 6.3718e-03,  2.3667e-05, -7.0870e-03, -8.0465e-03, -5.9984e-03],\n",
            "          [ 1.5156e-03, -2.5329e-03,  2.5571e-03,  3.5150e-03, -6.3376e-03],\n",
            "          [ 7.9751e-04,  9.6898e-03,  6.5876e-03, -1.1136e-03, -2.0899e-03]]]],\n",
            "       requires_grad=True) \n",
            "bias.shape: torch.Size([2]) \n",
            "bias: Parameter containing:\n",
            "tensor([-0.0039,  0.0033], requires_grad=True) \n",
            "conv_layer.weight.data.shape: torch.Size([2, 1, 5, 5]), conv_layer.bias.data.shape: torch.Size([2])\n",
            "conv_layer.weight.data: tensor([[[[-0.0041,  0.0003, -0.0050,  0.0038, -0.0085],\n",
            "          [ 0.0073, -0.0073, -0.0080, -0.0063,  0.0045],\n",
            "          [-0.0037,  0.0037, -0.0085, -0.0061, -0.0037],\n",
            "          [-0.0020, -0.0076,  0.0065, -0.0024,  0.0032],\n",
            "          [ 0.0071,  0.0019,  0.0027,  0.0097, -0.0045]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0032, -0.0044,  0.0071,  0.0080, -0.0092],\n",
            "          [ 0.0085,  0.0048,  0.0044,  0.0041,  0.0083],\n",
            "          [-0.0013, -0.0085, -0.0029, -0.0070,  0.0007],\n",
            "          [-0.0019, -0.0054, -0.0009,  0.0095, -0.0008],\n",
            "          [ 0.0003, -0.0016,  0.0016,  0.0089,  0.0061]]]]), conv_layer.bias.data: tensor([0.0035, 0.0022])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = conv_layer(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fs0iR9kb0Vy",
        "outputId": "7e9f8e06-0cce-49de-8006-5fc9bf30396b"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " num_amostras: 2, self.out_channels: 2, num_linhas_entrada: 28, num_colunas_entrada: 28, num_linhas_saida: 8, num_colunas_saida: 8\n",
            "saida.shape: torch.Size([2, 2, 8, 8])\n",
            "\n",
            "ndx_amostra: 0\n",
            "\n",
            "ndx_in_channels: 0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 0\n",
            " alvo do kernel em x: x[0,0,0:5, 0:5]\n",
            " \n",
            " tensor([[0.3153, 0.6871, 0.0756, 0.1966, 0.3164],\n",
            "        [0.1479, 0.5331, 0.4066, 0.2318, 0.4545],\n",
            "        [0.3834, 0.4451, 0.0126, 0.7341, 0.9389],\n",
            "        [0.3033, 0.6060, 0.9882, 0.8363, 0.9010],\n",
            "        [0.9998, 0.2855, 0.9753, 0.2518, 0.7204]])\n",
            " produto: tensor([[[[-1.2855e-03,  2.2760e-04, -3.7565e-04,  7.4155e-04, -2.6960e-03],\n",
            "          [ 1.0839e-03, -3.8744e-03, -3.2330e-03, -1.4648e-03,  2.0586e-03],\n",
            "          [-1.4166e-03,  1.6655e-03, -1.0656e-04, -4.4542e-03, -3.4473e-03],\n",
            "          [-5.9605e-04, -4.6229e-03,  6.4706e-03, -1.9723e-03,  2.8921e-03],\n",
            "          [ 7.0697e-03,  5.3193e-04,  2.6670e-03,  2.4301e-03, -3.2491e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 9.9857e-04, -3.0570e-03,  5.4053e-04,  1.5705e-03, -2.9172e-03],\n",
            "          [ 1.2622e-03,  2.5454e-03,  1.7720e-03,  9.5429e-04,  3.7786e-03],\n",
            "          [-5.0622e-04, -3.7638e-03, -3.6026e-05, -5.1704e-03,  6.2066e-04],\n",
            "          [-5.6629e-04, -3.2505e-03, -8.9848e-04,  7.9234e-03, -7.1067e-04],\n",
            "          [ 3.1742e-04, -4.4529e-04,  1.5332e-03,  2.2432e-03,  4.4052e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0050]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0091]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0050,  0.0091], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 0, 0] = -0.0049559930339455605\n",
            " somado na saída em [0, 1, 0, 0] = 0.009143250063061714\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 1\n",
            " alvo do kernel em x: x[0,0,0:5, 3:8]\n",
            " \n",
            " tensor([[0.1966, 0.3164, 0.4017, 0.1186, 0.8274],\n",
            "        [0.2318, 0.4545, 0.9737, 0.4606, 0.5159],\n",
            "        [0.7341, 0.9389, 0.8056, 0.1459, 0.0969],\n",
            "        [0.8363, 0.9010, 0.3950, 0.8809, 0.1084],\n",
            "        [0.2518, 0.7204, 0.6959, 0.6397, 0.8954]])\n",
            " produto: tensor([[[[-8.0184e-04,  1.0481e-04, -1.9953e-03,  4.4714e-04, -7.0499e-03],\n",
            "          [ 1.6993e-03, -3.3038e-03, -7.7413e-03, -2.9102e-03,  2.3364e-03],\n",
            "          [-2.7126e-03,  3.5134e-03, -6.8375e-03, -8.8541e-04, -3.5597e-04],\n",
            "          [-1.6436e-03, -6.8734e-03,  2.5865e-03, -2.0775e-03,  3.4790e-04],\n",
            "          [ 1.7803e-03,  1.3421e-03,  1.9029e-03,  6.1744e-03, -4.0383e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 6.2285e-04, -1.4078e-03,  2.8710e-03,  9.4695e-04, -7.6284e-03],\n",
            "          [ 1.9788e-03,  2.1705e-03,  4.2431e-03,  1.8960e-03,  4.2885e-03],\n",
            "          [-9.6935e-04, -7.9400e-03, -2.3117e-03, -1.0278e-03,  6.4089e-05],\n",
            "          [-1.5615e-03, -4.8328e-03, -3.5915e-04,  8.3460e-03, -8.5488e-05],\n",
            "          [ 7.9932e-05, -1.1235e-03,  1.0940e-03,  5.6995e-03,  5.4753e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0270]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0105]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0270,  0.0105], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 0, 1] = -0.026991628110408783\n",
            " somado na saída em [0, 1, 0, 1] = 0.010529066435992718\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 2\n",
            " alvo do kernel em x: x[0,0,0:5, 6:11]\n",
            " \n",
            " tensor([[0.1186, 0.8274, 0.3821, 0.6605, 0.8536],\n",
            "        [0.4606, 0.5159, 0.4220, 0.5786, 0.9455],\n",
            "        [0.1459, 0.0969, 0.7076, 0.5112, 0.7050],\n",
            "        [0.8809, 0.1084, 0.5432, 0.2185, 0.3834],\n",
            "        [0.6397, 0.8954, 0.2979, 0.6314, 0.5028]])\n",
            " produto: tensor([[[[-0.0005,  0.0003, -0.0019,  0.0025, -0.0073],\n",
            "          [ 0.0034, -0.0037, -0.0034, -0.0037,  0.0043],\n",
            "          [-0.0005,  0.0004, -0.0060, -0.0031, -0.0026],\n",
            "          [-0.0017, -0.0008,  0.0036, -0.0005,  0.0012],\n",
            "          [ 0.0045,  0.0017,  0.0008,  0.0061, -0.0023]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0004, -0.0037,  0.0027,  0.0053, -0.0079],\n",
            "          [ 0.0039,  0.0025,  0.0018,  0.0024,  0.0079],\n",
            "          [-0.0002, -0.0008, -0.0020, -0.0036,  0.0005],\n",
            "          [-0.0016, -0.0006, -0.0005,  0.0021, -0.0003],\n",
            "          [ 0.0002, -0.0014,  0.0005,  0.0056,  0.0031]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0093]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0162]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0093,  0.0162], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 0, 2] = -0.009316600859165192\n",
            " somado na saída em [0, 1, 0, 2] = 0.01615156978368759\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 3\n",
            " alvo do kernel em x: x[0,0,0:5, 9:14]\n",
            " \n",
            " tensor([[0.6605, 0.8536, 0.5932, 0.6367, 0.9826],\n",
            "        [0.5786, 0.9455, 0.8057, 0.6775, 0.6087],\n",
            "        [0.5112, 0.7050, 0.0114, 0.4702, 0.8526],\n",
            "        [0.2185, 0.3834, 0.3720, 0.5374, 0.9551],\n",
            "        [0.6314, 0.5028, 0.1239, 0.3786, 0.1661]])\n",
            " produto: tensor([[[[-2.6933e-03,  2.8274e-04, -2.9459e-03,  2.4012e-03, -8.3725e-03],\n",
            "          [ 4.2414e-03, -6.8723e-03, -6.4060e-03, -4.2809e-03,  2.7566e-03],\n",
            "          [-1.8890e-03,  2.6381e-03, -9.6961e-05, -2.8527e-03, -3.1306e-03],\n",
            "          [-4.2934e-04, -2.9248e-03,  2.4355e-03, -1.2674e-03,  3.0657e-03],\n",
            "          [ 4.4650e-03,  9.3676e-04,  3.3889e-04,  3.6544e-03, -7.4907e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 2.0921e-03, -3.7977e-03,  4.2390e-03,  5.0852e-03, -9.0596e-03],\n",
            "          [ 4.9392e-03,  4.5149e-03,  3.5112e-03,  2.7890e-03,  5.0597e-03],\n",
            "          [-6.7502e-04, -5.9619e-03, -3.2782e-05, -3.3114e-03,  5.6364e-04],\n",
            "          [-4.0790e-04, -2.0565e-03, -3.3818e-04,  5.0914e-03, -7.5332e-04],\n",
            "          [ 2.0047e-04, -7.8418e-04,  1.9483e-04,  3.3733e-03,  1.0156e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0177]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0155]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0177,  0.0155], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 0, 3] = -0.01769476756453514\n",
            " somado na saída em [0, 1, 0, 3] = 0.015491338446736336\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 4\n",
            " alvo do kernel em x: x[0,0,0:5, 12:17]\n",
            " \n",
            " tensor([[0.6367, 0.9826, 0.2745, 0.6584, 0.2775],\n",
            "        [0.6775, 0.6087, 0.6179, 0.6932, 0.4354],\n",
            "        [0.4702, 0.8526, 0.7320, 0.5183, 0.5983],\n",
            "        [0.5374, 0.9551, 0.7475, 0.4979, 0.8549],\n",
            "        [0.3786, 0.1661, 0.7211, 0.5449, 0.5490]])\n",
            " produto: tensor([[[[-0.0026,  0.0003, -0.0014,  0.0025, -0.0024],\n",
            "          [ 0.0050, -0.0044, -0.0049, -0.0044,  0.0020],\n",
            "          [-0.0017,  0.0032, -0.0062, -0.0031, -0.0022],\n",
            "          [-0.0011, -0.0073,  0.0049, -0.0012,  0.0027],\n",
            "          [ 0.0027,  0.0003,  0.0020,  0.0053, -0.0025]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0020, -0.0044,  0.0020,  0.0053, -0.0026],\n",
            "          [ 0.0058,  0.0029,  0.0027,  0.0029,  0.0036],\n",
            "          [-0.0006, -0.0072, -0.0021, -0.0036,  0.0004],\n",
            "          [-0.0010, -0.0051, -0.0007,  0.0047, -0.0007],\n",
            "          [ 0.0001, -0.0003,  0.0011,  0.0049,  0.0034]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0145]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0134]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0145,  0.0134], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 0, 4] = -0.014529412612318993\n",
            " somado na saída em [0, 1, 0, 4] = 0.013418990187346935\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 5\n",
            " alvo do kernel em x: x[0,0,0:5, 15:20]\n",
            " \n",
            " tensor([[0.6584, 0.2775, 0.8573, 0.8993, 0.0390],\n",
            "        [0.6932, 0.4354, 0.0353, 0.1908, 0.9268],\n",
            "        [0.5183, 0.5983, 0.4527, 0.2251, 0.3111],\n",
            "        [0.4979, 0.8549, 0.2438, 0.7577, 0.4536],\n",
            "        [0.5449, 0.5490, 0.3483, 0.5024, 0.3445]])\n",
            " produto: tensor([[[[-2.6847e-03,  9.1935e-05, -4.2580e-03,  3.3915e-03, -3.3242e-04],\n",
            "          [ 5.0812e-03, -3.1646e-03, -2.8061e-04, -1.2056e-03,  4.1974e-03],\n",
            "          [-1.9149e-03,  2.2390e-03, -3.8419e-03, -1.3656e-03, -1.1421e-03],\n",
            "          [-9.7844e-04, -6.5219e-03,  1.5962e-03, -1.7869e-03,  1.4561e-03],\n",
            "          [ 3.8536e-03,  1.0228e-03,  9.5247e-04,  4.8495e-03, -1.5536e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.0854e-03, -1.2348e-03,  6.1269e-03,  7.1825e-03, -3.5970e-04],\n",
            "          [ 5.9172e-03,  2.0790e-03,  1.5381e-04,  7.8545e-04,  7.7044e-03],\n",
            "          [-6.8431e-04, -5.0599e-03, -1.2989e-03, -1.5852e-03,  2.0563e-04],\n",
            "          [-9.2958e-04, -4.5857e-03, -2.2164e-04,  7.1783e-03, -3.5781e-04],\n",
            "          [ 1.7302e-04, -8.5620e-04,  5.4758e-04,  4.4765e-03,  2.1065e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0023]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0295]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0023,  0.0295], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 0, 5] = -0.0022996212355792522\n",
            " somado na saída em [0, 1, 0, 5] = 0.029548505321145058\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 6\n",
            " alvo do kernel em x: x[0,0,0:5, 18:23]\n",
            " \n",
            " tensor([[0.8993, 0.0390, 0.9268, 0.7388, 0.7179],\n",
            "        [0.1908, 0.9268, 0.5299, 0.0950, 0.5789],\n",
            "        [0.2251, 0.3111, 0.1955, 0.9153, 0.7751],\n",
            "        [0.7577, 0.4536, 0.4130, 0.5585, 0.1170],\n",
            "        [0.5024, 0.3445, 0.6437, 0.9856, 0.5757]])\n",
            " produto: tensor([[[[-3.6672e-03,  1.2923e-05, -4.6031e-03,  2.7860e-03, -6.1168e-03],\n",
            "          [ 1.3986e-03, -6.7363e-03, -4.2128e-03, -6.0006e-04,  2.6216e-03],\n",
            "          [-8.3166e-04,  1.1640e-03, -1.6594e-03, -5.5534e-03, -2.8461e-03],\n",
            "          [-1.4890e-03, -3.4606e-03,  2.7043e-03, -1.3172e-03,  3.7540e-04],\n",
            "          [ 3.5527e-03,  6.4178e-04,  1.7601e-03,  9.5134e-03, -2.5966e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.8486e-03, -1.7358e-04,  6.6235e-03,  5.9001e-03, -6.6187e-03],\n",
            "          [ 1.6287e-03,  4.4256e-03,  2.3091e-03,  3.9094e-04,  4.8121e-03],\n",
            "          [-2.9720e-04, -2.6305e-03, -5.6101e-04, -6.4463e-03,  5.1242e-04],\n",
            "          [-1.4147e-03, -2.4332e-03, -3.7550e-04,  5.2916e-03, -9.2246e-05],\n",
            "          [ 1.5951e-04, -5.3725e-04,  1.0119e-03,  8.7817e-03,  3.5206e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0192]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0266]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0192,  0.0266], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 0, 6] = -0.019159475341439247\n",
            " somado na saída em [0, 1, 0, 6] = 0.02663620375096798\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 7\n",
            " alvo do kernel em x: x[0,0,0:5, 21:26]\n",
            " \n",
            " tensor([[0.7388, 0.7179, 0.7058, 0.9156, 0.4340],\n",
            "        [0.0950, 0.5789, 0.9131, 0.0275, 0.1634],\n",
            "        [0.9153, 0.7751, 0.6749, 0.1166, 0.8858],\n",
            "        [0.5585, 0.1170, 0.5578, 0.6681, 0.9275],\n",
            "        [0.9856, 0.5757, 0.2785, 0.1946, 0.5382]])\n",
            " produto: tensor([[[[-0.0030,  0.0002, -0.0035,  0.0035, -0.0037],\n",
            "          [ 0.0007, -0.0042, -0.0073, -0.0002,  0.0007],\n",
            "          [-0.0034,  0.0029, -0.0057, -0.0007, -0.0033],\n",
            "          [-0.0011, -0.0009,  0.0037, -0.0016,  0.0030],\n",
            "          [ 0.0070,  0.0011,  0.0008,  0.0019, -0.0024]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0023, -0.0032,  0.0050,  0.0073, -0.0040],\n",
            "          [ 0.0008,  0.0028,  0.0040,  0.0001,  0.0014],\n",
            "          [-0.0012, -0.0066, -0.0019, -0.0008,  0.0006],\n",
            "          [-0.0010, -0.0006, -0.0005,  0.0063, -0.0007],\n",
            "          [ 0.0003, -0.0009,  0.0004,  0.0017,  0.0033]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0156]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0149]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0156,  0.0149], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 0, 7] = -0.015580205246806145\n",
            " somado na saída em [0, 1, 0, 7] = 0.014890311285853386\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 0\n",
            " alvo do kernel em x: x[0,0,3:8, 0:5]\n",
            " \n",
            " tensor([[0.3033, 0.6060, 0.9882, 0.8363, 0.9010],\n",
            "        [0.9998, 0.2855, 0.9753, 0.2518, 0.7204],\n",
            "        [0.1746, 0.3302, 0.5370, 0.8443, 0.6937],\n",
            "        [0.9355, 0.5855, 0.4695, 0.5201, 0.8118],\n",
            "        [0.5091, 0.5101, 0.4270, 0.8210, 0.3605]])\n",
            " produto: tensor([[[[-0.0012,  0.0002, -0.0049,  0.0032, -0.0077],\n",
            "          [ 0.0073, -0.0021, -0.0078, -0.0016,  0.0033],\n",
            "          [-0.0006,  0.0012, -0.0046, -0.0051, -0.0025],\n",
            "          [-0.0018, -0.0045,  0.0031, -0.0012,  0.0026],\n",
            "          [ 0.0036,  0.0010,  0.0012,  0.0079, -0.0016]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0010, -0.0027,  0.0071,  0.0067, -0.0083],\n",
            "          [ 0.0085,  0.0014,  0.0043,  0.0010,  0.0060],\n",
            "          [-0.0002, -0.0028, -0.0015, -0.0059,  0.0005],\n",
            "          [-0.0017, -0.0031, -0.0004,  0.0049, -0.0006],\n",
            "          [ 0.0002, -0.0008,  0.0007,  0.0073,  0.0022]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0128]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0234]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0128,  0.0234], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 1, 0] = -0.012766989879310131\n",
            " somado na saída em [0, 1, 1, 0] = 0.023350633680820465\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 1\n",
            " alvo do kernel em x: x[0,0,3:8, 3:8]\n",
            " \n",
            " tensor([[0.8363, 0.9010, 0.3950, 0.8809, 0.1084],\n",
            "        [0.2518, 0.7204, 0.6959, 0.6397, 0.8954],\n",
            "        [0.8443, 0.6937, 0.8831, 0.1861, 0.5422],\n",
            "        [0.5201, 0.8118, 0.0585, 0.1142, 0.3338],\n",
            "        [0.8210, 0.3605, 0.4516, 0.7056, 0.1853]])\n",
            " produto: tensor([[[[-3.4104e-03,  2.9845e-04, -1.9618e-03,  3.3221e-03, -9.2349e-04],\n",
            "          [ 1.8455e-03, -5.2361e-03, -5.5325e-03, -4.0420e-03,  4.0552e-03],\n",
            "          [-3.1196e-03,  2.5958e-03, -7.4948e-03, -1.1288e-03, -1.9908e-03],\n",
            "          [-1.0221e-03, -6.1927e-03,  3.8284e-04, -2.6933e-04,  1.0713e-03],\n",
            "          [ 5.8059e-03,  6.7158e-04,  1.2349e-03,  6.8108e-03, -8.3564e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 2.6491e-03, -4.0087e-03,  2.8229e-03,  7.0357e-03, -9.9927e-04],\n",
            "          [ 2.1491e-03,  3.4400e-03,  3.0324e-03,  2.6333e-03,  7.4435e-03],\n",
            "          [-1.1148e-03, -5.8664e-03, -2.5339e-03, -1.3103e-03,  3.5843e-04],\n",
            "          [-9.7103e-04, -4.3542e-03, -5.3160e-05,  1.0820e-03, -2.6326e-04],\n",
            "          [ 2.6068e-04, -5.6219e-04,  7.0995e-04,  6.2869e-03,  1.1330e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0151]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0190]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0151,  0.0190], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 1, 1] = -0.01506559643894434\n",
            " somado na saída em [0, 1, 1, 1] = 0.01899968460202217\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 2\n",
            " alvo do kernel em x: x[0,0,3:8, 6:11]\n",
            " \n",
            " tensor([[0.8809, 0.1084, 0.5432, 0.2185, 0.3834],\n",
            "        [0.6397, 0.8954, 0.2979, 0.6314, 0.5028],\n",
            "        [0.1861, 0.5422, 0.0556, 0.7868, 0.6042],\n",
            "        [0.1142, 0.3338, 0.2122, 0.7579, 0.8533],\n",
            "        [0.7056, 0.1853, 0.6339, 0.3894, 0.7398]])\n",
            " produto: tensor([[[[-3.5923e-03,  3.5902e-05, -2.6981e-03,  8.2389e-04, -3.2667e-03],\n",
            "          [ 4.6890e-03, -6.5081e-03, -2.3686e-03, -3.9898e-03,  2.2772e-03],\n",
            "          [-6.8745e-04,  2.0290e-03, -4.7155e-04, -4.7739e-03, -2.2185e-03],\n",
            "          [-2.2444e-04, -2.5462e-03,  1.3897e-03, -1.7873e-03,  2.7390e-03],\n",
            "          [ 4.9896e-03,  3.4519e-04,  1.7333e-03,  3.7591e-03, -3.3367e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.7904e-03, -4.8222e-04,  3.8823e-03,  1.7448e-03, -3.5348e-03],\n",
            "          [ 5.4605e-03,  4.2757e-03,  1.2982e-03,  2.5994e-03,  4.1798e-03],\n",
            "          [-2.4566e-04, -4.5853e-03, -1.5943e-04, -5.5414e-03,  3.9942e-04],\n",
            "          [-2.1323e-04, -1.7903e-03, -1.9297e-04,  7.1803e-03, -6.7304e-04],\n",
            "          [ 2.2403e-04, -2.8897e-04,  9.9650e-04,  3.4700e-03,  4.5240e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0137]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0253]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0137,  0.0253], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 1, 2] = -0.013658730313181877\n",
            " somado na saída em [0, 1, 1, 2] = 0.02531803399324417\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 3\n",
            " alvo do kernel em x: x[0,0,3:8, 9:14]\n",
            " \n",
            " tensor([[0.2185, 0.3834, 0.3720, 0.5374, 0.9551],\n",
            "        [0.6314, 0.5028, 0.1239, 0.3786, 0.1661],\n",
            "        [0.7868, 0.6042, 0.9836, 0.1444, 0.9010],\n",
            "        [0.7579, 0.8533, 0.0149, 0.0757, 0.0131],\n",
            "        [0.3894, 0.7398, 0.2288, 0.5185, 0.5489]])\n",
            " produto: tensor([[[[-8.9088e-04,  1.2700e-04, -1.8473e-03,  2.0266e-03, -8.1377e-03],\n",
            "          [ 4.6285e-03, -3.6546e-03, -9.8529e-04, -2.3923e-03,  7.5220e-04],\n",
            "          [-2.9073e-03,  2.2610e-03, -8.3482e-03, -8.7607e-04, -3.3081e-03],\n",
            "          [-1.4894e-03, -6.5095e-03,  9.7479e-05, -1.7843e-04,  4.2021e-05],\n",
            "          [ 2.7539e-03,  1.3784e-03,  6.2557e-04,  5.0047e-03, -2.4757e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 6.9201e-04, -1.7058e-03,  2.6581e-03,  4.2921e-03, -8.8055e-03],\n",
            "          [ 5.3900e-03,  2.4010e-03,  5.4004e-04,  1.5586e-03,  1.3807e-03],\n",
            "          [-1.0389e-03, -5.1098e-03, -2.8225e-03, -1.0169e-03,  5.9560e-04],\n",
            "          [-1.4150e-03, -4.5769e-03, -1.3536e-05,  7.1681e-04, -1.0326e-05],\n",
            "          [ 1.2365e-04, -1.1539e-03,  3.5964e-04,  4.6197e-03,  3.3566e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0243]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0010]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0243,  0.0010], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 1, 3] = -0.024303292855620384\n",
            " somado na saída em [0, 1, 1, 3] = 0.0010154841002076864\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 4\n",
            " alvo do kernel em x: x[0,0,3:8, 12:17]\n",
            " \n",
            " tensor([[0.5374, 0.9551, 0.7475, 0.4979, 0.8549],\n",
            "        [0.3786, 0.1661, 0.7211, 0.5449, 0.5490],\n",
            "        [0.1444, 0.9010, 0.9221, 0.9043, 0.5713],\n",
            "        [0.0757, 0.0131, 0.6886, 0.9024, 0.1123],\n",
            "        [0.5185, 0.5489, 0.0977, 0.1364, 0.6918]])\n",
            " produto: tensor([[[[-2.1914e-03,  3.1636e-04, -3.7127e-03,  1.8776e-03, -7.2844e-03],\n",
            "          [ 2.7753e-03, -1.2072e-03, -5.7329e-03, -3.4435e-03,  2.4863e-03],\n",
            "          [-5.3352e-04,  3.3715e-03, -7.8262e-03, -5.4864e-03, -2.0979e-03],\n",
            "          [-1.4869e-04, -9.9867e-05,  4.5091e-03, -2.1282e-03,  3.6057e-04],\n",
            "          [ 3.6664e-03,  1.0227e-03,  2.6717e-04,  1.3169e-03, -3.1199e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7023e-03, -4.2493e-03,  5.3423e-03,  3.9764e-03, -7.8822e-03],\n",
            "          [ 3.2318e-03,  7.9310e-04,  3.1422e-03,  2.2434e-03,  4.5637e-03],\n",
            "          [-1.9066e-04, -7.6194e-03, -2.6460e-03, -6.3685e-03,  3.7770e-04],\n",
            "          [-1.4126e-04, -7.0219e-05, -6.2611e-04,  8.5496e-03, -8.8601e-05],\n",
            "          [ 1.6462e-04, -8.5609e-04,  1.5359e-04,  1.2156e-03,  4.2300e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0230]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0089]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0230,  0.0089], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 1, 4] = -0.023042935878038406\n",
            " somado na saída em [0, 1, 1, 4] = 0.008948106318712234\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 5\n",
            " alvo do kernel em x: x[0,0,3:8, 15:20]\n",
            " \n",
            " tensor([[0.4979, 0.8549, 0.2438, 0.7577, 0.4536],\n",
            "        [0.5449, 0.5490, 0.3483, 0.5024, 0.3445],\n",
            "        [0.9043, 0.5713, 0.9546, 0.8339, 0.8730],\n",
            "        [0.9024, 0.1123, 0.2685, 0.6591, 0.1735],\n",
            "        [0.1364, 0.6918, 0.3545, 0.7969, 0.0061]])\n",
            " produto: tensor([[[[-2.0302e-03,  2.8319e-04, -1.2107e-03,  2.8573e-03, -3.8652e-03],\n",
            "          [ 3.9947e-03, -3.9902e-03, -2.7692e-03, -3.1746e-03,  1.5601e-03],\n",
            "          [-3.3412e-03,  2.1381e-03, -8.1023e-03, -5.0596e-03, -3.2056e-03],\n",
            "          [-1.7734e-03, -8.5692e-04,  1.7583e-03, -1.5544e-03,  5.5694e-04],\n",
            "          [ 9.6475e-04,  1.2888e-03,  9.6931e-04,  7.6926e-03, -2.7370e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5770e-03, -3.8037e-03,  1.7421e-03,  6.0513e-03, -4.1824e-03],\n",
            "          [ 4.6519e-03,  2.6215e-03,  1.5178e-03,  2.0683e-03,  2.8636e-03],\n",
            "          [-1.1940e-03, -4.8319e-03, -2.7393e-03, -5.8731e-03,  5.7714e-04],\n",
            "          [-1.6849e-03, -6.0252e-04, -2.4414e-04,  6.2444e-03, -1.3685e-04],\n",
            "          [ 4.3316e-05, -1.0789e-03,  5.5725e-04,  7.1009e-03,  3.7110e-05]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0169]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0113]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0169,  0.0113], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 1, 5] = -0.016896983608603477\n",
            " somado na saída em [0, 1, 1, 5] = 0.011282181367278099\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 6\n",
            " alvo do kernel em x: x[0,0,3:8, 18:23]\n",
            " \n",
            " tensor([[0.7577, 0.4536, 0.4130, 0.5585, 0.1170],\n",
            "        [0.5024, 0.3445, 0.6437, 0.9856, 0.5757],\n",
            "        [0.8339, 0.8730, 0.4675, 0.1163, 0.4938],\n",
            "        [0.6591, 0.1735, 0.9247, 0.6166, 0.3608],\n",
            "        [0.7969, 0.0061, 0.2528, 0.0882, 0.6997]])\n",
            " produto: tensor([[[[-3.0897e-03,  1.5026e-04, -2.0512e-03,  2.1063e-03, -9.9649e-04],\n",
            "          [ 3.6828e-03, -2.5038e-03, -5.1174e-03, -6.2278e-03,  2.6075e-03],\n",
            "          [-3.0813e-03,  3.2670e-03, -3.9680e-03, -7.0563e-04, -1.8130e-03],\n",
            "          [-1.2953e-03, -1.3236e-03,  6.0551e-03, -1.4541e-03,  1.1581e-03],\n",
            "          [ 5.6356e-03,  1.1306e-05,  6.9138e-04,  8.5106e-04, -3.1559e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.4000e-03, -2.0183e-03,  2.9515e-03,  4.4608e-03, -1.0783e-03],\n",
            "          [ 4.2888e-03,  1.6449e-03,  2.8049e-03,  4.0574e-03,  4.7861e-03],\n",
            "          [-1.1011e-03, -7.3833e-03, -1.3415e-03, -8.1908e-04,  3.2642e-04],\n",
            "          [-1.2306e-03, -9.3067e-04, -8.4079e-04,  5.8415e-03, -2.8459e-04],\n",
            "          [ 2.5303e-04, -9.4648e-06,  3.9748e-04,  7.8560e-04,  4.2788e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0106]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0222]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0106,  0.0222], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 1, 6] = -0.010566611774265766\n",
            " somado na saída em [0, 1, 1, 6] = 0.02223949506878853\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 7\n",
            " alvo do kernel em x: x[0,0,3:8, 21:26]\n",
            " \n",
            " tensor([[0.5585, 0.1170, 0.5578, 0.6681, 0.9275],\n",
            "        [0.9856, 0.5757, 0.2785, 0.1946, 0.5382],\n",
            "        [0.1163, 0.4938, 0.5938, 0.1594, 0.2132],\n",
            "        [0.6166, 0.3608, 0.5325, 0.6559, 0.3232],\n",
            "        [0.0882, 0.6997, 0.4855, 0.4067, 0.4168]])\n",
            " produto: tensor([[[[-2.2776e-03,  3.8740e-05, -2.7703e-03,  2.5196e-03, -7.9025e-03],\n",
            "          [ 7.2248e-03, -4.1847e-03, -2.2145e-03, -1.2296e-03,  2.4376e-03],\n",
            "          [-4.2972e-04,  1.8478e-03, -5.0395e-03, -9.6721e-04, -7.8275e-04],\n",
            "          [-1.2117e-03, -2.7525e-03,  3.4866e-03, -1.5468e-03,  1.0374e-03],\n",
            "          [ 6.2348e-04,  1.3036e-03,  1.3276e-03,  3.9261e-03, -1.8799e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7692e-03, -5.2034e-04,  3.9862e-03,  5.3360e-03, -8.5510e-03],\n",
            "          [ 8.4134e-03,  2.7492e-03,  1.2138e-03,  8.0106e-04,  4.4742e-03],\n",
            "          [-1.5356e-04, -4.1759e-03, -1.7038e-03, -1.1227e-03,  1.4093e-04],\n",
            "          [-1.1512e-03, -1.9353e-03, -4.8413e-04,  6.2139e-03, -2.5492e-04],\n",
            "          [ 2.7994e-05, -1.0913e-03,  7.6325e-04,  3.6241e-03,  2.5488e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0094]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0209]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0094,  0.0209], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 1, 7] = -0.009415848180651665\n",
            " somado na saída em [0, 1, 1, 7] = 0.020917747169733047\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 0\n",
            " alvo do kernel em x: x[0,0,6:11, 0:5]\n",
            " \n",
            " tensor([[0.9355, 0.5855, 0.4695, 0.5201, 0.8118],\n",
            "        [0.5091, 0.5101, 0.4270, 0.8210, 0.3605],\n",
            "        [0.5125, 0.1549, 0.6881, 0.4900, 0.0164],\n",
            "        [0.2337, 0.9794, 0.7788, 0.7945, 0.6613],\n",
            "        [0.9027, 0.3112, 0.9167, 0.4139, 0.4362]])\n",
            " produto: tensor([[[[-3.8149e-03,  1.9394e-04, -2.3316e-03,  1.9613e-03, -6.9168e-03],\n",
            "          [ 3.7320e-03, -3.7075e-03, -3.3951e-03, -5.1880e-03,  1.6325e-03],\n",
            "          [-1.8935e-03,  5.7982e-04, -5.8405e-03, -2.9726e-03, -6.0313e-05],\n",
            "          [-4.5921e-04, -7.4718e-03,  5.0997e-03, -1.8736e-03,  2.1227e-03],\n",
            "          [ 6.3831e-03,  5.7978e-04,  2.5068e-03,  3.9951e-03, -1.9675e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.9633e-03, -2.6050e-03,  3.3550e-03,  4.1536e-03, -7.4843e-03],\n",
            "          [ 4.3460e-03,  2.4357e-03,  1.8609e-03,  3.3800e-03,  2.9966e-03],\n",
            "          [-6.7665e-04, -1.3104e-03, -1.9746e-03, -3.4506e-03,  1.0859e-05],\n",
            "          [-4.3628e-04, -5.2536e-03, -7.0813e-04,  7.5267e-03, -5.2160e-04],\n",
            "          [ 2.8659e-04, -4.8534e-04,  1.4411e-03,  3.6878e-03,  2.6675e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0191]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0162]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0191,  0.0162], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 2, 0] = -0.019106131047010422\n",
            " somado na saída em [0, 1, 2, 0] = 0.016205258667469025\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 1\n",
            " alvo do kernel em x: x[0,0,6:11, 3:8]\n",
            " \n",
            " tensor([[0.5201, 0.8118, 0.0585, 0.1142, 0.3338],\n",
            "        [0.8210, 0.3605, 0.4516, 0.7056, 0.1853],\n",
            "        [0.4900, 0.0164, 0.7690, 0.7674, 0.4058],\n",
            "        [0.7945, 0.6613, 0.4502, 0.7815, 0.5085],\n",
            "        [0.4139, 0.4362, 0.6996, 0.4265, 0.4958]])\n",
            " produto: tensor([[[[-2.1208e-03,  2.6890e-04, -2.9039e-04,  4.3068e-04, -2.8439e-03],\n",
            "          [ 6.0186e-03, -2.6200e-03, -3.5904e-03, -4.4586e-03,  8.3913e-04],\n",
            "          [-1.8103e-03,  6.1469e-05, -6.5264e-03, -4.6563e-03, -1.4900e-03],\n",
            "          [-1.5613e-03, -5.0448e-03,  2.9480e-03, -1.8431e-03,  1.6323e-03],\n",
            "          [ 2.9268e-03,  8.1273e-04,  1.9129e-03,  4.1171e-03, -2.2361e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.6474e-03, -3.6117e-03,  4.1784e-04,  9.1211e-04, -3.0772e-03],\n",
            "          [ 7.0087e-03,  1.7213e-03,  1.9679e-03,  2.9048e-03,  1.5402e-03],\n",
            "          [-6.4693e-04, -1.3892e-04, -2.2065e-03, -5.4049e-03,  2.6826e-04],\n",
            "          [-1.4833e-03, -3.5471e-03, -4.0935e-04,  7.4043e-03, -4.0109e-04],\n",
            "          [ 1.3141e-04, -6.8035e-04,  1.0998e-03,  3.8005e-03,  3.0317e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0191]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0122]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0191,  0.0122], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 2, 1] = -0.019123602658510208\n",
            " somado na saída em [0, 1, 2, 1] = 0.01224871538579464\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 2\n",
            " alvo do kernel em x: x[0,0,6:11, 6:11]\n",
            " \n",
            " tensor([[0.1142, 0.3338, 0.2122, 0.7579, 0.8533],\n",
            "        [0.7056, 0.1853, 0.6339, 0.3894, 0.7398],\n",
            "        [0.7674, 0.4058, 0.1548, 0.5201, 0.8773],\n",
            "        [0.7815, 0.5085, 0.3176, 0.7582, 0.6569],\n",
            "        [0.4265, 0.4958, 0.8463, 0.6671, 0.4801]])\n",
            " produto: tensor([[[[-0.0005,  0.0001, -0.0011,  0.0029, -0.0073],\n",
            "          [ 0.0052, -0.0013, -0.0050, -0.0025,  0.0034],\n",
            "          [-0.0028,  0.0015, -0.0013, -0.0032, -0.0032],\n",
            "          [-0.0015, -0.0039,  0.0021, -0.0018,  0.0021],\n",
            "          [ 0.0030,  0.0009,  0.0023,  0.0064, -0.0022]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0004, -0.0015,  0.0015,  0.0061, -0.0079],\n",
            "          [ 0.0060,  0.0009,  0.0028,  0.0016,  0.0062],\n",
            "          [-0.0010, -0.0034, -0.0004, -0.0037,  0.0006],\n",
            "          [-0.0015, -0.0027, -0.0003,  0.0072, -0.0005],\n",
            "          [ 0.0001, -0.0008,  0.0013,  0.0059,  0.0029]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0076]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0198]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0076,  0.0198], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 2, 2] = -0.007639790419489145\n",
            " somado na saída em [0, 1, 2, 2] = 0.019792456179857254\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 3\n",
            " alvo do kernel em x: x[0,0,6:11, 9:14]\n",
            " \n",
            " tensor([[0.7579, 0.8533, 0.0149, 0.0757, 0.0131],\n",
            "        [0.3894, 0.7398, 0.2288, 0.5185, 0.5489],\n",
            "        [0.5201, 0.8773, 0.9577, 0.1226, 0.2742],\n",
            "        [0.7582, 0.6569, 0.3704, 0.3630, 0.0578],\n",
            "        [0.6671, 0.4801, 0.6904, 0.9355, 0.6260]])\n",
            " produto: tensor([[[[-3.0905e-03,  2.8265e-04, -7.3938e-05,  2.8532e-04, -1.1154e-04],\n",
            "          [ 2.8548e-03, -5.3774e-03, -1.8188e-03, -3.2762e-03,  2.4860e-03],\n",
            "          [-1.9216e-03,  3.2829e-03, -8.1280e-03, -7.4384e-04, -1.0067e-03],\n",
            "          [-1.4899e-03, -5.0113e-03,  2.4256e-03, -8.5600e-04,  1.8563e-04],\n",
            "          [ 4.7173e-03,  8.9445e-04,  1.8879e-03,  9.0297e-03, -2.8234e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.4006e-03, -3.7964e-03,  1.0639e-04,  6.0426e-04, -1.2070e-04],\n",
            "          [ 3.3245e-03,  3.5328e-03,  9.9689e-04,  2.1344e-03,  4.5631e-03],\n",
            "          [-6.8670e-04, -7.4192e-03, -2.7480e-03, -8.6344e-04,  1.8124e-04],\n",
            "          [-1.4155e-03, -3.5235e-03, -3.3681e-04,  3.4388e-03, -4.5614e-05],\n",
            "          [ 2.1180e-04, -7.4876e-04,  1.0854e-03,  8.3352e-03,  3.8281e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0074]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0130]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0074,  0.0130], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 2, 3] = -0.0073967888019979\n",
            " somado na saída em [0, 1, 2, 3] = 0.01303874608129263\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 4\n",
            " alvo do kernel em x: x[0,0,6:11, 12:17]\n",
            " \n",
            " tensor([[0.0757, 0.0131, 0.6886, 0.9024, 0.1123],\n",
            "        [0.5185, 0.5489, 0.0977, 0.1364, 0.6918],\n",
            "        [0.1226, 0.2742, 0.8893, 0.7444, 0.8095],\n",
            "        [0.3630, 0.0578, 0.3629, 0.2974, 0.2275],\n",
            "        [0.9355, 0.6260, 0.3534, 0.6638, 0.4563]])\n",
            " produto: tensor([[[[-3.0852e-04,  4.3364e-06, -3.4201e-03,  3.4032e-03, -9.5711e-04],\n",
            "          [ 3.8007e-03, -3.9897e-03, -7.7677e-04, -8.6208e-04,  3.1329e-03],\n",
            "          [-4.5300e-04,  1.0260e-03, -7.5479e-03, -4.5164e-03, -2.9723e-03],\n",
            "          [-7.1331e-04, -4.4117e-04,  2.3765e-03, -7.0146e-04,  7.3017e-04],\n",
            "          [ 6.6151e-03,  1.1663e-03,  9.6630e-04,  6.4077e-03, -2.0578e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.3965e-04, -5.8244e-05,  4.9213e-03,  7.2073e-03, -1.0357e-03],\n",
            "          [ 4.4260e-03,  2.6211e-03,  4.2575e-04,  5.6164e-04,  5.7506e-03],\n",
            "          [-1.6188e-04, -2.3186e-03, -2.5519e-03, -5.2425e-03,  5.3514e-04],\n",
            "          [-6.7770e-04, -3.1019e-04, -3.2999e-04,  2.8180e-03, -1.7942e-04],\n",
            "          [ 2.9701e-04, -9.7634e-04,  5.5553e-04,  5.9149e-03,  2.7900e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-8.8358e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 2.5221e-02]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-8.8358e-05,  2.5221e-02], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 2, 4] = -8.83578322827816e-05\n",
            " somado na saída em [0, 1, 2, 4] = 0.02522134594619274\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 5\n",
            " alvo do kernel em x: x[0,0,6:11, 15:20]\n",
            " \n",
            " tensor([[0.9024, 0.1123, 0.2685, 0.6591, 0.1735],\n",
            "        [0.1364, 0.6918, 0.3545, 0.7969, 0.0061],\n",
            "        [0.7444, 0.8095, 0.2511, 0.9308, 0.0890],\n",
            "        [0.2974, 0.2275, 0.0484, 0.8916, 0.0532],\n",
            "        [0.6638, 0.4563, 0.1091, 0.3069, 0.7274]])\n",
            " produto: tensor([[[[-3.6799e-03,  3.7209e-05, -1.3336e-03,  2.4856e-03, -1.4784e-03],\n",
            "          [ 1.0001e-03, -5.0280e-03, -2.8182e-03, -5.0358e-03,  2.7485e-05],\n",
            "          [-2.7505e-03,  3.0293e-03, -2.1314e-03, -5.6472e-03, -3.2667e-04],\n",
            "          [-5.8453e-04, -1.7353e-03,  3.1686e-04, -2.1028e-03,  1.7062e-04],\n",
            "          [ 4.6943e-03,  8.5003e-04,  2.9830e-04,  2.9627e-03, -3.2807e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.8584e-03, -4.9977e-04,  1.9190e-03,  5.2640e-03, -1.5997e-03],\n",
            "          [ 1.1646e-03,  3.3032e-03,  1.5447e-03,  3.2808e-03,  5.0449e-05],\n",
            "          [-9.8289e-04, -6.8460e-03, -7.2062e-04, -6.5552e-03,  5.8813e-05],\n",
            "          [-5.5535e-04, -1.2201e-03, -4.3998e-05,  8.4474e-03, -4.1926e-05],\n",
            "          [ 2.1077e-04, -7.1158e-04,  1.7149e-04,  2.7348e-03,  4.4480e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0221]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0157]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0221,  0.0157], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 2, 5] = -0.022060461342334747\n",
            " somado na saída em [0, 1, 2, 5] = 0.015679532662034035\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 6\n",
            " alvo do kernel em x: x[0,0,6:11, 18:23]\n",
            " \n",
            " tensor([[0.6591, 0.1735, 0.9247, 0.6166, 0.3608],\n",
            "        [0.7969, 0.0061, 0.2528, 0.0882, 0.6997],\n",
            "        [0.9308, 0.0890, 0.4759, 0.5104, 0.5840],\n",
            "        [0.8916, 0.0532, 0.9964, 0.2377, 0.4616],\n",
            "        [0.3069, 0.7274, 0.5164, 0.6845, 0.2073]])\n",
            " produto: tensor([[[[-2.6877e-03,  5.7474e-05, -4.5928e-03,  2.3252e-03, -3.0743e-03],\n",
            "          [ 5.8420e-03, -4.4110e-05, -2.0101e-03, -5.5713e-04,  3.1691e-03],\n",
            "          [-3.4391e-03,  3.3293e-04, -4.0392e-03, -3.0966e-03, -2.1442e-03],\n",
            "          [-1.7522e-03, -4.0549e-04,  6.5241e-03, -5.6066e-04,  1.4816e-03],\n",
            "          [ 2.1705e-03,  1.3552e-03,  1.4121e-03,  6.6069e-03, -9.3516e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 2.0877e-03, -7.7196e-04,  6.6087e-03,  4.9244e-03, -3.3266e-03],\n",
            "          [ 6.8031e-03,  2.8979e-05,  1.1018e-03,  3.6297e-04,  5.8169e-03],\n",
            "          [-1.2290e-03, -7.5239e-04, -1.3656e-03, -3.5945e-03,  3.8605e-04],\n",
            "          [-1.6648e-03, -2.8511e-04, -9.0590e-04,  2.2523e-03, -3.6406e-04],\n",
            "          [ 9.7452e-05, -1.1345e-03,  8.1181e-04,  6.0987e-03,  1.2679e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[0.0019]]],\n",
            "\n",
            "\n",
            "        [[[0.0233]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([0.0019, 0.0233], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 2, 6] = 0.0019380472367629409\n",
            " somado na saída em [0, 1, 2, 6] = 0.02325449138879776\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 7\n",
            " alvo do kernel em x: x[0,0,6:11, 21:26]\n",
            " \n",
            " tensor([[0.6166, 0.3608, 0.5325, 0.6559, 0.3232],\n",
            "        [0.0882, 0.6997, 0.4855, 0.4067, 0.4168],\n",
            "        [0.5104, 0.5840, 0.1227, 0.9587, 0.9914],\n",
            "        [0.2377, 0.4616, 0.9079, 0.6650, 0.3573],\n",
            "        [0.6845, 0.2073, 0.9727, 0.2913, 0.6066]])\n",
            " produto: tensor([[[[-0.0025,  0.0001, -0.0026,  0.0025, -0.0028],\n",
            "          [ 0.0006, -0.0051, -0.0039, -0.0026,  0.0019],\n",
            "          [-0.0019,  0.0022, -0.0010, -0.0058, -0.0036],\n",
            "          [-0.0005, -0.0035,  0.0059, -0.0016,  0.0011],\n",
            "          [ 0.0048,  0.0004,  0.0027,  0.0028, -0.0027]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0020, -0.0016,  0.0038,  0.0052, -0.0030],\n",
            "          [ 0.0008,  0.0033,  0.0021,  0.0017,  0.0035],\n",
            "          [-0.0007, -0.0049, -0.0004, -0.0068,  0.0007],\n",
            "          [-0.0004, -0.0025, -0.0008,  0.0063, -0.0003],\n",
            "          [ 0.0002, -0.0003,  0.0015,  0.0026,  0.0037]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0150]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0157]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0150,  0.0157], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 2, 7] = -0.015003260225057602\n",
            " somado na saída em [0, 1, 2, 7] = 0.015700485557317734\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 0\n",
            " alvo do kernel em x: x[0,0,9:14, 0:5]\n",
            " \n",
            " tensor([[0.2337, 0.9794, 0.7788, 0.7945, 0.6613],\n",
            "        [0.9027, 0.3112, 0.9167, 0.4139, 0.4362],\n",
            "        [0.7239, 0.3604, 0.1829, 0.2956, 0.8646],\n",
            "        [0.3051, 0.8070, 0.9271, 0.6647, 0.9296],\n",
            "        [0.2077, 0.4474, 0.5746, 0.6429, 0.0369]])\n",
            " produto: tensor([[[[-9.5285e-04,  3.2444e-04, -3.8681e-03,  2.9960e-03, -5.6347e-03],\n",
            "          [ 6.6168e-03, -2.2619e-03, -7.2882e-03, -2.6153e-03,  1.9757e-03],\n",
            "          [-2.6749e-03,  1.3488e-03, -1.5522e-03, -1.7936e-03, -3.1746e-03],\n",
            "          [-5.9949e-04, -6.1565e-03,  6.0709e-03, -1.5676e-03,  2.9839e-03],\n",
            "          [ 1.4690e-03,  8.3348e-04,  1.5713e-03,  6.2056e-03, -1.6650e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 7.4015e-04, -4.3577e-03,  5.5659e-03,  6.3449e-03, -6.0970e-03],\n",
            "          [ 7.7055e-03,  1.4860e-03,  3.9947e-03,  1.7039e-03,  3.6264e-03],\n",
            "          [-9.5588e-04, -3.0481e-03, -5.2478e-04, -2.0820e-03,  5.7156e-04],\n",
            "          [-5.6955e-04, -4.3288e-03, -8.4297e-04,  6.2977e-03, -7.3322e-04],\n",
            "          [ 6.5957e-05, -6.9772e-04,  9.0336e-04,  5.7283e-03,  2.2575e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0079]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0207]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0079,  0.0207], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 3, 0] = -0.007910709828138351\n",
            " somado na saída em [0, 1, 3, 0] = 0.020722292363643646\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 1\n",
            " alvo do kernel em x: x[0,0,9:14, 3:8]\n",
            " \n",
            " tensor([[0.7945, 0.6613, 0.4502, 0.7815, 0.5085],\n",
            "        [0.4139, 0.4362, 0.6996, 0.4265, 0.4958],\n",
            "        [0.2956, 0.8646, 0.8010, 0.8044, 0.0733],\n",
            "        [0.6647, 0.9296, 0.3848, 0.9357, 0.2616],\n",
            "        [0.6429, 0.0369, 0.5224, 0.7605, 0.7823]])\n",
            " produto: tensor([[[[-3.2396e-03,  2.1905e-04, -2.2361e-03,  2.9473e-03, -4.3328e-03],\n",
            "          [ 3.0340e-03, -3.1707e-03, -5.5618e-03, -2.6952e-03,  2.2454e-03],\n",
            "          [-1.0923e-03,  3.2354e-03, -6.7982e-03, -4.8802e-03, -2.6903e-04],\n",
            "          [-1.3063e-03, -7.0915e-03,  2.5199e-03, -2.2067e-03,  8.3966e-04],\n",
            "          [ 4.5462e-03,  6.8780e-05,  1.4284e-03,  7.3409e-03, -3.5281e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.5164e-03, -2.9422e-03,  3.2175e-03,  6.2417e-03, -4.6884e-03],\n",
            "          [ 3.5332e-03,  2.0831e-03,  3.0484e-03,  1.7559e-03,  4.1215e-03],\n",
            "          [-3.9035e-04, -7.3119e-03, -2.2984e-03, -5.6648e-03,  4.8436e-05],\n",
            "          [-1.2411e-03, -4.9862e-03, -3.4990e-04,  8.8649e-03, -2.0633e-04],\n",
            "          [ 2.0412e-04, -5.7577e-05,  8.2120e-04,  6.7762e-03,  4.7835e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0200]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0179]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0200,  0.0179], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 3, 1] = -0.019983487203717232\n",
            " somado na saída em [0, 1, 3, 1] = 0.017878904938697815\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 2\n",
            " alvo do kernel em x: x[0,0,9:14, 6:11]\n",
            " \n",
            " tensor([[0.7815, 0.5085, 0.3176, 0.7582, 0.6569],\n",
            "        [0.4265, 0.4958, 0.8463, 0.6671, 0.4801],\n",
            "        [0.8044, 0.0733, 0.7355, 0.6248, 0.1638],\n",
            "        [0.9357, 0.2616, 0.4344, 0.8323, 0.2410],\n",
            "        [0.7605, 0.7823, 0.7459, 0.5791, 0.0204]])\n",
            " produto: tensor([[[[-3.1869e-03,  1.6844e-04, -1.5776e-03,  2.8591e-03, -5.5972e-03],\n",
            "          [ 3.1267e-03, -3.6036e-03, -6.7284e-03, -4.2153e-03,  2.1743e-03],\n",
            "          [-2.9720e-03,  2.7418e-04, -6.2421e-03, -3.7910e-03, -6.0143e-04],\n",
            "          [-1.8388e-03, -1.9956e-03,  2.8443e-03, -1.9628e-03,  7.7342e-04],\n",
            "          [ 5.3779e-03,  1.4574e-03,  2.0398e-03,  5.5895e-03, -9.1899e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 2.4755e-03, -2.2625e-03,  2.2700e-03,  6.0550e-03, -6.0565e-03],\n",
            "          [ 3.6411e-03,  2.3675e-03,  3.6879e-03,  2.7463e-03,  3.9910e-03],\n",
            "          [-1.0621e-03, -6.1964e-04, -2.1104e-03, -4.4005e-03,  1.0828e-04],\n",
            "          [-1.7470e-03, -1.4031e-03, -3.9495e-04,  7.8851e-03, -1.9005e-04],\n",
            "          [ 2.4146e-04, -1.2200e-03,  1.1727e-03,  5.1595e-03,  1.2460e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0177]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0205]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0177,  0.0205], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 3, 2] = -0.017719648778438568\n",
            " somado na saída em [0, 1, 3, 2] = 0.020459305495023727\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 3\n",
            " alvo do kernel em x: x[0,0,9:14, 9:14]\n",
            " \n",
            " tensor([[0.7582, 0.6569, 0.3704, 0.3630, 0.0578],\n",
            "        [0.6671, 0.4801, 0.6904, 0.9355, 0.6260],\n",
            "        [0.6248, 0.1638, 0.5158, 0.6000, 0.2299],\n",
            "        [0.8323, 0.2410, 0.8815, 0.6226, 0.4902],\n",
            "        [0.5791, 0.0204, 0.8290, 0.1063, 0.2062]])\n",
            " produto: tensor([[[[-3.0916e-03,  2.1760e-04, -1.8398e-03,  1.3688e-03, -4.9275e-04],\n",
            "          [ 4.8901e-03, -3.4895e-03, -5.4891e-03, -5.9111e-03,  2.8352e-03],\n",
            "          [-2.3087e-03,  6.1295e-04, -4.3778e-03, -3.6403e-03, -8.4408e-04],\n",
            "          [-1.6356e-03, -1.8381e-03,  5.7722e-03, -1.4682e-03,  1.5735e-03],\n",
            "          [ 4.0948e-03,  3.7962e-05,  2.2669e-03,  1.0260e-03, -9.2977e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 2.4015e-03, -2.9227e-03,  2.6474e-03,  2.8989e-03, -5.3318e-04],\n",
            "          [ 5.6947e-03,  2.2925e-03,  3.0086e-03,  3.8511e-03,  5.2041e-03],\n",
            "          [-8.2502e-04, -1.3852e-03, -1.4801e-03, -4.2256e-03,  1.5197e-04],\n",
            "          [-1.5539e-03, -1.2924e-03, -8.0150e-04,  5.8981e-03, -3.8665e-04],\n",
            "          [ 1.8385e-04, -3.1779e-05,  1.3032e-03,  9.4706e-04,  1.2606e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0127]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0223]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0127,  0.0223], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 3, 3] = -0.0126604363322258\n",
            " somado na saída em [0, 1, 3, 3] = 0.022305481135845184\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 4\n",
            " alvo do kernel em x: x[0,0,9:14, 12:17]\n",
            " \n",
            " tensor([[0.3630, 0.0578, 0.3629, 0.2974, 0.2275],\n",
            "        [0.9355, 0.6260, 0.3534, 0.6638, 0.4563],\n",
            "        [0.6000, 0.2299, 0.2890, 0.9078, 0.4596],\n",
            "        [0.6226, 0.4902, 0.9279, 0.8751, 0.2943],\n",
            "        [0.1063, 0.2062, 0.5058, 0.6522, 0.7905]])\n",
            " produto: tensor([[[[-1.4801e-03,  1.9156e-05, -1.8026e-03,  1.1217e-03, -1.9382e-03],\n",
            "          [ 6.8574e-03, -4.5502e-03, -2.8095e-03, -4.1947e-03,  2.0664e-03],\n",
            "          [-2.2169e-03,  8.6025e-04, -2.4528e-03, -5.5081e-03, -1.6876e-03],\n",
            "          [-1.2234e-03, -3.7396e-03,  6.0758e-03, -2.0637e-03,  9.4482e-04],\n",
            "          [ 7.5162e-04,  3.8407e-04,  1.3832e-03,  6.2958e-03, -3.5652e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1497e-03, -2.5730e-04,  2.5938e-03,  2.3755e-03, -2.0973e-03],\n",
            "          [ 7.9856e-03,  2.9893e-03,  1.5399e-03,  2.7328e-03,  3.7928e-03],\n",
            "          [-7.9222e-04, -1.9441e-03, -8.2927e-04, -6.3937e-03,  3.0383e-04],\n",
            "          [-1.1624e-03, -2.6294e-03, -8.4367e-04,  8.2903e-03, -2.3217e-04],\n",
            "          [ 3.3747e-05, -3.2152e-04,  7.9523e-04,  5.8116e-03,  4.8338e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0125]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0277]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0125,  0.0277], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 3, 4] = -0.012472150847315788\n",
            " somado na saída em [0, 1, 3, 4] = 0.027725044637918472\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 5\n",
            " alvo do kernel em x: x[0,0,9:14, 15:20]\n",
            " \n",
            " tensor([[0.2974, 0.2275, 0.0484, 0.8916, 0.0532],\n",
            "        [0.6638, 0.4563, 0.1091, 0.3069, 0.7274],\n",
            "        [0.9078, 0.4596, 0.4947, 0.1836, 0.2010],\n",
            "        [0.8751, 0.2943, 0.5485, 0.5583, 0.9096],\n",
            "        [0.6522, 0.7905, 0.4298, 0.2427, 0.4570]])\n",
            " produto: tensor([[[[-1.2129e-03,  7.5350e-05, -2.4034e-04,  3.3625e-03, -4.5290e-04],\n",
            "          [ 4.8662e-03, -3.3162e-03, -8.6730e-04, -1.9395e-03,  3.2944e-03],\n",
            "          [-3.3544e-03,  1.7199e-03, -4.1988e-03, -1.1137e-03, -7.3809e-04],\n",
            "          [-1.7197e-03, -2.2455e-03,  3.5915e-03, -1.3166e-03,  2.9196e-03],\n",
            "          [ 4.6123e-03,  1.4727e-03,  1.1752e-03,  2.3424e-03, -2.0609e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 9.4215e-04, -1.0121e-03,  3.4582e-04,  7.1211e-03, -4.9007e-04],\n",
            "          [ 5.6668e-03,  2.1787e-03,  4.7537e-04,  1.2636e-03,  6.0469e-03],\n",
            "          [-1.1987e-03, -3.8869e-03, -1.4196e-03, -1.2927e-03,  1.3289e-04],\n",
            "          [-1.6338e-03, -1.5788e-03, -4.9870e-04,  5.2891e-03, -7.1742e-04],\n",
            "          [ 2.0709e-04, -1.2329e-03,  6.7565e-04,  2.1622e-03,  2.7942e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[0.0047]]],\n",
            "\n",
            "\n",
            "        [[[0.0203]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([0.0047, 0.0203], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 3, 5] = 0.004655292257666588\n",
            " somado na saída em [0, 1, 3, 5] = 0.02034001052379608\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 6\n",
            " alvo do kernel em x: x[0,0,9:14, 18:23]\n",
            " \n",
            " tensor([[0.8916, 0.0532, 0.9964, 0.2377, 0.4616],\n",
            "        [0.3069, 0.7274, 0.5164, 0.6845, 0.2073],\n",
            "        [0.1836, 0.2010, 0.9603, 0.6861, 0.4209],\n",
            "        [0.5583, 0.9096, 0.7810, 0.9049, 0.8048],\n",
            "        [0.2427, 0.4570, 0.6638, 0.2187, 0.0657]])\n",
            " produto: tensor([[[[-3.6359e-03,  1.7607e-05, -4.9485e-03,  8.9654e-04, -3.9328e-03],\n",
            "          [ 2.2500e-03, -5.2871e-03, -4.1056e-03, -4.3251e-03,  9.3906e-04],\n",
            "          [-6.7821e-04,  7.5224e-04, -8.1507e-03, -4.1626e-03, -1.5453e-03],\n",
            "          [-1.0971e-03, -6.9387e-03,  5.1136e-03, -2.1339e-03,  2.5834e-03],\n",
            "          [ 1.7160e-03,  8.5133e-04,  1.8153e-03,  2.1112e-03, -2.9644e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 2.8243e-03, -2.3649e-04,  7.1205e-03,  1.8987e-03, -4.2555e-03],\n",
            "          [ 2.6201e-03,  3.4735e-03,  2.2503e-03,  2.8178e-03,  1.7237e-03],\n",
            "          [-2.4236e-04, -1.7000e-03, -2.7557e-03, -4.8319e-03,  2.7822e-04],\n",
            "          [-1.0423e-03, -4.8787e-03, -7.1005e-04,  8.5726e-03, -6.3480e-04],\n",
            "          [ 7.7048e-05, -7.1267e-04,  1.0436e-03,  1.9488e-03,  4.0192e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0322]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0151]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0322,  0.0151], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 3, 6] = -0.0321916863322258\n",
            " somado na saída em [0, 1, 3, 6] = 0.015050476416945457\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 7\n",
            " alvo do kernel em x: x[0,0,9:14, 21:26]\n",
            " \n",
            " tensor([[0.2377, 0.4616, 0.9079, 0.6650, 0.3573],\n",
            "        [0.6845, 0.2073, 0.9727, 0.2913, 0.6066],\n",
            "        [0.6861, 0.4209, 0.8046, 0.2621, 0.0638],\n",
            "        [0.9049, 0.8048, 0.0649, 0.8322, 0.3672],\n",
            "        [0.2187, 0.0657, 0.7387, 0.1691, 0.2186]])\n",
            " produto: tensor([[[[-9.6944e-04,  1.5289e-04, -4.5090e-03,  2.5076e-03, -3.0440e-03],\n",
            "          [ 5.0175e-03, -1.5071e-03, -7.7331e-03, -1.8409e-03,  2.7474e-03],\n",
            "          [-2.5350e-03,  1.5749e-03, -6.8289e-03, -1.5904e-03, -2.3440e-04],\n",
            "          [-1.7782e-03, -6.1397e-03,  4.2520e-04, -1.9625e-03,  1.1787e-03],\n",
            "          [ 1.5466e-03,  1.2246e-04,  2.0200e-03,  1.6324e-03, -9.8589e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 7.5304e-04, -2.0536e-03,  6.4881e-03,  5.3107e-03, -3.2937e-03],\n",
            "          [ 5.8430e-03,  9.9011e-04,  4.2386e-03,  1.1994e-03,  5.0429e-03],\n",
            "          [-9.0590e-04, -3.5592e-03, -2.3088e-03, -1.8461e-03,  4.2201e-05],\n",
            "          [-1.6894e-03, -4.3169e-03, -5.9041e-05,  7.8841e-03, -2.8965e-04],\n",
            "          [ 6.9442e-05, -1.0251e-04,  1.1613e-03,  1.5068e-03,  1.3367e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0227]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0214]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0227,  0.0214], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 3, 7] = -0.022732825949788094\n",
            " somado na saída em [0, 1, 3, 7] = 0.021441439166665077\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 0\n",
            " alvo do kernel em x: x[0,0,12:17, 0:5]\n",
            " \n",
            " tensor([[0.3051, 0.8070, 0.9271, 0.6647, 0.9296],\n",
            "        [0.2077, 0.4474, 0.5746, 0.6429, 0.0369],\n",
            "        [0.0943, 0.8800, 0.2614, 0.5325, 0.9981],\n",
            "        [0.1427, 0.4906, 0.4970, 0.3552, 0.2576],\n",
            "        [0.1189, 0.9508, 0.8715, 0.0552, 0.4556]])\n",
            " produto: tensor([[[[-1.2439e-03,  2.6732e-04, -4.6047e-03,  2.5068e-03, -7.9206e-03],\n",
            "          [ 1.5228e-03, -3.2517e-03, -4.5685e-03, -4.0624e-03,  1.6720e-04],\n",
            "          [-3.4828e-04,  3.2932e-03, -2.2186e-03, -3.2305e-03, -3.6648e-03],\n",
            "          [-2.8049e-04, -3.7423e-03,  3.2542e-03, -8.3779e-04,  8.2699e-04],\n",
            "          [ 8.4096e-04,  1.7715e-03,  2.3832e-03,  5.3310e-04, -2.0547e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 9.6626e-04, -3.5906e-03,  6.6258e-03,  5.3089e-03, -8.5705e-03],\n",
            "          [ 1.7733e-03,  2.1363e-03,  2.5040e-03,  2.6466e-03,  3.0690e-04],\n",
            "          [-1.2446e-04, -7.4424e-03, -7.5010e-04, -3.7500e-03,  6.5981e-04],\n",
            "          [-2.6648e-04, -2.6313e-03, -4.5186e-04,  3.3656e-03, -2.0321e-04],\n",
            "          [ 3.7758e-05, -1.4829e-03,  1.3701e-03,  4.9210e-04,  2.7859e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0247]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0017]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0247,  0.0017], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 4, 0] = -0.024662215262651443\n",
            " somado na saída em [0, 1, 4, 0] = 0.0017156051471829414\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 1\n",
            " alvo do kernel em x: x[0,0,12:17, 3:8]\n",
            " \n",
            " tensor([[0.6647, 0.9296, 0.3848, 0.9357, 0.2616],\n",
            "        [0.6429, 0.0369, 0.5224, 0.7605, 0.7823],\n",
            "        [0.5325, 0.9981, 0.3005, 0.9657, 0.8973],\n",
            "        [0.3552, 0.2576, 0.7346, 0.4564, 0.4009],\n",
            "        [0.0552, 0.4556, 0.2310, 0.9920, 0.4791]])\n",
            " produto: tensor([[[[-2.7106e-03,  3.0792e-04, -1.9113e-03,  3.5287e-03, -2.2289e-03],\n",
            "          [ 4.7127e-03, -2.6833e-04, -4.1531e-03, -4.8055e-03,  3.5428e-03],\n",
            "          [-1.9674e-03,  3.7350e-03, -2.5503e-03, -5.8592e-03, -3.2945e-03],\n",
            "          [-6.9813e-04, -1.9654e-03,  4.8099e-03, -1.0764e-03,  1.2869e-03],\n",
            "          [ 3.9055e-04,  8.4879e-04,  6.3173e-04,  9.5751e-03, -2.1610e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.1055e-03, -4.1359e-03,  2.7502e-03,  7.4731e-03, -2.4118e-03],\n",
            "          [ 5.4881e-03,  1.7629e-04,  2.2763e-03,  3.1308e-03,  6.5029e-03],\n",
            "          [-7.0305e-04, -8.4409e-03, -8.6223e-04, -6.8013e-03,  5.9314e-04],\n",
            "          [-6.6328e-04, -1.3819e-03, -6.6789e-04,  4.3244e-03, -3.1622e-04],\n",
            "          [ 1.7535e-05, -7.1054e-04,  3.6318e-04,  8.8386e-03,  2.9299e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0023]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0199]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0023,  0.0199], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 4, 1] = -0.0022799852304160595\n",
            " somado na saída em [0, 1, 4, 1] = 0.01987498253583908\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 2\n",
            " alvo do kernel em x: x[0,0,12:17, 6:11]\n",
            " \n",
            " tensor([[0.9357, 0.2616, 0.4344, 0.8323, 0.2410],\n",
            "        [0.7605, 0.7823, 0.7459, 0.5791, 0.0204],\n",
            "        [0.9657, 0.8973, 0.8862, 0.6483, 0.2746],\n",
            "        [0.4564, 0.4009, 0.8474, 0.1203, 0.8265],\n",
            "        [0.9920, 0.4791, 0.7945, 0.9323, 0.1144]])\n",
            " produto: tensor([[[[-3.8156e-03,  8.6650e-05, -2.1574e-03,  3.1387e-03, -2.0530e-03],\n",
            "          [ 5.5748e-03, -5.6858e-03, -5.9305e-03, -3.6590e-03,  9.2283e-05],\n",
            "          [-3.5683e-03,  3.3576e-03, -7.5212e-03, -3.9334e-03, -1.0084e-03],\n",
            "          [-8.9701e-04, -3.0584e-03,  5.5484e-03, -2.8371e-04,  2.6530e-03],\n",
            "          [ 7.0147e-03,  8.9267e-04,  2.1726e-03,  8.9989e-03, -5.1614e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 2.9639e-03, -1.1638e-03,  3.1043e-03,  6.6471e-03, -2.2215e-03],\n",
            "          [ 6.4920e-03,  3.7354e-03,  3.2505e-03,  2.3839e-03,  1.6939e-04],\n",
            "          [-1.2751e-03, -7.5880e-03, -2.5429e-03, -4.5659e-03,  1.8155e-04],\n",
            "          [-8.5222e-04, -2.1504e-03, -7.7043e-04,  1.1397e-03, -6.5192e-04],\n",
            "          [ 3.1495e-04, -7.4727e-04,  1.2490e-03,  8.3067e-03,  6.9980e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0046]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0161]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0046,  0.0161], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 4, 2] = -0.004557394422590733\n",
            " somado na saída em [0, 1, 4, 2] = 0.016108868643641472\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 3\n",
            " alvo do kernel em x: x[0,0,12:17, 9:14]\n",
            " \n",
            " tensor([[0.8323, 0.2410, 0.8815, 0.6226, 0.4902],\n",
            "        [0.5791, 0.0204, 0.8290, 0.1063, 0.2062],\n",
            "        [0.6483, 0.2746, 0.8148, 0.1575, 0.2087],\n",
            "        [0.1203, 0.8265, 0.9441, 0.1928, 0.0263],\n",
            "        [0.9323, 0.1144, 0.8039, 0.0651, 0.3650]])\n",
            " produto: tensor([[[[-3.3939e-03,  7.9814e-05, -4.3782e-03,  2.3477e-03, -4.1768e-03],\n",
            "          [ 4.2448e-03, -1.4810e-04, -6.5908e-03, -6.7163e-04,  9.3365e-04],\n",
            "          [-2.3954e-03,  1.0277e-03, -6.9155e-03, -9.5573e-04, -7.6629e-04],\n",
            "          [-2.3642e-04, -6.3052e-03,  6.1816e-03, -4.5476e-04,  8.4261e-05],\n",
            "          [ 6.5925e-03,  2.1321e-04,  2.1984e-03,  6.2801e-04, -1.6460e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.6363e-03, -1.0720e-03,  6.2999e-03,  4.9721e-03, -4.5196e-03],\n",
            "          [ 4.9432e-03,  9.7300e-05,  3.6124e-03,  4.3757e-04,  1.7137e-03],\n",
            "          [-8.5602e-04, -2.3225e-03, -2.3381e-03, -1.1094e-03,  1.3796e-04],\n",
            "          [-2.2461e-04, -4.4333e-03, -8.5835e-04,  1.8269e-03, -2.0705e-05],\n",
            "          [ 2.9600e-04, -1.7848e-04,  1.2639e-03,  5.7970e-04,  2.2317e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0145]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0131]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0145,  0.0131], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 4, 3] = -0.014503058046102524\n",
            " somado na saída em [0, 1, 4, 3] = 0.013115562498569489\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 4\n",
            " alvo do kernel em x: x[0,0,12:17, 12:17]\n",
            " \n",
            " tensor([[0.6226, 0.4902, 0.9279, 0.8751, 0.2943],\n",
            "        [0.1063, 0.2062, 0.5058, 0.6522, 0.7905],\n",
            "        [0.1575, 0.2087, 0.2590, 0.7162, 0.5689],\n",
            "        [0.1928, 0.0263, 0.5696, 0.1197, 0.7091],\n",
            "        [0.0651, 0.3650, 0.2984, 0.0324, 0.0290]])\n",
            " produto: tensor([[[[-2.5386e-03,  1.6238e-04, -4.6085e-03,  3.3000e-03, -2.5080e-03],\n",
            "          [ 7.7915e-04, -1.4984e-03, -4.0217e-03, -4.1214e-03,  3.5801e-03],\n",
            "          [-5.8204e-04,  7.8098e-04, -2.1980e-03, -4.3457e-03, -2.0887e-03],\n",
            "          [-3.7896e-04, -2.0026e-04,  3.7294e-03, -2.8232e-04,  2.2760e-03],\n",
            "          [ 4.6008e-04,  6.7995e-04,  8.1595e-04,  3.1239e-04, -1.3098e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 1.9720e-03, -2.1810e-03,  6.6313e-03,  6.9887e-03, -2.7138e-03],\n",
            "          [ 9.0734e-04,  9.8441e-04,  2.2043e-03,  2.6851e-03,  6.5713e-03],\n",
            "          [-2.0799e-04, -1.7650e-03, -7.4312e-04, -5.0444e-03,  3.7606e-04],\n",
            "          [-3.6004e-04, -1.4080e-04, -5.1784e-04,  1.1341e-03, -5.5929e-04],\n",
            "          [ 2.0657e-05, -5.6920e-04,  4.6909e-04,  2.8836e-04,  1.7759e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0126]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0166]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0126,  0.0166], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 4, 4] = -0.012627318501472473\n",
            " somado na saída em [0, 1, 4, 4] = 0.016607927158474922\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 5\n",
            " alvo do kernel em x: x[0,0,12:17, 15:20]\n",
            " \n",
            " tensor([[0.8751, 0.2943, 0.5485, 0.5583, 0.9096],\n",
            "        [0.6522, 0.7905, 0.4298, 0.2427, 0.4570],\n",
            "        [0.7162, 0.5689, 0.8181, 0.8286, 0.5292],\n",
            "        [0.1197, 0.7091, 0.1012, 0.1098, 0.6353],\n",
            "        [0.0324, 0.0290, 0.0179, 0.1132, 0.2206]])\n",
            " produto: tensor([[[[-3.5683e-03,  9.7502e-05, -2.7242e-03,  2.1053e-03, -7.7500e-03],\n",
            "          [ 4.7812e-03, -5.7456e-03, -3.4170e-03, -1.5334e-03,  2.0695e-03],\n",
            "          [-2.6465e-03,  2.1288e-03, -6.9436e-03, -5.0274e-03, -1.9431e-03],\n",
            "          [-2.3526e-04, -5.4093e-03,  6.6287e-04, -2.5883e-04,  2.0391e-03],\n",
            "          [ 2.2885e-04,  5.4107e-05,  4.9059e-05,  1.0930e-03, -9.9499e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 2.7717e-03, -1.3096e-03,  3.9198e-03,  4.4587e-03, -8.3859e-03],\n",
            "          [ 5.5678e-03,  3.7747e-03,  1.8729e-03,  9.9901e-04,  3.7987e-03],\n",
            "          [-9.4573e-04, -4.8109e-03, -2.3476e-03, -5.8358e-03,  3.4983e-04],\n",
            "          [-2.2351e-04, -3.8034e-03, -9.2043e-05,  1.0398e-03, -5.0106e-04],\n",
            "          [ 1.0275e-05, -4.5294e-05,  2.8204e-05,  1.0089e-03,  1.3490e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0329]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0026]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0329,  0.0026], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 4, 5] = -0.032887980341911316\n",
            " somado na saída em [0, 1, 4, 5] = 0.0026486669667065144\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 6\n",
            " alvo do kernel em x: x[0,0,12:17, 18:23]\n",
            " \n",
            " tensor([[0.5583, 0.9096, 0.7810, 0.9049, 0.8048],\n",
            "        [0.2427, 0.4570, 0.6638, 0.2187, 0.0657],\n",
            "        [0.8286, 0.5292, 0.7914, 0.1387, 0.0221],\n",
            "        [0.1098, 0.6353, 0.3719, 0.0574, 0.6951],\n",
            "        [0.1132, 0.2206, 0.3352, 0.7797, 0.4196]])\n",
            " produto: tensor([[[[-2.2765e-03,  3.0129e-04, -3.8787e-03,  3.4123e-03, -6.8575e-03],\n",
            "          [ 1.7789e-03, -3.3213e-03, -5.2779e-03, -1.3820e-03,  2.9768e-04],\n",
            "          [-3.0617e-03,  1.9803e-03, -6.7172e-03, -8.4123e-04, -8.1255e-05],\n",
            "          [-2.1568e-04, -4.8461e-03,  2.4349e-03, -1.3539e-04,  2.2312e-03],\n",
            "          [ 8.0072e-04,  4.1102e-04,  9.1659e-04,  7.5265e-03, -1.8925e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7683e-03, -4.0468e-03,  5.5811e-03,  7.2267e-03, -7.4202e-03],\n",
            "          [ 2.0715e-03,  2.1820e-03,  2.8928e-03,  9.0039e-04,  5.4640e-04],\n",
            "          [-1.0941e-03, -4.4754e-03, -2.2711e-03, -9.7648e-04,  1.4629e-05],\n",
            "          [-2.0491e-04, -3.4074e-03, -3.3810e-04,  5.4392e-04, -5.4826e-04],\n",
            "          [ 3.5952e-05, -3.4407e-04,  5.2695e-04,  6.9476e-03,  2.5660e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0187]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0087]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0187,  0.0087], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 4, 6] = -0.018693629652261734\n",
            " somado na saída em [0, 1, 4, 6] = 0.008677495643496513\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 7\n",
            " alvo do kernel em x: x[0,0,12:17, 21:26]\n",
            " \n",
            " tensor([[0.9049, 0.8048, 0.0649, 0.8322, 0.3672],\n",
            "        [0.2187, 0.0657, 0.7387, 0.1691, 0.2186],\n",
            "        [0.1387, 0.0221, 0.0927, 0.7759, 0.9598],\n",
            "        [0.0574, 0.6951, 0.6766, 0.5674, 0.8267],\n",
            "        [0.7797, 0.4196, 0.0050, 0.1368, 0.8588]])\n",
            " produto: tensor([[[[-3.6898e-03,  2.6659e-04, -3.2251e-04,  3.1383e-03, -3.1290e-03],\n",
            "          [ 1.6033e-03, -4.7774e-04, -5.8731e-03, -1.0686e-03,  9.9001e-04],\n",
            "          [-5.1230e-04,  8.2813e-05, -7.8637e-04, -4.7077e-03, -3.5240e-03],\n",
            "          [-1.1282e-04, -5.3026e-03,  4.4304e-03, -1.3381e-03,  2.6537e-03],\n",
            "          [ 5.5139e-03,  7.8179e-04,  1.3536e-05,  1.3206e-03, -3.8734e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.8661e-03, -3.5808e-03,  4.6407e-04,  6.6463e-03, -3.3857e-03],\n",
            "          [ 1.8671e-03,  3.1386e-04,  3.2191e-03,  6.9620e-04,  1.8172e-03],\n",
            "          [-1.8307e-04, -1.8715e-04, -2.6587e-04, -5.4646e-03,  6.3446e-04],\n",
            "          [-1.0719e-04, -3.7284e-03, -6.1519e-04,  5.3754e-03, -6.5208e-04],\n",
            "          [ 2.4757e-04, -6.5445e-04,  7.7818e-06,  1.2191e-03,  5.2517e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0139]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0118]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0139,  0.0118], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 4, 7] = -0.01392311230301857\n",
            " somado na saída em [0, 1, 4, 7] = 0.011801395565271378\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 0\n",
            " alvo do kernel em x: x[0,0,15:20, 0:5]\n",
            " \n",
            " tensor([[0.1427, 0.4906, 0.4970, 0.3552, 0.2576],\n",
            "        [0.1189, 0.9508, 0.8715, 0.0552, 0.4556],\n",
            "        [0.0475, 0.7690, 0.8418, 0.5438, 0.2486],\n",
            "        [0.5577, 0.3350, 0.4620, 0.7872, 0.3279],\n",
            "        [0.7429, 0.9616, 0.5214, 0.5024, 0.6241]])\n",
            " produto: tensor([[[[-5.8200e-04,  1.6250e-04, -2.4683e-03,  1.3397e-03, -2.1952e-03],\n",
            "          [ 8.7176e-04, -6.9111e-03, -6.9290e-03, -3.4898e-04,  2.0633e-03],\n",
            "          [-1.7549e-04,  2.8778e-03, -7.1443e-03, -3.2991e-03, -9.1295e-04],\n",
            "          [-1.0960e-03, -2.5552e-03,  3.0254e-03, -1.8565e-03,  1.0525e-03],\n",
            "          [ 5.2530e-03,  1.7916e-03,  1.4257e-03,  4.8494e-03, -2.8147e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 4.5209e-04, -2.1826e-03,  3.5517e-03,  2.8372e-03, -2.3754e-03],\n",
            "          [ 1.0152e-03,  4.5404e-03,  3.7978e-03,  2.2736e-04,  3.7873e-03],\n",
            "          [-6.2712e-05, -6.5036e-03, -2.4154e-03, -3.8295e-03,  1.6437e-04],\n",
            "          [-1.0413e-03, -1.7966e-03, -4.2010e-04,  7.4580e-03, -2.5862e-04],\n",
            "          [ 2.3586e-04, -1.4998e-03,  8.1963e-04,  4.4764e-03,  3.8163e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0146]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0148]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0146,  0.0148], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 5, 0] = -0.014576214365661144\n",
            " somado na saída em [0, 1, 5, 0] = 0.014793984591960907\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 1\n",
            " alvo do kernel em x: x[0,0,15:20, 3:8]\n",
            " \n",
            " tensor([[0.3552, 0.2576, 0.7346, 0.4564, 0.4009],\n",
            "        [0.0552, 0.4556, 0.2310, 0.9920, 0.4791],\n",
            "        [0.5438, 0.2486, 0.3788, 0.5291, 0.7095],\n",
            "        [0.7872, 0.3279, 0.1213, 0.5302, 0.3608],\n",
            "        [0.5024, 0.6241, 0.0379, 0.6748, 0.4962]])\n",
            " produto: tensor([[[[-1.4486e-03,  8.5341e-05, -3.6483e-03,  1.7213e-03, -3.4159e-03],\n",
            "          [ 4.0485e-04, -3.3114e-03, -1.8367e-03, -6.2682e-03,  2.1700e-03],\n",
            "          [-2.0091e-03,  9.3045e-04, -3.2148e-03, -3.2104e-03, -2.6053e-03],\n",
            "          [-1.5470e-03, -2.5014e-03,  7.9398e-04, -1.2504e-03,  1.1580e-03],\n",
            "          [ 3.5527e-03,  1.1627e-03,  1.0362e-04,  6.5137e-03, -2.2381e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1253e-03, -1.1463e-03,  5.2496e-03,  3.6454e-03, -3.6962e-03],\n",
            "          [ 4.7146e-04,  2.1755e-03,  1.0067e-03,  4.0837e-03,  3.9831e-03],\n",
            "          [-7.1797e-04, -2.1028e-03, -1.0869e-03, -3.7266e-03,  4.6906e-04],\n",
            "          [-1.4698e-03, -1.7588e-03, -1.1025e-04,  5.0232e-03, -2.8456e-04],\n",
            "          [ 1.5951e-04, -9.7335e-04,  5.9568e-05,  6.0127e-03,  3.0345e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0199]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0194]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0199,  0.0194], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 5, 1] = -0.019909054040908813\n",
            " somado na saída em [0, 1, 5, 1] = 0.019425775855779648\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 2\n",
            " alvo do kernel em x: x[0,0,15:20, 6:11]\n",
            " \n",
            " tensor([[0.4564, 0.4009, 0.8474, 0.1203, 0.8265],\n",
            "        [0.9920, 0.4791, 0.7945, 0.9323, 0.1144],\n",
            "        [0.5291, 0.7095, 0.5086, 0.2669, 0.5242],\n",
            "        [0.5302, 0.3608, 0.2668, 0.3473, 0.2165],\n",
            "        [0.6748, 0.4962, 0.4761, 0.5288, 0.9429]])\n",
            " produto: tensor([[[[-0.0019,  0.0001, -0.0042,  0.0005, -0.0070],\n",
            "          [ 0.0073, -0.0035, -0.0063, -0.0059,  0.0005],\n",
            "          [-0.0020,  0.0027, -0.0043, -0.0016, -0.0019],\n",
            "          [-0.0010, -0.0028,  0.0017, -0.0008,  0.0007],\n",
            "          [ 0.0048,  0.0009,  0.0013,  0.0051, -0.0043]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0014, -0.0018,  0.0061,  0.0010, -0.0076],\n",
            "          [ 0.0085,  0.0023,  0.0035,  0.0038,  0.0010],\n",
            "          [-0.0007, -0.0060, -0.0015, -0.0019,  0.0003],\n",
            "          [-0.0010, -0.0019, -0.0002,  0.0033, -0.0002],\n",
            "          [ 0.0002, -0.0008,  0.0007,  0.0047,  0.0058]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0219]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0190]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0219,  0.0190], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 5, 2] = -0.021908022463321686\n",
            " somado na saída em [0, 1, 5, 2] = 0.01899130269885063\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 3\n",
            " alvo do kernel em x: x[0,0,15:20, 9:14]\n",
            " \n",
            " tensor([[0.1203, 0.8265, 0.9441, 0.1928, 0.0263],\n",
            "        [0.9323, 0.1144, 0.8039, 0.0651, 0.3650],\n",
            "        [0.2669, 0.5242, 0.5153, 0.5047, 0.7175],\n",
            "        [0.3473, 0.2165, 0.9389, 0.5344, 0.2346],\n",
            "        [0.5288, 0.9429, 0.6435, 0.0470, 0.9632]])\n",
            " produto: tensor([[[[-0.0005,  0.0003, -0.0047,  0.0007, -0.0002],\n",
            "          [ 0.0068, -0.0008, -0.0064, -0.0004,  0.0017],\n",
            "          [-0.0010,  0.0020, -0.0044, -0.0031, -0.0026],\n",
            "          [-0.0007, -0.0017,  0.0061, -0.0013,  0.0008],\n",
            "          [ 0.0037,  0.0018,  0.0018,  0.0005, -0.0043]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0004, -0.0037,  0.0067,  0.0015, -0.0002],\n",
            "          [ 0.0080,  0.0005,  0.0035,  0.0003,  0.0030],\n",
            "          [-0.0004, -0.0044, -0.0015, -0.0036,  0.0005],\n",
            "          [-0.0006, -0.0012, -0.0009,  0.0051, -0.0002],\n",
            "          [ 0.0002, -0.0015,  0.0010,  0.0004,  0.0059]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0060]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0189]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0060,  0.0189], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 5, 3] = -0.005972486920654774\n",
            " somado na saída em [0, 1, 5, 3] = 0.018946390599012375\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 4\n",
            " alvo do kernel em x: x[0,0,15:20, 12:17]\n",
            " \n",
            " tensor([[0.1928, 0.0263, 0.5696, 0.1197, 0.7091],\n",
            "        [0.0651, 0.3650, 0.2984, 0.0324, 0.0290],\n",
            "        [0.5047, 0.7175, 0.3116, 0.5315, 0.5021],\n",
            "        [0.5344, 0.2346, 0.8188, 0.5773, 0.7870],\n",
            "        [0.0470, 0.9632, 0.8049, 0.7523, 0.7063]])\n",
            " produto: tensor([[[[-7.8633e-04,  8.6954e-06, -2.8287e-03,  4.5145e-04, -6.0417e-03],\n",
            "          [ 4.7693e-04, -2.6527e-03, -2.3723e-03, -2.0450e-04,  1.3153e-04],\n",
            "          [-1.8647e-03,  2.6849e-03, -2.6443e-03, -3.2247e-03, -1.8437e-03],\n",
            "          [-1.0502e-03, -1.7899e-03,  5.3614e-03, -1.3616e-03,  2.5263e-03],\n",
            "          [ 3.3258e-04,  1.7945e-03,  2.2011e-03,  7.2618e-03, -3.1856e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 6.1080e-04, -1.1679e-04,  4.0703e-03,  9.5608e-04, -6.5375e-03],\n",
            "          [ 5.5539e-04,  1.7428e-03,  1.3003e-03,  1.3323e-04,  2.4143e-04],\n",
            "          [-6.6635e-04, -6.0677e-03, -8.9403e-04, -3.7432e-03,  3.3194e-04],\n",
            "          [-9.9772e-04, -1.2585e-03, -7.4446e-04,  5.4698e-03, -6.2079e-04],\n",
            "          [ 1.4933e-05, -1.5022e-03,  1.2654e-03,  6.7033e-03,  4.3192e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0086]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0046]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0086,  0.0046], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 5, 4] = -0.008619697764515877\n",
            " somado na saída em [0, 1, 5, 4] = 0.004565461538732052\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 5\n",
            " alvo do kernel em x: x[0,0,15:20, 15:20]\n",
            " \n",
            " tensor([[0.1197, 0.7091, 0.1012, 0.1098, 0.6353],\n",
            "        [0.0324, 0.0290, 0.0179, 0.1132, 0.2206],\n",
            "        [0.5315, 0.5021, 0.7111, 0.1939, 0.1091],\n",
            "        [0.5773, 0.7870, 0.8855, 0.9941, 0.3705],\n",
            "        [0.7523, 0.7063, 0.5488, 0.2239, 0.8205]])\n",
            " produto: tensor([[[[-4.8815e-04,  2.3488e-04, -5.0278e-04,  4.1389e-04, -5.4127e-03],\n",
            "          [ 2.3723e-04, -2.1109e-04, -1.4264e-04, -7.1551e-04,  9.9915e-04],\n",
            "          [-1.9638e-03,  1.8790e-03, -6.0352e-03, -1.1766e-03, -4.0057e-04],\n",
            "          [-1.1346e-03, -6.0041e-03,  5.7979e-03, -2.3445e-03,  1.1891e-03],\n",
            "          [ 5.3200e-03,  1.3159e-03,  1.5006e-03,  2.1615e-03, -3.7005e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 3.7919e-04, -3.1548e-03,  7.2346e-04,  8.7653e-04, -5.8569e-03],\n",
            "          [ 2.7627e-04,  1.3868e-04,  7.8180e-05,  4.6615e-04,  1.8340e-03],\n",
            "          [-7.0178e-04, -4.2465e-03, -2.0404e-03, -1.3658e-03,  7.2119e-05],\n",
            "          [-1.0779e-03, -4.2216e-03, -8.0507e-04,  9.4185e-03, -2.9219e-04],\n",
            "          [ 2.3886e-04, -1.1016e-03,  8.6270e-04,  1.9952e-03,  5.0173e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0092]]],\n",
            "\n",
            "\n",
            "        [[[-0.0025]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0092, -0.0025], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 5, 5] = -0.009183604270219803\n",
            " somado na saída em [0, 1, 5, 5] = -0.002487480640411377\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 6\n",
            " alvo do kernel em x: x[0,0,15:20, 18:23]\n",
            " \n",
            " tensor([[0.1098, 0.6353, 0.3719, 0.0574, 0.6951],\n",
            "        [0.1132, 0.2206, 0.3352, 0.7797, 0.4196],\n",
            "        [0.1939, 0.1091, 0.0931, 0.7101, 0.8978],\n",
            "        [0.9941, 0.3705, 0.5148, 0.2103, 0.9562],\n",
            "        [0.2239, 0.8205, 0.1264, 0.1976, 0.5013]])\n",
            " produto: tensor([[[[-4.4754e-04,  2.1043e-04, -1.8469e-03,  2.1651e-04, -5.9226e-03],\n",
            "          [ 8.3005e-04, -1.6035e-03, -2.6649e-03, -4.9271e-03,  1.9005e-03],\n",
            "          [-7.1654e-04,  4.0825e-04, -7.8986e-04, -4.3081e-03, -3.2964e-03],\n",
            "          [-1.9537e-03, -2.8260e-03,  3.3710e-03, -4.9589e-04,  3.0693e-03],\n",
            "          [ 1.5835e-03,  1.5286e-03,  3.4556e-04,  1.9075e-03, -2.2607e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 3.4764e-04, -2.8264e-03,  2.6575e-03,  4.5852e-04, -6.4086e-03],\n",
            "          [ 9.6661e-04,  1.0535e-03,  1.4607e-03,  3.2100e-03,  3.4883e-03],\n",
            "          [-2.5606e-04, -9.2261e-04, -2.6704e-04, -5.0008e-03,  5.9349e-04],\n",
            "          [-1.8561e-03, -1.9870e-03, -4.6809e-04,  1.9921e-03, -7.5420e-04],\n",
            "          [ 7.1096e-05, -1.2797e-03,  1.9866e-04,  1.7608e-03,  3.0651e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0187]]],\n",
            "\n",
            "\n",
            "        [[[-0.0007]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0187, -0.0007], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 5, 6] = -0.018688729032874107\n",
            " somado na saída em [0, 1, 5, 6] = -0.000702513032592833\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 7\n",
            " alvo do kernel em x: x[0,0,15:20, 21:26]\n",
            " \n",
            " tensor([[0.0574, 0.6951, 0.6766, 0.5674, 0.8267],\n",
            "        [0.7797, 0.4196, 0.0050, 0.1368, 0.8588],\n",
            "        [0.7101, 0.8978, 0.9959, 0.6785, 0.3981],\n",
            "        [0.2103, 0.9562, 0.6591, 0.4172, 0.6253],\n",
            "        [0.1976, 0.5013, 0.1121, 0.9536, 0.9967]])\n",
            " produto: tensor([[[[-2.3411e-04,  2.3025e-04, -3.3605e-03,  2.1397e-03, -7.0441e-03],\n",
            "          [ 5.7158e-03, -3.0500e-03, -3.9355e-05, -8.6453e-04,  3.8896e-03],\n",
            "          [-2.6236e-03,  3.3596e-03, -8.4527e-03, -4.1169e-03, -1.4616e-03],\n",
            "          [-4.1323e-04, -7.2945e-03,  4.3160e-03, -9.8394e-04,  2.0071e-03],\n",
            "          [ 1.3974e-03,  9.3387e-04,  3.0643e-04,  9.2046e-03, -4.4954e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.8185e-04, -3.0926e-03,  4.8354e-03,  4.5314e-03, -7.6222e-03],\n",
            "          [ 6.6562e-03,  2.0038e-03,  2.1571e-05,  5.6324e-04,  7.1395e-03],\n",
            "          [-9.3757e-04, -7.5925e-03, -2.8578e-03, -4.7788e-03,  2.6314e-04],\n",
            "          [-3.9260e-04, -5.1289e-03, -5.9930e-04,  3.9528e-03, -4.9321e-04],\n",
            "          [ 6.2743e-05, -7.8176e-04,  1.7616e-04,  8.4966e-03,  6.0950e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0109]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0107]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0109,  0.0107], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 5, 7] = -0.010934015735983849\n",
            " somado na saída em [0, 1, 5, 7] = 0.010702241212129593\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 0\n",
            " alvo do kernel em x: x[0,0,18:23, 0:5]\n",
            " \n",
            " tensor([[0.5577, 0.3350, 0.4620, 0.7872, 0.3279],\n",
            "        [0.7429, 0.9616, 0.5214, 0.5024, 0.6241],\n",
            "        [0.0157, 0.9315, 0.5878, 0.1842, 0.1508],\n",
            "        [0.7006, 0.9619, 0.1965, 0.0994, 0.6232],\n",
            "        [0.1685, 0.3713, 0.9908, 0.8435, 0.6818]])\n",
            " produto: tensor([[[[-2.2743e-03,  1.1095e-04, -2.2948e-03,  2.9686e-03, -2.7938e-03],\n",
            "          [ 5.4454e-03, -6.9895e-03, -4.1451e-03, -3.1746e-03,  2.8265e-03],\n",
            "          [-5.7884e-05,  3.4859e-03, -4.9889e-03, -1.1176e-03, -5.5382e-04],\n",
            "          [-1.3769e-03, -7.3380e-03,  1.2865e-03, -2.3453e-04,  2.0004e-03],\n",
            "          [ 1.1914e-03,  6.9180e-04,  2.7093e-03,  8.1422e-03, -3.0748e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7666e-03, -1.4902e-03,  3.3020e-03,  6.2870e-03, -3.0231e-03],\n",
            "          [ 6.3413e-03,  4.5919e-03,  2.2719e-03,  2.0682e-03,  5.1881e-03],\n",
            "          [-2.0685e-05, -7.8779e-03, -1.6867e-03, -1.2972e-03,  9.9709e-05],\n",
            "          [-1.3082e-03, -5.1595e-03, -1.7864e-04,  9.4218e-04, -4.9155e-04],\n",
            "          [ 5.3491e-05, -5.7912e-04,  1.5576e-03,  7.5159e-03,  4.1690e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0096]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0230]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0096,  0.0230], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 6, 0] = -0.009555590339004993\n",
            " somado na saída em [0, 1, 6, 0] = 0.02304217964410782\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 1\n",
            " alvo do kernel em x: x[0,0,18:23, 3:8]\n",
            " \n",
            " tensor([[0.7872, 0.3279, 0.1213, 0.5302, 0.3608],\n",
            "        [0.5024, 0.6241, 0.0379, 0.6748, 0.4962],\n",
            "        [0.1842, 0.1508, 0.6205, 0.8014, 0.3660],\n",
            "        [0.0994, 0.6232, 0.5908, 0.9808, 0.9848],\n",
            "        [0.8435, 0.6818, 0.8176, 0.3984, 0.2316]])\n",
            " produto: tensor([[[[-0.0032,  0.0001, -0.0006,  0.0020, -0.0031],\n",
            "          [ 0.0037, -0.0045, -0.0003, -0.0043,  0.0022],\n",
            "          [-0.0007,  0.0006, -0.0053, -0.0049, -0.0013],\n",
            "          [-0.0002, -0.0048,  0.0039, -0.0023,  0.0032],\n",
            "          [ 0.0060,  0.0013,  0.0022,  0.0038, -0.0010]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0025, -0.0015,  0.0009,  0.0042, -0.0033],\n",
            "          [ 0.0043,  0.0030,  0.0002,  0.0028,  0.0041],\n",
            "          [-0.0002, -0.0013, -0.0018, -0.0056,  0.0002],\n",
            "          [-0.0002, -0.0033, -0.0005,  0.0093, -0.0008],\n",
            "          [ 0.0003, -0.0011,  0.0013,  0.0035,  0.0014]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0075]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0184]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0075,  0.0184], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 6, 1] = -0.007499287836253643\n",
            " somado na saída em [0, 1, 6, 1] = 0.018351055681705475\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 2\n",
            " alvo do kernel em x: x[0,0,18:23, 6:11]\n",
            " \n",
            " tensor([[0.5302, 0.3608, 0.2668, 0.3473, 0.2165],\n",
            "        [0.6748, 0.4962, 0.4761, 0.5288, 0.9429],\n",
            "        [0.8014, 0.3660, 0.3785, 0.4034, 0.0322],\n",
            "        [0.9808, 0.9848, 0.7145, 0.7961, 0.7276],\n",
            "        [0.3984, 0.2316, 0.7526, 0.6348, 0.3449]])\n",
            " produto: tensor([[[[-2.1620e-03,  1.1950e-04, -1.3253e-03,  1.3096e-03, -1.8448e-03],\n",
            "          [ 4.9467e-03, -3.6069e-03, -3.7848e-03, -3.3412e-03,  4.2702e-03],\n",
            "          [-2.9610e-03,  1.3698e-03, -3.2124e-03, -2.4474e-03, -1.1828e-04],\n",
            "          [-1.9275e-03, -7.5124e-03,  4.6785e-03, -1.8775e-03,  2.3355e-03],\n",
            "          [ 2.8173e-03,  4.3142e-04,  2.0580e-03,  6.1279e-03, -1.5555e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.6794e-03, -1.6051e-03,  1.9070e-03,  2.7735e-03, -1.9962e-03],\n",
            "          [ 5.7605e-03,  2.3696e-03,  2.0745e-03,  2.1768e-03,  7.8381e-03],\n",
            "          [-1.0581e-03, -3.0956e-03, -1.0861e-03, -2.8409e-03,  2.1295e-05],\n",
            "          [-1.8312e-03, -5.2821e-03, -6.4964e-04,  7.5426e-03, -5.7389e-04],\n",
            "          [ 1.2649e-04, -3.6115e-04,  1.1831e-03,  5.6565e-03,  2.1090e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0072]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0228]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0072,  0.0228], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 6, 2] = -0.0072128260508179665\n",
            " somado na saída em [0, 1, 6, 2] = 0.022838443517684937\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 3\n",
            " alvo do kernel em x: x[0,0,18:23, 9:14]\n",
            " \n",
            " tensor([[0.3473, 0.2165, 0.9389, 0.5344, 0.2346],\n",
            "        [0.5288, 0.9429, 0.6435, 0.0470, 0.9632],\n",
            "        [0.4034, 0.0322, 0.8597, 0.4570, 0.0412],\n",
            "        [0.7961, 0.7276, 0.4627, 0.0319, 0.3020],\n",
            "        [0.6348, 0.3449, 0.8858, 0.1437, 0.4895]])\n",
            " produto: tensor([[[[-1.4161e-03,  7.1720e-05, -4.6630e-03,  2.0152e-03, -1.9992e-03],\n",
            "          [ 3.8761e-03, -6.8532e-03, -5.1159e-03, -2.9719e-04,  4.3623e-03],\n",
            "          [-1.4905e-03,  1.2055e-04, -7.2968e-03, -2.7727e-03, -1.5124e-04],\n",
            "          [-1.5646e-03, -5.5505e-03,  3.0297e-03, -7.5185e-05,  9.6924e-04],\n",
            "          [ 4.4892e-03,  6.4257e-04,  2.4221e-03,  1.3873e-03, -2.2075e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1000e-03, -9.6331e-04,  6.7097e-03,  4.2678e-03, -2.1633e-03],\n",
            "          [ 4.5138e-03,  4.5024e-03,  2.8041e-03,  1.9362e-04,  8.0072e-03],\n",
            "          [-5.3263e-04, -2.7243e-04, -2.4670e-03, -3.2185e-03,  2.7229e-05],\n",
            "          [-1.4864e-03, -3.9027e-03, -4.2069e-04,  3.0204e-04, -2.3817e-04],\n",
            "          [ 2.0156e-04, -5.3790e-04,  1.3925e-03,  1.2806e-03,  2.9930e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0181]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0221]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0181,  0.0221], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 6, 3] = -0.018067797645926476\n",
            " somado na saída em [0, 1, 6, 3] = 0.022092288359999657\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 4\n",
            " alvo do kernel em x: x[0,0,18:23, 12:17]\n",
            " \n",
            " tensor([[0.5344, 0.2346, 0.8188, 0.5773, 0.7870],\n",
            "        [0.0470, 0.9632, 0.8049, 0.7523, 0.7063],\n",
            "        [0.4570, 0.0412, 0.1252, 0.6568, 0.0195],\n",
            "        [0.0319, 0.3020, 0.0755, 0.8552, 0.2297],\n",
            "        [0.1437, 0.4895, 0.9042, 0.6609, 0.1076]])\n",
            " produto: tensor([[[[-2.1790e-03,  7.7721e-05, -4.0666e-03,  2.1772e-03, -6.7061e-03],\n",
            "          [ 3.4476e-04, -7.0010e-03, -6.3995e-03, -4.7538e-03,  3.1989e-03],\n",
            "          [-1.6886e-03,  1.5414e-04, -1.0623e-03, -3.9850e-03, -7.1585e-05],\n",
            "          [-6.2653e-05, -2.3035e-03,  4.9461e-04, -2.0168e-03,  7.3745e-04],\n",
            "          [ 1.0163e-03,  9.1189e-04,  2.4727e-03,  6.3792e-03, -4.8526e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 1.6926e-03, -1.0439e-03,  5.8515e-03,  4.6110e-03, -7.2564e-03],\n",
            "          [ 4.0148e-04,  4.5995e-03,  3.5076e-03,  3.0971e-03,  5.8717e-03],\n",
            "          [-6.0342e-04, -3.4834e-04, -3.5916e-04, -4.6258e-03,  1.2888e-05],\n",
            "          [-5.9524e-05, -1.6196e-03, -6.8680e-05,  8.1019e-03, -1.8121e-04],\n",
            "          [ 4.5632e-05, -7.6336e-04,  1.4215e-03,  5.8885e-03,  6.5793e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0248]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0288]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0248,  0.0288], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 6, 4] = -0.024816876277327538\n",
            " somado na saída em [0, 1, 6, 4] = 0.028831560164690018\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 5\n",
            " alvo do kernel em x: x[0,0,18:23, 15:20]\n",
            " \n",
            " tensor([[0.5773, 0.7870, 0.8855, 0.9941, 0.3705],\n",
            "        [0.7523, 0.7063, 0.5488, 0.2239, 0.8205],\n",
            "        [0.6568, 0.0195, 0.8521, 0.0871, 0.4829],\n",
            "        [0.8552, 0.2297, 0.1057, 0.4344, 0.8401],\n",
            "        [0.6609, 0.1076, 0.5814, 0.4285, 0.7065]])\n",
            " produto: tensor([[[[-2.3543e-03,  2.6071e-04, -4.3977e-03,  3.7490e-03, -3.1564e-03],\n",
            "          [ 5.5148e-03, -5.1339e-03, -4.3629e-03, -1.4150e-03,  3.7160e-03],\n",
            "          [-2.4269e-03,  7.2957e-05, -7.2324e-03, -5.2833e-04, -1.7732e-03],\n",
            "          [-1.6806e-03, -1.7526e-03,  6.9239e-04, -1.0245e-03,  2.6965e-03],\n",
            "          [ 4.6733e-03,  2.0045e-04,  1.5898e-03,  4.1359e-03, -3.1865e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.8287e-03, -3.5017e-03,  6.3279e-03,  7.9398e-03, -3.4155e-03],\n",
            "          [ 6.4221e-03,  3.3728e-03,  2.3913e-03,  9.2184e-04,  6.8208e-03],\n",
            "          [-8.6725e-04, -1.6488e-04, -2.4452e-03, -6.1328e-04,  3.1924e-04],\n",
            "          [-1.5967e-03, -1.2323e-03, -9.6142e-05,  4.1157e-03, -6.6260e-04],\n",
            "          [ 2.0983e-04, -1.6780e-04,  9.1396e-04,  3.8178e-03,  4.3204e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0131]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0350]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0131,  0.0350], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 6, 5] = -0.013123253360390663\n",
            " somado na saída em [0, 1, 6, 5] = 0.034959036856889725\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 6\n",
            " alvo do kernel em x: x[0,0,18:23, 18:23]\n",
            " \n",
            " tensor([[0.9941, 0.3705, 0.5148, 0.2103, 0.9562],\n",
            "        [0.2239, 0.8205, 0.1264, 0.1976, 0.5013],\n",
            "        [0.0871, 0.4829, 0.6474, 0.2642, 0.1753],\n",
            "        [0.4344, 0.8401, 0.7186, 0.6829, 0.4696],\n",
            "        [0.4285, 0.7065, 0.7816, 0.1461, 0.3353]])\n",
            " produto: tensor([[[[-0.0041,  0.0001, -0.0026,  0.0008, -0.0081],\n",
            "          [ 0.0016, -0.0060, -0.0010, -0.0012,  0.0023],\n",
            "          [-0.0003,  0.0018, -0.0055, -0.0016, -0.0006],\n",
            "          [-0.0009, -0.0064,  0.0047, -0.0016,  0.0015],\n",
            "          [ 0.0030,  0.0013,  0.0021,  0.0014, -0.0015]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0031, -0.0016,  0.0037,  0.0017, -0.0088],\n",
            "          [ 0.0019,  0.0039,  0.0006,  0.0008,  0.0042],\n",
            "          [-0.0001, -0.0041, -0.0019, -0.0019,  0.0001],\n",
            "          [-0.0008, -0.0045, -0.0007,  0.0065, -0.0004],\n",
            "          [ 0.0001, -0.0011,  0.0012,  0.0013,  0.0021]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0207]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0053]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0207,  0.0053], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 6, 6] = -0.02068278379738331\n",
            " somado na saída em [0, 1, 6, 6] = 0.005346553400158882\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 7\n",
            " alvo do kernel em x: x[0,0,18:23, 21:26]\n",
            " \n",
            " tensor([[0.2103, 0.9562, 0.6591, 0.4172, 0.6253],\n",
            "        [0.1976, 0.5013, 0.1121, 0.9536, 0.9967],\n",
            "        [0.2642, 0.1753, 0.4471, 0.5900, 0.4111],\n",
            "        [0.6829, 0.4696, 0.0429, 0.2037, 0.0771],\n",
            "        [0.1461, 0.3353, 0.9155, 0.1354, 0.3867]])\n",
            " produto: tensor([[[[-8.5745e-04,  3.1674e-04, -3.2737e-03,  1.5734e-03, -5.3279e-03],\n",
            "          [ 1.4486e-03, -3.6433e-03, -8.9091e-04, -6.0256e-03,  4.5142e-03],\n",
            "          [-9.7636e-04,  6.5617e-04, -3.7943e-03, -3.5799e-03, -1.5094e-03],\n",
            "          [-1.3420e-03, -3.5822e-03,  2.8081e-04, -4.8030e-04,  2.4758e-04],\n",
            "          [ 1.0333e-03,  6.2474e-04,  2.5035e-03,  1.3069e-03, -1.7439e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 6.6605e-04, -4.2543e-03,  4.7106e-03,  3.3322e-03, -5.7651e-03],\n",
            "          [ 1.6869e-03,  2.3936e-03,  4.8831e-04,  3.9257e-03,  8.2860e-03],\n",
            "          [-3.4891e-04, -1.4829e-03, -1.2828e-03, -4.1555e-03,  2.7175e-04],\n",
            "          [-1.2750e-03, -2.5187e-03, -3.8992e-05,  1.9295e-03, -6.0838e-05],\n",
            "          [ 4.6393e-05, -5.2298e-04,  1.4392e-03,  1.2064e-03,  2.3644e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0225]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0110]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0225,  0.0110], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 6, 7] = -0.022521378472447395\n",
            " somado na saída em [0, 1, 6, 7] = 0.011040928773581982\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 0\n",
            " alvo do kernel em x: x[0,0,21:26, 0:5]\n",
            " \n",
            " tensor([[0.7006, 0.9619, 0.1965, 0.0994, 0.6232],\n",
            "        [0.1685, 0.3713, 0.9908, 0.8435, 0.6818],\n",
            "        [0.4312, 0.7871, 0.8124, 0.3208, 0.5582],\n",
            "        [0.4508, 0.9062, 0.2921, 0.2096, 0.4673],\n",
            "        [0.0697, 0.6010, 0.1875, 0.5835, 0.5996]])\n",
            " produto: tensor([[[[-2.8571e-03,  3.1862e-04, -9.7581e-04,  3.7503e-04, -5.3100e-03],\n",
            "          [ 1.2350e-03, -2.6989e-03, -7.8770e-03, -5.3301e-03,  3.0877e-03],\n",
            "          [-1.5932e-03,  2.9454e-03, -6.8955e-03, -1.9465e-03, -2.0496e-03],\n",
            "          [-8.8598e-04, -6.9132e-03,  1.9127e-03, -4.9433e-04,  1.5001e-03],\n",
            "          [ 4.9258e-04,  1.1197e-03,  5.1276e-04,  5.6327e-03, -2.7044e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.2193e-03, -4.2796e-03,  1.4041e-03,  7.9425e-04, -5.7457e-03],\n",
            "          [ 1.4382e-03,  1.7731e-03,  4.3174e-03,  3.4726e-03,  5.6675e-03],\n",
            "          [-5.6933e-04, -6.6565e-03, -2.3313e-03, -2.2595e-03,  3.6901e-04],\n",
            "          [-8.4175e-04, -4.8608e-03, -2.6559e-04,  1.9859e-03, -3.6862e-04],\n",
            "          [ 2.2117e-05, -9.3735e-04,  2.9479e-04,  5.1995e-03,  3.6668e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0294]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0035]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0294,  0.0035], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 7, 0] = -0.029399210587143898\n",
            " somado na saída em [0, 1, 7, 0] = 0.0035084960982203484\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 1\n",
            " alvo do kernel em x: x[0,0,21:26, 3:8]\n",
            " \n",
            " tensor([[0.0994, 0.6232, 0.5908, 0.9808, 0.9848],\n",
            "        [0.8435, 0.6818, 0.8176, 0.3984, 0.2316],\n",
            "        [0.3208, 0.5582, 0.0361, 0.3112, 0.4533],\n",
            "        [0.2096, 0.4673, 0.4389, 0.1036, 0.5142],\n",
            "        [0.5835, 0.5996, 0.7442, 0.3506, 0.4934]])\n",
            " produto: tensor([[[[-0.0004,  0.0002, -0.0029,  0.0037, -0.0084],\n",
            "          [ 0.0062, -0.0050, -0.0065, -0.0025,  0.0010],\n",
            "          [-0.0012,  0.0021, -0.0003, -0.0019, -0.0017],\n",
            "          [-0.0004, -0.0036,  0.0029, -0.0002,  0.0017],\n",
            "          [ 0.0041,  0.0011,  0.0020,  0.0034, -0.0022]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0003, -0.0028,  0.0042,  0.0078, -0.0091],\n",
            "          [ 0.0072,  0.0033,  0.0036,  0.0016,  0.0019],\n",
            "          [-0.0004, -0.0047, -0.0001, -0.0022,  0.0003],\n",
            "          [-0.0004, -0.0025, -0.0004,  0.0010, -0.0004],\n",
            "          [ 0.0002, -0.0009,  0.0012,  0.0031,  0.0030]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0088]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0148]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0088,  0.0148], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 7, 1] = -0.008781194686889648\n",
            " somado na saída em [0, 1, 7, 1] = 0.014803040772676468\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 2\n",
            " alvo do kernel em x: x[0,0,21:26, 6:11]\n",
            " \n",
            " tensor([[0.9808, 0.9848, 0.7145, 0.7961, 0.7276],\n",
            "        [0.3984, 0.2316, 0.7526, 0.6348, 0.3449],\n",
            "        [0.3112, 0.4533, 0.4819, 0.5912, 0.5274],\n",
            "        [0.1036, 0.5142, 0.7655, 0.2849, 0.1029],\n",
            "        [0.3506, 0.4934, 0.2320, 0.5407, 0.5300]])\n",
            " produto: tensor([[[[-3.9995e-03,  3.2620e-04, -3.5486e-03,  3.0023e-03, -6.1995e-03],\n",
            "          [ 2.9205e-03, -1.6831e-03, -5.9835e-03, -4.0115e-03,  1.5620e-03],\n",
            "          [-1.1497e-03,  1.6962e-03, -4.0896e-03, -3.5872e-03, -1.9366e-03],\n",
            "          [-2.0361e-04, -3.9224e-03,  5.0122e-03, -6.7183e-04,  3.3036e-04],\n",
            "          [ 2.4795e-03,  9.1923e-04,  6.3437e-04,  5.2188e-03, -2.3904e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 3.1067e-03, -4.3814e-03,  5.1062e-03,  6.3584e-03, -6.7082e-03],\n",
            "          [ 3.4009e-03,  1.1058e-03,  3.2796e-03,  2.6135e-03,  2.8671e-03],\n",
            "          [-4.1086e-04, -3.8333e-03, -1.3827e-03, -4.1640e-03,  3.4867e-04],\n",
            "          [-1.9344e-04, -2.7579e-03, -6.9598e-04,  2.6989e-03, -8.1179e-05],\n",
            "          [ 1.1133e-04, -7.6950e-04,  3.6470e-04,  4.8174e-03,  3.2410e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0193]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0140]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0193,  0.0140], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 7, 2] = -0.019275419414043427\n",
            " somado na saída em [0, 1, 7, 2] = 0.014041783288121223\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 3\n",
            " alvo do kernel em x: x[0,0,21:26, 9:14]\n",
            " \n",
            " tensor([[0.7961, 0.7276, 0.4627, 0.0319, 0.3020],\n",
            "        [0.6348, 0.3449, 0.8858, 0.1437, 0.4895],\n",
            "        [0.5912, 0.5274, 0.3513, 0.8600, 0.3362],\n",
            "        [0.2849, 0.1029, 0.1462, 0.7376, 0.4695],\n",
            "        [0.5407, 0.5300, 0.9356, 0.9819, 0.4110]])\n",
            " produto: tensor([[[[-0.0032,  0.0002, -0.0023,  0.0001, -0.0026],\n",
            "          [ 0.0047, -0.0025, -0.0070, -0.0009,  0.0022],\n",
            "          [-0.0022,  0.0020, -0.0030, -0.0052, -0.0012],\n",
            "          [-0.0006, -0.0008,  0.0010, -0.0017,  0.0015],\n",
            "          [ 0.0038,  0.0010,  0.0026,  0.0095, -0.0019]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0025, -0.0032,  0.0033,  0.0003, -0.0028],\n",
            "          [ 0.0054,  0.0016,  0.0039,  0.0006,  0.0041],\n",
            "          [-0.0008, -0.0045, -0.0010, -0.0061,  0.0002],\n",
            "          [-0.0005, -0.0006, -0.0001,  0.0070, -0.0004],\n",
            "          [ 0.0002, -0.0008,  0.0015,  0.0087,  0.0025]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0066]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0210]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0066,  0.0210], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 7, 3] = -0.00661398284137249\n",
            " somado na saída em [0, 1, 7, 3] = 0.021043628454208374\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 4\n",
            " alvo do kernel em x: x[0,0,21:26, 12:17]\n",
            " \n",
            " tensor([[0.0319, 0.3020, 0.0755, 0.8552, 0.2297],\n",
            "        [0.1437, 0.4895, 0.9042, 0.6609, 0.1076],\n",
            "        [0.8600, 0.3362, 0.8992, 0.7952, 0.4890],\n",
            "        [0.7376, 0.4695, 0.8627, 0.4548, 0.5098],\n",
            "        [0.9819, 0.4110, 0.2879, 0.4350, 0.1694]])\n",
            " produto: tensor([[[[-0.0001,  0.0001, -0.0004,  0.0032, -0.0020],\n",
            "          [ 0.0011, -0.0036, -0.0072, -0.0042,  0.0005],\n",
            "          [-0.0032,  0.0013, -0.0076, -0.0048, -0.0018],\n",
            "          [-0.0014, -0.0036,  0.0056, -0.0011,  0.0016],\n",
            "          [ 0.0069,  0.0008,  0.0008,  0.0042, -0.0008]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0001, -0.0013,  0.0005,  0.0068, -0.0021],\n",
            "          [ 0.0012,  0.0023,  0.0039,  0.0027,  0.0009],\n",
            "          [-0.0011, -0.0028, -0.0026, -0.0056,  0.0003],\n",
            "          [-0.0014, -0.0025, -0.0008,  0.0043, -0.0004],\n",
            "          [ 0.0003, -0.0006,  0.0005,  0.0039,  0.0010]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0156]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0076]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0156,  0.0076], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 7, 4] = -0.015578309074044228\n",
            " somado na saída em [0, 1, 7, 4] = 0.007554702460765839\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 5\n",
            " alvo do kernel em x: x[0,0,21:26, 15:20]\n",
            " \n",
            " tensor([[0.8552, 0.2297, 0.1057, 0.4344, 0.8401],\n",
            "        [0.6609, 0.1076, 0.5814, 0.4285, 0.7065],\n",
            "        [0.7952, 0.4890, 0.3156, 0.8078, 0.5055],\n",
            "        [0.4548, 0.5098, 0.9156, 0.6635, 0.1461],\n",
            "        [0.4350, 0.1694, 0.2705, 0.1740, 0.1762]])\n",
            " produto: tensor([[[[-3.4872e-03,  7.6101e-05, -5.2518e-04,  1.6383e-03, -7.1578e-03],\n",
            "          [ 4.8445e-03, -7.8203e-04, -4.6222e-03, -2.7075e-03,  3.1998e-03],\n",
            "          [-2.9380e-03,  1.8297e-03, -2.6784e-03, -4.9011e-03, -1.8561e-03],\n",
            "          [-8.9383e-04, -3.8889e-03,  5.9949e-03, -1.5648e-03,  4.6887e-04],\n",
            "          [ 3.0760e-03,  3.1559e-04,  7.3966e-04,  1.6799e-03, -7.9470e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 2.7088e-03, -1.0222e-03,  7.5569e-04,  3.4695e-03, -7.7451e-03],\n",
            "          [ 5.6415e-03,  5.1377e-04,  2.5334e-03,  1.7639e-03,  5.8734e-03],\n",
            "          [-1.0499e-03, -4.1351e-03, -9.0556e-04, -5.6892e-03,  3.3417e-04],\n",
            "          [-8.4920e-04, -2.7344e-03, -8.3243e-04,  6.2865e-03, -1.1521e-04],\n",
            "          [ 1.3811e-04, -2.6419e-04,  4.2523e-04,  1.5507e-03,  1.0775e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0149]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0077]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0149,  0.0077], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 7, 5] = -0.014934362843632698\n",
            " somado na saída em [0, 1, 7, 5] = 0.007729812525212765\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 6\n",
            " alvo do kernel em x: x[0,0,21:26, 18:23]\n",
            " \n",
            " tensor([[0.4344, 0.8401, 0.7186, 0.6829, 0.4696],\n",
            "        [0.4285, 0.7065, 0.7816, 0.1461, 0.3353],\n",
            "        [0.8078, 0.5055, 0.2281, 0.7708, 0.5385],\n",
            "        [0.6635, 0.1461, 0.5924, 0.4857, 0.1711],\n",
            "        [0.1740, 0.1762, 0.8907, 0.6352, 0.2929]])\n",
            " produto: tensor([[[[-1.7715e-03,  2.7827e-04, -3.5691e-03,  2.5753e-03, -4.0010e-03],\n",
            "          [ 3.1409e-03, -5.1354e-03, -6.2142e-03, -9.2331e-04,  1.5187e-03],\n",
            "          [-2.9848e-03,  1.8916e-03, -1.9356e-03, -4.6766e-03, -1.9774e-03],\n",
            "          [-1.3040e-03, -1.1143e-03,  3.8788e-03, -1.1455e-03,  5.4920e-04],\n",
            "          [ 1.2307e-03,  3.2828e-04,  2.4355e-03,  6.1313e-03, -1.3210e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.3760e-03, -3.7376e-03,  5.1356e-03,  5.4540e-03, -4.3293e-03],\n",
            "          [ 3.6577e-03,  3.3738e-03,  3.4060e-03,  6.0154e-04,  2.7876e-03],\n",
            "          [-1.0666e-03, -4.2750e-03, -6.5440e-04, -5.4285e-03,  3.5601e-04],\n",
            "          [-1.2389e-03, -7.8350e-04, -5.3860e-04,  4.6018e-03, -1.3495e-04],\n",
            "          [ 5.5258e-05, -2.7481e-04,  1.4002e-03,  5.6597e-03,  1.7911e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0141]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0172]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0141,  0.0172], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 7, 6] = -0.014114798977971077\n",
            " somado na saída em [0, 1, 7, 6] = 0.017194196581840515\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 7\n",
            " alvo do kernel em x: x[0,0,21:26, 21:26]\n",
            " \n",
            " tensor([[0.6829, 0.4696, 0.0429, 0.2037, 0.0771],\n",
            "        [0.1461, 0.3353, 0.9155, 0.1354, 0.3867],\n",
            "        [0.7708, 0.5385, 0.9798, 0.0083, 0.6219],\n",
            "        [0.4857, 0.1711, 0.9303, 0.7285, 0.2891],\n",
            "        [0.6352, 0.2929, 0.0072, 0.7181, 0.1904]])\n",
            " produto: tensor([[[[-2.7847e-03,  1.5554e-04, -2.1299e-04,  7.6803e-04, -6.5721e-04],\n",
            "          [ 1.0711e-03, -2.4373e-03, -7.2787e-03, -8.5555e-04,  1.7512e-03],\n",
            "          [-2.8480e-03,  2.0153e-03, -8.3158e-03, -5.0185e-05, -2.2834e-03],\n",
            "          [-9.5455e-04, -1.3052e-03,  6.0916e-03, -1.7179e-03,  9.2796e-04],\n",
            "          [ 4.4918e-03,  5.4569e-04,  1.9658e-05,  6.9317e-03, -8.5878e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 2.1631e-03, -2.0892e-03,  3.0648e-04,  1.6265e-03, -7.1114e-04],\n",
            "          [ 1.2473e-03,  1.6012e-03,  3.9895e-03,  5.5739e-04,  3.2144e-03],\n",
            "          [-1.0177e-03, -4.5544e-03, -2.8115e-03, -5.8253e-05,  4.1111e-04],\n",
            "          [-9.0688e-04, -9.1774e-04, -8.4586e-04,  6.9014e-03, -2.2802e-04],\n",
            "          [ 2.0168e-04, -4.5681e-04,  1.1301e-05,  6.3986e-03,  1.1644e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0078]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0152]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0078,  0.0152], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [0, 0, 7, 7] = -0.007790704257786274\n",
            " somado na saída em [0, 1, 7, 7] = 0.015196793712675571\n",
            "\n",
            "ndx_amostra: 1\n",
            "\n",
            "ndx_in_channels: 0\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 0\n",
            " alvo do kernel em x: x[1,0,0:5, 0:5]\n",
            " \n",
            " tensor([[0.8272, 0.9483, 0.8171, 0.8718, 0.5126],\n",
            "        [0.1849, 0.2540, 0.4626, 0.4399, 0.1210],\n",
            "        [0.8571, 0.0257, 0.7619, 0.8098, 0.6170],\n",
            "        [0.0745, 0.0971, 0.4206, 0.9615, 0.2299],\n",
            "        [0.3994, 0.1294, 0.4593, 0.8265, 0.7534]])\n",
            " produto: tensor([[[[-3.3732e-03,  3.1411e-04, -4.0581e-03,  3.2878e-03, -4.3680e-03],\n",
            "          [ 1.3556e-03, -1.8458e-03, -3.6779e-03, -2.7799e-03,  5.4779e-04],\n",
            "          [-3.1671e-03,  9.6258e-05, -6.4663e-03, -4.9133e-03, -2.2655e-03],\n",
            "          [-1.4647e-04, -7.4084e-04,  2.7542e-03, -2.2676e-03,  7.3794e-04],\n",
            "          [ 2.8246e-03,  2.4113e-04,  1.2561e-03,  7.9774e-03, -3.3980e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.6202e-03, -4.2190e-03,  5.8392e-03,  6.9629e-03, -4.7264e-03],\n",
            "          [ 1.5786e-03,  1.2127e-03,  2.0159e-03,  1.8111e-03,  1.0055e-03],\n",
            "          [-1.1318e-03, -2.1754e-04, -2.1862e-03, -5.7032e-03,  4.0787e-04],\n",
            "          [-1.3915e-04, -5.2090e-04, -3.8243e-04,  9.1097e-03, -1.8133e-04],\n",
            "          [ 1.2682e-04, -2.0186e-04,  7.2212e-04,  7.3638e-03,  4.6072e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0221]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0258]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0221,  0.0258], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 0, 0] = -0.022075146436691284\n",
            " somado na saída em [1, 1, 0, 0] = 0.025773724541068077\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 1\n",
            " alvo do kernel em x: x[1,0,0:5, 3:8]\n",
            " \n",
            " tensor([[0.8718, 0.5126, 0.0086, 0.8053, 0.0787],\n",
            "        [0.4399, 0.1210, 0.0457, 0.4320, 0.6941],\n",
            "        [0.8098, 0.6170, 0.9368, 0.9163, 0.7747],\n",
            "        [0.9615, 0.2299, 0.3241, 0.2886, 0.6110],\n",
            "        [0.8265, 0.7534, 0.0449, 0.3689, 0.1210]])\n",
            " produto: tensor([[[[-3.5551e-03,  1.6981e-04, -4.2744e-05,  3.0368e-03, -6.7086e-04],\n",
            "          [ 3.2250e-03, -8.7914e-04, -3.6298e-04, -2.7295e-03,  3.1434e-03],\n",
            "          [-2.9922e-03,  2.3089e-03, -7.9511e-03, -5.5595e-03, -2.8447e-03],\n",
            "          [-1.8896e-03, -1.7538e-03,  2.1221e-03, -6.8053e-04,  1.9612e-03],\n",
            "          [ 5.8442e-03,  1.4037e-03,  1.2282e-04,  3.5610e-03, -5.4580e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 2.7615e-03, -2.2808e-03,  6.1505e-05,  6.4314e-03, -7.2591e-04],\n",
            "          [ 3.7556e-03,  5.7757e-04,  1.9895e-04,  1.7783e-03,  5.7698e-03],\n",
            "          [-1.0693e-03, -5.2179e-03, -2.6882e-03, -6.4534e-03,  5.1216e-04],\n",
            "          [-1.7953e-03, -1.2331e-03, -2.9467e-04,  2.7339e-03, -4.8192e-04],\n",
            "          [ 2.6240e-04, -1.1751e-03,  7.0607e-05,  3.2871e-03,  7.4001e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0056]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0055]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0056,  0.0055], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 0, 1] = -0.00555855268612504\n",
            " somado na saída em [1, 1, 0, 1] = 0.005525183863937855\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 2\n",
            " alvo do kernel em x: x[1,0,0:5, 6:11]\n",
            " \n",
            " tensor([[0.8053, 0.0787, 0.6293, 0.2914, 0.8203],\n",
            "        [0.4320, 0.6941, 0.6661, 0.1499, 0.7697],\n",
            "        [0.9163, 0.7747, 0.8472, 0.9266, 0.8811],\n",
            "        [0.2886, 0.6110, 0.8021, 0.2710, 0.2675],\n",
            "        [0.3689, 0.1210, 0.1820, 0.7347, 0.6027]])\n",
            " produto: tensor([[[[-3.2837e-03,  2.6081e-05, -3.1256e-03,  1.0988e-03, -6.9891e-03],\n",
            "          [ 3.1665e-03, -5.0448e-03, -5.2960e-03, -9.4703e-04,  3.4858e-03],\n",
            "          [-3.3857e-03,  2.8992e-03, -7.1906e-03, -5.6218e-03, -3.2352e-03],\n",
            "          [-5.6709e-04, -4.6610e-03,  5.2521e-03, -6.3906e-04,  8.5863e-04],\n",
            "          [ 2.6088e-03,  2.2546e-04,  4.9766e-04,  7.0920e-03, -2.7184e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.5507e-03, -3.5030e-04,  4.4974e-03,  2.3271e-03, -7.5626e-03],\n",
            "          [ 3.6874e-03,  3.3143e-03,  2.9027e-03,  6.1699e-04,  6.3983e-03],\n",
            "          [-1.2099e-03, -6.5520e-03, -2.4311e-03, -6.5257e-03,  5.8248e-04],\n",
            "          [-5.3877e-04, -3.2773e-03, -7.2929e-04,  2.5673e-03, -2.1099e-04],\n",
            "          [ 1.1713e-04, -1.8874e-04,  2.8610e-04,  6.5465e-03,  3.6857e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0255]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0105]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0255,  0.0105], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 0, 2] = -0.025494059547781944\n",
            " somado na saída em [1, 1, 0, 2] = 0.010503539815545082\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 3\n",
            " alvo do kernel em x: x[1,0,0:5, 9:14]\n",
            " \n",
            " tensor([[0.2914, 0.8203, 0.8336, 0.4739, 0.3258],\n",
            "        [0.1499, 0.7697, 0.1543, 0.2570, 0.9078],\n",
            "        [0.9266, 0.8811, 0.7464, 0.1591, 0.7705],\n",
            "        [0.2710, 0.2675, 0.6637, 0.0328, 0.7964],\n",
            "        [0.7347, 0.6027, 0.9755, 0.6853, 0.1452]])\n",
            " produto: tensor([[[[-1.1882e-03,  2.7171e-04, -4.1403e-03,  1.7873e-03, -2.7764e-03],\n",
            "          [ 1.0986e-03, -5.5943e-03, -1.2269e-03, -1.6240e-03,  4.1114e-03],\n",
            "          [-3.4236e-03,  3.2973e-03, -6.3351e-03, -9.6521e-04, -2.8293e-03],\n",
            "          [-5.3253e-04, -2.0406e-03,  4.3457e-03, -7.7437e-05,  2.5564e-03],\n",
            "          [ 5.1955e-03,  1.1229e-03,  2.6676e-03,  6.6147e-03, -6.5482e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 9.2294e-04, -3.6495e-03,  5.9575e-03,  3.7852e-03, -3.0042e-03],\n",
            "          [ 1.2794e-03,  3.6753e-03,  6.7246e-04,  1.0580e-03,  7.5465e-03],\n",
            "          [-1.2235e-03, -7.4516e-03, -2.1419e-03, -1.1204e-03,  5.0938e-04],\n",
            "          [-5.0594e-04, -1.4348e-03, -6.0343e-04,  3.1109e-04, -6.2819e-04],\n",
            "          [ 2.3327e-04, -9.4003e-04,  1.5336e-03,  6.1060e-03,  8.8783e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0003]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0118]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0003,  0.0118], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 0, 3] = -0.00033946568146348\n",
            " somado na saída em [1, 1, 0, 3] = 0.011775064282119274\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 4\n",
            " alvo do kernel em x: x[1,0,0:5, 12:17]\n",
            " \n",
            " tensor([[0.4739, 0.3258, 0.8870, 0.3426, 0.1150],\n",
            "        [0.2570, 0.9078, 0.6252, 0.6827, 0.0185],\n",
            "        [0.1591, 0.7705, 0.4842, 0.7066, 0.4988],\n",
            "        [0.0328, 0.7964, 0.3069, 0.7251, 0.8869],\n",
            "        [0.6853, 0.1452, 0.6365, 0.1683, 0.0279]])\n",
            " produto: tensor([[[[-1.9326e-03,  1.0794e-04, -4.4051e-03,  1.2921e-03, -9.8013e-04],\n",
            "          [ 1.8840e-03, -6.5982e-03, -4.9708e-03, -4.3137e-03,  8.3595e-05],\n",
            "          [-5.8781e-04,  2.8835e-03, -4.1099e-03, -4.2873e-03, -1.8316e-03],\n",
            "          [-6.4529e-05, -6.0757e-03,  2.0099e-03, -1.7100e-03,  2.8467e-03],\n",
            "          [ 4.8459e-03,  2.7050e-04,  1.7406e-03,  1.6241e-03, -1.2602e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5012e-03, -1.4498e-03,  6.3386e-03,  2.7365e-03, -1.0606e-03],\n",
            "          [ 2.1939e-03,  4.3349e-03,  2.7245e-03,  2.8104e-03,  1.5344e-04],\n",
            "          [-2.1006e-04, -6.5165e-03, -1.3895e-03, -4.9766e-03,  3.2977e-04],\n",
            "          [-6.1307e-05, -4.2719e-03, -2.7908e-04,  6.8696e-03, -6.9951e-04],\n",
            "          [ 2.1758e-04, -2.2644e-04,  1.0007e-03,  1.4992e-03,  1.7086e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0224]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0117]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0224,  0.0117], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 0, 4] = -0.02240452915430069\n",
            " somado na saída em [1, 1, 0, 4] = 0.011739895679056644\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 5\n",
            " alvo do kernel em x: x[1,0,0:5, 15:20]\n",
            " \n",
            " tensor([[0.3426, 0.1150, 0.1767, 0.0215, 0.8699],\n",
            "        [0.6827, 0.0185, 0.0652, 0.4068, 0.9610],\n",
            "        [0.7066, 0.4988, 0.7778, 0.0516, 0.1730],\n",
            "        [0.7251, 0.8869, 0.6115, 0.0128, 0.3534],\n",
            "        [0.1683, 0.0279, 0.0741, 0.9723, 0.2570]])\n",
            " produto: tensor([[[[-1.3972e-03,  3.8104e-05, -8.7782e-04,  8.0910e-05, -7.4121e-03],\n",
            "          [ 5.0042e-03, -1.3416e-04, -5.1808e-04, -2.5708e-03,  4.3521e-03],\n",
            "          [-2.6110e-03,  1.8667e-03, -6.6016e-03, -3.1309e-04, -6.3514e-04],\n",
            "          [-1.4250e-03, -6.7655e-03,  4.0042e-03, -3.0216e-05,  1.1343e-03],\n",
            "          [ 1.1898e-03,  5.2057e-05,  2.0265e-04,  9.3849e-03, -1.1590e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0853e-03, -5.1179e-04,  1.2631e-03,  1.7135e-04, -8.0203e-03],\n",
            "          [ 5.8275e-03,  8.8139e-05,  2.8396e-04,  1.6749e-03,  7.9885e-03],\n",
            "          [-9.3303e-04, -4.2187e-03, -2.2319e-03, -3.6343e-04,  1.1435e-04],\n",
            "          [-1.3538e-03, -4.7570e-03, -5.5601e-04,  1.2139e-04, -2.7874e-04],\n",
            "          [ 5.3423e-05, -4.3578e-05,  1.1650e-04,  8.6630e-03,  1.5714e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0051]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0058]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0051,  0.0058], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 0, 5] = -0.005140447989106178\n",
            " somado na saída em [1, 1, 0, 5] = 0.005754558835178614\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 6\n",
            " alvo do kernel em x: x[1,0,0:5, 18:23]\n",
            " \n",
            " tensor([[0.0215, 0.8699, 0.8756, 0.3727, 0.7206],\n",
            "        [0.4068, 0.9610, 0.0068, 0.7761, 0.2644],\n",
            "        [0.0516, 0.1730, 0.3308, 0.9275, 0.1775],\n",
            "        [0.0128, 0.3534, 0.9266, 0.0387, 0.9173],\n",
            "        [0.9723, 0.2570, 0.8827, 0.1683, 0.9514]])\n",
            " produto: tensor([[[[-8.7489e-05,  2.8815e-04, -4.3487e-03,  1.4055e-03, -6.1398e-03],\n",
            "          [ 2.9823e-03, -6.9846e-03, -5.3958e-05, -4.9041e-03,  1.1975e-03],\n",
            "          [-1.9067e-04,  6.4732e-04, -2.8078e-03, -5.6276e-03, -6.5178e-04],\n",
            "          [-2.5179e-05, -2.6959e-03,  6.0671e-03, -9.1294e-05,  2.9445e-03],\n",
            "          [ 6.8753e-03,  4.7878e-04,  2.4138e-03,  1.6241e-03, -4.2909e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 6.7959e-05, -3.8703e-03,  6.2574e-03,  2.9766e-03, -6.6437e-03],\n",
            "          [ 3.4730e-03,  4.5887e-03,  2.9574e-05,  3.1951e-03,  2.1981e-03],\n",
            "          [-6.8137e-05, -1.4629e-03, -9.4930e-04, -6.5324e-03,  1.1735e-04],\n",
            "          [-2.3922e-05, -1.8955e-03, -8.4246e-04,  3.6675e-04, -7.2355e-04],\n",
            "          [ 3.0870e-04, -4.0079e-04,  1.3877e-03,  1.4992e-03,  5.8177e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0120]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0089]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0120,  0.0089], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 0, 6] = -0.01197536289691925\n",
            " somado na saída em [1, 1, 0, 6] = 0.008870836347341537\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 0, 7\n",
            " alvo do kernel em x: x[1,0,0:5, 21:26]\n",
            " \n",
            " tensor([[3.7270e-01, 7.2059e-01, 7.8469e-01, 2.9878e-01, 5.8486e-01],\n",
            "        [7.7611e-01, 2.6442e-01, 1.4285e-01, 8.8732e-01, 1.2021e-01],\n",
            "        [9.2754e-01, 1.7751e-01, 4.6892e-01, 3.3725e-01, 2.6404e-02],\n",
            "        [3.8711e-02, 9.1733e-01, 1.1971e-01, 3.9132e-01, 8.4936e-01],\n",
            "        [1.6826e-01, 9.5139e-01, 2.0317e-01, 6.4285e-01, 8.4507e-04]])\n",
            " produto: tensor([[[[-1.5198e-03,  2.3869e-04, -3.8972e-03,  1.1267e-03, -4.9833e-03],\n",
            "          [ 5.6892e-03, -1.9219e-03, -1.1357e-03, -5.6069e-03,  5.4441e-04],\n",
            "          [-3.4272e-03,  6.6428e-04, -3.9798e-03, -2.0462e-03, -9.6950e-05],\n",
            "          [-7.6076e-05, -6.9980e-03,  7.8385e-04, -9.2287e-04,  2.7263e-03],\n",
            "          [ 1.1898e-03,  1.7725e-03,  5.5556e-04,  6.2052e-03, -3.8114e-06]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1805e-03, -3.2060e-03,  5.6077e-03,  2.3862e-03, -5.3923e-03],\n",
            "          [ 6.6252e-03,  1.2626e-03,  6.2250e-04,  3.6529e-03,  9.9928e-04],\n",
            "          [-1.2247e-03, -1.5012e-03, -1.3456e-03, -2.3752e-03,  1.7455e-05],\n",
            "          [-7.2277e-05, -4.9204e-03, -1.0884e-04,  3.7074e-03, -6.6994e-04],\n",
            "          [ 5.3422e-05, -1.4838e-03,  3.1939e-04,  5.7279e-03,  5.1676e-06]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0151]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0099]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0151,  0.0099], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 0, 7] = -0.015119027346372604\n",
            " somado na saída em [1, 1, 0, 7] = 0.009867568500339985\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 0\n",
            " alvo do kernel em x: x[1,0,3:8, 0:5]\n",
            " \n",
            " tensor([[0.0745, 0.0971, 0.4206, 0.9615, 0.2299],\n",
            "        [0.3994, 0.1294, 0.4593, 0.8265, 0.7534],\n",
            "        [0.4611, 0.2826, 0.3834, 0.4523, 0.8467],\n",
            "        [0.0031, 0.9999, 0.5459, 0.2633, 0.5924],\n",
            "        [0.0329, 0.6061, 0.9745, 0.2383, 0.3850]])\n",
            " produto: tensor([[[[-3.0392e-04,  3.2168e-05, -2.0891e-03,  3.6261e-03, -1.9588e-03],\n",
            "          [ 2.9280e-03, -9.4073e-04, -3.6520e-03, -5.2223e-03,  3.4122e-03],\n",
            "          [-1.7036e-03,  1.0574e-03, -3.2536e-03, -2.7443e-03, -3.1087e-03],\n",
            "          [-6.1455e-06, -7.6275e-03,  3.5746e-03, -6.2103e-04,  1.9015e-03],\n",
            "          [ 2.3278e-04,  1.1293e-03,  2.6648e-03,  2.3000e-03, -1.7362e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.3608e-04, -4.3207e-04,  3.0060e-03,  7.6794e-03, -2.1196e-03],\n",
            "          [ 3.4098e-03,  6.1803e-04,  2.0017e-03,  3.4023e-03,  6.2633e-03],\n",
            "          [-6.0878e-04, -2.3897e-03, -1.1000e-03, -3.1855e-03,  5.5970e-04],\n",
            "          [-5.8386e-06, -5.3631e-03, -4.9635e-04,  2.4949e-03, -4.6726e-04],\n",
            "          [ 1.0452e-05, -9.4534e-04,  1.5320e-03,  2.1231e-03,  2.3540e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0121]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0186]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0121,  0.0186], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 1, 0] = -0.012108854949474335\n",
            " somado na saída em [1, 1, 1, 0] = 0.018577054142951965\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 1\n",
            " alvo do kernel em x: x[1,0,3:8, 3:8]\n",
            " \n",
            " tensor([[0.9615, 0.2299, 0.3241, 0.2886, 0.6110],\n",
            "        [0.8265, 0.7534, 0.0449, 0.3689, 0.1210],\n",
            "        [0.4523, 0.8467, 0.0259, 0.1286, 0.6807],\n",
            "        [0.2633, 0.5924, 0.1780, 0.2866, 0.5828],\n",
            "        [0.2383, 0.3850, 0.5965, 0.3689, 0.7561]])\n",
            " produto: tensor([[[[-3.9209e-03,  7.6152e-05, -1.6096e-03,  1.0882e-03, -5.2060e-03],\n",
            "          [ 6.0583e-03, -5.4762e-03, -3.5708e-04, -2.3311e-03,  5.4808e-04],\n",
            "          [-1.6713e-03,  3.1683e-03, -2.1955e-04, -7.7996e-04, -2.4993e-03],\n",
            "          [-5.1751e-04, -4.5192e-03,  1.1658e-03, -6.7599e-04,  1.8706e-03],\n",
            "          [ 1.6850e-03,  7.1719e-04,  1.6310e-03,  3.5609e-03, -3.4100e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 3.0457e-03, -1.0228e-03,  2.3161e-03,  2.3046e-03, -5.6332e-03],\n",
            "          [ 7.0550e-03,  3.5977e-03,  1.9572e-04,  1.5187e-03,  1.0060e-03],\n",
            "          [-5.9723e-04, -7.1602e-03, -7.4229e-05, -9.0537e-04,  4.4998e-04],\n",
            "          [-4.9167e-04, -3.1775e-03, -1.6188e-04,  2.7157e-03, -4.5966e-04],\n",
            "          [ 7.5655e-05, -6.0037e-04,  9.3768e-04,  3.2870e-03,  4.6233e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0116]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0128]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0116,  0.0128], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 1, 1] = -0.011624184437096119\n",
            " somado na saída em [1, 1, 1, 1] = 0.012844879180192947\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 2\n",
            " alvo do kernel em x: x[1,0,3:8, 6:11]\n",
            " \n",
            " tensor([[0.2886, 0.6110, 0.8021, 0.2710, 0.2675],\n",
            "        [0.3689, 0.1210, 0.1820, 0.7347, 0.6027],\n",
            "        [0.1286, 0.6807, 0.4233, 0.3871, 0.4767],\n",
            "        [0.2866, 0.5828, 0.3426, 0.1260, 0.4786],\n",
            "        [0.3689, 0.7561, 0.6216, 0.4727, 0.4849]])\n",
            " produto: tensor([[[[-0.0012,  0.0002, -0.0040,  0.0010, -0.0023],\n",
            "          [ 0.0027, -0.0009, -0.0014, -0.0046,  0.0027],\n",
            "          [-0.0005,  0.0025, -0.0036, -0.0023, -0.0018],\n",
            "          [-0.0006, -0.0044,  0.0022, -0.0003,  0.0015],\n",
            "          [ 0.0026,  0.0014,  0.0017,  0.0046, -0.0022]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0009, -0.0027,  0.0057,  0.0022, -0.0025],\n",
            "          [ 0.0031,  0.0006,  0.0008,  0.0030,  0.0050],\n",
            "          [-0.0002, -0.0058, -0.0012, -0.0027,  0.0003],\n",
            "          [-0.0005, -0.0031, -0.0003,  0.0012, -0.0004],\n",
            "          [ 0.0001, -0.0012,  0.0010,  0.0042,  0.0030]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0068]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0106]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0068,  0.0106], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 1, 2] = -0.00680379057303071\n",
            " somado na saída em [1, 1, 1, 2] = 0.010564962401986122\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 3\n",
            " alvo do kernel em x: x[1,0,3:8, 9:14]\n",
            " \n",
            " tensor([[0.2710, 0.2675, 0.6637, 0.0328, 0.7964],\n",
            "        [0.7347, 0.6027, 0.9755, 0.6853, 0.1452],\n",
            "        [0.3871, 0.4767, 0.9563, 0.0205, 0.8683],\n",
            "        [0.1260, 0.4786, 0.9687, 0.4984, 0.5602],\n",
            "        [0.4727, 0.4849, 0.3053, 0.4298, 0.1450]])\n",
            " produto: tensor([[[[-1.1050e-03,  8.8607e-05, -3.2962e-03,  1.2383e-04, -6.7860e-03],\n",
            "          [ 5.3858e-03, -4.3809e-03, -7.7558e-03, -4.3302e-03,  6.5756e-04],\n",
            "          [-1.4302e-03,  1.7840e-03, -8.1162e-03, -1.2458e-04, -3.1880e-03],\n",
            "          [-2.4767e-04, -3.6512e-03,  6.3430e-03, -1.1755e-03,  1.7981e-03],\n",
            "          [ 3.3426e-03,  9.0333e-04,  8.3493e-04,  4.1491e-03, -6.5407e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 8.5834e-04, -1.1901e-03,  4.7430e-03,  2.6224e-04, -7.3428e-03],\n",
            "          [ 6.2719e-03,  2.8782e-03,  4.2510e-03,  2.8211e-03,  1.2070e-03],\n",
            "          [-5.1110e-04, -4.0318e-03, -2.7440e-03, -1.4461e-04,  5.7398e-04],\n",
            "          [-2.3531e-04, -2.5672e-03, -8.8076e-04,  4.7223e-03, -4.4183e-04],\n",
            "          [ 1.5008e-04, -7.5620e-04,  4.8000e-04,  3.8300e-03,  8.8681e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0208]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0131]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0208,  0.0131], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 1, 3] = -0.020830731838941574\n",
            " somado na saída em [1, 1, 1, 3] = 0.013090033084154129\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 4\n",
            " alvo do kernel em x: x[1,0,3:8, 12:17]\n",
            " \n",
            " tensor([[0.0328, 0.7964, 0.3069, 0.7251, 0.8869],\n",
            "        [0.6853, 0.1452, 0.6365, 0.1683, 0.0279],\n",
            "        [0.0205, 0.8683, 0.7231, 0.2049, 0.3977],\n",
            "        [0.4984, 0.5602, 0.4914, 0.1934, 0.5655],\n",
            "        [0.4298, 0.1450, 0.9963, 0.4436, 0.6687]])\n",
            " produto: tensor([[[[-1.3390e-04,  2.6381e-04, -1.5245e-03,  2.7345e-03, -7.5565e-03],\n",
            "          [ 5.0234e-03, -1.0553e-03, -5.0608e-03, -1.0632e-03,  1.2655e-04],\n",
            "          [-7.5869e-05,  3.2491e-03, -6.1373e-03, -1.2434e-03, -1.4604e-03],\n",
            "          [-9.7954e-04, -4.2733e-03,  3.2179e-03, -4.5599e-04,  1.8151e-03],\n",
            "          [ 3.0396e-03,  2.7019e-04,  2.7244e-03,  4.2816e-03, -3.0160e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0401e-04, -3.5434e-03,  2.1936e-03,  5.7911e-03, -8.1766e-03],\n",
            "          [ 5.8499e-03,  6.9330e-04,  2.7739e-03,  6.9268e-04,  2.3228e-04],\n",
            "          [-2.7112e-05, -7.3428e-03, -2.0750e-03, -1.4433e-03,  2.6292e-04],\n",
            "          [-9.3063e-04, -3.0046e-03, -4.4683e-04,  1.8319e-03, -4.4601e-04],\n",
            "          [ 1.3648e-04, -2.2618e-04,  1.5663e-03,  3.9522e-03,  4.0892e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0073]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0025]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0073,  0.0025], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 1, 4] = -0.0072898478247225285\n",
            " somado na saída em [1, 1, 1, 4] = 0.002507175784558058\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 5\n",
            " alvo do kernel em x: x[1,0,3:8, 15:20]\n",
            " \n",
            " tensor([[0.7251, 0.8869, 0.6115, 0.0128, 0.3534],\n",
            "        [0.1683, 0.0279, 0.0741, 0.9723, 0.2570],\n",
            "        [0.2049, 0.3977, 0.3508, 0.3306, 0.1937],\n",
            "        [0.1934, 0.5655, 0.1395, 0.7179, 0.9780],\n",
            "        [0.4436, 0.6687, 0.6897, 0.8295, 0.3543]])\n",
            " produto: tensor([[[[-2.9568e-03,  2.9377e-04, -3.0372e-03,  4.8318e-05, -3.0111e-03],\n",
            "          [ 1.2334e-03, -2.0309e-04, -5.8920e-04, -6.1436e-03,  1.1639e-03],\n",
            "          [-7.5721e-04,  1.4883e-03, -2.9771e-03, -2.0056e-03, -7.1138e-04],\n",
            "          [-3.7998e-04, -4.3137e-03,  9.1326e-04, -1.6931e-03,  3.1392e-03],\n",
            "          [ 3.1366e-03,  1.2459e-03,  1.8861e-03,  8.0071e-03, -1.5980e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.2968e-03, -3.9458e-03,  4.3703e-03,  1.0233e-04, -3.2582e-03],\n",
            "          [ 1.4363e-03,  1.3342e-04,  3.2294e-04,  4.0026e-03,  2.1363e-03],\n",
            "          [-2.7059e-04, -3.3636e-03, -1.0065e-03, -2.3281e-03,  1.2808e-04],\n",
            "          [-3.6101e-04, -3.0331e-03, -1.2681e-04,  6.8016e-03, -7.7139e-04],\n",
            "          [ 1.4083e-04, -1.0430e-03,  1.0843e-03,  7.3912e-03,  2.1666e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0078]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0130]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0078,  0.0130], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 1, 5] = -0.007821120321750641\n",
            " somado na saída em [1, 1, 1, 5] = 0.01300564594566822\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 6\n",
            " alvo do kernel em x: x[1,0,3:8, 18:23]\n",
            " \n",
            " tensor([[0.0128, 0.3534, 0.9266, 0.0387, 0.9173],\n",
            "        [0.9723, 0.2570, 0.8827, 0.1683, 0.9514],\n",
            "        [0.3306, 0.1937, 0.9071, 0.9709, 0.6138],\n",
            "        [0.7179, 0.9780, 0.9830, 0.3872, 0.0545],\n",
            "        [0.8295, 0.3543, 0.1060, 0.4351, 0.0805]])\n",
            " produto: tensor([[[[-5.2246e-05,  1.1706e-04, -4.6019e-03,  1.4599e-04, -7.8161e-03],\n",
            "          [ 7.1272e-03, -1.8679e-03, -7.0179e-03, -1.0632e-03,  4.3088e-03],\n",
            "          [-1.2214e-03,  7.2501e-04, -7.6988e-03, -5.8906e-03, -2.2538e-03],\n",
            "          [-1.4108e-03, -7.4607e-03,  6.4368e-03, -9.1308e-04,  1.7485e-04],\n",
            "          [ 5.8660e-03,  6.6010e-04,  2.8997e-04,  4.1994e-03, -3.6301e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 4.0584e-05, -1.5723e-03,  6.6218e-03,  3.0917e-04, -8.4575e-03],\n",
            "          [ 8.2997e-03,  1.2271e-03,  3.8466e-03,  6.9268e-04,  7.9089e-03],\n",
            "          [-4.3648e-04, -1.6385e-03, -2.6029e-03, -6.8377e-03,  4.0578e-04],\n",
            "          [-1.3404e-03, -5.2457e-03, -8.9378e-04,  3.6681e-03, -4.2967e-05],\n",
            "          [ 2.6338e-04, -5.5258e-04,  1.6670e-04,  3.8764e-03,  4.9218e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0196]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0082]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0196,  0.0082], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 1, 6] = -0.01958039589226246\n",
            " somado na saída em [1, 1, 1, 6] = 0.008198253810405731\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 1, 7\n",
            " alvo do kernel em x: x[1,0,3:8, 21:26]\n",
            " \n",
            " tensor([[3.8711e-02, 9.1733e-01, 1.1971e-01, 3.9132e-01, 8.4936e-01],\n",
            "        [1.6826e-01, 9.5139e-01, 2.0317e-01, 6.4285e-01, 8.4507e-04],\n",
            "        [9.7089e-01, 6.1383e-01, 7.6678e-01, 9.0303e-01, 7.4551e-01],\n",
            "        [3.8717e-01, 5.4474e-02, 5.8483e-01, 8.7221e-01, 5.9142e-01],\n",
            "        [4.3506e-01, 8.0488e-02, 3.4315e-01, 2.4547e-01, 3.7389e-03]])\n",
            " produto: tensor([[[[-1.5786e-04,  3.0386e-04, -5.9455e-04,  1.4757e-03, -7.2370e-03],\n",
            "          [ 1.2334e-03, -6.9151e-03, -1.6153e-03, -4.0621e-03,  3.8273e-06],\n",
            "          [-3.5874e-03,  2.2970e-03, -6.5079e-03, -5.4789e-03, -2.7374e-03],\n",
            "          [-7.6087e-04, -4.1556e-04,  3.8294e-03, -2.0569e-03,  1.8984e-03],\n",
            "          [ 3.0765e-03,  1.4995e-04,  9.3836e-04,  2.3695e-03, -1.6863e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2262e-04, -4.0813e-03,  8.5551e-04,  3.1253e-03, -7.8309e-03],\n",
            "          [ 1.4363e-03,  4.5430e-03,  8.8533e-04,  2.6465e-03,  7.0251e-06],\n",
            "          [-1.2820e-03, -5.1911e-03, -2.2003e-03, -6.3598e-03,  4.9284e-04],\n",
            "          [-7.2288e-04, -2.9219e-04, -5.3174e-04,  8.2633e-03, -4.6648e-04],\n",
            "          [ 1.3813e-04, -1.2553e-04,  5.3946e-04,  2.1872e-03,  2.2863e-05]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0246]]],\n",
            "\n",
            "\n",
            "        [[[-0.0038]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0246, -0.0038], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 1, 7] = -0.02456779032945633\n",
            " somado na saída em [1, 1, 1, 7] = -0.0038187066093087196\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 0\n",
            " alvo do kernel em x: x[1,0,6:11, 0:5]\n",
            " \n",
            " tensor([[0.0031, 0.9999, 0.5459, 0.2633, 0.5924],\n",
            "        [0.0329, 0.6061, 0.9745, 0.2383, 0.3850],\n",
            "        [0.5116, 0.8966, 0.8308, 0.9115, 0.5589],\n",
            "        [0.3059, 0.7875, 0.4745, 0.9682, 0.5997],\n",
            "        [0.2981, 0.3215, 0.1325, 0.9128, 0.8084]])\n",
            " produto: tensor([[[[-1.2752e-05,  3.3120e-04, -2.7113e-03,  9.9309e-04, -5.0476e-03],\n",
            "          [ 2.4131e-04, -4.4057e-03, -7.7479e-03, -1.5057e-03,  1.7434e-03],\n",
            "          [-1.8903e-03,  3.3552e-03, -7.0508e-03, -5.5303e-03, -2.0520e-03],\n",
            "          [-6.0121e-04, -6.0075e-03,  3.1067e-03, -2.2834e-03,  1.9250e-03],\n",
            "          [ 2.1083e-03,  5.9897e-04,  3.6223e-04,  8.8111e-03, -3.6460e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 9.9053e-06, -4.4485e-03,  3.9013e-03,  2.1032e-03, -5.4618e-03],\n",
            "          [ 2.8101e-04,  2.8944e-03,  4.2467e-03,  9.8095e-04,  3.2001e-03],\n",
            "          [-6.7552e-04, -7.5826e-03, -2.3838e-03, -6.4195e-03,  3.6944e-04],\n",
            "          [-5.7119e-04, -4.2240e-03, -4.3138e-04,  9.1731e-03, -4.7303e-04],\n",
            "          [ 9.4659e-05, -5.0141e-04,  2.0825e-04,  8.1333e-03,  4.9434e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0269]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0074]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0269,  0.0074], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 2, 0] = -0.02691597118973732\n",
            " somado na saída em [1, 1, 2, 0] = 0.007366979029029608\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 1\n",
            " alvo do kernel em x: x[1,0,6:11, 3:8]\n",
            " \n",
            " tensor([[0.2633, 0.5924, 0.1780, 0.2866, 0.5828],\n",
            "        [0.2383, 0.3850, 0.5965, 0.3689, 0.7561],\n",
            "        [0.9115, 0.5589, 0.8239, 0.1299, 0.0250],\n",
            "        [0.9682, 0.5997, 0.5014, 0.8170, 0.4343],\n",
            "        [0.9128, 0.8084, 0.3976, 0.3634, 0.9109]])\n",
            " produto: tensor([[[[-1.0738e-03,  1.9623e-04, -8.8428e-04,  1.0810e-03, -4.9655e-03],\n",
            "          [ 1.7467e-03, -2.7980e-03, -4.7421e-03, -2.3311e-03,  3.4242e-03],\n",
            "          [-3.3679e-03,  2.0913e-03, -6.9924e-03, -7.8803e-04, -9.1833e-05],\n",
            "          [-1.9028e-03, -4.5750e-03,  3.2828e-03, -1.9269e-03,  1.3941e-03],\n",
            "          [ 6.4549e-03,  1.5061e-03,  1.0872e-03,  3.5074e-03, -4.1081e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 8.3413e-04, -2.6357e-03,  1.2724e-03,  2.2893e-03, -5.3729e-03],\n",
            "          [ 2.0341e-03,  1.8382e-03,  2.5992e-03,  1.5187e-03,  6.2852e-03],\n",
            "          [-1.2035e-03, -4.7262e-03, -2.3641e-03, -9.1473e-04,  1.6534e-05],\n",
            "          [-1.8078e-03, -3.2168e-03, -4.5584e-04,  7.7407e-03, -3.4258e-04],\n",
            "          [ 2.8982e-04, -1.2608e-03,  6.2506e-04,  3.2377e-03,  5.5699e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0148]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0119]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0148,  0.0119], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 2, 1] = -0.014775482937693596\n",
            " somado na saída em [1, 1, 2, 1] = 0.011850018054246902\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 2\n",
            " alvo do kernel em x: x[1,0,6:11, 6:11]\n",
            " \n",
            " tensor([[0.2866, 0.5828, 0.3426, 0.1260, 0.4786],\n",
            "        [0.3689, 0.7561, 0.6216, 0.4727, 0.4849],\n",
            "        [0.1299, 0.0250, 0.6655, 0.2683, 0.9916],\n",
            "        [0.8170, 0.4343, 0.7601, 0.6575, 0.4868],\n",
            "        [0.3634, 0.9109, 0.3658, 0.3227, 0.6418]])\n",
            " produto: tensor([[[[-1.1689e-03,  1.9304e-04, -1.7014e-03,  4.7528e-04, -4.0781e-03],\n",
            "          [ 2.7043e-03, -5.4954e-03, -4.9417e-03, -2.9868e-03,  2.1959e-03],\n",
            "          [-4.7991e-04,  9.3593e-05, -5.6480e-03, -1.6278e-03, -3.6408e-03],\n",
            "          [-1.6057e-03, -3.3133e-03,  4.9772e-03, -1.5505e-03,  1.5626e-03],\n",
            "          [ 2.5695e-03,  1.6970e-03,  1.0002e-03,  3.1145e-03, -2.8948e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 9.0794e-04, -2.5928e-03,  2.4482e-03,  1.0065e-03, -4.4127e-03],\n",
            "          [ 3.1492e-03,  3.6104e-03,  2.7085e-03,  1.9459e-03,  4.0307e-03],\n",
            "          [-1.7150e-04, -2.1151e-04, -1.9096e-03, -1.8895e-03,  6.5550e-04],\n",
            "          [-1.5255e-03, -2.3297e-03, -6.9111e-04,  6.2290e-03, -3.8396e-04],\n",
            "          [ 1.1537e-04, -1.4206e-03,  5.7499e-04,  2.8749e-03,  3.9248e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0206]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0166]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0206,  0.0166], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 2, 2] = -0.020550064742565155\n",
            " somado na saída em [1, 1, 2, 2] = 0.01664355769753456\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 3\n",
            " alvo do kernel em x: x[1,0,6:11, 9:14]\n",
            " \n",
            " tensor([[0.1260, 0.4786, 0.9687, 0.4984, 0.5602],\n",
            "        [0.4727, 0.4849, 0.3053, 0.4298, 0.1450],\n",
            "        [0.2683, 0.9916, 0.5703, 0.3389, 0.9356],\n",
            "        [0.6575, 0.4868, 0.1473, 0.8604, 0.1361],\n",
            "        [0.3227, 0.6418, 0.3129, 0.5017, 0.8790]])\n",
            " produto: tensor([[[[-0.0005,  0.0002, -0.0048,  0.0019, -0.0048],\n",
            "          [ 0.0035, -0.0035, -0.0024, -0.0027,  0.0007],\n",
            "          [-0.0010,  0.0037, -0.0048, -0.0021, -0.0034],\n",
            "          [-0.0013, -0.0037,  0.0010, -0.0020,  0.0004],\n",
            "          [ 0.0023,  0.0012,  0.0009,  0.0048, -0.0040]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0004, -0.0021,  0.0069,  0.0040, -0.0052],\n",
            "          [ 0.0040,  0.0023,  0.0013,  0.0018,  0.0012],\n",
            "          [-0.0004, -0.0084, -0.0016, -0.0024,  0.0006],\n",
            "          [-0.0012, -0.0026, -0.0001,  0.0082, -0.0001],\n",
            "          [ 0.0001, -0.0010,  0.0005,  0.0045,  0.0054]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0206]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0160]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0206,  0.0160], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 2, 3] = -0.02064112015068531\n",
            " somado na saída em [1, 1, 2, 3] = 0.016029460355639458\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 4\n",
            " alvo do kernel em x: x[1,0,6:11, 12:17]\n",
            " \n",
            " tensor([[0.4984, 0.5602, 0.4914, 0.1934, 0.5655],\n",
            "        [0.4298, 0.1450, 0.9963, 0.4436, 0.6687],\n",
            "        [0.3389, 0.9356, 0.9790, 0.8712, 0.8077],\n",
            "        [0.8604, 0.1361, 0.6921, 0.0079, 0.5514],\n",
            "        [0.5017, 0.8790, 0.1260, 0.8008, 0.2195]])\n",
            " produto: tensor([[[[-2.0325e-03,  1.8555e-04, -2.4408e-03,  7.2917e-04, -4.8181e-03],\n",
            "          [ 3.1509e-03, -1.0541e-03, -7.9210e-03, -2.8028e-03,  3.0286e-03],\n",
            "          [-1.2523e-03,  3.5013e-03, -8.3089e-03, -5.2859e-03, -2.9656e-03],\n",
            "          [-1.6908e-03, -1.0383e-03,  4.5320e-03, -1.8664e-05,  1.7699e-03],\n",
            "          [ 3.5475e-03,  1.6377e-03,  3.4466e-04,  7.7300e-03, -9.9016e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5788e-03, -2.4923e-03,  3.5121e-03,  1.5442e-03, -5.2134e-03],\n",
            "          [ 3.6693e-03,  6.9251e-04,  4.3415e-03,  1.8260e-03,  5.5591e-03],\n",
            "          [-4.4750e-04, -7.9126e-03, -2.8092e-03, -6.1358e-03,  5.3394e-04],\n",
            "          [-1.6063e-03, -7.3008e-04, -6.2929e-04,  7.4979e-05, -4.3490e-04],\n",
            "          [ 1.5928e-04, -1.3709e-03,  1.9814e-04,  7.1355e-03,  1.3425e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0125]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0024]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0125,  0.0024], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 2, 4] = -0.012462709099054337\n",
            " somado na saída em [1, 1, 2, 4] = 0.002385704778134823\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 5\n",
            " alvo do kernel em x: x[1,0,6:11, 15:20]\n",
            " \n",
            " tensor([[0.1934, 0.5655, 0.1395, 0.7179, 0.9780],\n",
            "        [0.4436, 0.6687, 0.6897, 0.8295, 0.3543],\n",
            "        [0.8712, 0.8077, 0.3568, 0.7764, 0.6486],\n",
            "        [0.0079, 0.5514, 0.5196, 0.6977, 0.1832],\n",
            "        [0.8008, 0.2195, 0.3863, 0.7480, 0.6036]])\n",
            " produto: tensor([[[[-7.8845e-04,  1.8731e-04, -6.9271e-04,  2.7074e-03, -8.3329e-03],\n",
            "          [ 3.2515e-03, -4.8606e-03, -5.4838e-03, -5.2417e-03,  1.6046e-03],\n",
            "          [-3.2191e-03,  3.0225e-03, -3.0287e-03, -4.7106e-03, -2.3816e-03],\n",
            "          [-1.5553e-05, -4.2063e-03,  3.4023e-03, -1.6453e-03,  5.8820e-04],\n",
            "          [ 5.6630e-03,  4.0902e-04,  1.0564e-03,  7.2201e-03, -2.7225e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 6.1245e-04, -2.5159e-03,  9.9675e-04,  5.7337e-03, -9.0167e-03],\n",
            "          [ 3.7865e-03,  3.1933e-03,  3.0057e-03,  3.4150e-03,  2.9454e-03],\n",
            "          [-1.1504e-03, -6.8306e-03, -1.0240e-03, -5.4680e-03,  4.2879e-04],\n",
            "          [-1.4776e-05, -2.9575e-03, -4.7243e-04,  6.6096e-03, -1.4454e-04],\n",
            "          [ 2.5426e-04, -3.4240e-04,  6.0733e-04,  6.6647e-03,  3.6913e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0182]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0120]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0182,  0.0120], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 2, 5] = -0.018217487260699272\n",
            " somado na saída em [1, 1, 2, 5] = 0.012007559649646282\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 6\n",
            " alvo do kernel em x: x[1,0,6:11, 18:23]\n",
            " \n",
            " tensor([[0.7179, 0.9780, 0.9830, 0.3872, 0.0545],\n",
            "        [0.8295, 0.3543, 0.1060, 0.4351, 0.0805],\n",
            "        [0.7764, 0.6486, 0.3112, 0.1459, 0.9996],\n",
            "        [0.6977, 0.1832, 0.0885, 0.3461, 0.2592],\n",
            "        [0.7480, 0.6036, 0.8129, 0.3820, 0.8986]])\n",
            " produto: tensor([[[[-2.9275e-03,  3.2395e-04, -4.8823e-03,  1.4601e-03, -4.6415e-04],\n",
            "          [ 6.0808e-03, -2.5753e-03, -8.4307e-04, -2.7491e-03,  3.6452e-04],\n",
            "          [-2.8687e-03,  2.4273e-03, -2.6411e-03, -8.8507e-04, -3.6704e-03],\n",
            "          [-1.3710e-03, -1.3979e-03,  5.7953e-04, -8.1629e-04,  8.3202e-04],\n",
            "          [ 5.2894e-03,  1.1246e-03,  2.2229e-03,  3.6871e-03, -4.0529e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.2740e-03, -4.3512e-03,  7.0252e-03,  3.0922e-03, -5.0223e-04],\n",
            "          [ 7.0813e-03,  1.6919e-03,  4.6209e-04,  1.7910e-03,  6.6909e-04],\n",
            "          [-1.0252e-03, -5.4855e-03, -8.9293e-04, -1.0274e-03,  6.6083e-04],\n",
            "          [-1.3026e-03, -9.8291e-04, -8.0471e-05,  3.2793e-03, -2.0445e-04],\n",
            "          [ 2.3749e-04, -9.4145e-04,  1.2779e-03,  3.4035e-03,  5.4951e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0078]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0216]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0078,  0.0216], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 2, 6] = -0.007752547971904278\n",
            " somado na saída em [1, 1, 2, 6] = 0.02164461649954319\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 2, 7\n",
            " alvo do kernel em x: x[1,0,6:11, 21:26]\n",
            " \n",
            " tensor([[0.3872, 0.0545, 0.5848, 0.8722, 0.5914],\n",
            "        [0.4351, 0.0805, 0.3432, 0.2455, 0.0037],\n",
            "        [0.1459, 0.9996, 0.0596, 0.6133, 0.2568],\n",
            "        [0.3461, 0.2592, 0.0361, 0.8626, 0.5530],\n",
            "        [0.3820, 0.8986, 0.1504, 0.6495, 0.2503]])\n",
            " produto: tensor([[[[-1.5788e-03,  1.8044e-05, -2.9046e-03,  3.2892e-03, -5.0392e-03],\n",
            "          [ 3.1892e-03, -5.8502e-04, -2.7282e-03, -1.5511e-03,  1.6933e-05],\n",
            "          [-5.3901e-04,  3.7408e-03, -5.0557e-04, -3.7211e-03, -9.4281e-04],\n",
            "          [-6.8022e-04, -1.9774e-03,  2.3670e-04, -2.0342e-03,  1.7752e-03],\n",
            "          [ 2.7012e-03,  1.6742e-03,  4.1117e-04,  6.2693e-03, -1.1287e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2264e-03, -2.4236e-04,  4.1795e-03,  6.9660e-03, -5.4527e-03],\n",
            "          [ 3.7139e-03,  3.8434e-04,  1.4954e-03,  1.0106e-03,  3.1081e-05],\n",
            "          [-1.9262e-04, -8.4539e-03, -1.7093e-04, -4.3194e-03,  1.6974e-04],\n",
            "          [-6.4626e-04, -1.3903e-03, -3.2867e-05,  8.1719e-03, -4.3622e-04],\n",
            "          [ 1.2128e-04, -1.4015e-03,  2.3638e-04,  5.7871e-03,  1.5303e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0026]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0123]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0026,  0.0123], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 2, 7] = -0.0025940239429473877\n",
            " somado na saída em [1, 1, 2, 7] = 0.012284662574529648\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 0\n",
            " alvo do kernel em x: x[1,0,9:14, 0:5]\n",
            " \n",
            " tensor([[0.3059, 0.7875, 0.4745, 0.9682, 0.5997],\n",
            "        [0.2981, 0.3215, 0.1325, 0.9128, 0.8084],\n",
            "        [0.0120, 0.7569, 0.6564, 0.3525, 0.7781],\n",
            "        [0.3039, 0.9221, 0.9685, 0.0319, 0.7618],\n",
            "        [0.8159, 0.0257, 0.6732, 0.9152, 0.1816]])\n",
            " produto: tensor([[[[-1.2475e-03,  2.6085e-04, -2.3564e-03,  3.6513e-03, -5.1099e-03],\n",
            "          [ 2.1855e-03, -2.3368e-03, -1.0532e-03, -5.7680e-03,  3.6612e-03],\n",
            "          [-4.4475e-05,  2.8326e-03, -5.5706e-03, -2.1385e-03, -2.8571e-03],\n",
            "          [-5.9720e-04, -7.0344e-03,  6.3416e-03, -7.5336e-05,  2.4454e-03],\n",
            "          [ 5.7694e-03,  4.7865e-05,  1.8409e-03,  8.8338e-03, -8.1910e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 9.6903e-04, -3.5037e-03,  3.3907e-03,  7.7328e-03, -5.5292e-03],\n",
            "          [ 2.5450e-03,  1.5352e-03,  5.7725e-04,  3.7578e-03,  6.7203e-03],\n",
            "          [-1.5893e-05, -6.4014e-03, -1.8834e-03, -2.4823e-03,  5.1440e-04],\n",
            "          [-5.6739e-04, -4.9460e-03, -8.8057e-04,  3.0265e-04, -6.0091e-04],\n",
            "          [ 2.5904e-04, -4.0068e-05,  1.0583e-03,  8.1543e-03,  1.1106e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[0.0009]]],\n",
            "\n",
            "\n",
            "        [[[0.0118]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([0.0009, 0.0118], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 3, 0] = 0.0008620242588222027\n",
            " somado na saída em [1, 1, 3, 0] = 0.011776648461818695\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 1\n",
            " alvo do kernel em x: x[1,0,9:14, 3:8]\n",
            " \n",
            " tensor([[0.9682, 0.5997, 0.5014, 0.8170, 0.4343],\n",
            "        [0.9128, 0.8084, 0.3976, 0.3634, 0.9109],\n",
            "        [0.3525, 0.7781, 0.8937, 0.1869, 0.8212],\n",
            "        [0.0319, 0.7618, 0.1817, 0.6748, 0.0791],\n",
            "        [0.9152, 0.1816, 0.5394, 0.6807, 0.3152]])\n",
            " produto: tensor([[[[-3.9482e-03,  1.9865e-04, -2.4900e-03,  3.0812e-03, -3.7007e-03],\n",
            "          [ 6.6914e-03, -5.8759e-03, -3.1611e-03, -2.2961e-03,  4.1253e-03],\n",
            "          [-1.3023e-03,  2.9119e-03, -7.5850e-03, -1.1342e-03, -3.0153e-03],\n",
            "          [-6.2778e-05, -5.8119e-03,  1.1898e-03, -1.5913e-03,  2.5387e-04],\n",
            "          [ 6.4716e-03,  3.3836e-04,  1.4751e-03,  6.5709e-03, -1.4215e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 3.0669e-03, -2.6682e-03,  3.5829e-03,  6.5254e-03, -4.0043e-03],\n",
            "          [ 7.7922e-03,  3.8603e-03,  1.7326e-03,  1.4959e-03,  7.5721e-03],\n",
            "          [-4.6539e-04, -6.5807e-03, -2.5644e-03, -1.3165e-03,  5.4287e-04],\n",
            "          [-5.9643e-05, -4.0864e-03, -1.6522e-04,  6.3928e-03, -6.2383e-05],\n",
            "          [ 2.9057e-04, -2.8325e-04,  8.4801e-04,  6.0655e-03,  1.9273e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0101]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0294]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0101,  0.0294], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 3, 1] = -0.010088149458169937\n",
            " somado na saída em [1, 1, 3, 1] = 0.029438909143209457\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 2\n",
            " alvo do kernel em x: x[1,0,9:14, 6:11]\n",
            " \n",
            " tensor([[0.8170, 0.4343, 0.7601, 0.6575, 0.4868],\n",
            "        [0.3634, 0.9109, 0.3658, 0.3227, 0.6418],\n",
            "        [0.1869, 0.8212, 0.1774, 0.2484, 0.8753],\n",
            "        [0.6748, 0.0791, 0.9459, 0.0815, 0.1211],\n",
            "        [0.6807, 0.3152, 0.9381, 0.3895, 0.6427]])\n",
            " produto: tensor([[[[-3.3317e-03,  1.4387e-04, -3.7752e-03,  2.4794e-03, -4.1478e-03],\n",
            "          [ 2.6637e-03, -6.6206e-03, -2.9079e-03, -2.0388e-03,  2.9069e-03],\n",
            "          [-6.9070e-04,  3.0731e-03, -1.5053e-03, -1.5072e-03, -3.2139e-03],\n",
            "          [-1.3261e-03, -6.0335e-04,  6.1935e-03, -1.9217e-04,  3.8869e-04],\n",
            "          [ 4.8138e-03,  5.8719e-04,  2.5652e-03,  3.7595e-03, -2.8985e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.5880e-03, -1.9324e-03,  5.4322e-03,  5.2510e-03, -4.4881e-03],\n",
            "          [ 3.1019e-03,  4.3495e-03,  1.5938e-03,  1.3283e-03,  5.3356e-03],\n",
            "          [-2.4682e-04, -6.9449e-03, -5.0894e-04, -1.7496e-03,  5.7863e-04],\n",
            "          [-1.2599e-03, -4.2423e-04, -8.6000e-04,  7.7199e-04, -9.5513e-05],\n",
            "          [ 2.1614e-04, -4.9155e-04,  1.4747e-03,  3.4703e-03,  3.9298e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0052]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0204]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0052,  0.0204], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 3, 2] = -0.005184512585401535\n",
            " somado na saída em [1, 1, 3, 2] = 0.020420078188180923\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 3\n",
            " alvo do kernel em x: x[1,0,9:14, 9:14]\n",
            " \n",
            " tensor([[0.6575, 0.4868, 0.1473, 0.8604, 0.1361],\n",
            "        [0.3227, 0.6418, 0.3129, 0.5017, 0.8790],\n",
            "        [0.2484, 0.8753, 0.8060, 0.7236, 0.0432],\n",
            "        [0.0815, 0.1211, 0.8094, 0.5193, 0.4020],\n",
            "        [0.3895, 0.6427, 0.7231, 0.2321, 0.3456]])\n",
            " produto: tensor([[[[-2.6810e-03,  1.6125e-04, -7.3149e-04,  3.2445e-03, -1.1597e-03],\n",
            "          [ 2.3652e-03, -4.6652e-03, -2.4875e-03, -3.1699e-03,  3.9810e-03],\n",
            "          [-9.1789e-04,  3.2755e-03, -6.8411e-03, -4.3901e-03, -1.5849e-04],\n",
            "          [-1.6013e-04, -9.2378e-04,  5.2996e-03, -1.2247e-03,  1.2902e-03],\n",
            "          [ 2.7542e-03,  1.1973e-03,  1.9774e-03,  2.2404e-03, -1.5588e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.0826e-03, -2.1658e-03,  1.0526e-03,  6.8713e-03, -1.2549e-03],\n",
            "          [ 2.7544e-03,  3.0649e-03,  1.3634e-03,  2.0652e-03,  7.3073e-03],\n",
            "          [-3.2801e-04, -7.4024e-03, -2.3129e-03, -5.0960e-03,  2.8535e-05],\n",
            "          [-1.5214e-04, -6.4953e-04, -7.3587e-04,  4.9199e-03, -3.1705e-04],\n",
            "          [ 1.2366e-04, -1.0023e-03,  1.1368e-03,  2.0681e-03,  2.1134e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0033]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0155]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0033,  0.0155], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 3, 3] = -0.003283119760453701\n",
            " somado na saída em [1, 1, 3, 3] = 0.015535028651356697\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 4\n",
            " alvo do kernel em x: x[1,0,9:14, 12:17]\n",
            " \n",
            " tensor([[0.8604, 0.1361, 0.6921, 0.0079, 0.5514],\n",
            "        [0.5017, 0.8790, 0.1260, 0.8008, 0.2195],\n",
            "        [0.7236, 0.0432, 0.7503, 0.6868, 0.6477],\n",
            "        [0.5193, 0.4020, 0.8446, 0.2828, 0.2669],\n",
            "        [0.2321, 0.3456, 0.4724, 0.9395, 0.1244]])\n",
            " produto: tensor([[[[-3.5083e-03,  4.5086e-05, -3.4375e-03,  2.9845e-05, -4.6981e-03],\n",
            "          [ 3.6774e-03, -6.3891e-03, -1.0021e-03, -5.0603e-03,  9.9430e-04],\n",
            "          [-2.6736e-03,  1.6153e-04, -6.3683e-03, -4.1671e-03, -2.3781e-03],\n",
            "          [-1.0205e-03, -3.0664e-03,  5.5303e-03, -6.6684e-04,  8.5670e-04],\n",
            "          [ 1.6413e-03,  6.4391e-04,  1.2918e-03,  9.0684e-03, -5.6093e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 2.7252e-03, -6.0558e-04,  4.9463e-03,  6.3207e-05, -5.0836e-03],\n",
            "          [ 4.2824e-03,  4.1975e-03,  5.4924e-04,  3.2968e-03,  1.8251e-03],\n",
            "          [-9.5541e-04, -3.6505e-04, -2.1531e-03, -4.8371e-03,  4.2816e-04],\n",
            "          [-9.6958e-04, -2.1560e-03, -7.6792e-04,  2.6789e-03, -2.1052e-04],\n",
            "          [ 7.3694e-05, -5.3903e-04,  7.4264e-04,  8.3709e-03,  7.6053e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0211]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0163]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0211,  0.0163], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 3, 4] = -0.02105657383799553\n",
            " somado na saída em [1, 1, 3, 4] = 0.016297589987516403\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 5\n",
            " alvo do kernel em x: x[1,0,9:14, 15:20]\n",
            " \n",
            " tensor([[0.0079, 0.5514, 0.5196, 0.6977, 0.1832],\n",
            "        [0.8008, 0.2195, 0.3863, 0.7480, 0.6036],\n",
            "        [0.6868, 0.6477, 0.7566, 0.7427, 0.9168],\n",
            "        [0.2828, 0.2669, 0.3802, 0.8401, 0.0866],\n",
            "        [0.9395, 0.1244, 0.7523, 0.9187, 0.6009]])\n",
            " produto: tensor([[[[-3.2272e-05,  1.8264e-04, -2.5806e-03,  2.6310e-03, -1.5614e-03],\n",
            "          [ 5.8704e-03, -1.5957e-03, -3.0715e-03, -4.7265e-03,  2.7339e-03],\n",
            "          [-2.5377e-03,  2.4237e-03, -6.4219e-03, -4.5063e-03, -3.3663e-03],\n",
            "          [-5.5568e-04, -2.0361e-03,  2.4897e-03, -1.9813e-03,  2.7805e-04],\n",
            "          [ 6.6435e-03,  2.3171e-04,  2.0572e-03,  8.8683e-03, -2.7099e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.5068e-05, -2.4532e-03,  3.7133e-03,  5.5719e-03, -1.6895e-03],\n",
            "          [ 6.8362e-03,  1.0484e-03,  1.6835e-03,  3.0793e-03,  5.0181e-03],\n",
            "          [-9.0687e-04, -5.4775e-03, -2.1712e-03, -5.2308e-03,  6.0606e-04],\n",
            "          [-5.2794e-04, -1.4316e-03, -3.4571e-04,  7.9596e-03, -6.8324e-05],\n",
            "          [ 2.9829e-04, -1.9397e-04,  1.1827e-03,  8.1862e-03,  3.6742e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0033]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0284]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0033,  0.0284], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 3, 5] = -0.0032729865051805973\n",
            " somado na saída em [1, 1, 3, 5] = 0.028386190533638\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 6\n",
            " alvo do kernel em x: x[1,0,9:14, 18:23]\n",
            " \n",
            " tensor([[0.6977, 0.1832, 0.0885, 0.3461, 0.2592],\n",
            "        [0.7480, 0.6036, 0.8129, 0.3820, 0.8986],\n",
            "        [0.7427, 0.9168, 0.5724, 0.4488, 0.5717],\n",
            "        [0.8401, 0.0866, 0.3048, 0.2321, 0.9298],\n",
            "        [0.9187, 0.6009, 0.1983, 0.8010, 0.0779]])\n",
            " produto: tensor([[[[-2.8449e-03,  6.0700e-05, -4.3957e-04,  1.3053e-03, -2.2086e-03],\n",
            "          [ 5.4831e-03, -4.3875e-03, -6.4628e-03, -2.4137e-03,  4.0698e-03],\n",
            "          [-2.7443e-03,  3.4308e-03, -4.8579e-03, -2.7231e-03, -2.0992e-03],\n",
            "          [-1.6511e-03, -6.6081e-04,  1.9956e-03, -5.4746e-04,  2.9844e-03],\n",
            "          [ 6.4969e-03,  1.1194e-03,  5.4231e-04,  7.7313e-03, -3.5126e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 2.2098e-03, -8.1529e-04,  6.3251e-04,  2.7644e-03, -2.3898e-03],\n",
            "          [ 6.3852e-03,  2.8825e-03,  3.5423e-03,  1.5725e-03,  7.4703e-03],\n",
            "          [-9.8069e-04, -7.7533e-03, -1.6424e-03, -3.1609e-03,  3.7795e-04],\n",
            "          [-1.5686e-03, -4.6463e-04, -2.7711e-04,  2.1993e-03, -7.3335e-04],\n",
            "          [ 2.9170e-04, -9.3710e-04,  3.1177e-04,  7.1367e-03,  4.7625e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[0.0008]]],\n",
            "\n",
            "\n",
            "        [[[0.0175]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([0.0008, 0.0175], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 3, 6] = 0.0008274898864328861\n",
            " somado na saída em [1, 1, 3, 6] = 0.01752997562289238\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 3, 7\n",
            " alvo do kernel em x: x[1,0,9:14, 21:26]\n",
            " \n",
            " tensor([[0.3461, 0.2592, 0.0361, 0.8626, 0.5530],\n",
            "        [0.3820, 0.8986, 0.1504, 0.6495, 0.2503],\n",
            "        [0.4488, 0.5717, 0.4071, 0.8968, 0.3798],\n",
            "        [0.2321, 0.9298, 0.1362, 0.7575, 0.8210],\n",
            "        [0.8010, 0.0779, 0.6491, 0.3563, 0.4176]])\n",
            " produto: tensor([[[[-1.4115e-03,  8.5861e-05, -1.7954e-04,  3.2528e-03, -4.7122e-03],\n",
            "          [ 2.8001e-03, -6.5316e-03, -1.1955e-03, -4.1041e-03,  1.1334e-03],\n",
            "          [-1.6583e-03,  2.1395e-03, -3.4555e-03, -5.4411e-03, -1.3945e-03],\n",
            "          [-4.5620e-04, -7.0928e-03,  8.9154e-04, -1.7864e-03,  2.6353e-03],\n",
            "          [ 5.6639e-03,  1.4510e-04,  1.7750e-03,  3.4396e-03, -1.8836e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0964e-03, -1.1533e-03,  2.5834e-04,  6.8889e-03, -5.0989e-03],\n",
            "          [ 3.2608e-03,  4.2911e-03,  6.5523e-04,  2.6738e-03,  2.0804e-03],\n",
            "          [-5.9261e-04, -4.8351e-03, -1.1683e-03, -6.3160e-03,  2.5107e-04],\n",
            "          [-4.3342e-04, -4.9871e-03, -1.2380e-04,  7.1764e-03, -6.4757e-04],\n",
            "          [ 2.5431e-04, -1.2147e-04,  1.0204e-03,  3.1750e-03,  2.5539e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0173]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0102]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0173,  0.0102], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 3, 7] = -0.017340611666440964\n",
            " somado na saída em [1, 1, 3, 7] = 0.010158654302358627\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 0\n",
            " alvo do kernel em x: x[1,0,12:17, 0:5]\n",
            " \n",
            " tensor([[0.3039, 0.9221, 0.9685, 0.0319, 0.7618],\n",
            "        [0.8159, 0.0257, 0.6732, 0.9152, 0.1816],\n",
            "        [0.1909, 0.9689, 0.5822, 0.0803, 0.2396],\n",
            "        [0.0742, 0.0342, 0.4293, 0.9718, 0.5944],\n",
            "        [0.1914, 0.8704, 0.2341, 0.2799, 0.5159]])\n",
            " produto: tensor([[[[-1.2392e-03,  3.0544e-04, -4.8101e-03,  1.2047e-04, -6.4914e-03],\n",
            "          [ 5.9808e-03, -1.8674e-04, -5.3523e-03, -5.7829e-03,  8.2252e-04],\n",
            "          [-7.0543e-04,  3.6259e-03, -4.9409e-03, -4.8730e-04, -8.7968e-04],\n",
            "          [-1.4589e-04, -2.6092e-04,  2.8111e-03, -2.2918e-03,  1.9078e-03],\n",
            "          [ 1.3532e-03,  1.6216e-03,  6.4024e-04,  2.7017e-03, -2.3269e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 9.6258e-04, -4.1026e-03,  6.9213e-03,  2.5513e-04, -7.0240e-03],\n",
            "          [ 6.9647e-03,  1.2268e-04,  2.9336e-03,  3.7675e-03,  1.5098e-03],\n",
            "          [-2.5209e-04, -8.1942e-03, -1.6705e-03, -5.6565e-04,  1.5838e-04],\n",
            "          [-1.3860e-04, -1.8346e-04, -3.9034e-04,  9.2068e-03, -4.6881e-04],\n",
            "          [ 6.0759e-05, -1.3575e-03,  3.6807e-04,  2.4939e-03,  3.1549e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0140]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0145]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0140,  0.0145], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 4, 0] = -0.014010605402290821\n",
            " somado na saída em [1, 1, 4, 0] = 0.014532424509525299\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 1\n",
            " alvo do kernel em x: x[1,0,12:17, 3:8]\n",
            " \n",
            " tensor([[0.0319, 0.7618, 0.1817, 0.6748, 0.0791],\n",
            "        [0.9152, 0.1816, 0.5394, 0.6807, 0.3152],\n",
            "        [0.0803, 0.2396, 0.8363, 0.8285, 0.2859],\n",
            "        [0.9718, 0.5944, 0.0464, 0.6309, 0.8447],\n",
            "        [0.2799, 0.5159, 0.2680, 0.4354, 0.1799]])\n",
            " produto: tensor([[[[-1.3026e-04,  2.5236e-04, -9.0249e-04,  2.5447e-03, -6.7390e-04],\n",
            "          [ 6.7086e-03, -1.3200e-03, -4.2886e-03, -4.3015e-03,  1.4274e-03],\n",
            "          [-2.9676e-04,  8.9654e-04, -7.0979e-03, -5.0270e-03, -1.0496e-03],\n",
            "          [-1.9098e-03, -4.5342e-03,  3.0398e-04, -1.4880e-03,  2.7115e-03],\n",
            "          [ 1.9793e-03,  9.6123e-04,  7.3280e-04,  4.2030e-03, -8.1143e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0119e-04, -3.3896e-03,  1.2986e-03,  5.3891e-03, -7.2919e-04],\n",
            "          [ 7.8123e-03,  8.6723e-04,  2.3506e-03,  2.8024e-03,  2.6200e-03],\n",
            "          [-1.0605e-04, -2.0261e-03, -2.3997e-03, -5.8352e-03,  1.8898e-04],\n",
            "          [-1.8144e-03, -3.1881e-03, -4.2209e-05,  5.9776e-03, -6.6630e-04],\n",
            "          [ 8.8867e-05, -8.0466e-04,  4.2129e-04,  3.8797e-03,  1.1002e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0111]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0139]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0111,  0.0139], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 4, 1] = -0.011110015213489532\n",
            " somado na saída em [1, 1, 4, 1] = 0.013896609656512737\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 2\n",
            " alvo do kernel em x: x[1,0,12:17, 6:11]\n",
            " \n",
            " tensor([[0.6748, 0.0791, 0.9459, 0.0815, 0.1211],\n",
            "        [0.6807, 0.3152, 0.9381, 0.3895, 0.6427],\n",
            "        [0.8285, 0.2859, 0.6497, 0.7276, 0.0510],\n",
            "        [0.6309, 0.8447, 0.1597, 0.7814, 0.7198],\n",
            "        [0.4354, 0.1799, 0.1770, 0.9764, 0.0239]])\n",
            " produto: tensor([[[[-2.7516e-03,  2.6198e-05, -4.6977e-03,  3.0729e-04, -1.0318e-03],\n",
            "          [ 4.9901e-03, -2.2908e-03, -7.4580e-03, -2.4611e-03,  2.9106e-03],\n",
            "          [-3.0614e-03,  1.0697e-03, -5.5146e-03, -4.4148e-03, -1.8722e-04],\n",
            "          [-1.2399e-03, -6.4443e-03,  1.0458e-03, -1.8427e-03,  2.3103e-03],\n",
            "          [ 3.0791e-03,  3.3519e-04,  4.8407e-04,  9.4247e-03, -1.0760e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 2.1374e-03, -3.5189e-04,  6.7596e-03,  6.5079e-04, -1.1164e-03],\n",
            "          [ 5.8111e-03,  1.5050e-03,  4.0878e-03,  1.6034e-03,  5.3424e-03],\n",
            "          [-1.0940e-03, -2.4175e-03, -1.8644e-03, -5.1246e-03,  3.3707e-05],\n",
            "          [-1.1780e-03, -4.5311e-03, -1.4522e-04,  7.4027e-03, -5.6771e-04],\n",
            "          [ 1.3825e-04, -2.8059e-04,  2.7829e-04,  8.6997e-03,  1.4589e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0175]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0259]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0175,  0.0259], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 4, 2] = -0.017520392313599586\n",
            " somado na saída em [1, 1, 4, 2] = 0.025924529880285263\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 3\n",
            " alvo do kernel em x: x[1,0,12:17, 9:14]\n",
            " \n",
            " tensor([[0.0815, 0.1211, 0.8094, 0.5193, 0.4020],\n",
            "        [0.3895, 0.6427, 0.7231, 0.2321, 0.3456],\n",
            "        [0.7276, 0.0510, 0.7362, 0.1710, 0.3667],\n",
            "        [0.7814, 0.7198, 0.6066, 0.6638, 0.4412],\n",
            "        [0.9764, 0.0239, 0.4702, 0.7306, 0.2297]])\n",
            " produto: tensor([[[[-3.3228e-04,  4.0112e-05, -4.0197e-03,  1.9584e-03, -3.4249e-03],\n",
            "          [ 2.8550e-03, -4.6711e-03, -5.7493e-03, -1.4666e-03,  1.5653e-03],\n",
            "          [-2.6886e-03,  1.9081e-04, -6.2485e-03, -1.0375e-03, -1.3464e-03],\n",
            "          [-1.5355e-03, -5.4907e-03,  3.9718e-03, -1.5654e-03,  1.4162e-03],\n",
            "          [ 6.9045e-03,  4.4450e-05,  1.2858e-03,  7.0522e-03, -1.0359e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.5811e-04, -5.3876e-04,  5.7840e-03,  4.1475e-03, -3.7059e-03],\n",
            "          [ 3.3248e-03,  3.0688e-03,  3.1512e-03,  9.5552e-04,  2.8731e-03],\n",
            "          [-9.6078e-04, -4.3122e-04, -2.1126e-03, -1.2043e-03,  2.4240e-04],\n",
            "          [-1.4589e-03, -3.8607e-03, -5.5151e-04,  6.2886e-03, -3.4801e-04],\n",
            "          [ 3.1000e-04, -3.7210e-05,  7.3922e-04,  6.5097e-03,  1.4045e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0133]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0238]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0133,  0.0238], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 4, 3] = -0.013327885419130325\n",
            " somado na saída em [1, 1, 4, 3] = 0.02384759671986103\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 4\n",
            " alvo do kernel em x: x[1,0,12:17, 12:17]\n",
            " \n",
            " tensor([[0.5193, 0.4020, 0.8446, 0.2828, 0.2669],\n",
            "        [0.2321, 0.3456, 0.4724, 0.9395, 0.1244],\n",
            "        [0.1710, 0.3667, 0.5481, 0.8190, 0.1408],\n",
            "        [0.6638, 0.4412, 0.1072, 0.4626, 0.8429],\n",
            "        [0.7306, 0.2297, 0.7039, 0.5367, 0.9239]])\n",
            " produto: tensor([[[[-2.1176e-03,  1.3315e-04, -4.1948e-03,  1.0663e-03, -2.2741e-03],\n",
            "          [ 1.7014e-03, -2.5121e-03, -3.7557e-03, -5.9365e-03,  5.6328e-04],\n",
            "          [-6.3185e-04,  1.3722e-03, -4.6520e-03, -4.9692e-03, -5.1687e-04],\n",
            "          [-1.3044e-03, -3.3658e-03,  7.0223e-04, -1.0910e-03,  2.7055e-03],\n",
            "          [ 5.1664e-03,  4.2791e-04,  1.9247e-03,  5.1803e-03, -4.1668e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.6449e-03, -1.7884e-03,  6.0359e-03,  2.2583e-03, -2.4607e-03],\n",
            "          [ 1.9814e-03,  1.6504e-03,  2.0585e-03,  3.8676e-03,  1.0339e-03],\n",
            "          [-2.2579e-04, -3.1010e-03, -1.5728e-03, -5.7681e-03,  9.3057e-05],\n",
            "          [-1.2393e-03, -2.3666e-03, -9.7508e-05,  4.3829e-03, -6.6482e-04],\n",
            "          [ 2.3197e-04, -3.5821e-04,  1.1065e-03,  4.7818e-03,  5.6495e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0205]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0171]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0205,  0.0171], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 4, 4] = -0.020545272156596184\n",
            " somado na saída em [1, 1, 4, 4] = 0.0171333197504282\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 5\n",
            " alvo do kernel em x: x[1,0,12:17, 15:20]\n",
            " \n",
            " tensor([[0.2828, 0.2669, 0.3802, 0.8401, 0.0866],\n",
            "        [0.9395, 0.1244, 0.7523, 0.9187, 0.6009],\n",
            "        [0.8190, 0.1408, 0.8363, 0.7444, 0.9772],\n",
            "        [0.4626, 0.8429, 0.5212, 0.4363, 0.1431],\n",
            "        [0.5367, 0.9239, 0.9241, 0.5033, 0.1917]])\n",
            " produto: tensor([[[[-1.1530e-03,  8.8408e-05, -1.8885e-03,  3.1683e-03, -7.3807e-04],\n",
            "          [ 6.8868e-03, -9.0399e-04, -5.9812e-03, -5.8054e-03,  2.7212e-03],\n",
            "          [-3.0262e-03,  5.2677e-04, -7.0976e-03, -4.5166e-03, -3.5882e-03],\n",
            "          [-9.0914e-04, -6.4299e-03,  3.4125e-03, -1.0289e-03,  4.5923e-04],\n",
            "          [ 3.7951e-03,  1.7213e-03,  2.5271e-03,  4.8584e-03, -8.6471e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 8.9565e-04, -1.1875e-03,  2.7173e-03,  6.7099e-03, -7.9864e-04],\n",
            "          [ 8.0198e-03,  5.9390e-04,  3.2783e-03,  3.7823e-03,  4.9949e-03],\n",
            "          [-1.0814e-03, -1.1905e-03, -2.3996e-03, -5.2427e-03,  6.4602e-04],\n",
            "          [-8.6374e-04, -4.5210e-03, -4.7384e-04,  4.1332e-03, -1.1284e-04],\n",
            "          [ 1.7039e-04, -1.4409e-03,  1.4528e-03,  4.4847e-03,  1.1724e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0138]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0237]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0138,  0.0237], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 4, 5] = -0.013766305521130562\n",
            " somado na saída em [1, 1, 4, 5] = 0.023739010095596313\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 6\n",
            " alvo do kernel em x: x[1,0,12:17, 18:23]\n",
            " \n",
            " tensor([[0.8401, 0.0866, 0.3048, 0.2321, 0.9298],\n",
            "        [0.9187, 0.6009, 0.1983, 0.8010, 0.0779],\n",
            "        [0.7444, 0.9772, 0.4364, 0.4717, 0.8233],\n",
            "        [0.4363, 0.1431, 0.1026, 0.5028, 0.6635],\n",
            "        [0.5033, 0.1917, 0.3999, 0.7527, 0.8967]])\n",
            " produto: tensor([[[[-3.4259e-03,  2.8693e-05, -1.5137e-03,  8.7543e-04, -7.9221e-03],\n",
            "          [ 6.7348e-03, -4.3673e-03, -1.5767e-03, -5.0612e-03,  3.5273e-04],\n",
            "          [-2.7506e-03,  3.6570e-03, -3.7038e-03, -2.8621e-03, -3.0229e-03],\n",
            "          [-8.5736e-04, -1.0914e-03,  6.7170e-04, -1.1857e-03,  2.1297e-03],\n",
            "          [ 3.5593e-03,  3.5720e-04,  1.0937e-03,  7.2657e-03, -4.0441e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.6612e-03, -3.8540e-04,  2.1781e-03,  1.8540e-03, -8.5721e-03],\n",
            "          [ 7.8429e-03,  2.8692e-03,  8.6421e-04,  3.2973e-03,  6.4745e-04],\n",
            "          [-9.8293e-04, -8.2646e-03, -1.2522e-03, -3.3223e-03,  5.4424e-04],\n",
            "          [-8.1455e-04, -7.6739e-04, -9.3270e-05,  4.7634e-03, -5.2334e-04],\n",
            "          [ 1.5981e-04, -2.9902e-04,  6.2874e-04,  6.7068e-03,  5.4831e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0167]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0152]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0167,  0.0152], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 4, 6] = -0.01665886864066124\n",
            " somado na saída em [1, 1, 4, 6] = 0.015223349444568157\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 4, 7\n",
            " alvo do kernel em x: x[1,0,12:17, 21:26]\n",
            " \n",
            " tensor([[0.2321, 0.9298, 0.1362, 0.7575, 0.8210],\n",
            "        [0.8010, 0.0779, 0.6491, 0.3563, 0.4176],\n",
            "        [0.4717, 0.8233, 0.0392, 0.2321, 0.3299],\n",
            "        [0.5028, 0.6635, 0.8726, 0.4722, 0.6950],\n",
            "        [0.7527, 0.8967, 0.5505, 0.2609, 0.7562]])\n",
            " produto: tensor([[[[-0.0009,  0.0003, -0.0007,  0.0029, -0.0070],\n",
            "          [ 0.0059, -0.0006, -0.0052, -0.0023,  0.0019],\n",
            "          [-0.0017,  0.0031, -0.0003, -0.0014, -0.0012],\n",
            "          [-0.0010, -0.0051,  0.0057, -0.0011,  0.0022],\n",
            "          [ 0.0053,  0.0017,  0.0015,  0.0025, -0.0034]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0007, -0.0041,  0.0010,  0.0060, -0.0076],\n",
            "          [ 0.0068,  0.0004,  0.0028,  0.0015,  0.0035],\n",
            "          [-0.0006, -0.0070, -0.0001, -0.0016,  0.0002],\n",
            "          [-0.0009, -0.0036, -0.0008,  0.0045, -0.0005],\n",
            "          [ 0.0002, -0.0014,  0.0009,  0.0023,  0.0046]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[0.0011]]],\n",
            "\n",
            "\n",
            "        [[[0.0072]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([0.0011, 0.0072], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 4, 7] = 0.0011036705691367388\n",
            " somado na saída em [1, 1, 4, 7] = 0.007203325629234314\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 0\n",
            " alvo do kernel em x: x[1,0,15:20, 0:5]\n",
            " \n",
            " tensor([[0.0742, 0.0342, 0.4293, 0.9718, 0.5944],\n",
            "        [0.1914, 0.8704, 0.2341, 0.2799, 0.5159],\n",
            "        [0.3322, 0.2517, 0.0749, 0.7168, 0.9404],\n",
            "        [0.5733, 0.1226, 0.2016, 0.6602, 0.9445],\n",
            "        [0.8904, 0.4322, 0.4296, 0.6690, 0.6446]])\n",
            " produto: tensor([[[[-3.0272e-04,  1.1329e-05, -2.1322e-03,  3.6648e-03, -5.0643e-03],\n",
            "          [ 1.4028e-03, -6.3265e-03, -1.8615e-03, -1.7686e-03,  2.3367e-03],\n",
            "          [-1.2275e-03,  9.4202e-04, -6.3529e-04, -4.3488e-03, -3.4531e-03],\n",
            "          [-1.1266e-03, -9.3524e-04,  1.3201e-03, -1.5570e-03,  3.0316e-03],\n",
            "          [ 6.2961e-03,  8.0514e-04,  1.1748e-03,  6.4578e-03, -2.9074e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.3514e-04, -1.5217e-04,  3.0681e-03,  7.7613e-03, -5.4799e-03],\n",
            "          [ 1.6336e-03,  4.1563e-03,  1.0203e-03,  1.1523e-03,  4.2890e-03],\n",
            "          [-4.3866e-04, -2.1289e-03, -2.1479e-04, -5.0480e-03,  6.2169e-04],\n",
            "          [-1.0704e-03, -6.5759e-04, -1.8330e-04,  6.2551e-03, -7.4494e-04],\n",
            "          [ 2.8269e-04, -6.7400e-04,  6.7541e-04,  5.9611e-03,  3.9419e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0062]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0243]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0062,  0.0243], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 5, 0] = -0.0062036821618676186\n",
            " somado na saída em [1, 1, 5, 0] = 0.02426132932305336\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 1\n",
            " alvo do kernel em x: x[1,0,15:20, 3:8]\n",
            " \n",
            " tensor([[0.9718, 0.5944, 0.0464, 0.6309, 0.8447],\n",
            "        [0.2799, 0.5159, 0.2680, 0.4354, 0.1799],\n",
            "        [0.7168, 0.9404, 0.4429, 0.6445, 0.9054],\n",
            "        [0.6602, 0.9445, 0.7832, 0.6306, 0.7365],\n",
            "        [0.6690, 0.6446, 0.8576, 0.3629, 0.2140]])\n",
            " produto: tensor([[[[-0.0040,  0.0002, -0.0002,  0.0024, -0.0072],\n",
            "          [ 0.0021, -0.0038, -0.0021, -0.0028,  0.0008],\n",
            "          [-0.0026,  0.0035, -0.0038, -0.0039, -0.0033],\n",
            "          [-0.0013, -0.0072,  0.0051, -0.0015,  0.0024],\n",
            "          [ 0.0047,  0.0012,  0.0023,  0.0035, -0.0010]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0031, -0.0026,  0.0003,  0.0050, -0.0078],\n",
            "          [ 0.0024,  0.0025,  0.0012,  0.0018,  0.0015],\n",
            "          [-0.0009, -0.0080, -0.0013, -0.0045,  0.0006],\n",
            "          [-0.0012, -0.0051, -0.0007,  0.0060, -0.0006],\n",
            "          [ 0.0002, -0.0010,  0.0013,  0.0032,  0.0013]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0164]]],\n",
            "\n",
            "\n",
            "        [[[-0.0033]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0164, -0.0033], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 5, 1] = -0.016385061666369438\n",
            " somado na saída em [1, 1, 5, 1] = -0.003306295722723007\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 2\n",
            " alvo do kernel em x: x[1,0,15:20, 6:11]\n",
            " \n",
            " tensor([[0.6309, 0.8447, 0.1597, 0.7814, 0.7198],\n",
            "        [0.4354, 0.1799, 0.1770, 0.9764, 0.0239],\n",
            "        [0.6445, 0.9054, 0.1784, 0.6697, 0.1351],\n",
            "        [0.6306, 0.7365, 0.8663, 0.9485, 0.0083],\n",
            "        [0.3629, 0.2140, 0.7355, 0.1336, 0.8058]])\n",
            " produto: tensor([[[[-2.5728e-03,  2.7982e-04, -7.9325e-04,  2.9466e-03, -6.1327e-03],\n",
            "          [ 3.1919e-03, -1.3077e-03, -1.4074e-03, -6.1697e-03,  1.0805e-04],\n",
            "          [-2.3814e-03,  3.3881e-03, -1.5143e-03, -4.0634e-03, -4.9607e-04],\n",
            "          [-1.2393e-03, -5.6188e-03,  5.6724e-03, -2.2367e-03,  2.6591e-05],\n",
            "          [ 2.5660e-03,  3.9863e-04,  2.0112e-03,  1.2894e-03, -3.6341e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.9985e-03, -3.7584e-03,  1.1414e-03,  6.2404e-03, -6.6359e-03],\n",
            "          [ 3.7170e-03,  8.5911e-04,  7.7140e-04,  4.0195e-03,  1.9834e-04],\n",
            "          [-8.5101e-04, -7.6568e-03, -5.1198e-04, -4.7167e-03,  8.9313e-05],\n",
            "          [-1.1774e-03, -3.9507e-03, -7.8764e-04,  8.9857e-03, -6.5343e-06],\n",
            "          [ 1.1521e-04, -3.3370e-04,  1.1562e-03,  1.1903e-03,  4.9273e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0177]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0050]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0177,  0.0050], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 5, 2] = -0.017688997089862823\n",
            " somado na saída em [1, 1, 5, 2] = 0.005022998433560133\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 3\n",
            " alvo do kernel em x: x[1,0,15:20, 9:14]\n",
            " \n",
            " tensor([[0.7814, 0.7198, 0.6066, 0.6638, 0.4412],\n",
            "        [0.9764, 0.0239, 0.4702, 0.7306, 0.2297],\n",
            "        [0.6697, 0.1351, 0.5577, 0.4542, 0.4254],\n",
            "        [0.9485, 0.0083, 0.5005, 0.1835, 0.3013],\n",
            "        [0.1336, 0.8058, 0.3869, 0.7523, 0.1501]])\n",
            " produto: tensor([[[[-3.1862e-03,  2.3842e-04, -3.0126e-03,  2.5032e-03, -3.7593e-03],\n",
            "          [ 7.1574e-03, -1.7341e-04, -3.7385e-03, -4.6166e-03,  1.0402e-03],\n",
            "          [-2.4746e-03,  5.0558e-04, -4.7332e-03, -2.7559e-03, -1.5619e-03],\n",
            "          [-1.8639e-03, -6.3198e-05,  3.2775e-03, -4.3279e-04,  9.6718e-04],\n",
            "          [ 9.4463e-04,  1.5012e-03,  1.0581e-03,  7.2619e-03, -6.7710e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 2.4750e-03, -3.2023e-03,  4.3349e-03,  5.3012e-03, -4.0678e-03],\n",
            "          [ 8.3349e-03,  1.1393e-04,  2.0491e-03,  3.0077e-03,  1.9093e-03],\n",
            "          [-8.8430e-04, -1.1426e-03, -1.6003e-03, -3.1990e-03,  2.8120e-04],\n",
            "          [-1.7708e-03, -4.4436e-05, -4.5510e-04,  1.7386e-03, -2.3766e-04],\n",
            "          [ 4.2413e-05, -1.2567e-03,  6.0830e-04,  6.7034e-03,  9.1803e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0066]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0200]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0066,  0.0200], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 5, 3] = -0.006593875586986542\n",
            " somado na saída em [1, 1, 5, 3] = 0.019957032054662704\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 4\n",
            " alvo do kernel em x: x[1,0,15:20, 12:17]\n",
            " \n",
            " tensor([[0.6638, 0.4412, 0.1072, 0.4626, 0.8429],\n",
            "        [0.7306, 0.2297, 0.7039, 0.5367, 0.9239],\n",
            "        [0.4542, 0.4254, 0.8631, 0.6434, 0.0601],\n",
            "        [0.1835, 0.3013, 0.0048, 0.0933, 0.8212],\n",
            "        [0.7523, 0.1501, 0.1501, 0.3409, 0.5355]])\n",
            " produto: tensor([[[[-2.7067e-03,  1.4615e-04, -5.3264e-04,  1.7446e-03, -7.1817e-03],\n",
            "          [ 5.3556e-03, -1.6694e-03, -5.5960e-03, -3.3912e-03,  4.1842e-03],\n",
            "          [-1.6783e-03,  1.5918e-03, -7.3256e-03, -3.9034e-03, -2.2054e-04],\n",
            "          [-3.6065e-04, -2.2986e-03,  3.1515e-05, -2.2001e-04,  2.6359e-03],\n",
            "          [ 5.3201e-03,  2.7970e-04,  4.1058e-04,  3.2902e-03, -2.4153e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.1025e-03, -1.9630e-03,  7.6642e-04,  3.6947e-03, -7.7710e-03],\n",
            "          [ 6.2367e-03,  1.0968e-03,  3.0672e-03,  2.2093e-03,  7.6802e-03],\n",
            "          [-5.9976e-04, -3.5974e-03, -2.4767e-03, -4.5311e-03,  3.9706e-05],\n",
            "          [-3.4264e-04, -1.6162e-03, -4.3760e-06,  8.8385e-04, -6.4772e-04],\n",
            "          [ 2.3887e-04, -2.3414e-04,  2.3604e-04,  3.0371e-03,  3.2747e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0145]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0108]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0145,  0.0108], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 5, 4] = -0.014509720727801323\n",
            " somado na saída em [1, 1, 5, 4] = 0.010780176147818565\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 5\n",
            " alvo do kernel em x: x[1,0,15:20, 15:20]\n",
            " \n",
            " tensor([[0.4626, 0.8429, 0.5212, 0.4363, 0.1431],\n",
            "        [0.5367, 0.9239, 0.9241, 0.5033, 0.1917],\n",
            "        [0.6434, 0.0601, 0.3182, 0.3498, 0.0170],\n",
            "        [0.0933, 0.8212, 0.4290, 0.7540, 0.0816],\n",
            "        [0.3409, 0.5355, 0.3474, 0.8371, 0.6785]])\n",
            " produto: tensor([[[[-1.8864e-03,  2.7920e-04, -2.5884e-03,  1.6452e-03, -1.2190e-03],\n",
            "          [ 3.9341e-03, -6.7152e-03, -7.3473e-03, -3.1805e-03,  8.6833e-04],\n",
            "          [-2.3772e-03,  2.2477e-04, -2.7006e-03, -2.1225e-03, -6.2279e-05],\n",
            "          [-1.8334e-04, -6.2646e-03,  2.8088e-03, -1.7783e-03,  2.6196e-04],\n",
            "          [ 2.4104e-03,  9.9772e-04,  9.4998e-04,  8.0807e-03, -3.0602e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4653e-03, -3.7501e-03,  3.7245e-03,  3.4843e-03, -1.3190e-03],\n",
            "          [ 4.5813e-03,  4.4117e-03,  4.0271e-03,  2.0721e-03,  1.5938e-03],\n",
            "          [-8.4950e-04, -5.0796e-04, -9.1306e-04, -2.4637e-03,  1.1213e-05],\n",
            "          [-1.7418e-04, -4.4048e-03, -3.9002e-04,  7.1438e-03, -6.4371e-05],\n",
            "          [ 1.0822e-04, -8.3521e-04,  5.4614e-04,  7.4591e-03,  4.1491e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0190]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0291]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0190,  0.0291], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 5, 5] = -0.01902465708553791\n",
            " somado na saída em [1, 1, 5, 5] = 0.029105762019753456\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 6\n",
            " alvo do kernel em x: x[1,0,15:20, 18:23]\n",
            " \n",
            " tensor([[0.4363, 0.1431, 0.1026, 0.5028, 0.6635],\n",
            "        [0.5033, 0.1917, 0.3999, 0.7527, 0.8967],\n",
            "        [0.3498, 0.0170, 0.7369, 0.5973, 0.1269],\n",
            "        [0.7540, 0.0816, 0.4406, 0.8554, 0.8144],\n",
            "        [0.8371, 0.6785, 0.6564, 0.8204, 0.0539]])\n",
            " produto: tensor([[[[-1.7790e-03,  4.7390e-05, -5.0949e-04,  1.8961e-03, -5.6534e-03],\n",
            "          [ 3.6896e-03, -1.3936e-03, -3.1797e-03, -4.7563e-03,  4.0610e-03],\n",
            "          [-1.2926e-03,  6.3473e-05, -6.2545e-03, -3.6239e-03, -4.6579e-04],\n",
            "          [-1.4818e-03, -6.2258e-04,  2.8850e-03, -2.0173e-03,  2.6143e-03],\n",
            "          [ 5.9198e-03,  1.2641e-03,  1.7948e-03,  7.9188e-03, -2.4290e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 1.3819e-03, -6.3653e-04,  7.3311e-04,  4.0156e-03, -6.1173e-03],\n",
            "          [ 4.2967e-03,  9.1553e-04,  1.7428e-03,  3.0988e-03,  7.4540e-03],\n",
            "          [-4.6191e-04, -1.4345e-04, -2.1146e-03, -4.2065e-03,  8.3861e-05],\n",
            "          [-1.4078e-03, -4.3775e-04, -4.0060e-04,  8.1039e-03, -6.4240e-04],\n",
            "          [ 2.6580e-04, -1.0582e-03,  1.0319e-03,  7.3097e-03,  3.2933e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0011]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0231]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0011,  0.0231], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 5, 6] = -0.0011184141039848328\n",
            " somado na saída em [1, 1, 5, 6] = 0.023135703057050705\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 5, 7\n",
            " alvo do kernel em x: x[1,0,15:20, 21:26]\n",
            " \n",
            " tensor([[0.5028, 0.6635, 0.8726, 0.4722, 0.6950],\n",
            "        [0.7527, 0.8967, 0.5505, 0.2609, 0.7562],\n",
            "        [0.5973, 0.1269, 0.6650, 0.1177, 0.8899],\n",
            "        [0.8554, 0.8144, 0.9513, 0.9368, 0.0420],\n",
            "        [0.8204, 0.0539, 0.7422, 0.2216, 0.9450]])\n",
            " produto: tensor([[[[-2.0503e-03,  2.1978e-04, -4.3340e-03,  1.7808e-03, -5.9217e-03],\n",
            "          [ 5.5178e-03, -6.5174e-03, -4.3763e-03, -1.6483e-03,  3.4248e-03],\n",
            "          [-2.2069e-03,  4.7472e-04, -5.6437e-03, -7.1422e-04, -3.2675e-03],\n",
            "          [-1.6810e-03, -6.2131e-03,  6.2287e-03, -2.2094e-03,  1.3477e-04],\n",
            "          [ 5.8013e-03,  1.0034e-04,  2.0295e-03,  2.1393e-03, -4.2619e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5926e-03, -2.9520e-03,  6.2363e-03,  3.7714e-03, -6.4076e-03],\n",
            "          [ 6.4255e-03,  4.2817e-03,  2.3987e-03,  1.0739e-03,  6.2863e-03],\n",
            "          [-7.8865e-04, -1.0728e-03, -1.9081e-03, -8.2905e-04,  5.8828e-04],\n",
            "          [-1.5971e-03, -4.3686e-03, -8.6490e-04,  8.8757e-03, -3.3116e-05],\n",
            "          [ 2.6047e-04, -8.3995e-05,  1.1668e-03,  1.9748e-03,  5.7784e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0232]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0298]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0232,  0.0298], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 5, 7] = -0.023193921893835068\n",
            " somado na saída em [1, 1, 5, 7] = 0.029804952442646027\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 0\n",
            " alvo do kernel em x: x[1,0,18:23, 0:5]\n",
            " \n",
            " tensor([[0.5733, 0.1226, 0.2016, 0.6602, 0.9445],\n",
            "        [0.8904, 0.4322, 0.4296, 0.6690, 0.6446],\n",
            "        [0.8868, 0.4249, 0.1633, 0.5220, 0.7583],\n",
            "        [0.9603, 0.8089, 0.6245, 0.1951, 0.1788],\n",
            "        [0.3683, 0.2075, 0.7492, 0.5900, 0.6203]])\n",
            " produto: tensor([[[[-2.3377e-03,  4.0610e-05, -1.0013e-03,  2.4898e-03, -8.0472e-03],\n",
            "          [ 6.5267e-03, -3.1411e-03, -3.4158e-03, -4.2275e-03,  2.9195e-03],\n",
            "          [-3.2766e-03,  1.5900e-03, -1.3860e-03, -3.1668e-03, -2.7842e-03],\n",
            "          [-1.8871e-03, -6.1705e-03,  4.0894e-03, -4.6020e-04,  5.7404e-04],\n",
            "          [ 2.6042e-03,  3.8649e-04,  2.0488e-03,  5.6954e-03, -2.7974e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.8159e-03, -5.4545e-04,  1.4407e-03,  5.2730e-03, -8.7076e-03],\n",
            "          [ 7.6004e-03,  2.0636e-03,  1.8722e-03,  2.7542e-03,  5.3589e-03],\n",
            "          [-1.1709e-03, -3.5933e-03, -4.6861e-04, -3.6760e-03,  5.0127e-04],\n",
            "          [-1.7929e-03, -4.3386e-03, -5.6784e-04,  1.8487e-03, -1.4106e-04],\n",
            "          [ 1.1693e-04, -3.2354e-04,  1.1778e-03,  5.2573e-03,  3.7928e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0151]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0155]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0151,  0.0155], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 6, 0] = -0.015134465880692005\n",
            " somado na saída em [1, 1, 6, 0] = 0.015548108145594597\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 1\n",
            " alvo do kernel em x: x[1,0,18:23, 3:8]\n",
            " \n",
            " tensor([[0.6602, 0.9445, 0.7832, 0.6306, 0.7365],\n",
            "        [0.6690, 0.6446, 0.8576, 0.3629, 0.2140],\n",
            "        [0.5220, 0.7583, 0.7841, 0.0838, 0.4304],\n",
            "        [0.1951, 0.1788, 0.5764, 0.8628, 0.5481],\n",
            "        [0.5900, 0.6203, 0.8680, 0.3046, 0.7517]])\n",
            " produto: tensor([[[[-0.0027,  0.0003, -0.0039,  0.0024, -0.0063],\n",
            "          [ 0.0049, -0.0047, -0.0068, -0.0023,  0.0010],\n",
            "          [-0.0019,  0.0028, -0.0067, -0.0005, -0.0016],\n",
            "          [-0.0004, -0.0014,  0.0038, -0.0020,  0.0018],\n",
            "          [ 0.0042,  0.0012,  0.0024,  0.0029, -0.0034]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0021, -0.0042,  0.0056,  0.0050, -0.0068],\n",
            "          [ 0.0057,  0.0031,  0.0037,  0.0015,  0.0018],\n",
            "          [-0.0007, -0.0064, -0.0023, -0.0006,  0.0003],\n",
            "          [-0.0004, -0.0010, -0.0005,  0.0082, -0.0004],\n",
            "          [ 0.0002, -0.0010,  0.0014,  0.0027,  0.0046]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0169]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0217]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0169,  0.0217], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 6, 1] = -0.01692367158830166\n",
            " somado na saída em [1, 1, 6, 1] = 0.021662861108779907\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 2\n",
            " alvo do kernel em x: x[1,0,18:23, 6:11]\n",
            " \n",
            " tensor([[0.6306, 0.7365, 0.8663, 0.9485, 0.0083],\n",
            "        [0.3629, 0.2140, 0.7355, 0.1336, 0.8058],\n",
            "        [0.0838, 0.4304, 0.5082, 0.3141, 0.1689],\n",
            "        [0.8628, 0.5481, 0.8148, 0.9012, 0.9201],\n",
            "        [0.3046, 0.7517, 0.5895, 0.1279, 0.2288]])\n",
            " produto: tensor([[[[-2.5714e-03,  2.4398e-04, -4.3025e-03,  3.5767e-03, -7.0587e-05],\n",
            "          [ 2.6600e-03, -1.5552e-03, -5.8475e-03, -8.4410e-04,  3.6493e-03],\n",
            "          [-3.0975e-04,  1.6107e-03, -4.3136e-03, -1.9055e-03, -6.1999e-04],\n",
            "          [-1.6956e-03, -4.1810e-03,  5.3356e-03, -2.1254e-03,  2.9535e-03],\n",
            "          [ 2.1538e-03,  1.4005e-03,  1.6120e-03,  1.2347e-03, -1.0317e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.9974e-03, -3.2770e-03,  6.1909e-03,  7.5749e-03, -7.6379e-05],\n",
            "          [ 3.0976e-03,  1.0217e-03,  3.2050e-03,  5.4993e-04,  6.6984e-03],\n",
            "          [-1.1069e-04, -3.6402e-03, -1.4584e-03, -2.2119e-03,  1.1162e-04],\n",
            "          [-1.6109e-03, -2.9398e-03, -7.4087e-04,  8.5384e-03, -7.2576e-04],\n",
            "          [ 9.6705e-05, -1.1724e-03,  9.2674e-04,  1.1397e-03,  1.3988e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0049]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0246]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0049,  0.0246], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 6, 2] = -0.004942983388900757\n",
            " somado na saída em [1, 1, 6, 2] = 0.024583762511610985\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 3\n",
            " alvo do kernel em x: x[1,0,18:23, 9:14]\n",
            " \n",
            " tensor([[0.9485, 0.0083, 0.5005, 0.1835, 0.3013],\n",
            "        [0.1336, 0.8058, 0.3869, 0.7523, 0.1501],\n",
            "        [0.3141, 0.1689, 0.0869, 0.5135, 0.1087],\n",
            "        [0.9012, 0.9201, 0.2774, 0.2780, 0.9250],\n",
            "        [0.1279, 0.2288, 0.1911, 0.7824, 0.1864]])\n",
            " produto: tensor([[[[-3.8676e-03,  2.7441e-06, -2.4860e-03,  6.9206e-04, -2.5674e-03],\n",
            "          [ 9.7923e-04, -5.8567e-03, -3.0763e-03, -4.7539e-03,  6.7992e-04],\n",
            "          [-1.1604e-03,  6.3187e-04, -7.3742e-04, -3.1157e-03, -3.9896e-04],\n",
            "          [-1.7711e-03, -7.0193e-03,  1.8163e-03, -6.5562e-04,  2.9690e-03],\n",
            "          [ 9.0451e-04,  4.2619e-04,  5.2260e-04,  7.5521e-03, -8.4081e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 3.0042e-03, -3.6858e-05,  3.5771e-03,  1.4657e-03, -2.7780e-03],\n",
            "          [ 1.1403e-03,  3.8477e-03,  1.6862e-03,  3.0972e-03,  1.2480e-03],\n",
            "          [-4.1469e-04, -1.4280e-03, -2.4932e-04, -3.6166e-03,  7.1828e-05],\n",
            "          [-1.6827e-03, -4.9354e-03, -2.5220e-04,  2.6338e-03, -7.2957e-04],\n",
            "          [ 4.0612e-05, -3.5677e-04,  3.0044e-04,  6.9712e-03,  1.1400e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0211]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0137]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0211,  0.0137], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 6, 3] = -0.021130679175257683\n",
            " somado na saída em [1, 1, 6, 3] = 0.01374417170882225\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 4\n",
            " alvo do kernel em x: x[1,0,18:23, 12:17]\n",
            " \n",
            " tensor([[0.1835, 0.3013, 0.0048, 0.0933, 0.8212],\n",
            "        [0.7523, 0.1501, 0.1501, 0.3409, 0.5355],\n",
            "        [0.5135, 0.1087, 0.6680, 0.5044, 0.5654],\n",
            "        [0.2780, 0.9250, 0.5879, 0.9308, 0.9606],\n",
            "        [0.7824, 0.1864, 0.0266, 0.4059, 0.1886]])\n",
            " produto: tensor([[[[-7.4833e-04,  9.9809e-05, -2.3904e-05,  3.5182e-04, -6.9971e-03],\n",
            "          [ 5.5149e-03, -1.0912e-03, -1.1937e-03, -2.1539e-03,  2.4254e-03],\n",
            "          [-1.8974e-03,  4.0660e-04, -5.6692e-03, -3.0605e-03, -2.0759e-03],\n",
            "          [-5.4633e-04, -7.0562e-03,  3.8493e-03, -2.1951e-03,  3.0834e-03],\n",
            "          [ 5.5327e-03,  3.4733e-04,  7.2790e-05,  3.9180e-03, -8.5063e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 5.8129e-04, -1.3406e-03,  3.4396e-05,  7.4508e-04, -7.5712e-03],\n",
            "          [ 6.4222e-03,  7.1689e-04,  6.5429e-04,  1.4032e-03,  4.4518e-03],\n",
            "          [-6.7806e-04, -9.1890e-04, -1.9167e-03, -3.5525e-03,  3.7375e-04],\n",
            "          [-5.1905e-04, -4.9614e-03, -5.3450e-04,  8.8182e-03, -7.5767e-04],\n",
            "          [ 2.4841e-04, -2.9075e-04,  4.1847e-05,  3.6167e-03,  1.1533e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0100]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0062]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0100,  0.0062], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 6, 4] = -0.009957280941307545\n",
            " somado na saída em [1, 1, 6, 4] = 0.006220128852874041\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 5\n",
            " alvo do kernel em x: x[1,0,18:23, 15:20]\n",
            " \n",
            " tensor([[0.0933, 0.8212, 0.4290, 0.7540, 0.0816],\n",
            "        [0.3409, 0.5355, 0.3474, 0.8371, 0.6785],\n",
            "        [0.5044, 0.5654, 0.4855, 0.6873, 0.6315],\n",
            "        [0.9308, 0.9606, 0.0225, 0.9806, 0.5618],\n",
            "        [0.4059, 0.1886, 0.3056, 0.0704, 0.9784]])\n",
            " produto: tensor([[[[-3.8042e-04,  2.7202e-04, -2.1305e-03,  2.8436e-03, -6.9537e-04],\n",
            "          [ 2.4987e-03, -3.8924e-03, -2.7620e-03, -5.2898e-03,  3.0730e-03],\n",
            "          [-1.8638e-03,  2.1157e-03, -4.1204e-03, -4.1699e-03, -2.3187e-03],\n",
            "          [-1.8292e-03, -7.3280e-03,  1.4734e-04, -2.3125e-03,  1.8034e-03],\n",
            "          [ 2.8703e-03,  3.5138e-04,  8.3554e-04,  6.8001e-04, -4.4127e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.9550e-04, -3.6536e-03,  3.0656e-03,  6.0222e-03, -7.5244e-04],\n",
            "          [ 2.9098e-03,  2.5572e-03,  1.5139e-03,  3.4463e-03,  5.6405e-03],\n",
            "          [-6.6604e-04, -4.7814e-03, -1.3931e-03, -4.8404e-03,  4.1746e-04],\n",
            "          [-1.7378e-03, -5.1525e-03, -2.0459e-05,  9.2900e-03, -4.4314e-04],\n",
            "          [ 1.2888e-04, -2.9415e-04,  4.8035e-04,  6.2770e-04,  5.9828e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0260]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0186]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0260,  0.0186], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 6, 5] = -0.02601485699415207\n",
            " somado na saída em [1, 1, 6, 5] = 0.018643174320459366\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 6\n",
            " alvo do kernel em x: x[1,0,18:23, 18:23]\n",
            " \n",
            " tensor([[0.7540, 0.0816, 0.4406, 0.8554, 0.8144],\n",
            "        [0.8371, 0.6785, 0.6564, 0.8204, 0.0539],\n",
            "        [0.6873, 0.6315, 0.5607, 0.8737, 0.8729],\n",
            "        [0.9806, 0.5618, 0.2621, 0.7708, 0.1229],\n",
            "        [0.0704, 0.9784, 0.9738, 0.1030, 0.1536]])\n",
            " produto: tensor([[[[-3.0748e-03,  2.7033e-05, -2.1883e-03,  3.2258e-03, -6.9395e-03],\n",
            "          [ 6.1367e-03, -4.9317e-03, -5.2184e-03, -5.1839e-03,  2.4391e-04],\n",
            "          [-2.5395e-03,  2.3632e-03, -4.7584e-03, -5.3010e-03, -3.2049e-03],\n",
            "          [-1.9270e-03, -4.2859e-03,  1.7164e-03, -1.8178e-03,  3.9463e-04],\n",
            "          [ 4.9817e-04,  1.8228e-03,  2.6628e-03,  9.9406e-04, -6.9270e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 2.3884e-03, -3.6310e-04,  3.1487e-03,  6.8316e-03, -7.5090e-03],\n",
            "          [ 7.1463e-03,  3.2400e-03,  2.8602e-03,  3.3773e-03,  4.4771e-04],\n",
            "          [-9.0749e-04, -5.3406e-03, -1.6088e-03, -6.1533e-03,  5.7702e-04],\n",
            "          [-1.8308e-03, -3.0135e-03, -2.3833e-04,  7.3026e-03, -9.6972e-05],\n",
            "          [ 2.2367e-05, -1.5259e-03,  1.5309e-03,  9.1760e-04,  9.3918e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0320]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0121]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0320,  0.0121], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 6, 6] = -0.03197847306728363\n",
            " somado na saída em [1, 1, 6, 6] = 0.012142072431743145\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 6, 7\n",
            " alvo do kernel em x: x[1,0,18:23, 21:26]\n",
            " \n",
            " tensor([[0.8554, 0.8144, 0.9513, 0.9368, 0.0420],\n",
            "        [0.8204, 0.0539, 0.7422, 0.2216, 0.9450],\n",
            "        [0.8737, 0.8729, 0.3216, 0.9365, 0.0021],\n",
            "        [0.7708, 0.1229, 0.3504, 0.8441, 0.9065],\n",
            "        [0.1030, 0.1536, 0.4647, 0.1145, 0.3009]])\n",
            " produto: tensor([[[[-3.4881e-03,  2.6978e-04, -4.7245e-03,  3.5330e-03, -3.5774e-04],\n",
            "          [ 6.0137e-03, -3.9145e-04, -5.9008e-03, -1.4005e-03,  4.2797e-03],\n",
            "          [-3.2283e-03,  3.2664e-03, -2.7292e-03, -5.6819e-03, -7.8140e-06],\n",
            "          [-1.5148e-03, -9.3789e-04,  2.2945e-03, -1.9907e-03,  2.9097e-03],\n",
            "          [ 7.2824e-04,  2.8614e-04,  1.2708e-03,  1.1053e-03, -1.3571e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.7094e-03, -3.6236e-03,  6.7982e-03,  7.4821e-03, -3.8709e-04],\n",
            "          [ 7.0031e-03,  2.5717e-04,  3.2342e-03,  9.1241e-04,  7.8555e-03],\n",
            "          [-1.1536e-03, -7.3818e-03, -9.2272e-04, -6.5954e-03,  1.4068e-06],\n",
            "          [-1.4391e-03, -6.5945e-04, -3.1861e-04,  7.9974e-03, -7.1498e-04],\n",
            "          [ 3.2697e-05, -2.3954e-04,  7.3059e-04,  1.0203e-03,  1.8400e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0078]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0244]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0078,  0.0244], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 6, 7] = -0.007753363810479641\n",
            " somado na saída em [1, 1, 6, 7] = 0.02443856932222843\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 0\n",
            " alvo do kernel em x: x[1,0,21:26, 0:5]\n",
            " \n",
            " tensor([[0.9603, 0.8089, 0.6245, 0.1951, 0.1788],\n",
            "        [0.3683, 0.2075, 0.7492, 0.5900, 0.6203],\n",
            "        [0.9992, 0.9132, 0.0440, 0.0074, 0.2083],\n",
            "        [0.6770, 0.6826, 0.2888, 0.8483, 0.9896],\n",
            "        [0.4493, 0.0843, 0.3308, 0.6216, 0.1567]])\n",
            " produto: tensor([[[[-3.9157e-03,  2.6793e-04, -3.1018e-03,  7.3589e-04, -1.5238e-03],\n",
            "          [ 2.6996e-03, -1.5078e-03, -5.9566e-03, -3.7284e-03,  2.8091e-03],\n",
            "          [-3.6921e-03,  3.4172e-03, -3.7376e-04, -4.4603e-05, -7.6480e-04],\n",
            "          [-1.3305e-03, -5.2072e-03,  1.8908e-03, -2.0005e-03,  3.1765e-03],\n",
            "          [ 3.1770e-03,  1.5703e-04,  9.0445e-04,  6.0002e-03, -7.0671e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 3.0416e-03, -3.5988e-03,  4.4633e-03,  1.5585e-03, -1.6488e-03],\n",
            "          [ 3.1437e-03,  9.9060e-04,  3.2649e-03,  2.4291e-03,  5.1562e-03],\n",
            "          [-1.3194e-03, -7.7226e-03, -1.2637e-04, -5.1774e-05,  1.3769e-04],\n",
            "          [-1.2641e-03, -3.6613e-03, -2.6255e-04,  8.0366e-03, -7.8056e-04],\n",
            "          [ 1.4265e-04, -1.3145e-04,  5.1997e-04,  5.5387e-03,  9.5818e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0086]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0188]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0086,  0.0188], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 7, 0] = -0.008618706837296486\n",
            " somado na saída em [1, 1, 7, 0] = 0.01881403475999832\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 1\n",
            " alvo do kernel em x: x[1,0,21:26, 3:8]\n",
            " \n",
            " tensor([[0.1951, 0.1788, 0.5764, 0.8628, 0.5481],\n",
            "        [0.5900, 0.6203, 0.8680, 0.3046, 0.7517],\n",
            "        [0.0074, 0.2083, 0.7692, 0.1449, 0.8692],\n",
            "        [0.8483, 0.9896, 0.1457, 0.3154, 0.6381],\n",
            "        [0.6216, 0.1567, 0.3200, 0.0582, 0.6815]])\n",
            " produto: tensor([[[[-7.9572e-04,  5.9238e-05, -2.8627e-03,  3.2538e-03, -4.6698e-03],\n",
            "          [ 4.3253e-03, -4.5083e-03, -6.9013e-03, -1.9246e-03,  3.4045e-03],\n",
            "          [-2.7163e-05,  7.7946e-04, -6.5280e-03, -8.7935e-04, -3.1917e-03],\n",
            "          [-1.6670e-03, -7.5494e-03,  9.5404e-04, -7.4389e-04,  2.0483e-03],\n",
            "          [ 4.3957e-03,  2.9193e-04,  8.7507e-04,  5.6155e-04, -3.0736e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 6.1810e-04, -7.9566e-04,  4.1192e-03,  6.8909e-03, -5.0530e-03],\n",
            "          [ 5.0369e-03,  2.9618e-03,  3.7826e-03,  1.2539e-03,  6.2491e-03],\n",
            "          [-9.7068e-06, -1.7615e-03, -2.2071e-03, -1.0207e-03,  5.7463e-04],\n",
            "          [-1.5838e-03, -5.3081e-03, -1.3247e-04,  2.9884e-03, -5.0334e-04],\n",
            "          [ 1.9736e-04, -2.4438e-04,  5.0308e-04,  5.1836e-04,  4.1673e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0244]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0212]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0244,  0.0212], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 7, 1] = -0.024373628199100494\n",
            " somado na saída em [1, 1, 7, 1] = 0.021241862326860428\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 2\n",
            " alvo do kernel em x: x[1,0,21:26, 6:11]\n",
            " \n",
            " tensor([[0.8628, 0.5481, 0.8148, 0.9012, 0.9201],\n",
            "        [0.3046, 0.7517, 0.5895, 0.1279, 0.2288],\n",
            "        [0.1449, 0.8692, 0.5014, 0.7384, 0.7390],\n",
            "        [0.3154, 0.6381, 0.6555, 0.2204, 0.4549],\n",
            "        [0.0582, 0.6815, 0.6295, 0.5264, 0.6800]])\n",
            " produto: tensor([[[[-3.5183e-03,  1.8155e-04, -4.0470e-03,  3.3987e-03, -7.8400e-03],\n",
            "          [ 2.2327e-03, -5.4639e-03, -4.6868e-03, -8.0825e-04,  1.0360e-03],\n",
            "          [-5.3552e-04,  3.2528e-03, -4.2552e-03, -4.4799e-03, -2.7133e-03],\n",
            "          [-6.1989e-04, -4.8681e-03,  4.2924e-03, -5.1982e-04,  1.4603e-03],\n",
            "          [ 4.1139e-04,  1.2697e-03,  1.7213e-03,  5.0813e-03, -3.0668e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.7330e-03, -2.4384e-03,  5.8233e-03,  7.1979e-03, -8.4833e-03],\n",
            "          [ 2.6001e-03,  3.5896e-03,  2.5689e-03,  5.2658e-04,  1.9016e-03],\n",
            "          [-1.9137e-04, -7.3512e-03, -1.4386e-03, -5.2002e-03,  4.8850e-04],\n",
            "          [-5.8894e-04, -3.4229e-03, -5.9603e-04,  2.0883e-03, -3.5883e-04],\n",
            "          [ 1.8471e-05, -1.0629e-03,  9.8961e-04,  4.6904e-03,  4.1581e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0231]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0082]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0231,  0.0082], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 7, 2] = -0.02308453433215618\n",
            " somado na saída em [1, 1, 7, 2] = 0.008241575211286545\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 3\n",
            " alvo do kernel em x: x[1,0,21:26, 9:14]\n",
            " \n",
            " tensor([[0.9012, 0.9201, 0.2774, 0.2780, 0.9250],\n",
            "        [0.1279, 0.2288, 0.1911, 0.7824, 0.1864],\n",
            "        [0.7384, 0.7390, 0.8741, 0.7793, 0.9747],\n",
            "        [0.2204, 0.4549, 0.0385, 0.1135, 0.8426],\n",
            "        [0.5264, 0.6800, 0.6926, 0.3610, 0.8267]])\n",
            " produto: tensor([[[[-3.6751e-03,  3.0479e-04, -1.3777e-03,  1.0484e-03, -7.8812e-03],\n",
            "          [ 9.3764e-04, -1.6627e-03, -1.5194e-03, -4.9439e-03,  8.4432e-04],\n",
            "          [-2.7282e-03,  2.7653e-03, -7.4191e-03, -4.7279e-03, -3.5790e-03],\n",
            "          [-4.3317e-04, -3.4705e-03,  2.5232e-04, -2.6756e-04,  2.7047e-03],\n",
            "          [ 3.7225e-03,  1.2669e-03,  1.8940e-03,  3.4848e-03, -3.7283e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.8547e-03, -4.0938e-03,  1.9823e-03,  2.2203e-03, -8.5279e-03],\n",
            "          [ 1.0919e-03,  1.0923e-03,  8.3281e-04,  3.2209e-03,  1.5498e-03],\n",
            "          [-9.7494e-04, -6.2493e-03, -2.5083e-03, -5.4881e-03,  6.4436e-04],\n",
            "          [-4.1154e-04, -2.4402e-03, -3.5037e-05,  1.0749e-03, -6.6461e-04],\n",
            "          [ 1.6714e-04, -1.0605e-03,  1.0888e-03,  3.2168e-03,  5.0549e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0282]]],\n",
            "\n",
            "\n",
            "        [[[-0.0064]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0282, -0.0064], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 7, 3] = -0.028188098222017288\n",
            " somado na saída em [1, 1, 7, 3] = -0.006362296175211668\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 4\n",
            " alvo do kernel em x: x[1,0,21:26, 12:17]\n",
            " \n",
            " tensor([[2.7800e-01, 9.2496e-01, 5.8787e-01, 9.3078e-01, 9.6059e-01],\n",
            "        [7.8240e-01, 1.8643e-01, 2.6619e-02, 4.0591e-01, 1.8861e-01],\n",
            "        [7.7926e-01, 9.7473e-01, 3.9635e-01, 2.2619e-01, 6.6918e-01],\n",
            "        [1.1346e-01, 8.4261e-01, 8.5343e-01, 7.9145e-01, 4.0302e-01],\n",
            "        [3.6102e-01, 8.2666e-01, 7.3481e-04, 6.4284e-02, 1.2425e-01]])\n",
            " produto: tensor([[[[-1.1336e-03,  3.0639e-04, -2.9197e-03,  3.5101e-03, -8.1848e-03],\n",
            "          [ 5.7353e-03, -1.3550e-03, -2.1163e-04, -2.5649e-03,  8.5418e-04],\n",
            "          [-2.8793e-03,  3.6476e-03, -3.3639e-03, -1.3723e-03, -2.4571e-03],\n",
            "          [-2.2296e-04, -6.4280e-03,  5.5882e-03, -1.8665e-03,  1.2936e-03],\n",
            "          [ 2.5529e-03,  1.5401e-03,  2.0093e-06,  6.2050e-04, -5.6039e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 8.8058e-04, -4.1153e-03,  4.2012e-03,  7.4337e-03, -8.8564e-03],\n",
            "          [ 6.6789e-03,  8.9022e-04,  1.1600e-04,  1.6710e-03,  1.5679e-03],\n",
            "          [-1.0289e-03, -8.2432e-03, -1.1373e-03, -1.5930e-03,  4.4237e-04],\n",
            "          [-2.1183e-04, -4.5196e-03, -7.7595e-04,  7.4983e-03, -3.1788e-04],\n",
            "          [ 1.1462e-04, -1.2893e-03,  1.1552e-06,  5.7278e-04,  7.5979e-04]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0099]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0007]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0099,  0.0007], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 7, 4] = -0.009869217872619629\n",
            " somado na saída em [1, 1, 7, 4] = 0.0007398095913231373\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 5\n",
            " alvo do kernel em x: x[1,0,21:26, 15:20]\n",
            " \n",
            " tensor([[0.9308, 0.9606, 0.0225, 0.9806, 0.5618],\n",
            "        [0.4059, 0.1886, 0.3056, 0.0704, 0.9784],\n",
            "        [0.2262, 0.6692, 0.9024, 0.3440, 0.9779],\n",
            "        [0.7915, 0.4030, 0.8209, 0.3390, 0.6290],\n",
            "        [0.0643, 0.1243, 0.5286, 0.0583, 0.5357]])\n",
            " produto: tensor([[[[-3.7955e-03,  3.1819e-04, -1.1176e-04,  3.6979e-03, -4.7870e-03],\n",
            "          [ 2.9755e-03, -1.3709e-03, -2.4293e-03, -4.4515e-04,  4.4311e-03],\n",
            "          [-8.3574e-04,  2.5042e-03, -7.6592e-03, -2.0871e-03, -3.5907e-03],\n",
            "          [-1.5554e-03, -3.0745e-03,  5.3751e-03, -7.9950e-04,  2.0191e-03],\n",
            "          [ 4.5458e-04,  2.3149e-04,  1.4455e-03,  5.6298e-04, -2.4162e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.9483e-03, -4.2738e-03,  1.6081e-04,  7.8314e-03, -5.1799e-03],\n",
            "          [ 3.4650e-03,  9.0062e-04,  1.3315e-03,  2.9002e-04,  8.1334e-03],\n",
            "          [-2.9866e-04, -5.6593e-03, -2.5895e-03, -2.4227e-03,  6.4647e-04],\n",
            "          [-1.4777e-03, -2.1617e-03, -7.4637e-04,  3.2118e-03, -4.9615e-04],\n",
            "          [ 2.0410e-05, -1.9378e-04,  8.3102e-04,  5.1967e-04,  3.2760e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0109]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0081]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0109,  0.0081], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 7, 5] = -0.010942300781607628\n",
            " somado na saída em [1, 1, 7, 5] = 0.008066992275416851\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 6\n",
            " alvo do kernel em x: x[1,0,21:26, 18:23]\n",
            " \n",
            " tensor([[0.9806, 0.5618, 0.2621, 0.7708, 0.1229],\n",
            "        [0.0704, 0.9784, 0.9738, 0.1030, 0.1536],\n",
            "        [0.3440, 0.9779, 0.9154, 0.6843, 0.9358],\n",
            "        [0.3390, 0.6290, 0.8641, 0.8138, 0.5514],\n",
            "        [0.0583, 0.5357, 0.4934, 0.0413, 0.9909]])\n",
            " produto: tensor([[[[-3.9986e-03,  1.8610e-04, -1.3019e-03,  2.9068e-03, -1.0475e-03],\n",
            "          [ 5.1642e-04, -7.1114e-03, -7.7420e-03, -6.5074e-04,  6.9559e-04],\n",
            "          [-1.2710e-03,  3.6595e-03, -7.7696e-03, -4.1518e-03, -3.4359e-03],\n",
            "          [-6.6623e-04, -4.7986e-03,  5.6580e-03, -1.9192e-03,  1.7698e-03],\n",
            "          [ 4.1243e-04,  9.9812e-04,  1.3491e-03,  3.9820e-04, -4.4691e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 3.1060e-03, -2.4996e-03,  1.8733e-03,  6.1560e-03, -1.1335e-03],\n",
            "          [ 6.0138e-04,  4.6720e-03,  4.2435e-03,  4.2396e-04,  1.2768e-03],\n",
            "          [-4.5421e-04, -8.2703e-03, -2.6268e-03, -4.8193e-03,  6.1861e-04],\n",
            "          [-6.3296e-04, -3.3740e-03, -7.8564e-04,  7.7101e-03, -4.3489e-04],\n",
            "          [ 1.8518e-05, -8.3555e-04,  7.7563e-04,  3.6757e-04,  6.0593e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0318]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0120]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0318,  0.0120], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 7, 6] = -0.03178352490067482\n",
            " somado na saída em [1, 1, 7, 6] = 0.012035710737109184\n",
            "\n",
            "ndx_linhas_saida, ndx_colunas_saida: 7, 7\n",
            " alvo do kernel em x: x[1,0,21:26, 21:26]\n",
            " \n",
            " tensor([[0.7708, 0.1229, 0.3504, 0.8441, 0.9065],\n",
            "        [0.1030, 0.1536, 0.4647, 0.1145, 0.3009],\n",
            "        [0.6843, 0.9358, 0.5081, 0.7446, 0.0274],\n",
            "        [0.8138, 0.5514, 0.3976, 0.4924, 0.7192],\n",
            "        [0.0413, 0.9909, 0.3832, 0.8595, 0.9408]])\n",
            " produto: tensor([[[[-3.1431e-03,  4.0724e-05, -1.7404e-03,  3.1833e-03, -7.7236e-03],\n",
            "          [ 7.5491e-04, -1.1163e-03, -3.6948e-03, -7.2358e-04,  1.3627e-03],\n",
            "          [-2.5284e-03,  3.5018e-03, -4.3121e-03, -4.5177e-03, -1.0044e-04],\n",
            "          [-1.5993e-03, -4.2062e-03,  2.6035e-03, -1.1613e-03,  2.3086e-03],\n",
            "          [ 2.9172e-04,  1.8461e-03,  1.0478e-03,  8.2964e-03, -4.2429e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.4415e-03, -5.4700e-04,  2.5043e-03,  6.7417e-03, -8.3574e-03],\n",
            "          [ 8.7911e-04,  7.3341e-04,  2.0251e-03,  4.7141e-04,  2.5013e-03],\n",
            "          [-9.0354e-04, -7.9138e-03, -1.4579e-03, -5.2441e-03,  1.8084e-05],\n",
            "          [-1.5194e-03, -2.9575e-03, -3.6151e-04,  4.6653e-03, -5.6728e-04],\n",
            "          [ 1.3098e-05, -1.5454e-03,  6.0237e-04,  7.6583e-03,  5.7526e-03]]]],\n",
            "       grad_fn=<MulBackward0>)\n",
            " soma: tensor([[[[-0.0156]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0056]]]], grad_fn=<SumBackward1>)\n",
            " valor_soma: tensor([-0.0156,  0.0056], grad_fn=<SqueezeBackward0>)\n",
            " somado na saída em [1, 0, 7, 7] = -0.015572639182209969\n",
            " somado na saída em [1, 1, 7, 7] = 0.005632834043353796\n",
            " saida: tensor([[[[-4.9560e-03, -2.6992e-02, -9.3166e-03, -1.7695e-02, -1.4529e-02,\n",
            "           -2.2996e-03, -1.9159e-02, -1.5580e-02],\n",
            "          [-1.2767e-02, -1.5066e-02, -1.3659e-02, -2.4303e-02, -2.3043e-02,\n",
            "           -1.6897e-02, -1.0567e-02, -9.4158e-03],\n",
            "          [-1.9106e-02, -1.9124e-02, -7.6398e-03, -7.3968e-03, -8.8358e-05,\n",
            "           -2.2060e-02,  1.9380e-03, -1.5003e-02],\n",
            "          [-7.9107e-03, -1.9983e-02, -1.7720e-02, -1.2660e-02, -1.2472e-02,\n",
            "            4.6553e-03, -3.2192e-02, -2.2733e-02],\n",
            "          [-2.4662e-02, -2.2800e-03, -4.5574e-03, -1.4503e-02, -1.2627e-02,\n",
            "           -3.2888e-02, -1.8694e-02, -1.3923e-02],\n",
            "          [-1.4576e-02, -1.9909e-02, -2.1908e-02, -5.9725e-03, -8.6197e-03,\n",
            "           -9.1836e-03, -1.8689e-02, -1.0934e-02],\n",
            "          [-9.5556e-03, -7.4993e-03, -7.2128e-03, -1.8068e-02, -2.4817e-02,\n",
            "           -1.3123e-02, -2.0683e-02, -2.2521e-02],\n",
            "          [-2.9399e-02, -8.7812e-03, -1.9275e-02, -6.6140e-03, -1.5578e-02,\n",
            "           -1.4934e-02, -1.4115e-02, -7.7907e-03]],\n",
            "\n",
            "         [[ 9.1433e-03,  1.0529e-02,  1.6152e-02,  1.5491e-02,  1.3419e-02,\n",
            "            2.9549e-02,  2.6636e-02,  1.4890e-02],\n",
            "          [ 2.3351e-02,  1.9000e-02,  2.5318e-02,  1.0155e-03,  8.9481e-03,\n",
            "            1.1282e-02,  2.2239e-02,  2.0918e-02],\n",
            "          [ 1.6205e-02,  1.2249e-02,  1.9792e-02,  1.3039e-02,  2.5221e-02,\n",
            "            1.5680e-02,  2.3254e-02,  1.5700e-02],\n",
            "          [ 2.0722e-02,  1.7879e-02,  2.0459e-02,  2.2305e-02,  2.7725e-02,\n",
            "            2.0340e-02,  1.5050e-02,  2.1441e-02],\n",
            "          [ 1.7156e-03,  1.9875e-02,  1.6109e-02,  1.3116e-02,  1.6608e-02,\n",
            "            2.6487e-03,  8.6775e-03,  1.1801e-02],\n",
            "          [ 1.4794e-02,  1.9426e-02,  1.8991e-02,  1.8946e-02,  4.5655e-03,\n",
            "           -2.4875e-03, -7.0251e-04,  1.0702e-02],\n",
            "          [ 2.3042e-02,  1.8351e-02,  2.2838e-02,  2.2092e-02,  2.8832e-02,\n",
            "            3.4959e-02,  5.3466e-03,  1.1041e-02],\n",
            "          [ 3.5085e-03,  1.4803e-02,  1.4042e-02,  2.1044e-02,  7.5547e-03,\n",
            "            7.7298e-03,  1.7194e-02,  1.5197e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.2075e-02, -5.5586e-03, -2.5494e-02, -3.3947e-04, -2.2405e-02,\n",
            "           -5.1404e-03, -1.1975e-02, -1.5119e-02],\n",
            "          [-1.2109e-02, -1.1624e-02, -6.8038e-03, -2.0831e-02, -7.2898e-03,\n",
            "           -7.8211e-03, -1.9580e-02, -2.4568e-02],\n",
            "          [-2.6916e-02, -1.4775e-02, -2.0550e-02, -2.0641e-02, -1.2463e-02,\n",
            "           -1.8217e-02, -7.7525e-03, -2.5940e-03],\n",
            "          [ 8.6202e-04, -1.0088e-02, -5.1845e-03, -3.2831e-03, -2.1057e-02,\n",
            "           -3.2730e-03,  8.2749e-04, -1.7341e-02],\n",
            "          [-1.4011e-02, -1.1110e-02, -1.7520e-02, -1.3328e-02, -2.0545e-02,\n",
            "           -1.3766e-02, -1.6659e-02,  1.1037e-03],\n",
            "          [-6.2037e-03, -1.6385e-02, -1.7689e-02, -6.5939e-03, -1.4510e-02,\n",
            "           -1.9025e-02, -1.1184e-03, -2.3194e-02],\n",
            "          [-1.5134e-02, -1.6924e-02, -4.9430e-03, -2.1131e-02, -9.9573e-03,\n",
            "           -2.6015e-02, -3.1978e-02, -7.7534e-03],\n",
            "          [-8.6187e-03, -2.4374e-02, -2.3085e-02, -2.8188e-02, -9.8692e-03,\n",
            "           -1.0942e-02, -3.1784e-02, -1.5573e-02]],\n",
            "\n",
            "         [[ 2.5774e-02,  5.5252e-03,  1.0504e-02,  1.1775e-02,  1.1740e-02,\n",
            "            5.7546e-03,  8.8708e-03,  9.8676e-03],\n",
            "          [ 1.8577e-02,  1.2845e-02,  1.0565e-02,  1.3090e-02,  2.5072e-03,\n",
            "            1.3006e-02,  8.1983e-03, -3.8187e-03],\n",
            "          [ 7.3670e-03,  1.1850e-02,  1.6644e-02,  1.6029e-02,  2.3857e-03,\n",
            "            1.2008e-02,  2.1645e-02,  1.2285e-02],\n",
            "          [ 1.1777e-02,  2.9439e-02,  2.0420e-02,  1.5535e-02,  1.6298e-02,\n",
            "            2.8386e-02,  1.7530e-02,  1.0159e-02],\n",
            "          [ 1.4532e-02,  1.3897e-02,  2.5925e-02,  2.3848e-02,  1.7133e-02,\n",
            "            2.3739e-02,  1.5223e-02,  7.2033e-03],\n",
            "          [ 2.4261e-02, -3.3063e-03,  5.0230e-03,  1.9957e-02,  1.0780e-02,\n",
            "            2.9106e-02,  2.3136e-02,  2.9805e-02],\n",
            "          [ 1.5548e-02,  2.1663e-02,  2.4584e-02,  1.3744e-02,  6.2201e-03,\n",
            "            1.8643e-02,  1.2142e-02,  2.4439e-02],\n",
            "          [ 1.8814e-02,  2.1242e-02,  8.2416e-03, -6.3623e-03,  7.3981e-04,\n",
            "            8.0670e-03,  1.2036e-02,  5.6328e-03]]]], grad_fn=<CopySlices>)\n",
            "\n",
            "ndx_amostra: 0\n",
            "\n",
            "ndx_amostra: 1\n",
            " saida apos somar bias: tensor([[[[-0.0014, -0.0234, -0.0058, -0.0141, -0.0110,  0.0012, -0.0156,\n",
            "           -0.0120],\n",
            "          [-0.0092, -0.0115, -0.0101, -0.0208, -0.0195, -0.0133, -0.0070,\n",
            "           -0.0059],\n",
            "          [-0.0156, -0.0156, -0.0041, -0.0038,  0.0035, -0.0185,  0.0055,\n",
            "           -0.0115],\n",
            "          [-0.0044, -0.0164, -0.0142, -0.0091, -0.0089,  0.0082, -0.0286,\n",
            "           -0.0192],\n",
            "          [-0.0211,  0.0013, -0.0010, -0.0110, -0.0091, -0.0293, -0.0151,\n",
            "           -0.0104],\n",
            "          [-0.0110, -0.0164, -0.0184, -0.0024, -0.0051, -0.0056, -0.0151,\n",
            "           -0.0074],\n",
            "          [-0.0060, -0.0039, -0.0037, -0.0145, -0.0213, -0.0096, -0.0171,\n",
            "           -0.0190],\n",
            "          [-0.0258, -0.0052, -0.0157, -0.0031, -0.0120, -0.0114, -0.0106,\n",
            "           -0.0042]],\n",
            "\n",
            "         [[ 0.0113,  0.0127,  0.0183,  0.0177,  0.0156,  0.0317,  0.0288,\n",
            "            0.0171],\n",
            "          [ 0.0255,  0.0212,  0.0275,  0.0032,  0.0111,  0.0135,  0.0244,\n",
            "            0.0231],\n",
            "          [ 0.0184,  0.0144,  0.0220,  0.0152,  0.0274,  0.0179,  0.0254,\n",
            "            0.0179],\n",
            "          [ 0.0229,  0.0201,  0.0226,  0.0245,  0.0299,  0.0225,  0.0172,\n",
            "            0.0236],\n",
            "          [ 0.0039,  0.0220,  0.0183,  0.0153,  0.0188,  0.0048,  0.0109,\n",
            "            0.0140],\n",
            "          [ 0.0170,  0.0216,  0.0212,  0.0211,  0.0067, -0.0003,  0.0015,\n",
            "            0.0129],\n",
            "          [ 0.0252,  0.0205,  0.0250,  0.0243,  0.0310,  0.0371,  0.0075,\n",
            "            0.0132],\n",
            "          [ 0.0057,  0.0170,  0.0162,  0.0232,  0.0097,  0.0099,  0.0194,\n",
            "            0.0174]]],\n",
            "\n",
            "\n",
            "        [[[-0.0185, -0.0020, -0.0219,  0.0032, -0.0189, -0.0016, -0.0084,\n",
            "           -0.0116],\n",
            "          [-0.0086, -0.0081, -0.0033, -0.0173, -0.0037, -0.0043, -0.0160,\n",
            "           -0.0210],\n",
            "          [-0.0234, -0.0112, -0.0170, -0.0171, -0.0089, -0.0147, -0.0042,\n",
            "            0.0010],\n",
            "          [ 0.0044, -0.0065, -0.0016,  0.0003, -0.0175,  0.0003,  0.0044,\n",
            "           -0.0138],\n",
            "          [-0.0105, -0.0076, -0.0140, -0.0098, -0.0170, -0.0102, -0.0131,\n",
            "            0.0047],\n",
            "          [-0.0027, -0.0128, -0.0141, -0.0030, -0.0110, -0.0155,  0.0024,\n",
            "           -0.0196],\n",
            "          [-0.0116, -0.0134, -0.0014, -0.0176, -0.0064, -0.0225, -0.0284,\n",
            "           -0.0042],\n",
            "          [-0.0051, -0.0208, -0.0195, -0.0246, -0.0063, -0.0074, -0.0282,\n",
            "           -0.0120]],\n",
            "\n",
            "         [[ 0.0279,  0.0077,  0.0127,  0.0139,  0.0139,  0.0079,  0.0110,\n",
            "            0.0120],\n",
            "          [ 0.0208,  0.0150,  0.0127,  0.0153,  0.0047,  0.0152,  0.0104,\n",
            "           -0.0016],\n",
            "          [ 0.0095,  0.0140,  0.0188,  0.0182,  0.0046,  0.0142,  0.0238,\n",
            "            0.0145],\n",
            "          [ 0.0139,  0.0316,  0.0226,  0.0177,  0.0185,  0.0306,  0.0197,\n",
            "            0.0123],\n",
            "          [ 0.0167,  0.0161,  0.0281,  0.0260,  0.0193,  0.0259,  0.0174,\n",
            "            0.0094],\n",
            "          [ 0.0264, -0.0011,  0.0072,  0.0221,  0.0130,  0.0313,  0.0253,\n",
            "            0.0320],\n",
            "          [ 0.0177,  0.0238,  0.0268,  0.0159,  0.0084,  0.0208,  0.0143,\n",
            "            0.0266],\n",
            "          [ 0.0210,  0.0234,  0.0104, -0.0042,  0.0029,  0.0102,  0.0142,\n",
            "            0.0078]]]], grad_fn=<CopySlices>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Usa os mesmos pesos para minha implementação e a do pytorch\n",
        "pytorch_conv_layer = torch.nn.Conv2d( in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=0)\n",
        "pytorch_conv_layer.load_state_dict(dict(weight=initial_conv_weight, bias=initial_conv_bias))\n",
        "\n",
        "target_out = pytorch_conv_layer(x)"
      ],
      "metadata": {
        "id": "HzIjuGpWlbIM"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2Sesz6onCEw",
        "outputId": "1e16779a-d164-40d1-f39f-881ffb8b61e9"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2, 8, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert torch.allclose(out, target_out, atol=1e-6)"
      ],
      "metadata": {
        "id": "noWWzeCumRIY"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQA9Zg7GQT2G"
      },
      "source": [
        "## Modelo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inicializa_seed(123)"
      ],
      "metadata": {
        "id": "A7ToXbzHhkqS"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-20T21:03:10.802708Z",
          "start_time": "2018-08-20T21:03:10.793287Z"
        },
        "id": "_8Eg4h_kQT2H"
      },
      "source": [
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, height_in: int, width_in: int, in_channels: int, out_channels: int, kernel_size: int, stride: int):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv_layer = MyConv2dForSaida(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride)\n",
        "   \n",
        "        height_out = (height_in - kernel_size) // stride + 1\n",
        "        width_out = (width_in - kernel_size) // stride + 1\n",
        "        self.classification_layer = torch.nn.Linear(out_channels * height_out * width_out, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        hidden = self.conv_layer(x)\n",
        "        hidden = torch.nn.functional.relu(hidden)\n",
        "        hidden = hidden.reshape(x.shape[0], -1)\n",
        "        logits = self.classification_layer(hidden)\n",
        "        return logits"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NHQB4wGQT2K"
      },
      "source": [
        "## Treinamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqs2JhJoQT2L"
      },
      "source": [
        "### Definição dos hiperparâmetros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-20T21:03:14.146259Z",
          "start_time": "2018-08-20T21:03:14.139515Z"
        },
        "id": "oZuYEkn_QT2M"
      },
      "source": [
        "n_epochs = 50\n",
        "lr = 0.1"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmXarXeIQT2O"
      },
      "source": [
        "### Laço de treinamento"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net(height_in=height_in, width_in=width_in, in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride)\n",
        "\n",
        "# Usa pesos iniciais pré-difinidos\n",
        "model.classification_layer.load_state_dict(dict(weight=initial_classification_weight, bias=initial_classification_bias))\n",
        "model.conv_layer.weight.data = initial_conv_weight\n",
        "model.conv_layer.bias.data = initial_conv_bias\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr)\n"
      ],
      "metadata": {
        "id": "FzPTtf17cH8o"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "epochs = []\n",
        "loss_history = []\n",
        "loss_epoch_end = []\n",
        "total_trained_samples = 0\n",
        "for i in range(n_epochs):\n",
        "    for x_train, y_train in loader_train:\n",
        "        # predict da rede\n",
        "        outputs = model(x_train)\n",
        "\n",
        "        # calcula a perda\n",
        "        loss = criterion(outputs, y_train)\n",
        "\n",
        "        # zero, backpropagation, ajusta parâmetros pelo gradiente descendente\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_trained_samples += x_train.size(0)\n",
        "        epochs.append(total_trained_samples / len(dataset_train))\n",
        "        loss_history.append(loss.item())\n",
        "\n",
        "    loss_epoch_end.append(loss.item())\n",
        "    print(f'Epoch: {i:d}/{n_epochs - 1:d} Loss: {loss.item()}  time: {time.strftime(\"[%Y-%b-%d %H:%M:%S]\")}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GviNVFSEcJVY",
        "outputId": "b1778273-dff8-4a46-8e78-fcddc551576e"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0/49 Loss: 2.303267478942871  time: [2022-May-04 17:02:29]\n",
            "Epoch: 1/49 Loss: 2.227700710296631  time: [2022-May-04 17:02:50]\n",
            "Epoch: 2/49 Loss: 1.0923893451690674  time: [2022-May-04 17:03:10]\n",
            "Epoch: 3/49 Loss: 0.5867354869842529  time: [2022-May-04 17:03:30]\n",
            "Epoch: 4/49 Loss: 0.5144088864326477  time: [2022-May-04 17:03:50]\n",
            "Epoch: 5/49 Loss: 0.45026642084121704  time: [2022-May-04 17:04:11]\n",
            "Epoch: 6/49 Loss: 0.4075140655040741  time: [2022-May-04 17:04:30]\n",
            "Epoch: 7/49 Loss: 0.3771387040615082  time: [2022-May-04 17:04:50]\n",
            "Epoch: 8/49 Loss: 0.35344868898391724  time: [2022-May-04 17:05:10]\n",
            "Epoch: 9/49 Loss: 0.3341451585292816  time: [2022-May-04 17:05:31]\n",
            "Epoch: 10/49 Loss: 0.31811416149139404  time: [2022-May-04 17:05:51]\n",
            "Epoch: 11/49 Loss: 0.30457884073257446  time: [2022-May-04 17:06:11]\n",
            "Epoch: 12/49 Loss: 0.29283493757247925  time: [2022-May-04 17:06:31]\n",
            "Epoch: 13/49 Loss: 0.2827607989311218  time: [2022-May-04 17:06:51]\n",
            "Epoch: 14/49 Loss: 0.2738332748413086  time: [2022-May-04 17:07:11]\n",
            "Epoch: 15/49 Loss: 0.26577436923980713  time: [2022-May-04 17:07:30]\n",
            "Epoch: 16/49 Loss: 0.25832879543304443  time: [2022-May-04 17:07:49]\n",
            "Epoch: 17/49 Loss: 0.25117501616477966  time: [2022-May-04 17:08:08]\n",
            "Epoch: 18/49 Loss: 0.24439716339111328  time: [2022-May-04 17:08:28]\n",
            "Epoch: 19/49 Loss: 0.23789949715137482  time: [2022-May-04 17:08:47]\n",
            "Epoch: 20/49 Loss: 0.2316770702600479  time: [2022-May-04 17:09:06]\n",
            "Epoch: 21/49 Loss: 0.22562646865844727  time: [2022-May-04 17:09:25]\n",
            "Epoch: 22/49 Loss: 0.21984538435935974  time: [2022-May-04 17:09:44]\n",
            "Epoch: 23/49 Loss: 0.2142913043498993  time: [2022-May-04 17:10:03]\n",
            "Epoch: 24/49 Loss: 0.2089422643184662  time: [2022-May-04 17:10:23]\n",
            "Epoch: 25/49 Loss: 0.2038729041814804  time: [2022-May-04 17:10:42]\n",
            "Epoch: 26/49 Loss: 0.19903428852558136  time: [2022-May-04 17:11:01]\n",
            "Epoch: 27/49 Loss: 0.1943996548652649  time: [2022-May-04 17:11:20]\n",
            "Epoch: 28/49 Loss: 0.1899409145116806  time: [2022-May-04 17:11:39]\n",
            "Epoch: 29/49 Loss: 0.18563994765281677  time: [2022-May-04 17:11:58]\n",
            "Epoch: 30/49 Loss: 0.18147502839565277  time: [2022-May-04 17:12:18]\n",
            "Epoch: 31/49 Loss: 0.17744921147823334  time: [2022-May-04 17:12:37]\n",
            "Epoch: 32/49 Loss: 0.1734725832939148  time: [2022-May-04 17:12:56]\n",
            "Epoch: 33/49 Loss: 0.16947472095489502  time: [2022-May-04 17:13:15]\n",
            "Epoch: 34/49 Loss: 0.16547328233718872  time: [2022-May-04 17:13:34]\n",
            "Epoch: 35/49 Loss: 0.16150493919849396  time: [2022-May-04 17:13:53]\n",
            "Epoch: 36/49 Loss: 0.15746404230594635  time: [2022-May-04 17:14:12]\n",
            "Epoch: 37/49 Loss: 0.15340439975261688  time: [2022-May-04 17:14:31]\n",
            "Epoch: 38/49 Loss: 0.1492692232131958  time: [2022-May-04 17:14:51]\n",
            "Epoch: 39/49 Loss: 0.14520636200904846  time: [2022-May-04 17:15:10]\n",
            "Epoch: 40/49 Loss: 0.14123651385307312  time: [2022-May-04 17:15:29]\n",
            "Epoch: 41/49 Loss: 0.13712680339813232  time: [2022-May-04 17:15:48]\n",
            "Epoch: 42/49 Loss: 0.1331038475036621  time: [2022-May-04 17:16:07]\n",
            "Epoch: 43/49 Loss: 0.12914663553237915  time: [2022-May-04 17:16:26]\n",
            "Epoch: 44/49 Loss: 0.12515056133270264  time: [2022-May-04 17:16:46]\n",
            "Epoch: 45/49 Loss: 0.12116765230894089  time: [2022-May-04 17:17:05]\n",
            "Epoch: 46/49 Loss: 0.11731734126806259  time: [2022-May-04 17:17:24]\n",
            "Epoch: 47/49 Loss: 0.11364619433879852  time: [2022-May-04 17:17:43]\n",
            "Epoch: 48/49 Loss: 0.11001909524202347  time: [2022-May-04 17:18:02]\n",
            "Epoch: 49/49 Loss: 0.10655995458364487  time: [2022-May-04 17:18:21]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLL-GQlKQT2Y"
      },
      "source": [
        "### Visualização usual da perda, somente no final de cada minibatch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-20T21:03:55.246851Z",
          "start_time": "2018-08-20T21:03:54.994428Z"
        },
        "id": "w38EtNxhQT2Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "9e9bbfaf-92ac-47f5-80fa-3cf112491824"
      },
      "source": [
        "n_batches_train = len(loader_train)\n",
        "plt.plot(epochs[::n_batches_train], loss_history[::n_batches_train])\n",
        "plt.xlabel('época')"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'época')"
            ]
          },
          "metadata": {},
          "execution_count": 82
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_epoch_end"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_0RGftSe0ss",
        "outputId": "4849b6a2-75eb-499c-9f21-177083d963aa"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.303267478942871,\n",
              " 2.227700710296631,\n",
              " 1.0923893451690674,\n",
              " 0.5867354869842529,\n",
              " 0.5144088864326477,\n",
              " 0.45026642084121704,\n",
              " 0.4075140655040741,\n",
              " 0.3771387040615082,\n",
              " 0.35344868898391724,\n",
              " 0.3341451585292816,\n",
              " 0.31811416149139404,\n",
              " 0.30457884073257446,\n",
              " 0.29283493757247925,\n",
              " 0.2827607989311218,\n",
              " 0.2738332748413086,\n",
              " 0.26577436923980713,\n",
              " 0.25832879543304443,\n",
              " 0.25117501616477966,\n",
              " 0.24439716339111328,\n",
              " 0.23789949715137482,\n",
              " 0.2316770702600479,\n",
              " 0.22562646865844727,\n",
              " 0.21984538435935974,\n",
              " 0.2142913043498993,\n",
              " 0.2089422643184662,\n",
              " 0.2038729041814804,\n",
              " 0.19903428852558136,\n",
              " 0.1943996548652649,\n",
              " 0.1899409145116806,\n",
              " 0.18563994765281677,\n",
              " 0.18147502839565277,\n",
              " 0.17744921147823334,\n",
              " 0.1734725832939148,\n",
              " 0.16947472095489502,\n",
              " 0.16547328233718872,\n",
              " 0.16150493919849396,\n",
              " 0.15746404230594635,\n",
              " 0.15340439975261688,\n",
              " 0.1492692232131958,\n",
              " 0.14520636200904846,\n",
              " 0.14123651385307312,\n",
              " 0.13712680339813232,\n",
              " 0.1331038475036621,\n",
              " 0.12914663553237915,\n",
              " 0.12515056133270264,\n",
              " 0.12116765230894089,\n",
              " 0.11731734126806259,\n",
              " 0.11364619433879852,\n",
              " 0.11001909524202347,\n",
              " 0.10655995458364487]"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-20T21:03:48.786969Z",
          "start_time": "2018-08-20T21:03:48.781787Z"
        },
        "id": "PiuMsjYtQT2R"
      },
      "source": [
        "# Assert do histórico de losses\n",
        "target_loss_epoch_end = np.array([\n",
        "    2.303267478942871,\n",
        "    2.227701187133789,\n",
        "    1.0923893451690674,\n",
        "    0.5867354869842529,\n",
        "    0.5144089460372925,\n",
        "    0.45026642084121704,\n",
        "    0.4075140357017517,\n",
        "    0.37713879346847534,\n",
        "    0.3534485101699829,\n",
        "    0.3341451585292816,\n",
        "    0.3181140422821045,\n",
        "    0.30457887053489685,\n",
        "    0.29283496737480164,\n",
        "    0.2827608287334442,\n",
        "    0.2738332152366638,\n",
        "    0.2657742500305176,\n",
        "    0.2583288848400116,\n",
        "    0.25117507576942444,\n",
        "    0.24439716339111328,\n",
        "    0.23789969086647034,\n",
        "    0.23167723417282104,\n",
        "    0.22562651336193085,\n",
        "    0.21984536945819855,\n",
        "    0.2142913043498993,\n",
        "    0.20894232392311096,\n",
        "    0.203872948884964,\n",
        "    0.19903430342674255,\n",
        "    0.19439971446990967,\n",
        "    0.18994088470935822,\n",
        "    0.18563991785049438,\n",
        "    0.18147490918636322,\n",
        "    0.17744913697242737,\n",
        "    0.17347246408462524,\n",
        "    0.16947467625141144,\n",
        "    0.16547319293022156,\n",
        "    0.16150487959384918,\n",
        "    0.1574639081954956,\n",
        "    0.1534043848514557,\n",
        "    0.14926929771900177,\n",
        "    0.1452063024044037,\n",
        "    0.1412365883588791,\n",
        "    0.13712672889232635,\n",
        "    0.1331038922071457,\n",
        "    0.1291467249393463,\n",
        "    0.1251506358385086,\n",
        "    0.12116757035255432,\n",
        "    0.11731722950935364,\n",
        "    0.11364627629518509,\n",
        "    0.11001908034086227,\n",
        "    0.10655981302261353])\n",
        "\n",
        "assert np.allclose(np.array(loss_epoch_end), target_loss_epoch_end, atol=1e-6)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qaITi1GA7PUu"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementando Conv2d com for no Kernel"
      ],
      "metadata": {
        "id": "L2Q-X7s17Q61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inicializa_seed(123)"
      ],
      "metadata": {
        "id": "MzDJgkjO7iPN"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyConv2dForKernel(torch.nn.Module):\n",
        "  \"\"\"\n",
        "  Versão com for sobre o kernel \n",
        "  \"\"\"\n",
        "  def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int, verbose:bool = False):\n",
        "    super(MyConv2dForKernel, self).__init__()\n",
        "\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.kernel_size = kernel_size  # The same for height and width.\n",
        "    self.stride = stride  # The same for height and width.\n",
        "    self.weight = torch.nn.Parameter(torch.FloatTensor(out_channels, in_channels, kernel_size, kernel_size).uniform_(-0.01, 0.01))\n",
        "    self.bias = torch.nn.Parameter(torch.FloatTensor(out_channels,).uniform_(-0.01, 0.01))\n",
        "    self.verbose = verbose\n",
        "    if self.verbose:\n",
        "      print(f\"Inicializado MyConv2dForKernel\")\n",
        "      print(f\"in_channels: {self.in_channels} \")\n",
        "      print(f\"out_channels: {self.out_channels} \")\n",
        "      print(f\"kernel_size: {self.kernel_size} \")\n",
        "      print(f\"stride: {self.stride} \")\n",
        "      print(f\"weight.shape: {self.weight.shape} \")\n",
        "      print(f\"weight: {self.weight} \")\n",
        "      print(f\"bias.shape: {self.bias.shape} \")\n",
        "      print(f\"bias: {self.bias} \")\n",
        "\n",
        "  def forward(self, x):\n",
        "    assert x.dim() == 4, f'x must have 4 dimensions, not {x.shape}'\n",
        "    assert x.shape[1] == 1, f'x must have only 1 channel, not {x.shape[1]}' # Num_canais sempre 1 (mnist, preto/branco)\n",
        "\n",
        "    # print(f\"kernel.shape: {self.weight.shape}, kernel: {self.weight}\")\n",
        "    # Escreva seu código aqui.\n",
        "    # versão com for nas dimensões de X\n",
        "    num_amostras = x.shape[0]\n",
        "    num_linhas_entrada = x.shape[2]\n",
        "    num_colunas_entrada = x.shape[3]\n",
        "    num_linhas_saida = (num_linhas_entrada - self.kernel_size) // self.stride + 1\n",
        "    num_colunas_saida = (num_colunas_entrada - self.kernel_size) // self.stride + 1\n",
        "    saida = torch.zeros((num_amostras,self.out_channels,num_linhas_saida,num_colunas_saida), dtype=torch.float, requires_grad=False)        \n",
        "    if self.verbose:\n",
        "      print(f\" num_amostras: {num_amostras}, self.out_channels: {self.out_channels}, num_linhas_entrada: {num_linhas_entrada}, num_colunas_entrada: {num_colunas_entrada}, num_linhas_saida: {num_linhas_saida}, num_colunas_saida: {num_colunas_saida}\")\n",
        "      print(f\"saida.shape: {saida.shape}\")\n",
        "    for ndx_amostra in range(num_amostras):\n",
        "      if self.verbose:\n",
        "        print(f\"\\nndx_amostra: {ndx_amostra}\")\n",
        "\n",
        "      for ndx_linhas_kernel in range(self.kernel_size):\n",
        "        for ndx_colunas_kernel in range(self.kernel_size):\n",
        "          if self.verbose:\n",
        "            print(f\"\\nndx_linhas_kernel, ndx_colunas_kernel: {ndx_linhas_kernel}, {ndx_colunas_kernel}\")\n",
        "          # dica para visao_com_stride obtida em https://stackoverflow.com/questions/48097941/strided-convolution-of-2d-in-numpy\n",
        "          visao_com_stride=x[ndx_amostra, 0][ndx_linhas_kernel:num_linhas_entrada-self.kernel_size+ndx_linhas_kernel+1:self.stride,\n",
        "                             ndx_colunas_kernel: num_colunas_entrada - self.kernel_size + ndx_colunas_kernel +1:self.stride]\n",
        "          if self.verbose:\n",
        "            print(f\"vou multiplicar visao_com_stride.shape: {visao_com_stride.shape} por self.weight.data[:,:,{ndx_linhas_kernel},{ndx_colunas_kernel}].shape: {self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel].shape}\")\n",
        "            print(f\"\\nvisao_com_stride: {visao_com_stride}\")\n",
        "            print(f\"\\nself.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: {self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]}\")\n",
        "            print(f\"[self.weight.data[:,:,{ndx_linhas_kernel},{ndx_colunas_kernel}].view({self.out_channels},)[i] for i in range({self.out_channels})] = \")\n",
        "            #for i in range(self.out_channels):\n",
        "            print(f\"{self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel][0,0]}\")\n",
        "          produto = torch.stack([visao_com_stride * self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel][i, 0]  for i in range(self.out_channels)])\n",
        "          # produto = self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]*visao_com_stride\n",
        "          if self.verbose:\n",
        "            print(f\"\\nproduto.shape: {produto.shape} produto: {produto}\")\n",
        "          if self.verbose:\n",
        "            print(f\"\\nsaida[ndx_amostra,0].shape: {saida[ndx_amostra,0].shape}\")\n",
        "            print(f\"\\nsaida[ndx_amostra,0]: {saida[ndx_amostra,0]}\")\n",
        "          saida[ndx_amostra,:] += produto\n",
        "          \"\"\"\n",
        "          soma = produto.sum(axis=(-1, -2))\n",
        "          if self.verbose:\n",
        "            print(f\"\\nsoma: {soma}\")\n",
        "          \"\"\"\n",
        "    if self.verbose:\n",
        "      print(f\" saida: {saida}\")\n",
        "    # somando bias\n",
        "    for ndx_amostra in range(num_amostras):\n",
        "      if self.verbose:\n",
        "        print(f\"\\nndx_amostra: {ndx_amostra}\")\n",
        "      for ndx_out_channels in range(self.out_channels):\n",
        "        saida[ndx_amostra, ndx_out_channels] += self.bias[ndx_out_channels]\n",
        "    if self.verbose:\n",
        "      print(f\" saida apos somar bias: {saida}\")\n",
        "    # versão com for no kernel\n",
        "\n",
        "    return saida"
      ],
      "metadata": {
        "id": "4DgFIMilhP9j"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZwysnjdIBgly"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare se sua implementação está igual à do pytorch usando um exemplo simples"
      ],
      "metadata": {
        "id": "q4cOs-Sq8RyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "in_channels_dummy = 1\n",
        "out_channels_dummy = 1\n",
        "kernel_size_dummy = 2\n",
        "stride_dummy = 1\n",
        "x = torch.arange(30).float().reshape(1, 1, 5, 6)"
      ],
      "metadata": {
        "id": "OvY47dO28RyQ"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a5d32d8-d801-4511-f91c-4318c34b8ed5",
        "id": "WnjxBA1D8RyQ"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[ 0.,  1.,  2.,  3.,  4.,  5.],\n",
            "          [ 6.,  7.,  8.,  9., 10., 11.],\n",
            "          [12., 13., 14., 15., 16., 17.],\n",
            "          [18., 19., 20., 21., 22., 23.],\n",
            "          [24., 25., 26., 27., 28., 29.]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0,0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "228192d7-992e-4f8e-e35c-c9824ed4c95c",
        "id": "0Uj850g88RyR"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.,  1.,  2.,  3.,  4.,  5.],\n",
              "        [ 6.,  7.,  8.,  9., 10., 11.],\n",
              "        [12., 13., 14., 15., 16., 17.],\n",
              "        [18., 19., 20., 21., 22., 23.],\n",
              "        [24., 25., 26., 27., 28., 29.]])"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "conv_layer = MyConv2dForKernel( in_channels=in_channels_dummy,out_channels=out_channels_dummy, kernel_size=kernel_size_dummy, stride=stride_dummy, verbose=True)\n",
        "\n",
        "# Usa os mesmos pesos para minha implementação e a do pytorch\n",
        "initial_weights_dummy = torch.arange(in_channels_dummy * out_channels_dummy * kernel_size_dummy * kernel_size_dummy).float()\n",
        "initial_weights_dummy = initial_weights_dummy.reshape(in_channels_dummy, out_channels_dummy, kernel_size_dummy, kernel_size_dummy)\n",
        "initial_bias_dummy = torch.arange(out_channels_dummy,).float()\n",
        "\n",
        "conv_layer.weight.data = initial_weights_dummy\n",
        "conv_layer.bias.data = initial_bias_dummy\n",
        "\n",
        "out = conv_layer(x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d7cad68-8452-4f4a-a624-1bc94025eebd",
        "id": "2dvGxioY8RyR"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inicializado MyConv2dForKernel\n",
            "in_channels: 1 \n",
            "out_channels: 1 \n",
            "kernel_size: 2 \n",
            "stride: 1 \n",
            "weight.shape: torch.Size([1, 1, 2, 2]) \n",
            "weight: Parameter containing:\n",
            "tensor([[[[-0.0041,  0.0003],\n",
            "          [-0.0050,  0.0038]]]], requires_grad=True) \n",
            "bias.shape: torch.Size([1]) \n",
            "bias: Parameter containing:\n",
            "tensor([-0.0085], requires_grad=True) \n",
            " num_amostras: 1, self.out_channels: 1, num_linhas_entrada: 5, num_colunas_entrada: 6, num_linhas_saida: 4, num_colunas_saida: 5\n",
            "saida.shape: torch.Size([1, 1, 4, 5])\n",
            "\n",
            "ndx_amostra: 0\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 0, 0\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([4, 5]) por self.weight.data[:,:,0,0].shape: torch.Size([1, 1])\n",
            "\n",
            "visao_com_stride: tensor([[ 0.,  1.,  2.,  3.,  4.],\n",
            "        [ 6.,  7.,  8.,  9., 10.],\n",
            "        [12., 13., 14., 15., 16.],\n",
            "        [18., 19., 20., 21., 22.]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[0.]])\n",
            "[self.weight.data[:,:,0,0].view(1,)[i] for i in range(1)] = \n",
            "0.0\n",
            "\n",
            "produto.shape: torch.Size([1, 4, 5]) produto: tensor([[[0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([4, 5])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 0, 1\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([4, 5]) por self.weight.data[:,:,0,1].shape: torch.Size([1, 1])\n",
            "\n",
            "visao_com_stride: tensor([[ 1.,  2.,  3.,  4.,  5.],\n",
            "        [ 7.,  8.,  9., 10., 11.],\n",
            "        [13., 14., 15., 16., 17.],\n",
            "        [19., 20., 21., 22., 23.]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[1.]])\n",
            "[self.weight.data[:,:,0,1].view(1,)[i] for i in range(1)] = \n",
            "1.0\n",
            "\n",
            "produto.shape: torch.Size([1, 4, 5]) produto: tensor([[[ 1.,  2.,  3.,  4.,  5.],\n",
            "         [ 7.,  8.,  9., 10., 11.],\n",
            "         [13., 14., 15., 16., 17.],\n",
            "         [19., 20., 21., 22., 23.]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([4, 5])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 1, 0\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([4, 5]) por self.weight.data[:,:,1,0].shape: torch.Size([1, 1])\n",
            "\n",
            "visao_com_stride: tensor([[ 6.,  7.,  8.,  9., 10.],\n",
            "        [12., 13., 14., 15., 16.],\n",
            "        [18., 19., 20., 21., 22.],\n",
            "        [24., 25., 26., 27., 28.]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[2.]])\n",
            "[self.weight.data[:,:,1,0].view(1,)[i] for i in range(1)] = \n",
            "2.0\n",
            "\n",
            "produto.shape: torch.Size([1, 4, 5]) produto: tensor([[[12., 14., 16., 18., 20.],\n",
            "         [24., 26., 28., 30., 32.],\n",
            "         [36., 38., 40., 42., 44.],\n",
            "         [48., 50., 52., 54., 56.]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([4, 5])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[ 1.,  2.,  3.,  4.,  5.],\n",
            "        [ 7.,  8.,  9., 10., 11.],\n",
            "        [13., 14., 15., 16., 17.],\n",
            "        [19., 20., 21., 22., 23.]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 1, 1\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([4, 5]) por self.weight.data[:,:,1,1].shape: torch.Size([1, 1])\n",
            "\n",
            "visao_com_stride: tensor([[ 7.,  8.,  9., 10., 11.],\n",
            "        [13., 14., 15., 16., 17.],\n",
            "        [19., 20., 21., 22., 23.],\n",
            "        [25., 26., 27., 28., 29.]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[3.]])\n",
            "[self.weight.data[:,:,1,1].view(1,)[i] for i in range(1)] = \n",
            "3.0\n",
            "\n",
            "produto.shape: torch.Size([1, 4, 5]) produto: tensor([[[21., 24., 27., 30., 33.],\n",
            "         [39., 42., 45., 48., 51.],\n",
            "         [57., 60., 63., 66., 69.],\n",
            "         [75., 78., 81., 84., 87.]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([4, 5])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[13., 16., 19., 22., 25.],\n",
            "        [31., 34., 37., 40., 43.],\n",
            "        [49., 52., 55., 58., 61.],\n",
            "        [67., 70., 73., 76., 79.]])\n",
            " saida: tensor([[[[ 34.,  40.,  46.,  52.,  58.],\n",
            "          [ 70.,  76.,  82.,  88.,  94.],\n",
            "          [106., 112., 118., 124., 130.],\n",
            "          [142., 148., 154., 160., 166.]]]])\n",
            "\n",
            "ndx_amostra: 0\n",
            " saida apos somar bias: tensor([[[[ 34.,  40.,  46.,  52.,  58.],\n",
            "          [ 70.,  76.,  82.,  88.,  94.],\n",
            "          [106., 112., 118., 124., 130.],\n",
            "          [142., 148., 154., 160., 166.]]]], grad_fn=<CopySlices>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pytorch_conv_layer = torch.nn.Conv2d(out_channels=out_channels_dummy, in_channels=in_channels_dummy, kernel_size=kernel_size_dummy, stride=stride_dummy, padding=0)\n",
        "pytorch_conv_layer.load_state_dict(dict(weight=initial_weights_dummy, bias=initial_bias_dummy))\n",
        "target_out = pytorch_conv_layer(x)"
      ],
      "metadata": {
        "id": "3WJPvXxO8RyR"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94cf5466-26cc-4a61-a6cc-0ddc7968fc7b",
        "id": "8BqRXCo28RyR"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 4, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert torch.allclose(out, target_out, atol=1e-6)"
      ],
      "metadata": {
        "id": "QFsSvQPY8RyR"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare se sua implementação está igual à do pytorch usando um exemplo aleatório"
      ],
      "metadata": {
        "id": "6vSJ8OpG8RyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(2, in_channels, height_in, width_in)\n",
        "print(f\"x.shape: {x.shape}, x:{x}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3560896-c3ba-49f1-d987-06add160a5ed",
        "id": "neKNIZ0F8RyS"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x.shape: torch.Size([2, 1, 28, 28]), x:tensor([[[[0.3153, 0.6871, 0.0756,  ..., 0.4340, 0.0772, 0.3565],\n",
            "          [0.1479, 0.5331, 0.4066,  ..., 0.1634, 0.3009, 0.5201],\n",
            "          [0.3834, 0.4451, 0.0126,  ..., 0.8858, 0.6568, 0.8459],\n",
            "          ...,\n",
            "          [0.0697, 0.6010, 0.1875,  ..., 0.1904, 0.0051, 0.0117],\n",
            "          [0.6601, 0.6034, 0.5058,  ..., 0.1765, 0.4007, 0.9541],\n",
            "          [0.8567, 0.4604, 0.2238,  ..., 0.0509, 0.9271, 0.2894]]],\n",
            "\n",
            "\n",
            "        [[[0.8272, 0.9483, 0.8171,  ..., 0.5849, 0.4149, 0.2594],\n",
            "          [0.1849, 0.2540, 0.4626,  ..., 0.1202, 0.6813, 0.3728],\n",
            "          [0.8571, 0.0257, 0.7619,  ..., 0.0264, 0.0534, 0.0903],\n",
            "          ...,\n",
            "          [0.4493, 0.0843, 0.3308,  ..., 0.9408, 0.3042, 0.3526],\n",
            "          [0.9909, 0.5564, 0.9295,  ..., 0.0156, 0.8797, 0.2511],\n",
            "          [0.0361, 0.4623, 0.8646,  ..., 0.4430, 0.6219, 0.1061]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_layer = MyConv2dForKernel(out_channels=out_channels, in_channels=in_channels, kernel_size=kernel_size, stride=stride, verbose=True)\n",
        "conv_layer.weight.data = initial_conv_weight\n",
        "conv_layer.bias.data = initial_conv_bias\n",
        "print(f\"conv_layer.weight.data.shape: {conv_layer.weight.data.shape}, conv_layer.bias.data.shape: {conv_layer.bias.data.shape}\")\n",
        "print(f\"conv_layer.weight.data: {conv_layer.weight.data}, conv_layer.bias.data: {conv_layer.bias.data}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a1e0d1a-88dc-4e09-ccd0-a5d06bf18931",
        "id": "DNKiGaSj8RyS"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inicializado MyConv2dForKernel\n",
            "in_channels: 1 \n",
            "out_channels: 2 \n",
            "kernel_size: 5 \n",
            "stride: 3 \n",
            "weight.shape: torch.Size([2, 1, 5, 5]) \n",
            "weight: Parameter containing:\n",
            "tensor([[[[ 6.6078e-06, -9.2485e-03, -9.2362e-03,  1.8061e-04,  1.3908e-03],\n",
            "          [ 1.8874e-03, -3.6917e-03, -1.0977e-03, -1.1083e-03, -3.3335e-04],\n",
            "          [-6.4626e-03,  2.1828e-03,  3.0981e-03,  2.8529e-04, -8.1157e-04],\n",
            "          [ 4.8421e-03,  6.7688e-03, -1.2534e-04, -7.5895e-03, -6.9633e-03],\n",
            "          [-1.9524e-04, -9.1405e-03, -7.5606e-03, -2.4248e-03, -3.9989e-03]]],\n",
            "\n",
            "\n",
            "        [[[-1.2834e-03,  2.4163e-03,  6.8450e-03,  9.9526e-03, -3.9993e-03],\n",
            "          [-9.7703e-03,  6.6395e-03,  8.7120e-03,  9.5413e-03,  2.2681e-03],\n",
            "          [ 6.3718e-03,  2.3667e-05, -7.0870e-03, -8.0465e-03, -5.9984e-03],\n",
            "          [ 1.5156e-03, -2.5329e-03,  2.5571e-03,  3.5150e-03, -6.3376e-03],\n",
            "          [ 7.9751e-04,  9.6898e-03,  6.5876e-03, -1.1136e-03, -2.0899e-03]]]],\n",
            "       requires_grad=True) \n",
            "bias.shape: torch.Size([2]) \n",
            "bias: Parameter containing:\n",
            "tensor([-0.0039,  0.0033], requires_grad=True) \n",
            "conv_layer.weight.data.shape: torch.Size([2, 1, 5, 5]), conv_layer.bias.data.shape: torch.Size([2])\n",
            "conv_layer.weight.data: tensor([[[[ 4.2760e-02,  4.6799e-02,  4.2482e-02, -4.6000e-03, -6.1046e-02],\n",
            "          [ 2.5130e-02, -4.7408e-03, -9.7500e-03, -1.2179e-01, -1.6464e-01],\n",
            "          [-2.4726e-02, -9.1927e-03, -3.7821e-02, -1.6790e-01, -1.5897e-01],\n",
            "          [ 2.3130e-01,  2.6981e-01,  2.6483e-01,  1.0117e-01,  2.1522e-02],\n",
            "          [ 3.4179e-01,  5.1963e-01,  4.7169e-01,  2.0541e-01,  8.1363e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.9689e-04, -8.7135e-02,  1.9733e-01,  1.2020e-01, -2.1283e-01],\n",
            "          [ 2.3386e-02,  3.2401e-01,  1.0133e+00,  7.0226e-01,  4.6410e-01],\n",
            "          [-1.0659e-01,  5.7965e-01,  1.3028e+00,  1.0332e+00,  7.6364e-01],\n",
            "          [ 3.7933e-01,  1.1530e+00,  1.3851e+00,  1.1669e+00,  7.6185e-01],\n",
            "          [ 9.6202e-02,  8.7315e-01,  1.1107e+00,  2.8991e-01,  2.7996e-01]]]]), conv_layer.bias.data: tensor([ 0.1579, -0.0028])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = conv_layer(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80c794c4-4899-4309-d56b-e4cd9c9ac1db",
        "id": "Jm73uSGn8RyS"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " num_amostras: 2, self.out_channels: 2, num_linhas_entrada: 28, num_colunas_entrada: 28, num_linhas_saida: 8, num_colunas_saida: 8\n",
            "saida.shape: torch.Size([2, 2, 8, 8])\n",
            "\n",
            "ndx_amostra: 0\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 0, 0\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([8, 8]) por self.weight.data[:,:,0,0].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[0.3153, 0.1966, 0.1186, 0.6605, 0.6367, 0.6584, 0.8993, 0.7388],\n",
            "        [0.3033, 0.8363, 0.8809, 0.2185, 0.5374, 0.4979, 0.7577, 0.5585],\n",
            "        [0.9355, 0.5201, 0.1142, 0.7579, 0.0757, 0.9024, 0.6591, 0.6166],\n",
            "        [0.2337, 0.7945, 0.7815, 0.7582, 0.3630, 0.2974, 0.8916, 0.2377],\n",
            "        [0.3051, 0.6647, 0.9357, 0.8323, 0.6226, 0.8751, 0.5583, 0.9049],\n",
            "        [0.1427, 0.3552, 0.4564, 0.1203, 0.1928, 0.1197, 0.1098, 0.0574],\n",
            "        [0.5577, 0.7872, 0.5302, 0.3473, 0.5344, 0.5773, 0.9941, 0.2103],\n",
            "        [0.7006, 0.0994, 0.9808, 0.7961, 0.0319, 0.8552, 0.4344, 0.6829]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[0.0428],\n",
            "        [0.0003]])\n",
            "[self.weight.data[:,:,0,0].view(2,)[i] for i in range(2)] = \n",
            "0.042759574949741364\n",
            "\n",
            "produto.shape: torch.Size([2, 8, 8]) produto: tensor([[[1.3480e-02, 8.4082e-03, 5.0699e-03, 2.8242e-02, 2.7226e-02,\n",
            "          2.8152e-02, 3.8455e-02, 3.1589e-02],\n",
            "         [1.2969e-02, 3.5761e-02, 3.7669e-02, 9.3418e-03, 2.2979e-02,\n",
            "          2.1289e-02, 3.2398e-02, 2.3883e-02],\n",
            "         [4.0003e-02, 2.2238e-02, 4.8834e-03, 3.2407e-02, 3.2352e-03,\n",
            "          3.8587e-02, 2.8183e-02, 2.6365e-02],\n",
            "         [9.9916e-03, 3.3970e-02, 3.3418e-02, 3.2418e-02, 1.5521e-02,\n",
            "          1.2719e-02, 3.8126e-02, 1.0166e-02],\n",
            "         [1.3044e-02, 2.8424e-02, 4.0010e-02, 3.5588e-02, 2.6620e-02,\n",
            "          3.7417e-02, 2.3871e-02, 3.8691e-02],\n",
            "         [6.1029e-03, 1.5190e-02, 1.9517e-02, 5.1440e-03, 8.2455e-03,\n",
            "          5.1188e-03, 4.6929e-03, 2.4549e-03],\n",
            "         [2.3848e-02, 3.3660e-02, 2.2671e-02, 1.4849e-02, 2.2850e-02,\n",
            "          2.4687e-02, 4.2509e-02, 8.9912e-03],\n",
            "         [2.9959e-02, 4.2524e-03, 4.1939e-02, 3.4042e-02, 1.3632e-03,\n",
            "          3.6567e-02, 1.8576e-02, 2.9201e-02]],\n",
            "\n",
            "        [[9.3596e-05, 5.8380e-05, 3.5202e-05, 1.9609e-04, 1.8904e-04,\n",
            "          1.9547e-04, 2.6700e-04, 2.1933e-04],\n",
            "         [9.0048e-05, 2.4830e-04, 2.6154e-04, 6.4862e-05, 1.5955e-04,\n",
            "          1.4782e-04, 2.2495e-04, 1.6582e-04],\n",
            "         [2.7775e-04, 1.5441e-04, 3.3906e-05, 2.2501e-04, 2.2463e-05,\n",
            "          2.6792e-04, 1.9568e-04, 1.8306e-04],\n",
            "         [6.9374e-05, 2.3586e-04, 2.3203e-04, 2.2509e-04, 1.0776e-04,\n",
            "          8.8308e-05, 2.6472e-04, 7.0582e-05],\n",
            "         [9.0567e-05, 1.9735e-04, 2.7780e-04, 2.4710e-04, 1.8483e-04,\n",
            "          2.5980e-04, 1.6575e-04, 2.6864e-04],\n",
            "         [4.2374e-05, 1.0547e-04, 1.3551e-04, 3.5716e-05, 5.7251e-05,\n",
            "          3.5541e-05, 3.2584e-05, 1.7045e-05],\n",
            "         [1.6558e-04, 2.3371e-04, 1.5741e-04, 1.0310e-04, 1.5865e-04,\n",
            "          1.7141e-04, 2.9515e-04, 6.2428e-05],\n",
            "         [2.0801e-04, 2.9525e-05, 2.9119e-04, 2.3637e-04, 9.4652e-06,\n",
            "          2.5389e-04, 1.2898e-04, 2.0275e-04]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([8, 8])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 0, 1\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([8, 8]) por self.weight.data[:,:,0,1].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[0.6871, 0.3164, 0.8274, 0.8536, 0.9826, 0.2775, 0.0390, 0.7179],\n",
            "        [0.6060, 0.9010, 0.1084, 0.3834, 0.9551, 0.8549, 0.4536, 0.1170],\n",
            "        [0.5855, 0.8118, 0.3338, 0.8533, 0.0131, 0.1123, 0.1735, 0.3608],\n",
            "        [0.9794, 0.6613, 0.5085, 0.6569, 0.0578, 0.2275, 0.0532, 0.4616],\n",
            "        [0.8070, 0.9296, 0.2616, 0.2410, 0.4902, 0.2943, 0.9096, 0.8048],\n",
            "        [0.4906, 0.2576, 0.4009, 0.8265, 0.0263, 0.7091, 0.6353, 0.6951],\n",
            "        [0.3350, 0.3279, 0.3608, 0.2165, 0.2346, 0.7870, 0.3705, 0.9562],\n",
            "        [0.9619, 0.6232, 0.9848, 0.7276, 0.3020, 0.2297, 0.8401, 0.4696]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[ 0.0468],\n",
            "        [-0.0871]])\n",
            "[self.weight.data[:,:,0,1].view(2,)[i] for i in range(2)] = \n",
            "0.0467989407479763\n",
            "\n",
            "produto.shape: torch.Size([2, 8, 8]) produto: tensor([[[ 0.0322,  0.0148,  0.0387,  0.0399,  0.0460,  0.0130,  0.0018,\n",
            "           0.0336],\n",
            "         [ 0.0284,  0.0422,  0.0051,  0.0179,  0.0447,  0.0400,  0.0212,\n",
            "           0.0055],\n",
            "         [ 0.0274,  0.0380,  0.0156,  0.0399,  0.0006,  0.0053,  0.0081,\n",
            "           0.0169],\n",
            "         [ 0.0458,  0.0309,  0.0238,  0.0307,  0.0027,  0.0106,  0.0025,\n",
            "           0.0216],\n",
            "         [ 0.0378,  0.0435,  0.0122,  0.0113,  0.0229,  0.0138,  0.0426,\n",
            "           0.0377],\n",
            "         [ 0.0230,  0.0121,  0.0188,  0.0387,  0.0012,  0.0332,  0.0297,\n",
            "           0.0325],\n",
            "         [ 0.0157,  0.0153,  0.0169,  0.0101,  0.0110,  0.0368,  0.0173,\n",
            "           0.0447],\n",
            "         [ 0.0450,  0.0292,  0.0461,  0.0341,  0.0141,  0.0108,  0.0393,\n",
            "           0.0220]],\n",
            "\n",
            "        [[-0.0599, -0.0276, -0.0721, -0.0744, -0.0856, -0.0242, -0.0034,\n",
            "          -0.0626],\n",
            "         [-0.0528, -0.0785, -0.0094, -0.0334, -0.0832, -0.0745, -0.0395,\n",
            "          -0.0102],\n",
            "         [-0.0510, -0.0707, -0.0291, -0.0744, -0.0011, -0.0098, -0.0151,\n",
            "          -0.0314],\n",
            "         [-0.0853, -0.0576, -0.0443, -0.0572, -0.0050, -0.0198, -0.0046,\n",
            "          -0.0402],\n",
            "         [-0.0703, -0.0810, -0.0228, -0.0210, -0.0427, -0.0256, -0.0793,\n",
            "          -0.0701],\n",
            "         [-0.0427, -0.0224, -0.0349, -0.0720, -0.0023, -0.0618, -0.0554,\n",
            "          -0.0606],\n",
            "         [-0.0292, -0.0286, -0.0314, -0.0189, -0.0204, -0.0686, -0.0323,\n",
            "          -0.0833],\n",
            "         [-0.0838, -0.0543, -0.0858, -0.0634, -0.0263, -0.0200, -0.0732,\n",
            "          -0.0409]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([8, 8])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[0.0135, 0.0084, 0.0051, 0.0282, 0.0272, 0.0282, 0.0385, 0.0316],\n",
            "        [0.0130, 0.0358, 0.0377, 0.0093, 0.0230, 0.0213, 0.0324, 0.0239],\n",
            "        [0.0400, 0.0222, 0.0049, 0.0324, 0.0032, 0.0386, 0.0282, 0.0264],\n",
            "        [0.0100, 0.0340, 0.0334, 0.0324, 0.0155, 0.0127, 0.0381, 0.0102],\n",
            "        [0.0130, 0.0284, 0.0400, 0.0356, 0.0266, 0.0374, 0.0239, 0.0387],\n",
            "        [0.0061, 0.0152, 0.0195, 0.0051, 0.0082, 0.0051, 0.0047, 0.0025],\n",
            "        [0.0238, 0.0337, 0.0227, 0.0148, 0.0228, 0.0247, 0.0425, 0.0090],\n",
            "        [0.0300, 0.0043, 0.0419, 0.0340, 0.0014, 0.0366, 0.0186, 0.0292]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 0, 2\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([8, 8]) por self.weight.data[:,:,0,2].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[0.0756, 0.4017, 0.3821, 0.5932, 0.2745, 0.8573, 0.9268, 0.7058],\n",
            "        [0.9882, 0.3950, 0.5432, 0.3720, 0.7475, 0.2438, 0.4130, 0.5578],\n",
            "        [0.4695, 0.0585, 0.2122, 0.0149, 0.6886, 0.2685, 0.9247, 0.5325],\n",
            "        [0.7788, 0.4502, 0.3176, 0.3704, 0.3629, 0.0484, 0.9964, 0.9079],\n",
            "        [0.9271, 0.3848, 0.4344, 0.8815, 0.9279, 0.5485, 0.7810, 0.0649],\n",
            "        [0.4970, 0.7346, 0.8474, 0.9441, 0.5696, 0.1012, 0.3719, 0.6766],\n",
            "        [0.4620, 0.1213, 0.2668, 0.9389, 0.8188, 0.8855, 0.5148, 0.6591],\n",
            "        [0.1965, 0.5908, 0.7145, 0.4627, 0.0755, 0.1057, 0.7186, 0.0429]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[0.0425],\n",
            "        [0.1973]])\n",
            "[self.weight.data[:,:,0,2].view(2,)[i] for i in range(2)] = \n",
            "0.042481642216444016\n",
            "\n",
            "produto.shape: torch.Size([2, 8, 8]) produto: tensor([[[0.0032, 0.0171, 0.0162, 0.0252, 0.0117, 0.0364, 0.0394, 0.0300],\n",
            "         [0.0420, 0.0168, 0.0231, 0.0158, 0.0318, 0.0104, 0.0175, 0.0237],\n",
            "         [0.0199, 0.0025, 0.0090, 0.0006, 0.0293, 0.0114, 0.0393, 0.0226],\n",
            "         [0.0331, 0.0191, 0.0135, 0.0157, 0.0154, 0.0021, 0.0423, 0.0386],\n",
            "         [0.0394, 0.0163, 0.0185, 0.0374, 0.0394, 0.0233, 0.0332, 0.0028],\n",
            "         [0.0211, 0.0312, 0.0360, 0.0401, 0.0242, 0.0043, 0.0158, 0.0287],\n",
            "         [0.0196, 0.0052, 0.0113, 0.0399, 0.0348, 0.0376, 0.0219, 0.0280],\n",
            "         [0.0083, 0.0251, 0.0304, 0.0197, 0.0032, 0.0045, 0.0305, 0.0018]],\n",
            "\n",
            "        [[0.0149, 0.0793, 0.0754, 0.1170, 0.0542, 0.1692, 0.1829, 0.1393],\n",
            "         [0.1950, 0.0779, 0.1072, 0.0734, 0.1475, 0.0481, 0.0815, 0.1101],\n",
            "         [0.0926, 0.0115, 0.0419, 0.0029, 0.1359, 0.0530, 0.1825, 0.1051],\n",
            "         [0.1537, 0.0888, 0.0627, 0.0731, 0.0716, 0.0095, 0.1966, 0.1791],\n",
            "         [0.1830, 0.0759, 0.0857, 0.1740, 0.1831, 0.1082, 0.1541, 0.0128],\n",
            "         [0.0981, 0.1450, 0.1672, 0.1863, 0.1124, 0.0200, 0.0734, 0.1335],\n",
            "         [0.0912, 0.0239, 0.0527, 0.1853, 0.1616, 0.1747, 0.1016, 0.1301],\n",
            "         [0.0388, 0.1166, 0.1410, 0.0913, 0.0149, 0.0209, 0.1418, 0.0085]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([8, 8])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[0.0456, 0.0232, 0.0438, 0.0682, 0.0732, 0.0411, 0.0403, 0.0652],\n",
            "        [0.0413, 0.0779, 0.0427, 0.0273, 0.0677, 0.0613, 0.0536, 0.0294],\n",
            "        [0.0674, 0.0602, 0.0205, 0.0723, 0.0038, 0.0438, 0.0363, 0.0433],\n",
            "        [0.0558, 0.0649, 0.0572, 0.0632, 0.0182, 0.0234, 0.0406, 0.0318],\n",
            "        [0.0508, 0.0719, 0.0523, 0.0469, 0.0496, 0.0512, 0.0664, 0.0764],\n",
            "        [0.0291, 0.0272, 0.0383, 0.0438, 0.0095, 0.0383, 0.0344, 0.0350],\n",
            "        [0.0395, 0.0490, 0.0396, 0.0250, 0.0338, 0.0615, 0.0598, 0.0537],\n",
            "        [0.0750, 0.0334, 0.0880, 0.0681, 0.0155, 0.0473, 0.0579, 0.0512]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 0, 3\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([8, 8]) por self.weight.data[:,:,0,3].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[0.1966, 0.1186, 0.6605, 0.6367, 0.6584, 0.8993, 0.7388, 0.9156],\n",
            "        [0.8363, 0.8809, 0.2185, 0.5374, 0.4979, 0.7577, 0.5585, 0.6681],\n",
            "        [0.5201, 0.1142, 0.7579, 0.0757, 0.9024, 0.6591, 0.6166, 0.6559],\n",
            "        [0.7945, 0.7815, 0.7582, 0.3630, 0.2974, 0.8916, 0.2377, 0.6650],\n",
            "        [0.6647, 0.9357, 0.8323, 0.6226, 0.8751, 0.5583, 0.9049, 0.8322],\n",
            "        [0.3552, 0.4564, 0.1203, 0.1928, 0.1197, 0.1098, 0.0574, 0.5674],\n",
            "        [0.7872, 0.5302, 0.3473, 0.5344, 0.5773, 0.9941, 0.2103, 0.4172],\n",
            "        [0.0994, 0.9808, 0.7961, 0.0319, 0.8552, 0.4344, 0.6829, 0.2037]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[-0.0046],\n",
            "        [ 0.1202]])\n",
            "[self.weight.data[:,:,0,3].view(2,)[i] for i in range(2)] = \n",
            "-0.0046000368893146515\n",
            "\n",
            "produto.shape: torch.Size([2, 8, 8]) produto: tensor([[[-0.0009, -0.0005, -0.0030, -0.0029, -0.0030, -0.0041, -0.0034,\n",
            "          -0.0042],\n",
            "         [-0.0038, -0.0041, -0.0010, -0.0025, -0.0023, -0.0035, -0.0026,\n",
            "          -0.0031],\n",
            "         [-0.0024, -0.0005, -0.0035, -0.0003, -0.0042, -0.0030, -0.0028,\n",
            "          -0.0030],\n",
            "         [-0.0037, -0.0036, -0.0035, -0.0017, -0.0014, -0.0041, -0.0011,\n",
            "          -0.0031],\n",
            "         [-0.0031, -0.0043, -0.0038, -0.0029, -0.0040, -0.0026, -0.0042,\n",
            "          -0.0038],\n",
            "         [-0.0016, -0.0021, -0.0006, -0.0009, -0.0006, -0.0005, -0.0003,\n",
            "          -0.0026],\n",
            "         [-0.0036, -0.0024, -0.0016, -0.0025, -0.0027, -0.0046, -0.0010,\n",
            "          -0.0019],\n",
            "         [-0.0005, -0.0045, -0.0037, -0.0001, -0.0039, -0.0020, -0.0031,\n",
            "          -0.0009]],\n",
            "\n",
            "        [[ 0.0236,  0.0143,  0.0794,  0.0765,  0.0791,  0.1081,  0.0888,\n",
            "           0.1101],\n",
            "         [ 0.1005,  0.1059,  0.0263,  0.0646,  0.0598,  0.0911,  0.0671,\n",
            "           0.0803],\n",
            "         [ 0.0625,  0.0137,  0.0911,  0.0091,  0.1085,  0.0792,  0.0741,\n",
            "           0.0788],\n",
            "         [ 0.0955,  0.0939,  0.0911,  0.0436,  0.0358,  0.1072,  0.0286,\n",
            "           0.0799],\n",
            "         [ 0.0799,  0.1125,  0.1000,  0.0748,  0.1052,  0.0671,  0.1088,\n",
            "           0.1000],\n",
            "         [ 0.0427,  0.0549,  0.0145,  0.0232,  0.0144,  0.0132,  0.0069,\n",
            "           0.0682],\n",
            "         [ 0.0946,  0.0637,  0.0417,  0.0642,  0.0694,  0.1195,  0.0253,\n",
            "           0.0502],\n",
            "         [ 0.0120,  0.1179,  0.0957,  0.0038,  0.1028,  0.0522,  0.0821,\n",
            "           0.0245]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([8, 8])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[0.0488, 0.0403, 0.0600, 0.0934, 0.0849, 0.0776, 0.0797, 0.0952],\n",
            "        [0.0833, 0.0947, 0.0658, 0.0431, 0.0994, 0.0717, 0.0712, 0.0531],\n",
            "        [0.0873, 0.0627, 0.0295, 0.0730, 0.0331, 0.0553, 0.0756, 0.0659],\n",
            "        [0.0889, 0.0840, 0.0707, 0.0789, 0.0336, 0.0254, 0.0829, 0.0703],\n",
            "        [0.0902, 0.0883, 0.0707, 0.0843, 0.0890, 0.0745, 0.0996, 0.0791],\n",
            "        [0.0502, 0.0585, 0.0743, 0.0839, 0.0337, 0.0426, 0.0502, 0.0637],\n",
            "        [0.0592, 0.0542, 0.0509, 0.0649, 0.0686, 0.0991, 0.0817, 0.0817],\n",
            "        [0.0833, 0.0585, 0.1184, 0.0877, 0.0187, 0.0518, 0.0884, 0.0530]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 0, 4\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([8, 8]) por self.weight.data[:,:,0,4].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[0.3164, 0.8274, 0.8536, 0.9826, 0.2775, 0.0390, 0.7179, 0.4340],\n",
            "        [0.9010, 0.1084, 0.3834, 0.9551, 0.8549, 0.4536, 0.1170, 0.9275],\n",
            "        [0.8118, 0.3338, 0.8533, 0.0131, 0.1123, 0.1735, 0.3608, 0.3232],\n",
            "        [0.6613, 0.5085, 0.6569, 0.0578, 0.2275, 0.0532, 0.4616, 0.3573],\n",
            "        [0.9296, 0.2616, 0.2410, 0.4902, 0.2943, 0.9096, 0.8048, 0.3672],\n",
            "        [0.2576, 0.4009, 0.8265, 0.0263, 0.7091, 0.6353, 0.6951, 0.8267],\n",
            "        [0.3279, 0.3608, 0.2165, 0.2346, 0.7870, 0.3705, 0.9562, 0.6253],\n",
            "        [0.6232, 0.9848, 0.7276, 0.3020, 0.2297, 0.8401, 0.4696, 0.0771]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[-0.0610],\n",
            "        [-0.2128]])\n",
            "[self.weight.data[:,:,0,4].view(2,)[i] for i in range(2)] = \n",
            "-0.06104636937379837\n",
            "\n",
            "produto.shape: torch.Size([2, 8, 8]) produto: tensor([[[-0.0193, -0.0505, -0.0521, -0.0600, -0.0169, -0.0024, -0.0438,\n",
            "          -0.0265],\n",
            "         [-0.0550, -0.0066, -0.0234, -0.0583, -0.0522, -0.0277, -0.0071,\n",
            "          -0.0566],\n",
            "         [-0.0496, -0.0204, -0.0521, -0.0008, -0.0069, -0.0106, -0.0220,\n",
            "          -0.0197],\n",
            "         [-0.0404, -0.0310, -0.0401, -0.0035, -0.0139, -0.0032, -0.0282,\n",
            "          -0.0218],\n",
            "         [-0.0567, -0.0160, -0.0147, -0.0299, -0.0180, -0.0555, -0.0491,\n",
            "          -0.0224],\n",
            "         [-0.0157, -0.0245, -0.0505, -0.0016, -0.0433, -0.0388, -0.0424,\n",
            "          -0.0505],\n",
            "         [-0.0200, -0.0220, -0.0132, -0.0143, -0.0480, -0.0226, -0.0584,\n",
            "          -0.0382],\n",
            "         [-0.0380, -0.0601, -0.0444, -0.0184, -0.0140, -0.0513, -0.0287,\n",
            "          -0.0047]],\n",
            "\n",
            "        [[-0.0673, -0.1761, -0.1817, -0.2091, -0.0591, -0.0083, -0.1528,\n",
            "          -0.0924],\n",
            "         [-0.1918, -0.0231, -0.0816, -0.2033, -0.1820, -0.0965, -0.0249,\n",
            "          -0.1974],\n",
            "         [-0.1728, -0.0710, -0.1816, -0.0028, -0.0239, -0.0369, -0.0768,\n",
            "          -0.0688],\n",
            "         [-0.1407, -0.1082, -0.1398, -0.0123, -0.0484, -0.0113, -0.0982,\n",
            "          -0.0760],\n",
            "         [-0.1978, -0.0557, -0.0513, -0.1043, -0.0626, -0.1936, -0.1713,\n",
            "          -0.0782],\n",
            "         [-0.0548, -0.0853, -0.1759, -0.0056, -0.1509, -0.1352, -0.1479,\n",
            "          -0.1760],\n",
            "         [-0.0698, -0.0768, -0.0461, -0.0499, -0.1675, -0.0788, -0.2035,\n",
            "          -0.1331],\n",
            "         [-0.1326, -0.2096, -0.1549, -0.0643, -0.0489, -0.1788, -0.0999,\n",
            "          -0.0164]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([8, 8])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[0.0479, 0.0397, 0.0570, 0.0905, 0.0818, 0.0734, 0.0763, 0.0910],\n",
            "        [0.0795, 0.0907, 0.0648, 0.0406, 0.0971, 0.0682, 0.0686, 0.0500],\n",
            "        [0.0850, 0.0622, 0.0260, 0.0726, 0.0290, 0.0522, 0.0728, 0.0629],\n",
            "        [0.0853, 0.0804, 0.0672, 0.0772, 0.0323, 0.0213, 0.0818, 0.0673],\n",
            "        [0.0871, 0.0840, 0.0669, 0.0814, 0.0850, 0.0719, 0.0955, 0.0753],\n",
            "        [0.0485, 0.0564, 0.0737, 0.0830, 0.0331, 0.0421, 0.0500, 0.0611],\n",
            "        [0.0555, 0.0517, 0.0493, 0.0624, 0.0660, 0.0946, 0.0807, 0.0798],\n",
            "        [0.0829, 0.0540, 0.1147, 0.0876, 0.0148, 0.0498, 0.0853, 0.0521]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 1, 0\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([8, 8]) por self.weight.data[:,:,1,0].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[0.1479, 0.2318, 0.4606, 0.5786, 0.6775, 0.6932, 0.1908, 0.0950],\n",
            "        [0.9998, 0.2518, 0.6397, 0.6314, 0.3786, 0.5449, 0.5024, 0.9856],\n",
            "        [0.5091, 0.8210, 0.7056, 0.3894, 0.5185, 0.1364, 0.7969, 0.0882],\n",
            "        [0.9027, 0.4139, 0.4265, 0.6671, 0.9355, 0.6638, 0.3069, 0.6845],\n",
            "        [0.2077, 0.6429, 0.7605, 0.5791, 0.1063, 0.6522, 0.2427, 0.2187],\n",
            "        [0.1189, 0.0552, 0.9920, 0.9323, 0.0651, 0.0324, 0.1132, 0.7797],\n",
            "        [0.7429, 0.5024, 0.6748, 0.5288, 0.0470, 0.7523, 0.2239, 0.1976],\n",
            "        [0.1685, 0.8435, 0.3984, 0.6348, 0.1437, 0.6609, 0.4285, 0.1461]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[0.0251],\n",
            "        [0.0234]])\n",
            "[self.weight.data[:,:,1,0].view(2,)[i] for i in range(2)] = \n",
            "0.025130199268460274\n",
            "\n",
            "produto.shape: torch.Size([2, 8, 8]) produto: tensor([[[0.0037, 0.0058, 0.0116, 0.0145, 0.0170, 0.0174, 0.0048, 0.0024],\n",
            "         [0.0251, 0.0063, 0.0161, 0.0159, 0.0095, 0.0137, 0.0126, 0.0248],\n",
            "         [0.0128, 0.0206, 0.0177, 0.0098, 0.0130, 0.0034, 0.0200, 0.0022],\n",
            "         [0.0227, 0.0104, 0.0107, 0.0168, 0.0235, 0.0167, 0.0077, 0.0172],\n",
            "         [0.0052, 0.0162, 0.0191, 0.0146, 0.0027, 0.0164, 0.0061, 0.0055],\n",
            "         [0.0030, 0.0014, 0.0249, 0.0234, 0.0016, 0.0008, 0.0028, 0.0196],\n",
            "         [0.0187, 0.0126, 0.0170, 0.0133, 0.0012, 0.0189, 0.0056, 0.0050],\n",
            "         [0.0042, 0.0212, 0.0100, 0.0160, 0.0036, 0.0166, 0.0108, 0.0037]],\n",
            "\n",
            "        [[0.0035, 0.0054, 0.0108, 0.0135, 0.0158, 0.0162, 0.0045, 0.0022],\n",
            "         [0.0234, 0.0059, 0.0150, 0.0148, 0.0089, 0.0127, 0.0117, 0.0230],\n",
            "         [0.0119, 0.0192, 0.0165, 0.0091, 0.0121, 0.0032, 0.0186, 0.0021],\n",
            "         [0.0211, 0.0097, 0.0100, 0.0156, 0.0219, 0.0155, 0.0072, 0.0160],\n",
            "         [0.0049, 0.0150, 0.0178, 0.0135, 0.0025, 0.0153, 0.0057, 0.0051],\n",
            "         [0.0028, 0.0013, 0.0232, 0.0218, 0.0015, 0.0008, 0.0026, 0.0182],\n",
            "         [0.0174, 0.0117, 0.0158, 0.0124, 0.0011, 0.0176, 0.0052, 0.0046],\n",
            "         [0.0039, 0.0197, 0.0093, 0.0148, 0.0034, 0.0155, 0.0100, 0.0034]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([8, 8])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[ 0.0286, -0.0108,  0.0049,  0.0305,  0.0649,  0.0710,  0.0324,  0.0645],\n",
            "        [ 0.0245,  0.0840,  0.0414, -0.0177,  0.0450,  0.0405,  0.0615, -0.0066],\n",
            "        [ 0.0354,  0.0418, -0.0261,  0.0718,  0.0221,  0.0416,  0.0507,  0.0431],\n",
            "        [ 0.0449,  0.0494,  0.0271,  0.0737,  0.0184,  0.0181,  0.0537,  0.0455],\n",
            "        [ 0.0304,  0.0680,  0.0522,  0.0515,  0.0670,  0.0164,  0.0463,  0.0529],\n",
            "        [ 0.0328,  0.0319,  0.0233,  0.0814, -0.0102,  0.0033,  0.0075,  0.0106],\n",
            "        [ 0.0355,  0.0297,  0.0361,  0.0481,  0.0179,  0.0719,  0.0224,  0.0417],\n",
            "        [ 0.0448, -0.0061,  0.0703,  0.0692,  0.0007, -0.0015,  0.0566,  0.0474]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 1, 1\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([8, 8]) por self.weight.data[:,:,1,1].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[0.5331, 0.4545, 0.5159, 0.9455, 0.6087, 0.4354, 0.9268, 0.5789],\n",
            "        [0.2855, 0.7204, 0.8954, 0.5028, 0.1661, 0.5490, 0.3445, 0.5757],\n",
            "        [0.5101, 0.3605, 0.1853, 0.7398, 0.5489, 0.6918, 0.0061, 0.6997],\n",
            "        [0.3112, 0.4362, 0.4958, 0.4801, 0.6260, 0.4563, 0.7274, 0.2073],\n",
            "        [0.4474, 0.0369, 0.7823, 0.0204, 0.2062, 0.7905, 0.4570, 0.0657],\n",
            "        [0.9508, 0.4556, 0.4791, 0.1144, 0.3650, 0.0290, 0.2206, 0.4196],\n",
            "        [0.9616, 0.6241, 0.4962, 0.9429, 0.9632, 0.7063, 0.8205, 0.5013],\n",
            "        [0.3713, 0.6818, 0.2316, 0.3449, 0.4895, 0.1076, 0.7065, 0.3353]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[-0.0047],\n",
            "        [ 0.3240]])\n",
            "[self.weight.data[:,:,1,1].view(2,)[i] for i in range(2)] = \n",
            "-0.004740814678370953\n",
            "\n",
            "produto.shape: torch.Size([2, 8, 8]) produto: tensor([[[-2.5271e-03, -2.1549e-03, -2.4457e-03, -4.4825e-03, -2.8855e-03,\n",
            "          -2.0641e-03, -4.3938e-03, -2.7443e-03],\n",
            "         [-1.3536e-03, -3.4153e-03, -4.2449e-03, -2.3837e-03, -7.8739e-04,\n",
            "          -2.6026e-03, -1.6331e-03, -2.7295e-03],\n",
            "         [-2.4182e-03, -1.7089e-03, -8.7838e-04, -3.5074e-03, -2.6023e-03,\n",
            "          -3.2795e-03, -2.8771e-05, -3.3173e-03],\n",
            "         [-1.4753e-03, -2.0681e-03, -2.3504e-03, -2.2761e-03, -2.9678e-03,\n",
            "          -2.1630e-03, -3.4485e-03, -9.8300e-04],\n",
            "         [-2.1209e-03, -1.7502e-04, -3.7085e-03, -9.6600e-05, -9.7733e-04,\n",
            "          -3.7476e-03, -2.1663e-03, -3.1161e-04],\n",
            "         [-4.5077e-03, -2.1599e-03, -2.2715e-03, -5.4254e-04, -1.7302e-03,\n",
            "          -1.3768e-04, -1.0459e-03, -1.9894e-03],\n",
            "         [-4.5589e-03, -2.9587e-03, -2.3526e-03, -4.4700e-03, -4.5664e-03,\n",
            "          -3.3486e-03, -3.8898e-03, -2.3764e-03],\n",
            "         [-1.7604e-03, -3.2321e-03, -1.0978e-03, -1.6351e-03, -2.3204e-03,\n",
            "          -5.1008e-04, -3.3495e-03, -1.5897e-03]],\n",
            "\n",
            "        [[ 1.7272e-01,  1.4728e-01,  1.6715e-01,  3.0636e-01,  1.9721e-01,\n",
            "           1.4107e-01,  3.0029e-01,  1.8756e-01],\n",
            "         [ 9.2511e-02,  2.3342e-01,  2.9012e-01,  1.6292e-01,  5.3815e-02,\n",
            "           1.7788e-01,  1.1162e-01,  1.8655e-01],\n",
            "         [ 1.6527e-01,  1.1680e-01,  6.0034e-02,  2.3972e-01,  1.7786e-01,\n",
            "           2.2414e-01,  1.9663e-03,  2.2672e-01],\n",
            "         [ 1.0083e-01,  1.4135e-01,  1.6064e-01,  1.5556e-01,  2.0284e-01,\n",
            "           1.4783e-01,  2.3569e-01,  6.7183e-02],\n",
            "         [ 1.4495e-01,  1.1962e-02,  2.5346e-01,  6.6022e-03,  6.6796e-02,\n",
            "           2.5613e-01,  1.4806e-01,  2.1297e-02],\n",
            "         [ 3.0808e-01,  1.4762e-01,  1.5525e-01,  3.7080e-02,  1.1825e-01,\n",
            "           9.4100e-03,  7.1482e-02,  1.3596e-01],\n",
            "         [ 3.1158e-01,  2.0222e-01,  1.6079e-01,  3.0550e-01,  3.1209e-01,\n",
            "           2.2886e-01,  2.6585e-01,  1.6241e-01],\n",
            "         [ 1.2031e-01,  2.2090e-01,  7.5031e-02,  1.1175e-01,  1.5859e-01,\n",
            "           3.4862e-02,  2.2893e-01,  1.0865e-01]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([8, 8])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[ 0.0323, -0.0049,  0.0165,  0.0450,  0.0819,  0.0885,  0.0372,  0.0669],\n",
            "        [ 0.0496,  0.0904,  0.0575, -0.0018,  0.0545,  0.0542,  0.0741,  0.0181],\n",
            "        [ 0.0482,  0.0624, -0.0083,  0.0816,  0.0351,  0.0451,  0.0708,  0.0453],\n",
            "        [ 0.0676,  0.0598,  0.0378,  0.0905,  0.0419,  0.0348,  0.0614,  0.0627],\n",
            "        [ 0.0356,  0.0842,  0.0713,  0.0661,  0.0697,  0.0328,  0.0524,  0.0584],\n",
            "        [ 0.0358,  0.0333,  0.0482,  0.1049, -0.0085,  0.0041,  0.0104,  0.0302],\n",
            "        [ 0.0542,  0.0423,  0.0530,  0.0614,  0.0191,  0.0909,  0.0280,  0.0466],\n",
            "        [ 0.0491,  0.0151,  0.0803,  0.0851,  0.0044,  0.0151,  0.0674,  0.0510]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 1, 2\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([8, 8]) por self.weight.data[:,:,1,2].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[0.4066, 0.9737, 0.4220, 0.8057, 0.6179, 0.0353, 0.5299, 0.9131],\n",
            "        [0.9753, 0.6959, 0.2979, 0.1239, 0.7211, 0.3483, 0.6437, 0.2785],\n",
            "        [0.4270, 0.4516, 0.6339, 0.2288, 0.0977, 0.3545, 0.2528, 0.4855],\n",
            "        [0.9167, 0.6996, 0.8463, 0.6904, 0.3534, 0.1091, 0.5164, 0.9727],\n",
            "        [0.5746, 0.5224, 0.7459, 0.8290, 0.5058, 0.4298, 0.6638, 0.7387],\n",
            "        [0.8715, 0.2310, 0.7945, 0.8039, 0.2984, 0.0179, 0.3352, 0.0050],\n",
            "        [0.5214, 0.0379, 0.4761, 0.6435, 0.8049, 0.5488, 0.1264, 0.1121],\n",
            "        [0.9908, 0.8176, 0.7526, 0.8858, 0.9042, 0.5814, 0.7816, 0.9155]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[-0.0097],\n",
            "        [ 1.0133]])\n",
            "[self.weight.data[:,:,1,2].view(2,)[i] for i in range(2)] = \n",
            "-0.009749997407197952\n",
            "\n",
            "produto.shape: torch.Size([2, 8, 8]) produto: tensor([[[-3.9648e-03, -9.4936e-03, -4.1147e-03, -7.8560e-03, -6.0245e-03,\n",
            "          -3.4413e-04, -5.1664e-03, -8.9031e-03],\n",
            "         [-9.5091e-03, -6.7848e-03, -2.9047e-03, -1.2083e-03, -7.0305e-03,\n",
            "          -3.3961e-03, -6.2758e-03, -2.7158e-03],\n",
            "         [-4.1636e-03, -4.4031e-03, -6.1803e-03, -2.2305e-03, -9.5259e-04,\n",
            "          -3.4561e-03, -2.4651e-03, -4.7337e-03],\n",
            "         [-8.9379e-03, -6.8207e-03, -8.2514e-03, -6.7315e-03, -3.4454e-03,\n",
            "          -1.0636e-03, -5.0349e-03, -9.4835e-03],\n",
            "         [-5.6026e-03, -5.0931e-03, -7.2729e-03, -8.0826e-03, -4.9320e-03,\n",
            "          -4.1904e-03, -6.4725e-03, -7.2025e-03],\n",
            "         [-8.4974e-03, -2.2525e-03, -7.7466e-03, -7.8385e-03, -2.9093e-03,\n",
            "          -1.7492e-04, -3.2682e-03, -4.8263e-05],\n",
            "         [-5.0833e-03, -3.6944e-04, -4.6415e-03, -6.2739e-03, -7.8480e-03,\n",
            "          -5.3505e-03, -1.2321e-03, -1.0926e-03],\n",
            "         [-9.6600e-03, -7.9720e-03, -7.3379e-03, -8.6361e-03, -8.8164e-03,\n",
            "          -5.6684e-03, -7.6208e-03, -8.9262e-03]],\n",
            "\n",
            "        [[ 4.1205e-01,  9.8663e-01,  4.2762e-01,  8.1644e-01,  6.2610e-01,\n",
            "           3.5764e-02,  5.3692e-01,  9.2526e-01],\n",
            "         [ 9.8825e-01,  7.0511e-01,  3.0187e-01,  1.2557e-01,  7.3065e-01,\n",
            "           3.5294e-01,  6.5221e-01,  2.8224e-01],\n",
            "         [ 4.3270e-01,  4.5760e-01,  6.4230e-01,  2.3181e-01,  9.8999e-02,\n",
            "           3.5918e-01,  2.5619e-01,  4.9195e-01],\n",
            "         [ 9.2888e-01,  7.0884e-01,  8.5753e-01,  6.9958e-01,  3.5807e-01,\n",
            "           1.1054e-01,  5.2325e-01,  9.8558e-01],\n",
            "         [ 5.8226e-01,  5.2931e-01,  7.5584e-01,  8.3999e-01,  5.1257e-01,\n",
            "           4.3549e-01,  6.7266e-01,  7.4853e-01],\n",
            "         [ 8.8310e-01,  2.3409e-01,  8.0507e-01,  8.1462e-01,  3.0235e-01,\n",
            "           1.8179e-02,  3.3965e-01,  5.0158e-03],\n",
            "         [ 5.2829e-01,  3.8395e-02,  4.8238e-01,  6.5202e-01,  8.1561e-01,\n",
            "           5.5605e-01,  1.2805e-01,  1.1355e-01],\n",
            "         [ 1.0039e+00,  8.2850e-01,  7.6260e-01,  8.9751e-01,  9.1625e-01,\n",
            "           5.8909e-01,  7.9200e-01,  9.2766e-01]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([8, 8])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[ 0.0298, -0.0071,  0.0140,  0.0405,  0.0790,  0.0864,  0.0328,  0.0641],\n",
            "        [ 0.0482,  0.0869,  0.0532, -0.0042,  0.0537,  0.0516,  0.0725,  0.0154],\n",
            "        [ 0.0458,  0.0607, -0.0092,  0.0781,  0.0325,  0.0418,  0.0707,  0.0420],\n",
            "        [ 0.0661,  0.0577,  0.0355,  0.0882,  0.0389,  0.0326,  0.0579,  0.0617],\n",
            "        [ 0.0335,  0.0840,  0.0676,  0.0660,  0.0687,  0.0290,  0.0503,  0.0581],\n",
            "        [ 0.0313,  0.0311,  0.0459,  0.1043, -0.0103,  0.0040,  0.0093,  0.0283],\n",
            "        [ 0.0496,  0.0394,  0.0507,  0.0569,  0.0145,  0.0875,  0.0241,  0.0442],\n",
            "        [ 0.0473,  0.0119,  0.0792,  0.0835,  0.0020,  0.0146,  0.0640,  0.0494]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 1, 3\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([8, 8]) por self.weight.data[:,:,1,3].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[0.2318, 0.4606, 0.5786, 0.6775, 0.6932, 0.1908, 0.0950, 0.0275],\n",
            "        [0.2518, 0.6397, 0.6314, 0.3786, 0.5449, 0.5024, 0.9856, 0.1946],\n",
            "        [0.8210, 0.7056, 0.3894, 0.5185, 0.1364, 0.7969, 0.0882, 0.4067],\n",
            "        [0.4139, 0.4265, 0.6671, 0.9355, 0.6638, 0.3069, 0.6845, 0.2913],\n",
            "        [0.6429, 0.7605, 0.5791, 0.1063, 0.6522, 0.2427, 0.2187, 0.1691],\n",
            "        [0.0552, 0.9920, 0.9323, 0.0651, 0.0324, 0.1132, 0.7797, 0.1368],\n",
            "        [0.5024, 0.6748, 0.5288, 0.0470, 0.7523, 0.2239, 0.1976, 0.9536],\n",
            "        [0.8435, 0.3984, 0.6348, 0.1437, 0.6609, 0.4285, 0.1461, 0.1354]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[-0.1218],\n",
            "        [ 0.7023]])\n",
            "[self.weight.data[:,:,1,3].view(2,)[i] for i in range(2)] = \n",
            "-0.12179325520992279\n",
            "\n",
            "produto.shape: torch.Size([2, 8, 8]) produto: tensor([[[-0.0282, -0.0561, -0.0705, -0.0825, -0.0844, -0.0232, -0.0116,\n",
            "          -0.0033],\n",
            "         [-0.0307, -0.0779, -0.0769, -0.0461, -0.0664, -0.0612, -0.1200,\n",
            "          -0.0237],\n",
            "         [-0.1000, -0.0859, -0.0474, -0.0631, -0.0166, -0.0971, -0.0107,\n",
            "          -0.0495],\n",
            "         [-0.0504, -0.0519, -0.0812, -0.1139, -0.0809, -0.0374, -0.0834,\n",
            "          -0.0355],\n",
            "         [-0.0783, -0.0926, -0.0705, -0.0129, -0.0794, -0.0296, -0.0266,\n",
            "          -0.0206],\n",
            "         [-0.0067, -0.1208, -0.1135, -0.0079, -0.0039, -0.0138, -0.0950,\n",
            "          -0.0167],\n",
            "         [-0.0612, -0.0822, -0.0644, -0.0057, -0.0916, -0.0273, -0.0241,\n",
            "          -0.1161],\n",
            "         [-0.1027, -0.0485, -0.0773, -0.0175, -0.0805, -0.0522, -0.0178,\n",
            "          -0.0165]],\n",
            "\n",
            "        [[ 0.1628,  0.3234,  0.4063,  0.4758,  0.4868,  0.1340,  0.0667,\n",
            "           0.0193],\n",
            "         [ 0.1768,  0.4492,  0.4434,  0.2659,  0.3827,  0.3528,  0.6921,\n",
            "           0.1367],\n",
            "         [ 0.5766,  0.4955,  0.2735,  0.3641,  0.0958,  0.5597,  0.0619,\n",
            "           0.2856],\n",
            "         [ 0.2907,  0.2995,  0.4685,  0.6569,  0.4662,  0.2155,  0.4807,\n",
            "           0.2046],\n",
            "         [ 0.4515,  0.5341,  0.4067,  0.0746,  0.4580,  0.1704,  0.1536,\n",
            "           0.1188],\n",
            "         [ 0.0388,  0.6966,  0.6547,  0.0457,  0.0227,  0.0795,  0.5476,\n",
            "           0.0961],\n",
            "         [ 0.3528,  0.4739,  0.3713,  0.0330,  0.5283,  0.1573,  0.1388,\n",
            "           0.6697],\n",
            "         [ 0.5924,  0.2798,  0.4458,  0.1009,  0.4641,  0.3009,  0.1026,\n",
            "           0.0951]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([8, 8])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[ 0.0259, -0.0166,  0.0099,  0.0327,  0.0730,  0.0861,  0.0277,  0.0552],\n",
            "        [ 0.0387,  0.0802,  0.0503, -0.0054,  0.0466,  0.0482,  0.0662,  0.0127],\n",
            "        [ 0.0416,  0.0563, -0.0154,  0.0759,  0.0316,  0.0383,  0.0683,  0.0373],\n",
            "        [ 0.0572,  0.0509,  0.0272,  0.0815,  0.0355,  0.0315,  0.0529,  0.0522],\n",
            "        [ 0.0279,  0.0789,  0.0603,  0.0579,  0.0637,  0.0249,  0.0438,  0.0509],\n",
            "        [ 0.0228,  0.0289,  0.0382,  0.0965, -0.0132,  0.0038,  0.0061,  0.0282],\n",
            "        [ 0.0445,  0.0390,  0.0460,  0.0506,  0.0067,  0.0822,  0.0229,  0.0431],\n",
            "        [ 0.0376,  0.0039,  0.0719,  0.0749, -0.0068,  0.0090,  0.0564,  0.0405]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 1, 4\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([8, 8]) por self.weight.data[:,:,1,4].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[0.4545, 0.5159, 0.9455, 0.6087, 0.4354, 0.9268, 0.5789, 0.1634],\n",
            "        [0.7204, 0.8954, 0.5028, 0.1661, 0.5490, 0.3445, 0.5757, 0.5382],\n",
            "        [0.3605, 0.1853, 0.7398, 0.5489, 0.6918, 0.0061, 0.6997, 0.4168],\n",
            "        [0.4362, 0.4958, 0.4801, 0.6260, 0.4563, 0.7274, 0.2073, 0.6066],\n",
            "        [0.0369, 0.7823, 0.0204, 0.2062, 0.7905, 0.4570, 0.0657, 0.2186],\n",
            "        [0.4556, 0.4791, 0.1144, 0.3650, 0.0290, 0.2206, 0.4196, 0.8588],\n",
            "        [0.6241, 0.4962, 0.9429, 0.9632, 0.7063, 0.8205, 0.5013, 0.9967],\n",
            "        [0.6818, 0.2316, 0.3449, 0.4895, 0.1076, 0.7065, 0.3353, 0.3867]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[-0.1646],\n",
            "        [ 0.4641]])\n",
            "[self.weight.data[:,:,1,4].view(2,)[i] for i in range(2)] = \n",
            "-0.16463914513587952\n",
            "\n",
            "produto.shape: torch.Size([2, 8, 8]) produto: tensor([[[-0.0748, -0.0849, -0.1557, -0.1002, -0.0717, -0.1526, -0.0953,\n",
            "          -0.0269],\n",
            "         [-0.1186, -0.1474, -0.0828, -0.0273, -0.0904, -0.0567, -0.0948,\n",
            "          -0.0886],\n",
            "         [-0.0593, -0.0305, -0.1218, -0.0904, -0.1139, -0.0010, -0.1152,\n",
            "          -0.0686],\n",
            "         [-0.0718, -0.0816, -0.0790, -0.1031, -0.0751, -0.1198, -0.0341,\n",
            "          -0.0999],\n",
            "         [-0.0061, -0.1288, -0.0034, -0.0339, -0.1301, -0.0752, -0.0108,\n",
            "          -0.0360],\n",
            "         [-0.0750, -0.0789, -0.0188, -0.0601, -0.0048, -0.0363, -0.0691,\n",
            "          -0.1414],\n",
            "         [-0.1028, -0.0817, -0.1552, -0.1586, -0.1163, -0.1351, -0.0825,\n",
            "          -0.1641],\n",
            "         [-0.1122, -0.0381, -0.0568, -0.0806, -0.0177, -0.1163, -0.0552,\n",
            "          -0.0637]],\n",
            "\n",
            "        [[ 0.2110,  0.2394,  0.4388,  0.2825,  0.2021,  0.4301,  0.2687,\n",
            "           0.0758],\n",
            "         [ 0.3343,  0.4156,  0.2334,  0.0771,  0.2548,  0.1599,  0.2672,\n",
            "           0.2498],\n",
            "         [ 0.1673,  0.0860,  0.3434,  0.2548,  0.3210,  0.0028,  0.3247,\n",
            "           0.1934],\n",
            "         [ 0.2025,  0.2301,  0.2228,  0.2905,  0.2117,  0.3376,  0.0962,\n",
            "           0.2815],\n",
            "         [ 0.0171,  0.3630,  0.0095,  0.0957,  0.3669,  0.2121,  0.0305,\n",
            "           0.1015],\n",
            "         [ 0.2114,  0.2224,  0.0531,  0.1694,  0.0135,  0.1024,  0.1947,\n",
            "           0.3986],\n",
            "         [ 0.2896,  0.2303,  0.4376,  0.4470,  0.3278,  0.3808,  0.2326,\n",
            "           0.4626],\n",
            "         [ 0.3164,  0.1075,  0.1601,  0.2272,  0.0499,  0.3279,  0.1556,\n",
            "           0.1795]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([8, 8])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[-0.0024, -0.0727, -0.0606, -0.0498, -0.0114,  0.0628,  0.0161,  0.0519],\n",
            "        [ 0.0081,  0.0023, -0.0266, -0.0515, -0.0197, -0.0130, -0.0539, -0.0110],\n",
            "        [-0.0584, -0.0296, -0.0628,  0.0127,  0.0150, -0.0587,  0.0575, -0.0122],\n",
            "        [ 0.0068, -0.0010, -0.0540, -0.0325, -0.0454, -0.0059, -0.0305,  0.0167],\n",
            "        [-0.0504, -0.0137, -0.0102,  0.0450, -0.0157, -0.0047,  0.0171,  0.0303],\n",
            "        [ 0.0161, -0.0920, -0.0754,  0.0886, -0.0171, -0.0100, -0.0889,  0.0115],\n",
            "        [-0.0166, -0.0432, -0.0184,  0.0449, -0.0849,  0.0549, -0.0012, -0.0730],\n",
            "        [-0.0651, -0.0446, -0.0054,  0.0573, -0.0873, -0.0432,  0.0386,  0.0240]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 2, 0\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([8, 8]) por self.weight.data[:,:,2,0].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[0.3834, 0.7341, 0.1459, 0.5112, 0.4702, 0.5183, 0.2251, 0.9153],\n",
            "        [0.1746, 0.8443, 0.1861, 0.7868, 0.1444, 0.9043, 0.8339, 0.1163],\n",
            "        [0.5125, 0.4900, 0.7674, 0.5201, 0.1226, 0.7444, 0.9308, 0.5104],\n",
            "        [0.7239, 0.2956, 0.8044, 0.6248, 0.6000, 0.9078, 0.1836, 0.6861],\n",
            "        [0.0943, 0.5325, 0.9657, 0.6483, 0.1575, 0.7162, 0.8286, 0.1387],\n",
            "        [0.0475, 0.5438, 0.5291, 0.2669, 0.5047, 0.5315, 0.1939, 0.7101],\n",
            "        [0.0157, 0.1842, 0.8014, 0.4034, 0.4570, 0.6568, 0.0871, 0.2642],\n",
            "        [0.4312, 0.3208, 0.3112, 0.5912, 0.8600, 0.7952, 0.8078, 0.7708]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[-0.0247],\n",
            "        [-0.1066]])\n",
            "[self.weight.data[:,:,2,0].view(2,)[i] for i in range(2)] = \n",
            "-0.024726245552301407\n",
            "\n",
            "produto.shape: torch.Size([2, 8, 8]) produto: tensor([[[-0.0095, -0.0182, -0.0036, -0.0126, -0.0116, -0.0128, -0.0056,\n",
            "          -0.0226],\n",
            "         [-0.0043, -0.0209, -0.0046, -0.0195, -0.0036, -0.0224, -0.0206,\n",
            "          -0.0029],\n",
            "         [-0.0127, -0.0121, -0.0190, -0.0129, -0.0030, -0.0184, -0.0230,\n",
            "          -0.0126],\n",
            "         [-0.0179, -0.0073, -0.0199, -0.0154, -0.0148, -0.0224, -0.0045,\n",
            "          -0.0170],\n",
            "         [-0.0023, -0.0132, -0.0239, -0.0160, -0.0039, -0.0177, -0.0205,\n",
            "          -0.0034],\n",
            "         [-0.0012, -0.0134, -0.0131, -0.0066, -0.0125, -0.0131, -0.0048,\n",
            "          -0.0176],\n",
            "         [-0.0004, -0.0046, -0.0198, -0.0100, -0.0113, -0.0162, -0.0022,\n",
            "          -0.0065],\n",
            "         [-0.0107, -0.0079, -0.0077, -0.0146, -0.0213, -0.0197, -0.0200,\n",
            "          -0.0191]],\n",
            "\n",
            "        [[-0.0409, -0.0783, -0.0156, -0.0545, -0.0501, -0.0552, -0.0240,\n",
            "          -0.0976],\n",
            "         [-0.0186, -0.0900, -0.0198, -0.0839, -0.0154, -0.0964, -0.0889,\n",
            "          -0.0124],\n",
            "         [-0.0546, -0.0522, -0.0818, -0.0554, -0.0131, -0.0793, -0.0992,\n",
            "          -0.0544],\n",
            "         [-0.0772, -0.0315, -0.0857, -0.0666, -0.0640, -0.0968, -0.0196,\n",
            "          -0.0731],\n",
            "         [-0.0100, -0.0568, -0.1029, -0.0691, -0.0168, -0.0763, -0.0883,\n",
            "          -0.0148],\n",
            "         [-0.0051, -0.0580, -0.0564, -0.0284, -0.0538, -0.0567, -0.0207,\n",
            "          -0.0757],\n",
            "         [-0.0017, -0.0196, -0.0854, -0.0430, -0.0487, -0.0700, -0.0093,\n",
            "          -0.0282],\n",
            "         [-0.0460, -0.0342, -0.0332, -0.0630, -0.0917, -0.0848, -0.0861,\n",
            "          -0.0822]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([8, 8])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[-0.0772, -0.1576, -0.2162, -0.1500, -0.0831, -0.0898, -0.0792,  0.0250],\n",
            "        [-0.1105, -0.1452, -0.1093, -0.0789, -0.1101, -0.0697, -0.1486, -0.0996],\n",
            "        [-0.1177, -0.0601, -0.1846, -0.0776, -0.0989, -0.0597, -0.0577, -0.0809],\n",
            "        [-0.0651, -0.0827, -0.1331, -0.1355, -0.1205, -0.1256, -0.0646, -0.0832],\n",
            "        [-0.0565, -0.1425, -0.0136,  0.0110, -0.1458, -0.0799,  0.0063, -0.0057],\n",
            "        [-0.0589, -0.1708, -0.0942,  0.0285, -0.0219, -0.0463, -0.1580, -0.1299],\n",
            "        [-0.1194, -0.1249, -0.1736, -0.1137, -0.2012, -0.0802, -0.0837, -0.2371],\n",
            "        [-0.1773, -0.0828, -0.0622, -0.0232, -0.1050, -0.1595, -0.0166, -0.0396]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 2, 1\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([8, 8]) por self.weight.data[:,:,2,1].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[0.4451, 0.9389, 0.0969, 0.7050, 0.8526, 0.5983, 0.3111, 0.7751],\n",
            "        [0.3302, 0.6937, 0.5422, 0.6042, 0.9010, 0.5713, 0.8730, 0.4938],\n",
            "        [0.1549, 0.0164, 0.4058, 0.8773, 0.2742, 0.8095, 0.0890, 0.5840],\n",
            "        [0.3604, 0.8646, 0.0733, 0.1638, 0.2299, 0.4596, 0.2010, 0.4209],\n",
            "        [0.8800, 0.9981, 0.8973, 0.2746, 0.2087, 0.5689, 0.5292, 0.0221],\n",
            "        [0.7690, 0.2486, 0.7095, 0.5242, 0.7175, 0.5021, 0.1091, 0.8978],\n",
            "        [0.9315, 0.1508, 0.3660, 0.0322, 0.0412, 0.0195, 0.4829, 0.1753],\n",
            "        [0.7871, 0.5582, 0.4533, 0.5274, 0.3362, 0.4890, 0.5055, 0.5385]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[-0.0092],\n",
            "        [ 0.5797]])\n",
            "[self.weight.data[:,:,2,1].view(2,)[i] for i in range(2)] = \n",
            "-0.009192749857902527\n",
            "\n",
            "produto.shape: torch.Size([2, 8, 8]) produto: tensor([[[-4.0913e-03, -8.6308e-03, -8.9122e-04, -6.4806e-03, -7.8379e-03,\n",
            "          -5.5001e-03, -2.8594e-03, -7.1257e-03],\n",
            "         [-3.0352e-03, -6.3767e-03, -4.9843e-03, -5.5543e-03, -8.2823e-03,\n",
            "          -5.2523e-03, -8.0256e-03, -4.5392e-03],\n",
            "         [-1.4244e-03, -1.5100e-04, -3.7304e-03, -8.0647e-03, -2.5203e-03,\n",
            "          -7.4416e-03, -8.1785e-04, -5.3684e-03],\n",
            "         [-3.3133e-03, -7.9481e-03, -6.7355e-04, -1.5058e-03, -2.1133e-03,\n",
            "          -4.2250e-03, -1.8479e-03, -3.8689e-03],\n",
            "         [-8.0899e-03, -9.1753e-03, -8.2482e-03, -2.5246e-03, -1.9185e-03,\n",
            "          -5.2294e-03, -4.8648e-03, -2.0343e-04],\n",
            "         [-7.0694e-03, -2.2857e-03, -6.5227e-03, -4.8190e-03, -6.5956e-03,\n",
            "          -4.6160e-03, -1.0029e-03, -8.2531e-03],\n",
            "         [-8.5633e-03, -1.3866e-03, -3.3650e-03, -2.9613e-04, -3.7864e-04,\n",
            "          -1.7922e-04, -4.4394e-03, -1.6119e-03],\n",
            "         [-7.2356e-03, -5.1314e-03, -4.1668e-03, -4.8486e-03, -3.0906e-03,\n",
            "          -4.4948e-03, -4.6469e-03, -4.9507e-03]],\n",
            "\n",
            "        [[ 2.5798e-01,  5.4422e-01,  5.6196e-02,  4.0864e-01,  4.9422e-01,\n",
            "           3.4681e-01,  1.8030e-01,  4.4931e-01],\n",
            "         [ 1.9139e-01,  4.0209e-01,  3.1428e-01,  3.5023e-01,  5.2225e-01,\n",
            "           3.3118e-01,  5.0606e-01,  2.8622e-01],\n",
            "         [ 8.9813e-02,  9.5215e-03,  2.3522e-01,  5.0852e-01,  1.5892e-01,\n",
            "           4.6923e-01,  5.1570e-02,  3.3851e-01],\n",
            "         [ 2.0892e-01,  5.0117e-01,  4.2471e-02,  9.4946e-02,  1.3325e-01,\n",
            "           2.6641e-01,  1.1652e-01,  2.4395e-01],\n",
            "         [ 5.1011e-01,  5.7855e-01,  5.2009e-01,  1.5919e-01,  1.2097e-01,\n",
            "           3.2974e-01,  3.0675e-01,  1.2828e-02],\n",
            "         [ 4.4576e-01,  1.4413e-01,  4.1129e-01,  3.0387e-01,  4.1589e-01,\n",
            "           2.9106e-01,  6.3237e-02,  5.2040e-01],\n",
            "         [ 5.3996e-01,  8.7430e-02,  2.1218e-01,  1.8673e-02,  2.3876e-02,\n",
            "           1.1301e-02,  2.7993e-01,  1.0164e-01],\n",
            "         [ 4.5624e-01,  3.2356e-01,  2.6274e-01,  3.0573e-01,  1.9488e-01,\n",
            "           2.8342e-01,  2.9301e-01,  3.1217e-01]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([8, 8])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[-0.0867, -0.1758, -0.2199, -0.1627, -0.0947, -0.1026, -0.0848,  0.0023],\n",
            "        [-0.1149, -0.1660, -0.1139, -0.0983, -0.1137, -0.0921, -0.1693, -0.1025],\n",
            "        [-0.1304, -0.0722, -0.2036, -0.0905, -0.1020, -0.0781, -0.0807, -0.0935],\n",
            "        [-0.0830, -0.0900, -0.1529, -0.1510, -0.1353, -0.1481, -0.0691, -0.1001],\n",
            "        [-0.0588, -0.1557, -0.0375, -0.0050, -0.1497, -0.0976, -0.0142, -0.0092],\n",
            "        [-0.0601, -0.1843, -0.1073,  0.0219, -0.0344, -0.0594, -0.1628, -0.1474],\n",
            "        [-0.1198, -0.1295, -0.1934, -0.1237, -0.2125, -0.0964, -0.0859, -0.2436],\n",
            "        [-0.1880, -0.0907, -0.0699, -0.0379, -0.1263, -0.1792, -0.0366, -0.0587]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 2, 2\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([8, 8]) por self.weight.data[:,:,2,2].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[0.0126, 0.8056, 0.7076, 0.0114, 0.7320, 0.4527, 0.1955, 0.6749],\n",
            "        [0.5370, 0.8831, 0.0556, 0.9836, 0.9221, 0.9546, 0.4675, 0.5938],\n",
            "        [0.6881, 0.7690, 0.1548, 0.9577, 0.8893, 0.2511, 0.4759, 0.1227],\n",
            "        [0.1829, 0.8010, 0.7355, 0.5158, 0.2890, 0.4947, 0.9603, 0.8046],\n",
            "        [0.2614, 0.3005, 0.8862, 0.8148, 0.2590, 0.8181, 0.7914, 0.0927],\n",
            "        [0.8418, 0.3788, 0.5086, 0.5153, 0.3116, 0.7111, 0.0931, 0.9959],\n",
            "        [0.5878, 0.6205, 0.3785, 0.8597, 0.1252, 0.8521, 0.6474, 0.4471],\n",
            "        [0.8124, 0.0361, 0.4819, 0.3513, 0.8992, 0.3156, 0.2281, 0.9798]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[-0.0378],\n",
            "        [ 1.3028]])\n",
            "[self.weight.data[:,:,2,2].view(2,)[i] for i in range(2)] = \n",
            "-0.03782135993242264\n",
            "\n",
            "produto.shape: torch.Size([2, 8, 8]) produto: tensor([[[-4.7485e-04, -3.0470e-02, -2.6763e-02, -4.3208e-04, -2.7684e-02,\n",
            "          -1.7120e-02, -7.3945e-03, -2.5524e-02],\n",
            "         [-2.0310e-02, -3.3399e-02, -2.1013e-03, -3.7201e-02, -3.4876e-02,\n",
            "          -3.6106e-02, -1.7682e-02, -2.2457e-02],\n",
            "         [-2.6027e-02, -2.9083e-02, -5.8540e-03, -3.6220e-02, -3.3635e-02,\n",
            "          -9.4982e-03, -1.8000e-02, -4.6410e-03],\n",
            "         [-6.9169e-03, -3.0294e-02, -2.7816e-02, -1.9508e-02, -1.0930e-02,\n",
            "          -1.8711e-02, -3.6321e-02, -3.0431e-02],\n",
            "         [-9.8867e-03, -1.1365e-02, -3.3516e-02, -3.0817e-02, -9.7947e-03,\n",
            "          -3.0942e-02, -2.9934e-02, -3.5043e-03],\n",
            "         [-3.1837e-02, -1.4326e-02, -1.9237e-02, -1.9490e-02, -1.1784e-02,\n",
            "          -2.6894e-02, -3.5198e-03, -3.7667e-02],\n",
            "         [-2.2232e-02, -2.3469e-02, -1.4315e-02, -3.2516e-02, -4.7339e-03,\n",
            "          -3.2229e-02, -2.4487e-02, -1.6908e-02],\n",
            "         [-3.0728e-02, -1.3665e-03, -1.8224e-02, -1.3286e-02, -3.4010e-02,\n",
            "          -1.1936e-02, -8.6253e-03, -3.7057e-02]],\n",
            "\n",
            "        [[ 1.6357e-02,  1.0496e+00,  9.2193e-01,  1.4884e-02,  9.5363e-01,\n",
            "           5.8975e-01,  2.5472e-01,  8.7924e-01],\n",
            "         [ 6.9964e-01,  1.1505e+00,  7.2386e-02,  1.2815e+00,  1.2014e+00,\n",
            "           1.2437e+00,  6.0911e-01,  7.7359e-01],\n",
            "         [ 8.9655e-01,  1.0018e+00,  2.0166e-01,  1.2477e+00,  1.1586e+00,\n",
            "           3.2719e-01,  6.2005e-01,  1.5987e-01],\n",
            "         [ 2.3827e-01,  1.0436e+00,  9.5820e-01,  6.7202e-01,  3.7652e-01,\n",
            "           6.4454e-01,  1.2512e+00,  1.0483e+00],\n",
            "         [ 3.4057e-01,  3.9148e-01,  1.1545e+00,  1.0616e+00,  3.3740e-01,\n",
            "           1.0659e+00,  1.0311e+00,  1.2071e-01],\n",
            "         [ 1.0967e+00,  4.9350e-01,  6.6268e-01,  6.7138e-01,  4.0592e-01,\n",
            "           9.2643e-01,  1.2125e-01,  1.2975e+00],\n",
            "         [ 7.6583e-01,  8.0844e-01,  4.9312e-01,  1.1201e+00,  1.6307e-01,\n",
            "           1.1102e+00,  8.4350e-01,  5.8245e-01],\n",
            "         [ 1.0585e+00,  4.7072e-02,  6.2778e-01,  4.5768e-01,  1.1716e+00,\n",
            "           4.1116e-01,  2.9712e-01,  1.2765e+00]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([8, 8])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[-0.0908, -0.1844, -0.2207, -0.1692, -0.1026, -0.1081, -0.0876, -0.0048],\n",
            "        [-0.1179, -0.1724, -0.1189, -0.1039, -0.1220, -0.0973, -0.1773, -0.1070],\n",
            "        [-0.1318, -0.0724, -0.2073, -0.0986, -0.1045, -0.0856, -0.0815, -0.0989],\n",
            "        [-0.0863, -0.0979, -0.1536, -0.1525, -0.1374, -0.1523, -0.0710, -0.1040],\n",
            "        [-0.0669, -0.1649, -0.0457, -0.0075, -0.1517, -0.1029, -0.0190, -0.0094],\n",
            "        [-0.0672, -0.1866, -0.1138,  0.0171, -0.0410, -0.0641, -0.1638, -0.1557],\n",
            "        [-0.1284, -0.1308, -0.1968, -0.1240, -0.2129, -0.0966, -0.0903, -0.2452],\n",
            "        [-0.1952, -0.0958, -0.0741, -0.0427, -0.1293, -0.1837, -0.0412, -0.0637]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 2, 3\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([8, 8]) por self.weight.data[:,:,2,3].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[0.7341, 0.1459, 0.5112, 0.4702, 0.5183, 0.2251, 0.9153, 0.1166],\n",
            "        [0.8443, 0.1861, 0.7868, 0.1444, 0.9043, 0.8339, 0.1163, 0.1594],\n",
            "        [0.4900, 0.7674, 0.5201, 0.1226, 0.7444, 0.9308, 0.5104, 0.9587],\n",
            "        [0.2956, 0.8044, 0.6248, 0.6000, 0.9078, 0.1836, 0.6861, 0.2621],\n",
            "        [0.5325, 0.9657, 0.6483, 0.1575, 0.7162, 0.8286, 0.1387, 0.7759],\n",
            "        [0.5438, 0.5291, 0.2669, 0.5047, 0.5315, 0.1939, 0.7101, 0.6785],\n",
            "        [0.1842, 0.8014, 0.4034, 0.4570, 0.6568, 0.0871, 0.2642, 0.5900],\n",
            "        [0.3208, 0.3112, 0.5912, 0.8600, 0.7952, 0.8078, 0.7708, 0.0083]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[-0.1679],\n",
            "        [ 1.0332]])\n",
            "[self.weight.data[:,:,2,3].view(2,)[i] for i in range(2)] = \n",
            "-0.1679040640592575\n",
            "\n",
            "produto.shape: torch.Size([2, 8, 8]) produto: tensor([[[-0.1233, -0.0245, -0.0858, -0.0789, -0.0870, -0.0378, -0.1537,\n",
            "          -0.0196],\n",
            "         [-0.1418, -0.0312, -0.1321, -0.0242, -0.1518, -0.1400, -0.0195,\n",
            "          -0.0268],\n",
            "         [-0.0823, -0.1289, -0.0873, -0.0206, -0.1250, -0.1563, -0.0857,\n",
            "          -0.1610],\n",
            "         [-0.0496, -0.1351, -0.1049, -0.1007, -0.1524, -0.0308, -0.1152,\n",
            "          -0.0440],\n",
            "         [-0.0894, -0.1621, -0.1089, -0.0264, -0.1203, -0.1391, -0.0233,\n",
            "          -0.1303],\n",
            "         [-0.0913, -0.0888, -0.0448, -0.0847, -0.0892, -0.0326, -0.1192,\n",
            "          -0.1139],\n",
            "         [-0.0309, -0.1346, -0.0677, -0.0767, -0.1103, -0.0146, -0.0444,\n",
            "          -0.0991],\n",
            "         [-0.0539, -0.0522, -0.0993, -0.1444, -0.1335, -0.1356, -0.1294,\n",
            "          -0.0014]],\n",
            "\n",
            "        [[ 0.7585,  0.1508,  0.5282,  0.4858,  0.5355,  0.2326,  0.9457,\n",
            "           0.1204],\n",
            "         [ 0.8724,  0.1922,  0.8130,  0.1492,  0.9343,  0.8616,  0.1202,\n",
            "           0.1647],\n",
            "         [ 0.5062,  0.7929,  0.5374,  0.1267,  0.7691,  0.9617,  0.5273,\n",
            "           0.9906],\n",
            "         [ 0.3054,  0.8311,  0.6456,  0.6199,  0.9380,  0.1896,  0.7089,\n",
            "           0.2708],\n",
            "         [ 0.5501,  0.9978,  0.6698,  0.1628,  0.7400,  0.8561,  0.1433,\n",
            "           0.8017],\n",
            "         [ 0.5618,  0.5467,  0.2757,  0.5214,  0.5491,  0.2004,  0.7337,\n",
            "           0.7011],\n",
            "         [ 0.1903,  0.8280,  0.4168,  0.4722,  0.6786,  0.0900,  0.2730,\n",
            "           0.6096],\n",
            "         [ 0.3315,  0.3215,  0.6109,  0.8886,  0.8216,  0.8346,  0.7964,\n",
            "           0.0085]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([8, 8])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[-0.0913, -0.2149, -0.2475, -0.1696, -0.1302, -0.1252, -0.0950, -0.0303],\n",
            "        [-0.1382, -0.2058, -0.1210, -0.1411, -0.1568, -0.1334, -0.1950, -0.1295],\n",
            "        [-0.1579, -0.1015, -0.2132, -0.1348, -0.1381, -0.0951, -0.0995, -0.1035],\n",
            "        [-0.0932, -0.1282, -0.1814, -0.1720, -0.1484, -0.1710, -0.1073, -0.1344],\n",
            "        [-0.0768, -0.1762, -0.0792, -0.0384, -0.1614, -0.1338, -0.0490, -0.0129],\n",
            "        [-0.0990, -0.2009, -0.1331, -0.0024, -0.0528, -0.0909, -0.1673, -0.1933],\n",
            "        [-0.1506, -0.1543, -0.2111, -0.1565, -0.2177, -0.1289, -0.1148, -0.2622],\n",
            "        [-0.2260, -0.0972, -0.0923, -0.0560, -0.1634, -0.1956, -0.0498, -0.1007]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 2, 4\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([8, 8]) por self.weight.data[:,:,2,4].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[0.9389, 0.0969, 0.7050, 0.8526, 0.5983, 0.3111, 0.7751, 0.8858],\n",
            "        [0.6937, 0.5422, 0.6042, 0.9010, 0.5713, 0.8730, 0.4938, 0.2132],\n",
            "        [0.0164, 0.4058, 0.8773, 0.2742, 0.8095, 0.0890, 0.5840, 0.9914],\n",
            "        [0.8646, 0.0733, 0.1638, 0.2299, 0.4596, 0.2010, 0.4209, 0.0638],\n",
            "        [0.9981, 0.8973, 0.2746, 0.2087, 0.5689, 0.5292, 0.0221, 0.9598],\n",
            "        [0.2486, 0.7095, 0.5242, 0.7175, 0.5021, 0.1091, 0.8978, 0.3981],\n",
            "        [0.1508, 0.3660, 0.0322, 0.0412, 0.0195, 0.4829, 0.1753, 0.4111],\n",
            "        [0.5582, 0.4533, 0.5274, 0.3362, 0.4890, 0.5055, 0.5385, 0.6219]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[-0.1590],\n",
            "        [ 0.7636]])\n",
            "[self.weight.data[:,:,2,4].view(2,)[i] for i in range(2)] = \n",
            "-0.15897424519062042\n",
            "\n",
            "produto.shape: torch.Size([2, 8, 8]) produto: tensor([[[-0.1493, -0.0154, -0.1121, -0.1355, -0.0951, -0.0494, -0.1232,\n",
            "          -0.1408],\n",
            "         [-0.1103, -0.0862, -0.0961, -0.1432, -0.0908, -0.1388, -0.0785,\n",
            "          -0.0339],\n",
            "         [-0.0026, -0.0645, -0.1395, -0.0436, -0.1287, -0.0141, -0.0928,\n",
            "          -0.1576],\n",
            "         [-0.1374, -0.0116, -0.0260, -0.0365, -0.0731, -0.0320, -0.0669,\n",
            "          -0.0101],\n",
            "         [-0.1587, -0.1426, -0.0437, -0.0332, -0.0904, -0.0841, -0.0035,\n",
            "          -0.1526],\n",
            "         [-0.0395, -0.1128, -0.0833, -0.1141, -0.0798, -0.0173, -0.1427,\n",
            "          -0.0633],\n",
            "         [-0.0240, -0.0582, -0.0051, -0.0065, -0.0031, -0.0768, -0.0279,\n",
            "          -0.0654],\n",
            "         [-0.0887, -0.0721, -0.0838, -0.0534, -0.0777, -0.0804, -0.0856,\n",
            "          -0.0989]],\n",
            "\n",
            "        [[ 0.7170,  0.0740,  0.5383,  0.6511,  0.4569,  0.2375,  0.5919,\n",
            "           0.6764],\n",
            "         [ 0.5297,  0.4140,  0.4614,  0.6880,  0.4363,  0.6667,  0.3771,\n",
            "           0.1628],\n",
            "         [ 0.0125,  0.3099,  0.6699,  0.2094,  0.6182,  0.0679,  0.4460,\n",
            "           0.7571],\n",
            "         [ 0.6602,  0.0560,  0.1251,  0.1755,  0.3510,  0.1535,  0.3214,\n",
            "           0.0487],\n",
            "         [ 0.7622,  0.6852,  0.2097,  0.1594,  0.4344,  0.4041,  0.0169,\n",
            "           0.7329],\n",
            "         [ 0.1899,  0.5418,  0.4003,  0.5479,  0.3834,  0.0833,  0.6856,\n",
            "           0.3040],\n",
            "         [ 0.1152,  0.2795,  0.0246,  0.0315,  0.0149,  0.3688,  0.1339,\n",
            "           0.3139],\n",
            "         [ 0.4263,  0.3461,  0.4028,  0.2567,  0.3734,  0.3860,  0.4113,\n",
            "           0.4749]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([8, 8])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[-0.2145, -0.2394, -0.3333, -0.2485, -0.2173, -0.1630, -0.2487, -0.0499],\n",
            "        [-0.2800, -0.2371, -0.2531, -0.1653, -0.3087, -0.2735, -0.2145, -0.1563],\n",
            "        [-0.2401, -0.2303, -0.3005, -0.1554, -0.2631, -0.2514, -0.1852, -0.2645],\n",
            "        [-0.1428, -0.2633, -0.2863, -0.2728, -0.3008, -0.2018, -0.2225, -0.1784],\n",
            "        [-0.1662, -0.3384, -0.1881, -0.0648, -0.2817, -0.2729, -0.0722, -0.1432],\n",
            "        [-0.1903, -0.2897, -0.1779, -0.0872, -0.1420, -0.1235, -0.2865, -0.3073],\n",
            "        [-0.1815, -0.2889, -0.2788, -0.2332, -0.3279, -0.1435, -0.1592, -0.3612],\n",
            "        [-0.2798, -0.1494, -0.1916, -0.2004, -0.2969, -0.3313, -0.1793, -0.1021]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 3, 0\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([8, 8]) por self.weight.data[:,:,3,0].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[0.3033, 0.8363, 0.8809, 0.2185, 0.5374, 0.4979, 0.7577, 0.5585],\n",
            "        [0.9355, 0.5201, 0.1142, 0.7579, 0.0757, 0.9024, 0.6591, 0.6166],\n",
            "        [0.2337, 0.7945, 0.7815, 0.7582, 0.3630, 0.2974, 0.8916, 0.2377],\n",
            "        [0.3051, 0.6647, 0.9357, 0.8323, 0.6226, 0.8751, 0.5583, 0.9049],\n",
            "        [0.1427, 0.3552, 0.4564, 0.1203, 0.1928, 0.1197, 0.1098, 0.0574],\n",
            "        [0.5577, 0.7872, 0.5302, 0.3473, 0.5344, 0.5773, 0.9941, 0.2103],\n",
            "        [0.7006, 0.0994, 0.9808, 0.7961, 0.0319, 0.8552, 0.4344, 0.6829],\n",
            "        [0.4508, 0.2096, 0.1036, 0.2849, 0.7376, 0.4548, 0.6635, 0.4857]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[0.2313],\n",
            "        [0.3793]])\n",
            "[self.weight.data[:,:,3,0].view(2,)[i] for i in range(2)] = \n",
            "0.2313005030155182\n",
            "\n",
            "produto.shape: torch.Size([2, 8, 8]) produto: tensor([[[0.0702, 0.1934, 0.2038, 0.0505, 0.1243, 0.1152, 0.1753, 0.1292],\n",
            "         [0.2164, 0.1203, 0.0264, 0.1753, 0.0175, 0.2087, 0.1525, 0.1426],\n",
            "         [0.0540, 0.1838, 0.1808, 0.1754, 0.0840, 0.0688, 0.2062, 0.0550],\n",
            "         [0.0706, 0.1538, 0.2164, 0.1925, 0.1440, 0.2024, 0.1291, 0.2093],\n",
            "         [0.0330, 0.0822, 0.1056, 0.0278, 0.0446, 0.0277, 0.0254, 0.0133],\n",
            "         [0.1290, 0.1821, 0.1226, 0.0803, 0.1236, 0.1335, 0.2299, 0.0486],\n",
            "         [0.1621, 0.0230, 0.2269, 0.1841, 0.0074, 0.1978, 0.1005, 0.1580],\n",
            "         [0.1043, 0.0485, 0.0240, 0.0659, 0.1706, 0.1052, 0.1535, 0.1123]],\n",
            "\n",
            "        [[0.1151, 0.3172, 0.3342, 0.0829, 0.2039, 0.1889, 0.2874, 0.2119],\n",
            "         [0.3549, 0.1973, 0.0433, 0.2875, 0.0287, 0.3423, 0.2500, 0.2339],\n",
            "         [0.0886, 0.3014, 0.2965, 0.2876, 0.1377, 0.1128, 0.3382, 0.0902],\n",
            "         [0.1157, 0.2522, 0.3549, 0.3157, 0.2362, 0.3319, 0.2118, 0.3432],\n",
            "         [0.0541, 0.1348, 0.1731, 0.0456, 0.0731, 0.0454, 0.0416, 0.0218],\n",
            "         [0.2116, 0.2986, 0.2011, 0.1317, 0.2027, 0.2190, 0.3771, 0.0798],\n",
            "         [0.2658, 0.0377, 0.3720, 0.3020, 0.0121, 0.3244, 0.1648, 0.2590],\n",
            "         [0.1710, 0.0795, 0.0393, 0.1081, 0.2798, 0.1725, 0.2517, 0.1842]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([8, 8])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[-0.3638, -0.2548, -0.4454, -0.3841, -0.3124, -0.2124, -0.3719, -0.1907],\n",
            "        [-0.3902, -0.3232, -0.3492, -0.3086, -0.3995, -0.4123, -0.2930, -0.1902],\n",
            "        [-0.2427, -0.2948, -0.4400, -0.1990, -0.3918, -0.2655, -0.2780, -0.4221],\n",
            "        [-0.2803, -0.2749, -0.3124, -0.3093, -0.3739, -0.2338, -0.2894, -0.1886],\n",
            "        [-0.3249, -0.4810, -0.2317, -0.0980, -0.3721, -0.3571, -0.0758, -0.2957],\n",
            "        [-0.2298, -0.4025, -0.2612, -0.2012, -0.2218, -0.1408, -0.4293, -0.3705],\n",
            "        [-0.2055, -0.3471, -0.2839, -0.2397, -0.3310, -0.2202, -0.1870, -0.4266],\n",
            "        [-0.3686, -0.2215, -0.2754, -0.2538, -0.3746, -0.4116, -0.2649, -0.2010]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 3, 1\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([8, 8]) por self.weight.data[:,:,3,1].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[0.6060, 0.9010, 0.1084, 0.3834, 0.9551, 0.8549, 0.4536, 0.1170],\n",
            "        [0.5855, 0.8118, 0.3338, 0.8533, 0.0131, 0.1123, 0.1735, 0.3608],\n",
            "        [0.9794, 0.6613, 0.5085, 0.6569, 0.0578, 0.2275, 0.0532, 0.4616],\n",
            "        [0.8070, 0.9296, 0.2616, 0.2410, 0.4902, 0.2943, 0.9096, 0.8048],\n",
            "        [0.4906, 0.2576, 0.4009, 0.8265, 0.0263, 0.7091, 0.6353, 0.6951],\n",
            "        [0.3350, 0.3279, 0.3608, 0.2165, 0.2346, 0.7870, 0.3705, 0.9562],\n",
            "        [0.9619, 0.6232, 0.9848, 0.7276, 0.3020, 0.2297, 0.8401, 0.4696],\n",
            "        [0.9062, 0.4673, 0.5142, 0.1029, 0.4695, 0.5098, 0.1461, 0.1711]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[0.2698],\n",
            "        [1.1530]])\n",
            "[self.weight.data[:,:,3,1].view(2,)[i] for i in range(2)] = \n",
            "0.26980727910995483\n",
            "\n",
            "produto.shape: torch.Size([2, 8, 8]) produto: tensor([[[0.1635, 0.2431, 0.0292, 0.1034, 0.2577, 0.2307, 0.1224, 0.0316],\n",
            "         [0.1580, 0.2190, 0.0901, 0.2302, 0.0035, 0.0303, 0.0468, 0.0973],\n",
            "         [0.2643, 0.1784, 0.1372, 0.1772, 0.0156, 0.0614, 0.0143, 0.1245],\n",
            "         [0.2177, 0.2508, 0.0706, 0.0650, 0.1323, 0.0794, 0.2454, 0.2171],\n",
            "         [0.1324, 0.0695, 0.1082, 0.2230, 0.0071, 0.1913, 0.1714, 0.1875],\n",
            "         [0.0904, 0.0885, 0.0973, 0.0584, 0.0633, 0.2124, 0.1000, 0.2580],\n",
            "         [0.2595, 0.1681, 0.2657, 0.1963, 0.0815, 0.0620, 0.2267, 0.1267],\n",
            "         [0.2445, 0.1261, 0.1387, 0.0278, 0.1267, 0.1375, 0.0394, 0.0462]],\n",
            "\n",
            "        [[0.6987, 1.0388, 0.1250, 0.4421, 1.1012, 0.9857, 0.5230, 0.1348],\n",
            "         [0.6751, 0.9360, 0.3848, 0.9838, 0.0151, 0.1295, 0.2001, 0.4160],\n",
            "         [1.1293, 0.7625, 0.5863, 0.7574, 0.0667, 0.2623, 0.0613, 0.5322],\n",
            "         [0.9305, 1.0718, 0.3016, 0.2778, 0.5652, 0.3394, 1.0487, 0.9280],\n",
            "         [0.5656, 0.2971, 0.4622, 0.9530, 0.0303, 0.8176, 0.7324, 0.8014],\n",
            "         [0.3862, 0.3781, 0.4160, 0.2496, 0.2705, 0.9075, 0.4271, 1.1025],\n",
            "         [1.1091, 0.7185, 1.1354, 0.8389, 0.3482, 0.2649, 0.9686, 0.5414],\n",
            "         [1.0449, 0.5388, 0.5928, 0.1187, 0.5414, 0.5878, 0.1684, 0.1973]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([8, 8])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[-0.2936, -0.0613, -0.2417, -0.3336, -0.1881, -0.0973, -0.1967, -0.0615],\n",
            "        [-0.1739, -0.2030, -0.3228, -0.1333, -0.3820, -0.2035, -0.1405, -0.0475],\n",
            "        [-0.1887, -0.1111, -0.2592, -0.0236, -0.3078, -0.1967, -0.0718, -0.3671],\n",
            "        [-0.2097, -0.1212, -0.0960, -0.1168, -0.2299, -0.0314, -0.1603,  0.0207],\n",
            "        [-0.2919, -0.3988, -0.1262, -0.0702, -0.3275, -0.3294, -0.0504, -0.2824],\n",
            "        [-0.1008, -0.2205, -0.1386, -0.1209, -0.0982, -0.0073, -0.1993, -0.3219],\n",
            "        [-0.0434, -0.3241, -0.0571, -0.0556, -0.3237, -0.0224, -0.0866, -0.2686],\n",
            "        [-0.2643, -0.1730, -0.2515, -0.1880, -0.2040, -0.3064, -0.1114, -0.0886]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 3, 2\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([8, 8]) por self.weight.data[:,:,3,2].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[0.9882, 0.3950, 0.5432, 0.3720, 0.7475, 0.2438, 0.4130, 0.5578],\n",
            "        [0.4695, 0.0585, 0.2122, 0.0149, 0.6886, 0.2685, 0.9247, 0.5325],\n",
            "        [0.7788, 0.4502, 0.3176, 0.3704, 0.3629, 0.0484, 0.9964, 0.9079],\n",
            "        [0.9271, 0.3848, 0.4344, 0.8815, 0.9279, 0.5485, 0.7810, 0.0649],\n",
            "        [0.4970, 0.7346, 0.8474, 0.9441, 0.5696, 0.1012, 0.3719, 0.6766],\n",
            "        [0.4620, 0.1213, 0.2668, 0.9389, 0.8188, 0.8855, 0.5148, 0.6591],\n",
            "        [0.1965, 0.5908, 0.7145, 0.4627, 0.0755, 0.1057, 0.7186, 0.0429],\n",
            "        [0.2921, 0.4389, 0.7655, 0.1462, 0.8627, 0.9156, 0.5924, 0.9303]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[0.2648],\n",
            "        [1.3851]])\n",
            "[self.weight.data[:,:,3,2].view(2,)[i] for i in range(2)] = \n",
            "0.2648315131664276\n",
            "\n",
            "produto.shape: torch.Size([2, 8, 8]) produto: tensor([[[0.2617, 0.1046, 0.1439, 0.0985, 0.1980, 0.0646, 0.1094, 0.1477],\n",
            "         [0.1243, 0.0155, 0.0562, 0.0039, 0.1824, 0.0711, 0.2449, 0.1410],\n",
            "         [0.2063, 0.1192, 0.0841, 0.0981, 0.0961, 0.0128, 0.2639, 0.2404],\n",
            "         [0.2455, 0.1019, 0.1150, 0.2335, 0.2457, 0.1453, 0.2068, 0.0172],\n",
            "         [0.1316, 0.1945, 0.2244, 0.2500, 0.1508, 0.0268, 0.0985, 0.1792],\n",
            "         [0.1224, 0.0321, 0.0707, 0.2486, 0.2168, 0.2345, 0.1363, 0.1746],\n",
            "         [0.0520, 0.1565, 0.1892, 0.1225, 0.0200, 0.0280, 0.1903, 0.0114],\n",
            "         [0.0774, 0.1162, 0.2027, 0.0387, 0.2285, 0.2425, 0.1569, 0.2464]],\n",
            "\n",
            "        [[1.3688, 0.5471, 0.7525, 0.5152, 1.0354, 0.3377, 0.5720, 0.7726],\n",
            "         [0.6503, 0.0810, 0.2940, 0.0206, 0.9538, 0.3719, 1.2809, 0.7375],\n",
            "         [1.0788, 0.6236, 0.4400, 0.5131, 0.5027, 0.0670, 1.3801, 1.2575],\n",
            "         [1.2842, 0.5330, 0.6017, 1.2210, 1.2853, 0.7597, 1.0817, 0.0899],\n",
            "         [0.6884, 1.0175, 1.1737, 1.3076, 0.7889, 0.1402, 0.5151, 0.9372],\n",
            "         [0.6400, 0.1680, 0.3696, 1.3005, 1.1341, 1.2265, 0.7131, 0.9130],\n",
            "         [0.2721, 0.8183, 0.9897, 0.6409, 0.1046, 0.1465, 0.9954, 0.0594],\n",
            "         [0.4046, 0.6079, 1.0603, 0.2025, 1.1949, 1.2681, 0.8205, 1.2886]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([8, 8])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[-0.1301,  0.1817, -0.2124, -0.2301,  0.0696,  0.1334, -0.0743, -0.0300],\n",
            "        [-0.0159,  0.0161, -0.2327,  0.0970, -0.3785, -0.1732, -0.0937,  0.0498],\n",
            "        [ 0.0756,  0.0674, -0.1220,  0.1536, -0.2922, -0.1353, -0.0575, -0.2426],\n",
            "        [ 0.0080,  0.1297, -0.0254, -0.0518, -0.0976,  0.0480,  0.0851,  0.2379],\n",
            "        [-0.1595, -0.3293, -0.0180,  0.1528, -0.3205, -0.1381,  0.1210, -0.0949],\n",
            "        [-0.0105, -0.1320, -0.0412, -0.0625, -0.0349,  0.2050, -0.0994, -0.0639],\n",
            "        [ 0.2161, -0.1559,  0.2086,  0.1407, -0.2422,  0.0395,  0.1401, -0.1419],\n",
            "        [-0.0198, -0.0469, -0.1127, -0.1602, -0.0773, -0.1689, -0.0720, -0.0425]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 3, 3\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([8, 8]) por self.weight.data[:,:,3,3].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[0.8363, 0.8809, 0.2185, 0.5374, 0.4979, 0.7577, 0.5585, 0.6681],\n",
            "        [0.5201, 0.1142, 0.7579, 0.0757, 0.9024, 0.6591, 0.6166, 0.6559],\n",
            "        [0.7945, 0.7815, 0.7582, 0.3630, 0.2974, 0.8916, 0.2377, 0.6650],\n",
            "        [0.6647, 0.9357, 0.8323, 0.6226, 0.8751, 0.5583, 0.9049, 0.8322],\n",
            "        [0.3552, 0.4564, 0.1203, 0.1928, 0.1197, 0.1098, 0.0574, 0.5674],\n",
            "        [0.7872, 0.5302, 0.3473, 0.5344, 0.5773, 0.9941, 0.2103, 0.4172],\n",
            "        [0.0994, 0.9808, 0.7961, 0.0319, 0.8552, 0.4344, 0.6829, 0.2037],\n",
            "        [0.2096, 0.1036, 0.2849, 0.7376, 0.4548, 0.6635, 0.4857, 0.7285]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[0.1012],\n",
            "        [1.1669]])\n",
            "[self.weight.data[:,:,3,3].view(2,)[i] for i in range(2)] = \n",
            "0.10117228329181671\n",
            "\n",
            "produto.shape: torch.Size([2, 8, 8]) produto: tensor([[[0.0846, 0.0891, 0.0221, 0.0544, 0.0504, 0.0767, 0.0565, 0.0676],\n",
            "         [0.0526, 0.0116, 0.0767, 0.0077, 0.0913, 0.0667, 0.0624, 0.0664],\n",
            "         [0.0804, 0.0791, 0.0767, 0.0367, 0.0301, 0.0902, 0.0241, 0.0673],\n",
            "         [0.0673, 0.0947, 0.0842, 0.0630, 0.0885, 0.0565, 0.0915, 0.0842],\n",
            "         [0.0359, 0.0462, 0.0122, 0.0195, 0.0121, 0.0111, 0.0058, 0.0574],\n",
            "         [0.0796, 0.0536, 0.0351, 0.0541, 0.0584, 0.1006, 0.0213, 0.0422],\n",
            "         [0.0101, 0.0992, 0.0805, 0.0032, 0.0865, 0.0440, 0.0691, 0.0206],\n",
            "         [0.0212, 0.0105, 0.0288, 0.0746, 0.0460, 0.0671, 0.0491, 0.0737]],\n",
            "\n",
            "        [[0.9759, 1.0279, 0.2549, 0.6271, 0.5810, 0.8841, 0.6517, 0.7796],\n",
            "         [0.6069, 0.1333, 0.8844, 0.0883, 1.0530, 0.7691, 0.7195, 0.7653],\n",
            "         [0.9270, 0.9120, 0.8847, 0.4235, 0.3471, 1.0404, 0.2774, 0.7759],\n",
            "         [0.7757, 1.0919, 0.9712, 0.7264, 1.0211, 0.6514, 1.0559, 0.9711],\n",
            "         [0.4145, 0.5326, 0.1404, 0.2250, 0.1397, 0.1281, 0.0670, 0.6621],\n",
            "         [0.9186, 0.6187, 0.4052, 0.6236, 0.6737, 1.1600, 0.2454, 0.4868],\n",
            "         [0.1160, 1.1445, 0.9290, 0.0372, 0.9979, 0.5069, 0.7969, 0.2376],\n",
            "         [0.2446, 0.1209, 0.3324, 0.8607, 0.5307, 0.7743, 0.5668, 0.8500]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([8, 8])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[ 0.1316,  0.2864, -0.0685, -0.1316,  0.2676,  0.1979,  0.0351,  0.1177],\n",
            "        [ 0.1084,  0.0316, -0.1765,  0.1009, -0.1961, -0.1021,  0.1512,  0.1908],\n",
            "        [ 0.2818,  0.1866, -0.0379,  0.2517, -0.1961, -0.1225,  0.2064, -0.0021],\n",
            "        [ 0.2536,  0.2316,  0.0897,  0.1817,  0.1481,  0.1933,  0.2919,  0.2551],\n",
            "        [-0.0279, -0.1348,  0.2064,  0.4029, -0.1696, -0.1113,  0.2195,  0.0843],\n",
            "        [ 0.1119, -0.0999,  0.0294,  0.1862,  0.1819,  0.4395,  0.0370,  0.1106],\n",
            "        [ 0.2681,  0.0006,  0.3978,  0.2632, -0.2222,  0.0675,  0.3304, -0.1306],\n",
            "        [ 0.0576,  0.0693,  0.0900, -0.1215,  0.1512,  0.0736,  0.0849,  0.2039]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 3, 4\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([8, 8]) por self.weight.data[:,:,3,4].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[0.9010, 0.1084, 0.3834, 0.9551, 0.8549, 0.4536, 0.1170, 0.9275],\n",
            "        [0.8118, 0.3338, 0.8533, 0.0131, 0.1123, 0.1735, 0.3608, 0.3232],\n",
            "        [0.6613, 0.5085, 0.6569, 0.0578, 0.2275, 0.0532, 0.4616, 0.3573],\n",
            "        [0.9296, 0.2616, 0.2410, 0.4902, 0.2943, 0.9096, 0.8048, 0.3672],\n",
            "        [0.2576, 0.4009, 0.8265, 0.0263, 0.7091, 0.6353, 0.6951, 0.8267],\n",
            "        [0.3279, 0.3608, 0.2165, 0.2346, 0.7870, 0.3705, 0.9562, 0.6253],\n",
            "        [0.6232, 0.9848, 0.7276, 0.3020, 0.2297, 0.8401, 0.4696, 0.0771],\n",
            "        [0.4673, 0.5142, 0.1029, 0.4695, 0.5098, 0.1461, 0.1711, 0.2891]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[0.0215],\n",
            "        [0.7618]])\n",
            "[self.weight.data[:,:,3,4].view(2,)[i] for i in range(2)] = \n",
            "0.021521691232919693\n",
            "\n",
            "produto.shape: torch.Size([2, 8, 8]) produto: tensor([[[1.9391e-02, 2.3326e-03, 8.2513e-03, 2.0555e-02, 1.8399e-02,\n",
            "          9.7630e-03, 2.5170e-03, 1.9961e-02],\n",
            "         [1.7471e-02, 7.1832e-03, 1.8364e-02, 2.8174e-04, 2.4175e-03,\n",
            "          3.7342e-03, 7.7652e-03, 6.9557e-03],\n",
            "         [1.4232e-02, 1.0944e-02, 1.4138e-02, 1.2446e-03, 4.8957e-03,\n",
            "          1.1440e-03, 9.9337e-03, 7.6886e-03],\n",
            "         [2.0006e-02, 5.6298e-03, 5.1857e-03, 1.0550e-02, 6.3349e-03,\n",
            "          1.9575e-02, 1.7321e-02, 7.9033e-03],\n",
            "         [5.5448e-03, 8.6282e-03, 1.7788e-02, 5.6496e-04, 1.5261e-02,\n",
            "          1.3672e-02, 1.4960e-02, 1.7792e-02],\n",
            "         [7.0568e-03, 7.7643e-03, 4.6598e-03, 5.0497e-03, 1.6939e-02,\n",
            "          7.9727e-03, 2.0579e-02, 1.3457e-02],\n",
            "         [1.3412e-02, 2.1194e-02, 1.5659e-02, 6.4986e-03, 4.9444e-03,\n",
            "          1.8080e-02, 1.0106e-02, 1.6600e-03],\n",
            "         [1.0058e-02, 1.1066e-02, 2.2150e-03, 1.0105e-02, 1.0971e-02,\n",
            "          3.1437e-03, 3.6823e-03, 6.2218e-03]],\n",
            "\n",
            "        [[6.8642e-01, 8.2572e-02, 2.9209e-01, 7.2762e-01, 6.5132e-01,\n",
            "          3.4560e-01, 8.9099e-02, 7.0659e-01],\n",
            "         [6.1845e-01, 2.5428e-01, 6.5008e-01, 9.9734e-03, 8.5578e-02,\n",
            "          1.3219e-01, 2.7488e-01, 2.4622e-01],\n",
            "         [5.0381e-01, 3.8741e-01, 5.0046e-01, 4.4058e-02, 1.7330e-01,\n",
            "          4.0495e-02, 3.5164e-01, 2.7217e-01],\n",
            "         [7.0820e-01, 1.9929e-01, 1.8357e-01, 3.7346e-01, 2.2425e-01,\n",
            "          6.9295e-01, 6.1315e-01, 2.7977e-01],\n",
            "         [1.9628e-01, 3.0543e-01, 6.2968e-01, 1.9999e-02, 5.4021e-01,\n",
            "          4.8397e-01, 5.2956e-01, 6.2984e-01],\n",
            "         [2.4980e-01, 2.7485e-01, 1.6495e-01, 1.7876e-01, 5.9961e-01,\n",
            "          2.8223e-01, 7.2847e-01, 4.7638e-01],\n",
            "         [4.7478e-01, 7.5024e-01, 5.5432e-01, 2.3004e-01, 1.7503e-01,\n",
            "          6.4000e-01, 3.5774e-01, 5.8763e-02],\n",
            "         [3.5605e-01, 3.9172e-01, 7.8409e-02, 3.5770e-01, 3.8837e-01,\n",
            "          1.1128e-01, 1.3035e-01, 2.2025e-01]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([8, 8])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[ 0.2162,  0.3755, -0.0464, -0.0772,  0.3180,  0.2746,  0.0916,  0.1853],\n",
            "        [ 0.1611,  0.0431, -0.0998,  0.1086, -0.1048, -0.0354,  0.2135,  0.2572],\n",
            "        [ 0.3622,  0.2657,  0.0388,  0.2885, -0.1660, -0.0323,  0.2304,  0.0651],\n",
            "        [ 0.3208,  0.3262,  0.1739,  0.2447,  0.2367,  0.2498,  0.3835,  0.3392],\n",
            "        [ 0.0081, -0.0886,  0.2186,  0.4224, -0.1575, -0.1002,  0.2253,  0.1417],\n",
            "        [ 0.1915, -0.0462,  0.0646,  0.2402,  0.2403,  0.5401,  0.0582,  0.1529],\n",
            "        [ 0.2782,  0.0998,  0.4784,  0.2665, -0.1357,  0.1115,  0.3995, -0.1100],\n",
            "        [ 0.0788,  0.0798,  0.1188, -0.0468,  0.1972,  0.1407,  0.1340,  0.2776]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 4, 0\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([8, 8]) por self.weight.data[:,:,4,0].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[0.9998, 0.2518, 0.6397, 0.6314, 0.3786, 0.5449, 0.5024, 0.9856],\n",
            "        [0.5091, 0.8210, 0.7056, 0.3894, 0.5185, 0.1364, 0.7969, 0.0882],\n",
            "        [0.9027, 0.4139, 0.4265, 0.6671, 0.9355, 0.6638, 0.3069, 0.6845],\n",
            "        [0.2077, 0.6429, 0.7605, 0.5791, 0.1063, 0.6522, 0.2427, 0.2187],\n",
            "        [0.1189, 0.0552, 0.9920, 0.9323, 0.0651, 0.0324, 0.1132, 0.7797],\n",
            "        [0.7429, 0.5024, 0.6748, 0.5288, 0.0470, 0.7523, 0.2239, 0.1976],\n",
            "        [0.1685, 0.8435, 0.3984, 0.6348, 0.1437, 0.6609, 0.4285, 0.1461],\n",
            "        [0.0697, 0.5835, 0.3506, 0.5407, 0.9819, 0.4350, 0.1740, 0.6352]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[0.3418],\n",
            "        [0.0962]])\n",
            "[self.weight.data[:,:,4,0].view(2,)[i] for i in range(2)] = \n",
            "0.34178605675697327\n",
            "\n",
            "produto.shape: torch.Size([2, 8, 8]) produto: tensor([[[0.3417, 0.0860, 0.2186, 0.2158, 0.1294, 0.1863, 0.1717, 0.3369],\n",
            "         [0.1740, 0.2806, 0.2412, 0.1331, 0.1772, 0.0466, 0.2724, 0.0301],\n",
            "         [0.3085, 0.1415, 0.1458, 0.2280, 0.3197, 0.2269, 0.1049, 0.2339],\n",
            "         [0.0710, 0.2197, 0.2599, 0.1979, 0.0363, 0.2229, 0.0829, 0.0748],\n",
            "         [0.0406, 0.0189, 0.3390, 0.3186, 0.0222, 0.0111, 0.0387, 0.2665],\n",
            "         [0.2539, 0.1717, 0.2306, 0.1807, 0.0161, 0.2571, 0.0765, 0.0675],\n",
            "         [0.0576, 0.2883, 0.1362, 0.2170, 0.0491, 0.2259, 0.1464, 0.0499],\n",
            "         [0.0238, 0.1994, 0.1198, 0.1848, 0.3356, 0.1487, 0.0595, 0.2171]],\n",
            "\n",
            "        [[0.0962, 0.0242, 0.0615, 0.0607, 0.0364, 0.0524, 0.0483, 0.0948],\n",
            "         [0.0490, 0.0790, 0.0679, 0.0375, 0.0499, 0.0131, 0.0767, 0.0085],\n",
            "         [0.0868, 0.0398, 0.0410, 0.0642, 0.0900, 0.0639, 0.0295, 0.0658],\n",
            "         [0.0200, 0.0618, 0.0732, 0.0557, 0.0102, 0.0627, 0.0233, 0.0210],\n",
            "         [0.0114, 0.0053, 0.0954, 0.0897, 0.0063, 0.0031, 0.0109, 0.0750],\n",
            "         [0.0715, 0.0483, 0.0649, 0.0509, 0.0045, 0.0724, 0.0215, 0.0190],\n",
            "         [0.0162, 0.0811, 0.0383, 0.0611, 0.0138, 0.0636, 0.0412, 0.0141],\n",
            "         [0.0067, 0.0561, 0.0337, 0.0520, 0.0945, 0.0418, 0.0167, 0.0611]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([8, 8])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[ 0.2356,  0.3778, -0.0382, -0.0567,  0.3364,  0.2844,  0.0941,  0.2053],\n",
            "        [ 0.1785,  0.0503, -0.0815,  0.1088, -0.1024, -0.0317,  0.2213,  0.2641],\n",
            "        [ 0.3764,  0.2766,  0.0530,  0.2897, -0.1611, -0.0312,  0.2404,  0.0728],\n",
            "        [ 0.3408,  0.3319,  0.1791,  0.2552,  0.2430,  0.2694,  0.4008,  0.3472],\n",
            "        [ 0.0136, -0.0800,  0.2364,  0.4229, -0.1422, -0.0865,  0.2403,  0.1595],\n",
            "        [ 0.1986, -0.0385,  0.0692,  0.2453,  0.2573,  0.5481,  0.0788,  0.1663],\n",
            "        [ 0.2916,  0.1210,  0.4940,  0.2730, -0.1307,  0.1296,  0.4096, -0.1083],\n",
            "        [ 0.0888,  0.0909,  0.1210, -0.0367,  0.2081,  0.1439,  0.1377,  0.2838]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 4, 1\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([8, 8]) por self.weight.data[:,:,4,1].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[0.2855, 0.7204, 0.8954, 0.5028, 0.1661, 0.5490, 0.3445, 0.5757],\n",
            "        [0.5101, 0.3605, 0.1853, 0.7398, 0.5489, 0.6918, 0.0061, 0.6997],\n",
            "        [0.3112, 0.4362, 0.4958, 0.4801, 0.6260, 0.4563, 0.7274, 0.2073],\n",
            "        [0.4474, 0.0369, 0.7823, 0.0204, 0.2062, 0.7905, 0.4570, 0.0657],\n",
            "        [0.9508, 0.4556, 0.4791, 0.1144, 0.3650, 0.0290, 0.2206, 0.4196],\n",
            "        [0.9616, 0.6241, 0.4962, 0.9429, 0.9632, 0.7063, 0.8205, 0.5013],\n",
            "        [0.3713, 0.6818, 0.2316, 0.3449, 0.4895, 0.1076, 0.7065, 0.3353],\n",
            "        [0.6010, 0.5996, 0.4934, 0.5300, 0.4110, 0.1694, 0.1762, 0.2929]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[0.5196],\n",
            "        [0.8732]])\n",
            "[self.weight.data[:,:,4,1].view(2,)[i] for i in range(2)] = \n",
            "0.5196305513381958\n",
            "\n",
            "produto.shape: torch.Size([2, 8, 8]) produto: tensor([[[0.1484, 0.3743, 0.4653, 0.2613, 0.0863, 0.2853, 0.1790, 0.2992],\n",
            "         [0.2651, 0.1873, 0.0963, 0.3844, 0.2852, 0.3595, 0.0032, 0.3636],\n",
            "         [0.1617, 0.2267, 0.2576, 0.2495, 0.3253, 0.2371, 0.3780, 0.1077],\n",
            "         [0.2325, 0.0192, 0.4065, 0.0106, 0.1071, 0.4108, 0.2374, 0.0342],\n",
            "         [0.4941, 0.2367, 0.2490, 0.0595, 0.1896, 0.0151, 0.1146, 0.2180],\n",
            "         [0.4997, 0.3243, 0.2579, 0.4899, 0.5005, 0.3670, 0.4264, 0.2605],\n",
            "         [0.1930, 0.3543, 0.1203, 0.1792, 0.2543, 0.0559, 0.3671, 0.1742],\n",
            "         [0.3123, 0.3116, 0.2564, 0.2754, 0.2136, 0.0880, 0.0916, 0.1522]],\n",
            "\n",
            "        [[0.2493, 0.6290, 0.7818, 0.4390, 0.1450, 0.4793, 0.3008, 0.5027],\n",
            "         [0.4454, 0.3147, 0.1618, 0.6460, 0.4793, 0.6040, 0.0053, 0.6110],\n",
            "         [0.2717, 0.3809, 0.4329, 0.4192, 0.5466, 0.3984, 0.6351, 0.1810],\n",
            "         [0.3906, 0.0322, 0.6830, 0.0178, 0.1800, 0.6902, 0.3990, 0.0574],\n",
            "         [0.8302, 0.3978, 0.4184, 0.0999, 0.3187, 0.0254, 0.1926, 0.3664],\n",
            "         [0.8397, 0.5449, 0.4333, 0.8233, 0.8410, 0.6167, 0.7164, 0.4377],\n",
            "         [0.3242, 0.5953, 0.2022, 0.3011, 0.4274, 0.0939, 0.6169, 0.2928],\n",
            "         [0.5248, 0.5236, 0.4308, 0.4628, 0.3589, 0.1479, 0.1539, 0.2557]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([8, 8])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[ 0.5773,  0.4639,  0.1804,  0.1591,  0.4658,  0.4706,  0.2658,  0.5422],\n",
            "        [ 0.3525,  0.3309,  0.1597,  0.2420,  0.0748,  0.0149,  0.4937,  0.2943],\n",
            "        [ 0.6850,  0.4181,  0.1987,  0.5177,  0.1586,  0.1957,  0.3453,  0.3068],\n",
            "        [ 0.4118,  0.5516,  0.4390,  0.4531,  0.2793,  0.4923,  0.4838,  0.4219],\n",
            "        [ 0.0542, -0.0611,  0.5754,  0.7416, -0.1200, -0.0754,  0.2790,  0.4260],\n",
            "        [ 0.4525,  0.1332,  0.2999,  0.4260,  0.2734,  0.8052,  0.1554,  0.2339],\n",
            "        [ 0.3492,  0.4093,  0.6302,  0.4899, -0.0816,  0.3555,  0.5561, -0.0584],\n",
            "        [ 0.1126,  0.2903,  0.2409,  0.1481,  0.5438,  0.2925,  0.1972,  0.5010]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 4, 2\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([8, 8]) por self.weight.data[:,:,4,2].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[0.9753, 0.6959, 0.2979, 0.1239, 0.7211, 0.3483, 0.6437, 0.2785],\n",
            "        [0.4270, 0.4516, 0.6339, 0.2288, 0.0977, 0.3545, 0.2528, 0.4855],\n",
            "        [0.9167, 0.6996, 0.8463, 0.6904, 0.3534, 0.1091, 0.5164, 0.9727],\n",
            "        [0.5746, 0.5224, 0.7459, 0.8290, 0.5058, 0.4298, 0.6638, 0.7387],\n",
            "        [0.8715, 0.2310, 0.7945, 0.8039, 0.2984, 0.0179, 0.3352, 0.0050],\n",
            "        [0.5214, 0.0379, 0.4761, 0.6435, 0.8049, 0.5488, 0.1264, 0.1121],\n",
            "        [0.9908, 0.8176, 0.7526, 0.8858, 0.9042, 0.5814, 0.7816, 0.9155],\n",
            "        [0.1875, 0.7442, 0.2320, 0.9356, 0.2879, 0.2705, 0.8907, 0.0072]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[0.4717],\n",
            "        [1.1107]])\n",
            "[self.weight.data[:,:,4,2].view(2,)[i] for i in range(2)] = \n",
            "0.471690833568573\n",
            "\n",
            "produto.shape: torch.Size([2, 8, 8]) produto: tensor([[[0.4600, 0.3282, 0.1405, 0.0585, 0.3401, 0.1643, 0.3036, 0.1314],\n",
            "         [0.2014, 0.2130, 0.2990, 0.1079, 0.0461, 0.1672, 0.1193, 0.2290],\n",
            "         [0.4324, 0.3300, 0.3992, 0.3257, 0.1667, 0.0515, 0.2436, 0.4588],\n",
            "         [0.2710, 0.2464, 0.3519, 0.3910, 0.2386, 0.2027, 0.3131, 0.3484],\n",
            "         [0.4111, 0.1090, 0.3748, 0.3792, 0.1407, 0.0085, 0.1581, 0.0023],\n",
            "         [0.2459, 0.0179, 0.2246, 0.3035, 0.3797, 0.2588, 0.0596, 0.0529],\n",
            "         [0.4673, 0.3857, 0.3550, 0.4178, 0.4265, 0.2742, 0.3687, 0.4318],\n",
            "         [0.0884, 0.3510, 0.1094, 0.4413, 0.1358, 0.1276, 0.4201, 0.0034]],\n",
            "\n",
            "        [[1.0833, 0.7729, 0.3309, 0.1377, 0.8009, 0.3869, 0.7149, 0.3094],\n",
            "         [0.4743, 0.5016, 0.7041, 0.2541, 0.1085, 0.3937, 0.2808, 0.5393],\n",
            "         [1.0182, 0.7770, 0.9400, 0.7669, 0.3925, 0.1212, 0.5736, 1.0804],\n",
            "         [0.6383, 0.5802, 0.8285, 0.9208, 0.5619, 0.4774, 0.7374, 0.8205],\n",
            "         [0.9680, 0.2566, 0.8825, 0.8930, 0.3314, 0.0199, 0.3723, 0.0055],\n",
            "         [0.5791, 0.0421, 0.5288, 0.7147, 0.8941, 0.6095, 0.1404, 0.1245],\n",
            "         [1.1005, 0.9082, 0.8360, 0.9838, 1.0044, 0.6458, 0.8682, 1.0169],\n",
            "         [0.2083, 0.8266, 0.2577, 1.0392, 0.3198, 0.3004, 0.9893, 0.0080]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([8, 8])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[ 0.7256,  0.8382,  0.6457,  0.4204,  0.5521,  0.7559,  0.4448,  0.8413],\n",
            "        [ 0.6176,  0.5182,  0.2560,  0.6264,  0.3601,  0.3744,  0.4969,  0.6579],\n",
            "        [ 0.8467,  0.6447,  0.4564,  0.7672,  0.4839,  0.4328,  0.7233,  0.4145],\n",
            "        [ 0.6443,  0.5708,  0.8455,  0.4637,  0.3865,  0.9031,  0.7212,  0.4561],\n",
            "        [ 0.5483,  0.1756,  0.8244,  0.8010,  0.0696, -0.0603,  0.3936,  0.6440],\n",
            "        [ 0.9522,  0.4575,  0.5577,  0.9159,  0.7739,  1.1723,  0.5817,  0.4943],\n",
            "        [ 0.5421,  0.7635,  0.7505,  0.6692,  0.1727,  0.4114,  0.9232,  0.1159],\n",
            "        [ 0.4249,  0.6019,  0.4972,  0.4235,  0.7573,  0.3805,  0.2888,  0.6532]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 4, 3\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([8, 8]) por self.weight.data[:,:,4,3].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[0.2518, 0.6397, 0.6314, 0.3786, 0.5449, 0.5024, 0.9856, 0.1946],\n",
            "        [0.8210, 0.7056, 0.3894, 0.5185, 0.1364, 0.7969, 0.0882, 0.4067],\n",
            "        [0.4139, 0.4265, 0.6671, 0.9355, 0.6638, 0.3069, 0.6845, 0.2913],\n",
            "        [0.6429, 0.7605, 0.5791, 0.1063, 0.6522, 0.2427, 0.2187, 0.1691],\n",
            "        [0.0552, 0.9920, 0.9323, 0.0651, 0.0324, 0.1132, 0.7797, 0.1368],\n",
            "        [0.5024, 0.6748, 0.5288, 0.0470, 0.7523, 0.2239, 0.1976, 0.9536],\n",
            "        [0.8435, 0.3984, 0.6348, 0.1437, 0.6609, 0.4285, 0.1461, 0.1354],\n",
            "        [0.5835, 0.3506, 0.5407, 0.9819, 0.4350, 0.1740, 0.6352, 0.7181]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[0.2054],\n",
            "        [0.2899]])\n",
            "[self.weight.data[:,:,4,3].view(2,)[i] for i in range(2)] = \n",
            "0.20540891587734222\n",
            "\n",
            "produto.shape: torch.Size([2, 8, 8]) produto: tensor([[[0.0517, 0.1314, 0.1297, 0.0778, 0.1119, 0.1032, 0.2024, 0.0400],\n",
            "         [0.1686, 0.1449, 0.0800, 0.1065, 0.0280, 0.1637, 0.0181, 0.0835],\n",
            "         [0.0850, 0.0876, 0.1370, 0.1922, 0.1364, 0.0630, 0.1406, 0.0598],\n",
            "         [0.1321, 0.1562, 0.1189, 0.0218, 0.1340, 0.0498, 0.0449, 0.0347],\n",
            "         [0.0113, 0.2038, 0.1915, 0.0134, 0.0066, 0.0233, 0.1602, 0.0281],\n",
            "         [0.1032, 0.1386, 0.1086, 0.0097, 0.1545, 0.0460, 0.0406, 0.1959],\n",
            "         [0.1733, 0.0818, 0.1304, 0.0295, 0.1357, 0.0880, 0.0300, 0.0278],\n",
            "         [0.1199, 0.0720, 0.1111, 0.2017, 0.0893, 0.0357, 0.1305, 0.1475]],\n",
            "\n",
            "        [[0.0730, 0.1854, 0.1831, 0.1098, 0.1580, 0.1457, 0.2857, 0.0564],\n",
            "         [0.2380, 0.2046, 0.1129, 0.1503, 0.0396, 0.2310, 0.0256, 0.1179],\n",
            "         [0.1200, 0.1237, 0.1934, 0.2712, 0.1925, 0.0890, 0.1984, 0.0845],\n",
            "         [0.1864, 0.2205, 0.1679, 0.0308, 0.1891, 0.0704, 0.0634, 0.0490],\n",
            "         [0.0160, 0.2876, 0.2703, 0.0189, 0.0094, 0.0328, 0.2261, 0.0397],\n",
            "         [0.1457, 0.1956, 0.1533, 0.0136, 0.2181, 0.0649, 0.0573, 0.2765],\n",
            "         [0.2445, 0.1155, 0.1840, 0.0417, 0.1916, 0.1242, 0.0424, 0.0393],\n",
            "         [0.1692, 0.1017, 0.1567, 0.2847, 0.1261, 0.0505, 0.1842, 0.2082]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([8, 8])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[ 1.1857,  1.1664,  0.7862,  0.4788,  0.8922,  0.9202,  0.7484,  0.9727],\n",
            "        [ 0.8190,  0.7312,  0.5550,  0.7343,  0.4062,  0.5416,  0.6161,  0.8869],\n",
            "        [ 1.2791,  0.9747,  0.8556,  1.0929,  0.6506,  0.4843,  0.9669,  0.8733],\n",
            "        [ 0.9153,  0.8172,  1.1973,  0.8547,  0.6251,  1.1058,  1.0343,  0.8045],\n",
            "        [ 0.9594,  0.2846,  1.1992,  1.1802,  0.2104, -0.0519,  0.5517,  0.6464],\n",
            "        [ 1.1981,  0.4754,  0.7823,  1.2195,  1.1535,  1.4311,  0.6413,  0.5472],\n",
            "        [ 1.0095,  1.1492,  1.1055,  1.0870,  0.5993,  0.6856,  1.2919,  0.5477],\n",
            "        [ 0.5134,  0.9529,  0.6067,  0.8648,  0.8931,  0.5081,  0.7089,  0.6565]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 4, 4\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([8, 8]) por self.weight.data[:,:,4,4].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[0.7204, 0.8954, 0.5028, 0.1661, 0.5490, 0.3445, 0.5757, 0.5382],\n",
            "        [0.3605, 0.1853, 0.7398, 0.5489, 0.6918, 0.0061, 0.6997, 0.4168],\n",
            "        [0.4362, 0.4958, 0.4801, 0.6260, 0.4563, 0.7274, 0.2073, 0.6066],\n",
            "        [0.0369, 0.7823, 0.0204, 0.2062, 0.7905, 0.4570, 0.0657, 0.2186],\n",
            "        [0.4556, 0.4791, 0.1144, 0.3650, 0.0290, 0.2206, 0.4196, 0.8588],\n",
            "        [0.6241, 0.4962, 0.9429, 0.9632, 0.7063, 0.8205, 0.5013, 0.9967],\n",
            "        [0.6818, 0.2316, 0.3449, 0.4895, 0.1076, 0.7065, 0.3353, 0.3867],\n",
            "        [0.5996, 0.4934, 0.5300, 0.4110, 0.1694, 0.1762, 0.2929, 0.1904]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[0.0814],\n",
            "        [0.2800]])\n",
            "[self.weight.data[:,:,4,4].view(2,)[i] for i in range(2)] = \n",
            "0.08136263489723206\n",
            "\n",
            "produto.shape: torch.Size([2, 8, 8]) produto: tensor([[[0.0586, 0.0729, 0.0409, 0.0135, 0.0447, 0.0280, 0.0468, 0.0438],\n",
            "         [0.0293, 0.0151, 0.0602, 0.0447, 0.0563, 0.0005, 0.0569, 0.0339],\n",
            "         [0.0355, 0.0403, 0.0391, 0.0509, 0.0371, 0.0592, 0.0169, 0.0494],\n",
            "         [0.0030, 0.0636, 0.0017, 0.0168, 0.0643, 0.0372, 0.0053, 0.0178],\n",
            "         [0.0371, 0.0390, 0.0093, 0.0297, 0.0024, 0.0179, 0.0341, 0.0699],\n",
            "         [0.0508, 0.0404, 0.0767, 0.0784, 0.0575, 0.0668, 0.0408, 0.0811],\n",
            "         [0.0555, 0.0188, 0.0281, 0.0398, 0.0088, 0.0575, 0.0273, 0.0315],\n",
            "         [0.0488, 0.0401, 0.0431, 0.0334, 0.0138, 0.0143, 0.0238, 0.0155]],\n",
            "\n",
            "        [[0.2017, 0.2507, 0.1408, 0.0465, 0.1537, 0.0964, 0.1612, 0.1507],\n",
            "         [0.1009, 0.0519, 0.2071, 0.1537, 0.1937, 0.0017, 0.1959, 0.1167],\n",
            "         [0.1221, 0.1388, 0.1344, 0.1753, 0.1277, 0.2036, 0.0580, 0.1698],\n",
            "         [0.0103, 0.2190, 0.0057, 0.0577, 0.2213, 0.1279, 0.0184, 0.0612],\n",
            "         [0.1275, 0.1341, 0.0320, 0.1022, 0.0081, 0.0618, 0.1175, 0.2404],\n",
            "         [0.1747, 0.1389, 0.2640, 0.2697, 0.1977, 0.2297, 0.1403, 0.2790],\n",
            "         [0.1909, 0.0648, 0.0966, 0.1370, 0.0301, 0.1978, 0.0939, 0.1083],\n",
            "         [0.1679, 0.1381, 0.1484, 0.1151, 0.0474, 0.0493, 0.0820, 0.0533]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([8, 8])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[ 1.2374,  1.2978,  0.9159,  0.5566,  1.0041,  1.0234,  0.9509,  1.0127],\n",
            "        [ 0.9877,  0.8762,  0.6349,  0.8408,  0.4342,  0.7053,  0.6342,  0.9704],\n",
            "        [ 1.3641,  1.0623,  0.9926,  1.2850,  0.7869,  0.5473,  1.1074,  0.9332],\n",
            "        [ 1.0474,  0.9734,  1.3163,  0.8766,  0.7590,  1.1556,  1.0793,  0.8392],\n",
            "        [ 0.9708,  0.4884,  1.3907,  1.1936,  0.2170, -0.0286,  0.7119,  0.6745],\n",
            "        [ 1.3013,  0.6140,  0.8909,  1.2291,  1.3081,  1.4771,  0.6819,  0.7431],\n",
            "        [ 1.1827,  1.2311,  1.2359,  1.1165,  0.7350,  0.7736,  1.3219,  0.5755],\n",
            "        [ 0.6333,  1.0249,  0.7177,  1.0665,  0.9825,  0.5439,  0.8394,  0.8041]])\n",
            "\n",
            "ndx_amostra: 1\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 0, 0\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([8, 8]) por self.weight.data[:,:,0,0].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[0.8272, 0.8718, 0.8053, 0.2914, 0.4739, 0.3426, 0.0215, 0.3727],\n",
            "        [0.0745, 0.9615, 0.2886, 0.2710, 0.0328, 0.7251, 0.0128, 0.0387],\n",
            "        [0.0031, 0.2633, 0.2866, 0.1260, 0.4984, 0.1934, 0.7179, 0.3872],\n",
            "        [0.3059, 0.9682, 0.8170, 0.6575, 0.8604, 0.0079, 0.6977, 0.3461],\n",
            "        [0.3039, 0.0319, 0.6748, 0.0815, 0.5193, 0.2828, 0.8401, 0.2321],\n",
            "        [0.0742, 0.9718, 0.6309, 0.7814, 0.6638, 0.4626, 0.4363, 0.5028],\n",
            "        [0.5733, 0.6602, 0.6306, 0.9485, 0.1835, 0.0933, 0.7540, 0.8554],\n",
            "        [0.9603, 0.1951, 0.8628, 0.9012, 0.2780, 0.9308, 0.9806, 0.7708]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[0.0428],\n",
            "        [0.0003]])\n",
            "[self.weight.data[:,:,0,0].view(2,)[i] for i in range(2)] = \n",
            "0.042759574949741364\n",
            "\n",
            "produto.shape: torch.Size([2, 8, 8]) produto: tensor([[[3.5371e-02, 3.7279e-02, 3.4433e-02, 1.2459e-02, 2.0266e-02,\n",
            "          1.4651e-02, 9.1741e-04, 1.5937e-02],\n",
            "         [3.1869e-03, 4.1115e-02, 1.2339e-02, 1.1587e-02, 1.4040e-03,\n",
            "          3.1005e-02, 5.4786e-04, 1.6553e-03],\n",
            "         [1.3372e-04, 1.1260e-02, 1.2257e-02, 5.3890e-03, 2.1313e-02,\n",
            "          8.2678e-03, 3.0698e-02, 1.6555e-02],\n",
            "         [1.3081e-02, 4.1401e-02, 3.4937e-02, 2.8113e-02, 3.6788e-02,\n",
            "          3.3840e-04, 2.9832e-02, 1.4801e-02],\n",
            "         [1.2994e-02, 1.3659e-03, 2.8853e-02, 3.4843e-03, 2.2205e-02,\n",
            "          1.2091e-02, 3.5924e-02, 9.9261e-03],\n",
            "         [3.1743e-03, 4.1553e-02, 2.6979e-02, 3.3411e-02, 2.8383e-02,\n",
            "          1.9781e-02, 1.8655e-02, 2.1499e-02],\n",
            "         [2.4513e-02, 2.8231e-02, 2.6964e-02, 4.0555e-02, 7.8471e-03,\n",
            "          3.9891e-03, 3.2242e-02, 3.6576e-02],\n",
            "         [4.1060e-02, 8.3440e-03, 3.6893e-02, 3.8537e-02, 1.1887e-02,\n",
            "          3.9800e-02, 4.1929e-02, 3.2959e-02]],\n",
            "\n",
            "        [[2.4559e-04, 2.5884e-04, 2.3908e-04, 8.6507e-05, 1.4071e-04,\n",
            "          1.0173e-04, 6.3698e-06, 1.1065e-04],\n",
            "         [2.2127e-05, 2.8547e-04, 8.5672e-05, 8.0452e-05, 9.7486e-06,\n",
            "          2.1528e-04, 3.8039e-06, 1.1493e-05],\n",
            "         [9.2842e-07, 7.8183e-05, 8.5101e-05, 3.7417e-05, 1.4798e-04,\n",
            "          5.7405e-05, 2.1314e-04, 1.1495e-04],\n",
            "         [9.0827e-05, 2.8746e-04, 2.4257e-04, 1.9520e-04, 2.5543e-04,\n",
            "          2.3496e-06, 2.0713e-04, 1.0276e-04],\n",
            "         [9.0222e-05, 9.4841e-06, 2.0033e-04, 2.4192e-05, 1.5418e-04,\n",
            "          8.3949e-05, 2.4943e-04, 6.8920e-05],\n",
            "         [2.2040e-05, 2.8852e-04, 1.8732e-04, 2.3198e-04, 1.9707e-04,\n",
            "          1.3735e-04, 1.2952e-04, 1.4927e-04],\n",
            "         [1.7020e-04, 1.9602e-04, 1.8722e-04, 2.8159e-04, 5.4484e-05,\n",
            "          2.7697e-05, 2.2387e-04, 2.5396e-04],\n",
            "         [2.8509e-04, 5.7934e-05, 2.5616e-04, 2.6757e-04, 8.2536e-05,\n",
            "          2.7634e-04, 2.9112e-04, 2.2884e-04]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([8, 8])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 0, 1\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([8, 8]) por self.weight.data[:,:,0,1].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[0.9483, 0.5126, 0.0787, 0.8203, 0.3258, 0.1150, 0.8699, 0.7206],\n",
            "        [0.0971, 0.2299, 0.6110, 0.2675, 0.7964, 0.8869, 0.3534, 0.9173],\n",
            "        [0.9999, 0.5924, 0.5828, 0.4786, 0.5602, 0.5655, 0.9780, 0.0545],\n",
            "        [0.7875, 0.5997, 0.4343, 0.4868, 0.1361, 0.5514, 0.1832, 0.2592],\n",
            "        [0.9221, 0.7618, 0.0791, 0.1211, 0.4020, 0.2669, 0.0866, 0.9298],\n",
            "        [0.0342, 0.5944, 0.8447, 0.7198, 0.4412, 0.8429, 0.1431, 0.6635],\n",
            "        [0.1226, 0.9445, 0.7365, 0.0083, 0.3013, 0.8212, 0.0816, 0.8144],\n",
            "        [0.8089, 0.1788, 0.5481, 0.9201, 0.9250, 0.9606, 0.5618, 0.1229]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[ 0.0468],\n",
            "        [-0.0871]])\n",
            "[self.weight.data[:,:,0,1].view(2,)[i] for i in range(2)] = \n",
            "0.0467989407479763\n",
            "\n",
            "produto.shape: torch.Size([2, 8, 8]) produto: tensor([[[ 0.0444,  0.0240,  0.0037,  0.0384,  0.0152,  0.0054,  0.0407,\n",
            "           0.0337],\n",
            "         [ 0.0045,  0.0108,  0.0286,  0.0125,  0.0373,  0.0415,  0.0165,\n",
            "           0.0429],\n",
            "         [ 0.0468,  0.0277,  0.0273,  0.0224,  0.0262,  0.0265,  0.0458,\n",
            "           0.0025],\n",
            "         [ 0.0369,  0.0281,  0.0203,  0.0228,  0.0064,  0.0258,  0.0086,\n",
            "           0.0121],\n",
            "         [ 0.0432,  0.0357,  0.0037,  0.0057,  0.0188,  0.0125,  0.0041,\n",
            "           0.0435],\n",
            "         [ 0.0016,  0.0278,  0.0395,  0.0337,  0.0206,  0.0394,  0.0067,\n",
            "           0.0311],\n",
            "         [ 0.0057,  0.0442,  0.0345,  0.0004,  0.0141,  0.0384,  0.0038,\n",
            "           0.0381],\n",
            "         [ 0.0379,  0.0084,  0.0256,  0.0431,  0.0433,  0.0450,  0.0263,\n",
            "           0.0058]],\n",
            "\n",
            "        [[-0.0826, -0.0447, -0.0069, -0.0715, -0.0284, -0.0100, -0.0758,\n",
            "          -0.0628],\n",
            "         [-0.0085, -0.0200, -0.0532, -0.0233, -0.0694, -0.0773, -0.0308,\n",
            "          -0.0799],\n",
            "         [-0.0871, -0.0516, -0.0508, -0.0417, -0.0488, -0.0493, -0.0852,\n",
            "          -0.0047],\n",
            "         [-0.0686, -0.0523, -0.0378, -0.0424, -0.0119, -0.0480, -0.0160,\n",
            "          -0.0226],\n",
            "         [-0.0803, -0.0664, -0.0069, -0.0106, -0.0350, -0.0233, -0.0075,\n",
            "          -0.0810],\n",
            "         [-0.0030, -0.0518, -0.0736, -0.0627, -0.0384, -0.0734, -0.0125,\n",
            "          -0.0578],\n",
            "         [-0.0107, -0.0823, -0.0642, -0.0007, -0.0263, -0.0716, -0.0071,\n",
            "          -0.0710],\n",
            "         [-0.0705, -0.0156, -0.0478, -0.0802, -0.0806, -0.0837, -0.0490,\n",
            "          -0.0107]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([8, 8])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[0.0354, 0.0373, 0.0344, 0.0125, 0.0203, 0.0147, 0.0009, 0.0159],\n",
            "        [0.0032, 0.0411, 0.0123, 0.0116, 0.0014, 0.0310, 0.0005, 0.0017],\n",
            "        [0.0001, 0.0113, 0.0123, 0.0054, 0.0213, 0.0083, 0.0307, 0.0166],\n",
            "        [0.0131, 0.0414, 0.0349, 0.0281, 0.0368, 0.0003, 0.0298, 0.0148],\n",
            "        [0.0130, 0.0014, 0.0289, 0.0035, 0.0222, 0.0121, 0.0359, 0.0099],\n",
            "        [0.0032, 0.0416, 0.0270, 0.0334, 0.0284, 0.0198, 0.0187, 0.0215],\n",
            "        [0.0245, 0.0282, 0.0270, 0.0406, 0.0078, 0.0040, 0.0322, 0.0366],\n",
            "        [0.0411, 0.0083, 0.0369, 0.0385, 0.0119, 0.0398, 0.0419, 0.0330]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 0, 2\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([8, 8]) por self.weight.data[:,:,0,2].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[0.8171, 0.0086, 0.6293, 0.8336, 0.8870, 0.1767, 0.8756, 0.7847],\n",
            "        [0.4206, 0.3241, 0.8021, 0.6637, 0.3069, 0.6115, 0.9266, 0.1197],\n",
            "        [0.5459, 0.1780, 0.3426, 0.9687, 0.4914, 0.1395, 0.9830, 0.5848],\n",
            "        [0.4745, 0.5014, 0.7601, 0.1473, 0.6921, 0.5196, 0.0885, 0.0361],\n",
            "        [0.9685, 0.1817, 0.9459, 0.8094, 0.8446, 0.3802, 0.3048, 0.1362],\n",
            "        [0.4293, 0.0464, 0.1597, 0.6066, 0.1072, 0.5212, 0.1026, 0.8726],\n",
            "        [0.2016, 0.7832, 0.8663, 0.5005, 0.0048, 0.4290, 0.4406, 0.9513],\n",
            "        [0.6245, 0.5764, 0.8148, 0.2774, 0.5879, 0.0225, 0.2621, 0.3504]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[0.0425],\n",
            "        [0.1973]])\n",
            "[self.weight.data[:,:,0,2].view(2,)[i] for i in range(2)] = \n",
            "0.042481642216444016\n",
            "\n",
            "produto.shape: torch.Size([2, 8, 8]) produto: tensor([[[0.0347, 0.0004, 0.0267, 0.0354, 0.0377, 0.0075, 0.0372, 0.0333],\n",
            "         [0.0179, 0.0138, 0.0341, 0.0282, 0.0130, 0.0260, 0.0394, 0.0051],\n",
            "         [0.0232, 0.0076, 0.0146, 0.0412, 0.0209, 0.0059, 0.0418, 0.0248],\n",
            "         [0.0202, 0.0213, 0.0323, 0.0063, 0.0294, 0.0221, 0.0038, 0.0015],\n",
            "         [0.0411, 0.0077, 0.0402, 0.0344, 0.0359, 0.0162, 0.0129, 0.0058],\n",
            "         [0.0182, 0.0020, 0.0068, 0.0258, 0.0046, 0.0221, 0.0044, 0.0371],\n",
            "         [0.0086, 0.0333, 0.0368, 0.0213, 0.0002, 0.0182, 0.0187, 0.0404],\n",
            "         [0.0265, 0.0245, 0.0346, 0.0118, 0.0250, 0.0010, 0.0111, 0.0149]],\n",
            "\n",
            "        [[0.1612, 0.0017, 0.1242, 0.1645, 0.1750, 0.0349, 0.1728, 0.1548],\n",
            "         [0.0830, 0.0640, 0.1583, 0.1310, 0.0606, 0.1207, 0.1828, 0.0236],\n",
            "         [0.1077, 0.0351, 0.0676, 0.1912, 0.0970, 0.0275, 0.1940, 0.1154],\n",
            "         [0.0936, 0.0989, 0.1500, 0.0291, 0.1366, 0.1025, 0.0175, 0.0071],\n",
            "         [0.1911, 0.0359, 0.1866, 0.1597, 0.1667, 0.0750, 0.0601, 0.0269],\n",
            "         [0.0847, 0.0092, 0.0315, 0.1197, 0.0212, 0.1028, 0.0202, 0.1722],\n",
            "         [0.0398, 0.1545, 0.1709, 0.0988, 0.0009, 0.0846, 0.0869, 0.1877],\n",
            "         [0.1232, 0.1137, 0.1608, 0.0547, 0.1160, 0.0044, 0.0517, 0.0691]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([8, 8])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[0.0797, 0.0613, 0.0381, 0.0508, 0.0355, 0.0200, 0.0416, 0.0497],\n",
            "        [0.0077, 0.0519, 0.0409, 0.0241, 0.0387, 0.0725, 0.0171, 0.0446],\n",
            "        [0.0469, 0.0390, 0.0395, 0.0278, 0.0475, 0.0347, 0.0765, 0.0191],\n",
            "        [0.0499, 0.0695, 0.0553, 0.0509, 0.0432, 0.0261, 0.0384, 0.0269],\n",
            "        [0.0561, 0.0370, 0.0326, 0.0092, 0.0410, 0.0246, 0.0400, 0.0534],\n",
            "        [0.0048, 0.0694, 0.0665, 0.0671, 0.0490, 0.0592, 0.0254, 0.0526],\n",
            "        [0.0303, 0.0724, 0.0614, 0.0409, 0.0219, 0.0424, 0.0361, 0.0747],\n",
            "        [0.0789, 0.0167, 0.0625, 0.0816, 0.0552, 0.0848, 0.0682, 0.0387]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 0, 3\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([8, 8]) por self.weight.data[:,:,0,3].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[0.8718, 0.8053, 0.2914, 0.4739, 0.3426, 0.0215, 0.3727, 0.2988],\n",
            "        [0.9615, 0.2886, 0.2710, 0.0328, 0.7251, 0.0128, 0.0387, 0.3913],\n",
            "        [0.2633, 0.2866, 0.1260, 0.4984, 0.1934, 0.7179, 0.3872, 0.8722],\n",
            "        [0.9682, 0.8170, 0.6575, 0.8604, 0.0079, 0.6977, 0.3461, 0.8626],\n",
            "        [0.0319, 0.6748, 0.0815, 0.5193, 0.2828, 0.8401, 0.2321, 0.7575],\n",
            "        [0.9718, 0.6309, 0.7814, 0.6638, 0.4626, 0.4363, 0.5028, 0.4722],\n",
            "        [0.6602, 0.6306, 0.9485, 0.1835, 0.0933, 0.7540, 0.8554, 0.9368],\n",
            "        [0.1951, 0.8628, 0.9012, 0.2780, 0.9308, 0.9806, 0.7708, 0.8441]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[-0.0046],\n",
            "        [ 0.1202]])\n",
            "[self.weight.data[:,:,0,3].view(2,)[i] for i in range(2)] = \n",
            "-0.0046000368893146515\n",
            "\n",
            "produto.shape: torch.Size([2, 8, 8]) produto: tensor([[[-4.0104e-03, -3.7043e-03, -1.3404e-03, -2.1802e-03, -1.5761e-03,\n",
            "          -9.8694e-05, -1.7144e-03, -1.3744e-03],\n",
            "         [-4.4231e-03, -1.3274e-03, -1.2465e-03, -1.5105e-04, -3.3355e-03,\n",
            "          -5.8938e-05, -1.7807e-04, -1.8001e-03],\n",
            "         [-1.2114e-03, -1.3186e-03, -5.7974e-04, -2.2929e-03, -8.8944e-04,\n",
            "          -3.3024e-03, -1.7810e-03, -4.0122e-03],\n",
            "         [-4.4539e-03, -3.7585e-03, -3.0244e-03, -3.9577e-03, -3.6405e-05,\n",
            "          -3.2092e-03, -1.5922e-03, -3.9678e-03],\n",
            "         [-1.4695e-04, -3.1040e-03, -3.7483e-04, -2.3888e-03, -1.3007e-03,\n",
            "          -3.8647e-03, -1.0678e-03, -3.4844e-03],\n",
            "         [-4.4703e-03, -2.9024e-03, -3.5943e-03, -3.0534e-03, -2.1281e-03,\n",
            "          -2.0069e-03, -2.3128e-03, -2.1722e-03],\n",
            "         [-3.0371e-03, -2.9008e-03, -4.3629e-03, -8.4418e-04, -4.2915e-04,\n",
            "          -3.4686e-03, -3.9348e-03, -4.3095e-03],\n",
            "         [-8.9764e-04, -3.9690e-03, -4.1458e-03, -1.2788e-03, -4.2816e-03,\n",
            "          -4.5107e-03, -3.5457e-03, -3.8830e-03]],\n",
            "\n",
            "        [[ 1.0480e-01,  9.6796e-02,  3.5024e-02,  5.6969e-02,  4.1186e-02,\n",
            "           2.5789e-03,  4.4800e-02,  3.5914e-02],\n",
            "         [ 1.1558e-01,  3.4686e-02,  3.2572e-02,  3.9469e-03,  8.7159e-02,\n",
            "           1.5401e-03,  4.6532e-03,  4.7038e-02],\n",
            "         [ 3.1654e-02,  3.4455e-02,  1.5149e-02,  5.9914e-02,  2.3242e-02,\n",
            "           8.6295e-02,  4.6539e-02,  1.0484e-01],\n",
            "         [ 1.1638e-01,  9.8211e-02,  7.9030e-02,  1.0342e-01,  9.5129e-04,\n",
            "           8.3860e-02,  4.1606e-02,  1.0368e-01],\n",
            "         [ 3.8398e-03,  8.1109e-02,  9.7947e-03,  6.2421e-02,  3.3989e-02,\n",
            "           1.0099e-01,  2.7904e-02,  9.1050e-02],\n",
            "         [ 1.1681e-01,  7.5841e-02,  9.3922e-02,  7.9787e-02,  5.5608e-02,\n",
            "           5.2441e-02,  6.0436e-02,  5.6761e-02],\n",
            "         [ 7.9362e-02,  7.5799e-02,  1.1401e-01,  2.2059e-02,  1.1214e-02,\n",
            "           9.0637e-02,  1.0282e-01,  1.1261e-01],\n",
            "         [ 2.3456e-02,  1.0371e-01,  1.0833e-01,  3.3416e-02,  1.1188e-01,\n",
            "           1.1787e-01,  9.2652e-02,  1.0147e-01]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([8, 8])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[0.1145, 0.0616, 0.0649, 0.0863, 0.0732, 0.0275, 0.0788, 0.0830],\n",
            "        [0.0256, 0.0656, 0.0750, 0.0523, 0.0517, 0.0985, 0.0564, 0.0497],\n",
            "        [0.0701, 0.0465, 0.0541, 0.0689, 0.0684, 0.0407, 0.1182, 0.0439],\n",
            "        [0.0701, 0.0908, 0.0876, 0.0572, 0.0726, 0.0482, 0.0422, 0.0285],\n",
            "        [0.0973, 0.0447, 0.0727, 0.0435, 0.0769, 0.0407, 0.0529, 0.0592],\n",
            "        [0.0230, 0.0713, 0.0733, 0.0929, 0.0536, 0.0814, 0.0297, 0.0896],\n",
            "        [0.0388, 0.1057, 0.0982, 0.0622, 0.0222, 0.0606, 0.0548, 0.1151],\n",
            "        [0.1054, 0.0412, 0.0972, 0.0934, 0.0801, 0.0857, 0.0794, 0.0536]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 0, 4\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([8, 8]) por self.weight.data[:,:,0,4].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[0.5126, 0.0787, 0.8203, 0.3258, 0.1150, 0.8699, 0.7206, 0.5849],\n",
            "        [0.2299, 0.6110, 0.2675, 0.7964, 0.8869, 0.3534, 0.9173, 0.8494],\n",
            "        [0.5924, 0.5828, 0.4786, 0.5602, 0.5655, 0.9780, 0.0545, 0.5914],\n",
            "        [0.5997, 0.4343, 0.4868, 0.1361, 0.5514, 0.1832, 0.2592, 0.5530],\n",
            "        [0.7618, 0.0791, 0.1211, 0.4020, 0.2669, 0.0866, 0.9298, 0.8210],\n",
            "        [0.5944, 0.8447, 0.7198, 0.4412, 0.8429, 0.1431, 0.6635, 0.6950],\n",
            "        [0.9445, 0.7365, 0.0083, 0.3013, 0.8212, 0.0816, 0.8144, 0.0420],\n",
            "        [0.1788, 0.5481, 0.9201, 0.9250, 0.9606, 0.5618, 0.1229, 0.9065]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[-0.0610],\n",
            "        [-0.2128]])\n",
            "[self.weight.data[:,:,0,4].view(2,)[i] for i in range(2)] = \n",
            "-0.06104636937379837\n",
            "\n",
            "produto.shape: torch.Size([2, 8, 8]) produto: tensor([[[-0.0313, -0.0048, -0.0501, -0.0199, -0.0070, -0.0531, -0.0440,\n",
            "          -0.0357],\n",
            "         [-0.0140, -0.0373, -0.0163, -0.0486, -0.0541, -0.0216, -0.0560,\n",
            "          -0.0519],\n",
            "         [-0.0362, -0.0356, -0.0292, -0.0342, -0.0345, -0.0597, -0.0033,\n",
            "          -0.0361],\n",
            "         [-0.0366, -0.0265, -0.0297, -0.0083, -0.0337, -0.0112, -0.0158,\n",
            "          -0.0338],\n",
            "         [-0.0465, -0.0048, -0.0074, -0.0245, -0.0163, -0.0053, -0.0568,\n",
            "          -0.0501],\n",
            "         [-0.0363, -0.0516, -0.0439, -0.0269, -0.0515, -0.0087, -0.0405,\n",
            "          -0.0424],\n",
            "         [-0.0577, -0.0450, -0.0005, -0.0184, -0.0501, -0.0050, -0.0497,\n",
            "          -0.0026],\n",
            "         [-0.0109, -0.0335, -0.0562, -0.0565, -0.0586, -0.0343, -0.0075,\n",
            "          -0.0553]],\n",
            "\n",
            "        [[-0.1091, -0.0168, -0.1746, -0.0694, -0.0245, -0.1851, -0.1534,\n",
            "          -0.1245],\n",
            "         [-0.0489, -0.1300, -0.0569, -0.1695, -0.1888, -0.0752, -0.1952,\n",
            "          -0.1808],\n",
            "         [-0.1261, -0.1240, -0.1019, -0.1192, -0.1204, -0.2081, -0.0116,\n",
            "          -0.1259],\n",
            "         [-0.1276, -0.0924, -0.1036, -0.0290, -0.1174, -0.0390, -0.0552,\n",
            "          -0.1177],\n",
            "         [-0.1621, -0.0168, -0.0258, -0.0856, -0.0568, -0.0184, -0.1979,\n",
            "          -0.1747],\n",
            "         [-0.1265, -0.1798, -0.1532, -0.0939, -0.1794, -0.0304, -0.1412,\n",
            "          -0.1479],\n",
            "         [-0.2010, -0.1568, -0.0018, -0.0641, -0.1748, -0.0174, -0.1733,\n",
            "          -0.0089],\n",
            "         [-0.0381, -0.1166, -0.1958, -0.1969, -0.2044, -0.1196, -0.0262,\n",
            "          -0.1929]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([8, 8])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[0.1104, 0.0579, 0.0635, 0.0841, 0.0716, 0.0274, 0.0771, 0.0816],\n",
            "        [0.0212, 0.0643, 0.0738, 0.0521, 0.0484, 0.0984, 0.0563, 0.0479],\n",
            "        [0.0689, 0.0452, 0.0535, 0.0666, 0.0675, 0.0374, 0.1164, 0.0399],\n",
            "        [0.0656, 0.0870, 0.0845, 0.0532, 0.0725, 0.0450, 0.0406, 0.0245],\n",
            "        [0.0971, 0.0416, 0.0724, 0.0411, 0.0756, 0.0369, 0.0519, 0.0557],\n",
            "        [0.0185, 0.0684, 0.0697, 0.0898, 0.0515, 0.0794, 0.0274, 0.0874],\n",
            "        [0.0358, 0.1028, 0.0939, 0.0614, 0.0217, 0.0572, 0.0508, 0.1108],\n",
            "        [0.1045, 0.0372, 0.0930, 0.0921, 0.0759, 0.0812, 0.0758, 0.0497]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 1, 0\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([8, 8]) por self.weight.data[:,:,1,0].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[0.1849, 0.4399, 0.4320, 0.1499, 0.2570, 0.6827, 0.4068, 0.7761],\n",
            "        [0.3994, 0.8265, 0.3689, 0.7347, 0.6853, 0.1683, 0.9723, 0.1683],\n",
            "        [0.0329, 0.2383, 0.3689, 0.4727, 0.4298, 0.4436, 0.8295, 0.4351],\n",
            "        [0.2981, 0.9128, 0.3634, 0.3227, 0.5017, 0.8008, 0.7480, 0.3820],\n",
            "        [0.8159, 0.9152, 0.6807, 0.3895, 0.2321, 0.9395, 0.9187, 0.8010],\n",
            "        [0.1914, 0.2799, 0.4354, 0.9764, 0.7306, 0.5367, 0.5033, 0.7527],\n",
            "        [0.8904, 0.6690, 0.3629, 0.1336, 0.7523, 0.3409, 0.8371, 0.8204],\n",
            "        [0.3683, 0.5900, 0.3046, 0.1279, 0.7824, 0.4059, 0.0704, 0.1030]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[0.0251],\n",
            "        [0.0234]])\n",
            "[self.weight.data[:,:,1,0].view(2,)[i] for i in range(2)] = \n",
            "0.025130199268460274\n",
            "\n",
            "produto.shape: torch.Size([2, 8, 8]) produto: tensor([[[0.0046, 0.0111, 0.0109, 0.0038, 0.0065, 0.0172, 0.0102, 0.0195],\n",
            "         [0.0100, 0.0208, 0.0093, 0.0185, 0.0172, 0.0042, 0.0244, 0.0042],\n",
            "         [0.0008, 0.0060, 0.0093, 0.0119, 0.0108, 0.0111, 0.0208, 0.0109],\n",
            "         [0.0075, 0.0229, 0.0091, 0.0081, 0.0126, 0.0201, 0.0188, 0.0096],\n",
            "         [0.0205, 0.0230, 0.0171, 0.0098, 0.0058, 0.0236, 0.0231, 0.0201],\n",
            "         [0.0048, 0.0070, 0.0109, 0.0245, 0.0184, 0.0135, 0.0126, 0.0189],\n",
            "         [0.0224, 0.0168, 0.0091, 0.0034, 0.0189, 0.0086, 0.0210, 0.0206],\n",
            "         [0.0093, 0.0148, 0.0077, 0.0032, 0.0197, 0.0102, 0.0018, 0.0026]],\n",
            "\n",
            "        [[0.0043, 0.0103, 0.0101, 0.0035, 0.0060, 0.0160, 0.0095, 0.0182],\n",
            "         [0.0093, 0.0193, 0.0086, 0.0172, 0.0160, 0.0039, 0.0227, 0.0039],\n",
            "         [0.0008, 0.0056, 0.0086, 0.0111, 0.0101, 0.0104, 0.0194, 0.0102],\n",
            "         [0.0070, 0.0213, 0.0085, 0.0075, 0.0117, 0.0187, 0.0175, 0.0089],\n",
            "         [0.0191, 0.0214, 0.0159, 0.0091, 0.0054, 0.0220, 0.0215, 0.0187],\n",
            "         [0.0045, 0.0065, 0.0102, 0.0228, 0.0171, 0.0126, 0.0118, 0.0176],\n",
            "         [0.0208, 0.0156, 0.0085, 0.0031, 0.0176, 0.0080, 0.0196, 0.0192],\n",
            "         [0.0086, 0.0138, 0.0071, 0.0030, 0.0183, 0.0095, 0.0016, 0.0024]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([8, 8])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[ 7.9155e-02,  5.3125e-02,  1.3438e-02,  6.4188e-02,  6.4596e-02,\n",
            "         -2.5660e-02,  3.3121e-02,  4.5916e-02],\n",
            "        [ 7.1429e-03,  2.7016e-02,  5.7431e-02,  3.5300e-03, -5.7593e-03,\n",
            "          7.6856e-02,  2.7103e-04, -3.9798e-03],\n",
            "        [ 3.2742e-02,  9.6535e-03,  2.4285e-02,  3.2451e-02,  3.2997e-02,\n",
            "         -2.2348e-02,  1.1312e-01,  3.8331e-03],\n",
            "        [ 2.9026e-02,  6.0493e-02,  5.4812e-02,  4.4885e-02,  3.8865e-02,\n",
            "          3.3820e-02,  2.4751e-02, -9.2624e-03],\n",
            "        [ 5.0636e-02,  3.6807e-02,  6.4969e-02,  1.6607e-02,  5.9302e-02,\n",
            "          3.1582e-02, -4.9006e-03,  5.6182e-03],\n",
            "        [-1.7741e-02,  1.6870e-02,  2.5764e-02,  6.2876e-02,  4.5039e-06,\n",
            "          7.0626e-02, -1.3109e-02,  4.5022e-02],\n",
            "        [-2.1878e-02,  5.7838e-02,  9.3366e-02,  4.2969e-02, -2.8408e-02,\n",
            "          5.2193e-02,  1.1252e-03,  1.0823e-01],\n",
            "        [ 9.3631e-02,  3.7728e-03,  3.6842e-02,  3.5637e-02,  1.7226e-02,\n",
            "          4.6902e-02,  6.8306e-02, -5.6207e-03]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 1, 1\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([8, 8]) por self.weight.data[:,:,1,1].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[0.2540, 0.1210, 0.6941, 0.7697, 0.9078, 0.0185, 0.9610, 0.2644],\n",
            "        [0.1294, 0.7534, 0.1210, 0.6027, 0.1452, 0.0279, 0.2570, 0.9514],\n",
            "        [0.6061, 0.3850, 0.7561, 0.4849, 0.1450, 0.6687, 0.3543, 0.0805],\n",
            "        [0.3215, 0.8084, 0.9109, 0.6418, 0.8790, 0.2195, 0.6036, 0.8986],\n",
            "        [0.0257, 0.1816, 0.3152, 0.6427, 0.3456, 0.1244, 0.6009, 0.0779],\n",
            "        [0.8704, 0.5159, 0.1799, 0.0239, 0.2297, 0.9239, 0.1917, 0.8967],\n",
            "        [0.4322, 0.6446, 0.2140, 0.8058, 0.1501, 0.5355, 0.6785, 0.0539],\n",
            "        [0.2075, 0.6203, 0.7517, 0.2288, 0.1864, 0.1886, 0.9784, 0.1536]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[-0.0047],\n",
            "        [ 0.3240]])\n",
            "[self.weight.data[:,:,1,1].view(2,)[i] for i in range(2)] = \n",
            "-0.004740814678370953\n",
            "\n",
            "produto.shape: torch.Size([2, 8, 8]) produto: tensor([[[-1.2040e-03, -5.7342e-04, -3.2905e-03, -3.6489e-03, -4.3037e-03,\n",
            "          -8.7506e-05, -4.5557e-03, -1.2536e-03],\n",
            "         [-6.1359e-04, -3.5719e-03, -5.7372e-04, -2.8575e-03, -6.8832e-04,\n",
            "          -1.3247e-04, -1.2183e-03, -4.5104e-03],\n",
            "         [-2.8736e-03, -1.8250e-03, -3.5844e-03, -2.2987e-03, -6.8753e-04,\n",
            "          -3.1703e-03, -1.6797e-03, -3.8158e-04],\n",
            "         [-1.5242e-03, -3.8325e-03, -4.3183e-03, -3.0428e-03, -4.1673e-03,\n",
            "          -1.0408e-03, -2.8618e-03, -4.2602e-03],\n",
            "         [-1.2180e-04, -8.6100e-04, -1.4942e-03, -3.0467e-03, -1.6385e-03,\n",
            "          -5.8963e-04, -2.8486e-03, -3.6923e-04],\n",
            "         [-4.1265e-03, -2.4460e-03, -8.5294e-04, -1.1311e-04, -1.0889e-03,\n",
            "          -4.3800e-03, -9.0895e-04, -4.2510e-03],\n",
            "         [-2.0488e-03, -3.0561e-03, -1.0144e-03, -3.8201e-03, -7.1173e-04,\n",
            "          -2.5388e-03, -3.2167e-03, -2.5533e-04],\n",
            "         [-9.8348e-04, -2.9405e-03, -3.5638e-03, -1.0845e-03, -8.8382e-04,\n",
            "          -8.9414e-04, -4.6384e-03, -7.2813e-04]],\n",
            "\n",
            "        [[ 8.2285e-02,  3.9191e-02,  2.2489e-01,  2.4938e-01,  2.9414e-01,\n",
            "           5.9806e-03,  3.1136e-01,  8.5675e-02],\n",
            "         [ 4.1936e-02,  2.4412e-01,  3.9211e-02,  1.9529e-01,  4.7044e-02,\n",
            "           9.0534e-03,  8.3266e-02,  3.0826e-01],\n",
            "         [ 1.9640e-01,  1.2473e-01,  2.4498e-01,  1.5710e-01,  4.6990e-02,\n",
            "           2.1668e-01,  1.1480e-01,  2.6079e-02],\n",
            "         [ 1.0417e-01,  2.6194e-01,  2.9513e-01,  2.0797e-01,  2.8481e-01,\n",
            "           7.1135e-02,  1.9559e-01,  2.9117e-01],\n",
            "         [ 8.3244e-03,  5.8845e-02,  1.0212e-01,  2.0823e-01,  1.1198e-01,\n",
            "           4.0298e-02,  1.9469e-01,  2.5235e-02],\n",
            "         [ 2.8202e-01,  1.6717e-01,  5.8294e-02,  7.7305e-03,  7.4420e-02,\n",
            "           2.9935e-01,  6.2123e-02,  2.9053e-01],\n",
            "         [ 1.4003e-01,  2.0887e-01,  6.9327e-02,  2.6108e-01,  4.8644e-02,\n",
            "           1.7352e-01,  2.1985e-01,  1.7450e-02],\n",
            "         [ 6.7217e-02,  2.0097e-01,  2.4357e-01,  7.4120e-02,  6.0405e-02,\n",
            "           6.1111e-02,  3.1701e-01,  4.9765e-02]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([8, 8])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[ 0.0838,  0.0642,  0.0243,  0.0680,  0.0711, -0.0085,  0.0433,  0.0654],\n",
            "        [ 0.0172,  0.0478,  0.0667,  0.0220,  0.0115,  0.0811,  0.0247,  0.0002],\n",
            "        [ 0.0336,  0.0156,  0.0336,  0.0443,  0.0438, -0.0112,  0.1340,  0.0148],\n",
            "        [ 0.0365,  0.0834,  0.0639,  0.0530,  0.0515,  0.0539,  0.0435,  0.0003],\n",
            "        [ 0.0711,  0.0598,  0.0821,  0.0264,  0.0651,  0.0552,  0.0182,  0.0257],\n",
            "        [-0.0129,  0.0239,  0.0367,  0.0874,  0.0184,  0.0841, -0.0005,  0.0639],\n",
            "        [ 0.0005,  0.0747,  0.1025,  0.0463, -0.0095,  0.0608,  0.0222,  0.1288],\n",
            "        [ 0.1029,  0.0186,  0.0445,  0.0389,  0.0369,  0.0571,  0.0701, -0.0030]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 1, 2\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([8, 8]) por self.weight.data[:,:,1,2].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[0.4626, 0.0457, 0.6661, 0.1543, 0.6252, 0.0652, 0.0068, 0.1429],\n",
            "        [0.4593, 0.0449, 0.1820, 0.9755, 0.6365, 0.0741, 0.8827, 0.2032],\n",
            "        [0.9745, 0.5965, 0.6216, 0.3053, 0.9963, 0.6897, 0.1060, 0.3432],\n",
            "        [0.1325, 0.3976, 0.3658, 0.3129, 0.1260, 0.3863, 0.8129, 0.1504],\n",
            "        [0.6732, 0.5394, 0.9381, 0.7231, 0.4724, 0.7523, 0.1983, 0.6491],\n",
            "        [0.2341, 0.2680, 0.1770, 0.4702, 0.7039, 0.9241, 0.3999, 0.5505],\n",
            "        [0.4296, 0.8576, 0.7355, 0.3869, 0.1501, 0.3474, 0.6564, 0.7422],\n",
            "        [0.7492, 0.8680, 0.5895, 0.1911, 0.0266, 0.3056, 0.9738, 0.4647]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[-0.0097],\n",
            "        [ 1.0133]])\n",
            "[self.weight.data[:,:,1,2].view(2,)[i] for i in range(2)] = \n",
            "-0.009749997407197952\n",
            "\n",
            "produto.shape: torch.Size([2, 8, 8]) produto: tensor([[[-4.5104e-03, -4.4514e-04, -6.4947e-03, -1.5046e-03, -6.0959e-03,\n",
            "          -6.3535e-04, -6.6171e-05, -1.3928e-03],\n",
            "         [-4.4786e-03, -4.3790e-04, -1.7744e-03, -9.5113e-03, -6.2064e-03,\n",
            "          -7.2256e-04, -8.6064e-03, -1.9809e-03],\n",
            "         [-9.5016e-03, -5.8155e-03, -6.0602e-03, -2.9770e-03, -9.7139e-03,\n",
            "          -6.7251e-03, -1.0339e-03, -3.3458e-03],\n",
            "         [-1.2916e-03, -3.8766e-03, -3.5661e-03, -3.0505e-03, -1.2289e-03,\n",
            "          -3.7667e-03, -7.9257e-03, -1.4660e-03],\n",
            "         [-6.5638e-03, -5.2594e-03, -9.1462e-03, -7.0507e-03, -4.6059e-03,\n",
            "          -7.3350e-03, -1.9336e-03, -6.3288e-03],\n",
            "         [-2.2828e-03, -2.6128e-03, -1.7260e-03, -4.5847e-03, -6.8626e-03,\n",
            "          -9.0104e-03, -3.8995e-03, -5.3669e-03],\n",
            "         [-4.1889e-03, -8.3619e-03, -7.1710e-03, -3.7727e-03, -1.4639e-03,\n",
            "          -3.3872e-03, -6.3996e-03, -7.2364e-03],\n",
            "         [-7.3049e-03, -8.4634e-03, -5.7476e-03, -1.8634e-03, -2.5953e-04,\n",
            "          -2.9792e-03, -9.4944e-03, -4.5311e-03]],\n",
            "\n",
            "        [[ 4.6874e-01,  4.6262e-02,  6.7497e-01,  1.5637e-01,  6.3352e-01,\n",
            "           6.6030e-02,  6.8769e-03,  1.4475e-01],\n",
            "         [ 4.6544e-01,  4.5510e-02,  1.8441e-01,  9.8847e-01,  6.4500e-01,\n",
            "           7.5093e-02,  8.9443e-01,  2.0586e-01],\n",
            "         [ 9.8746e-01,  6.0438e-01,  6.2981e-01,  3.0938e-01,  1.0095e+00,\n",
            "           6.9891e-01,  1.0745e-01,  3.4771e-01],\n",
            "         [ 1.3423e-01,  4.0288e-01,  3.7061e-01,  3.1702e-01,  1.2771e-01,\n",
            "           3.9146e-01,  8.2368e-01,  1.5236e-01],\n",
            "         [ 6.8215e-01,  5.4659e-01,  9.5052e-01,  7.3275e-01,  4.7867e-01,\n",
            "           7.6230e-01,  2.0095e-01,  6.5772e-01],\n",
            "         [ 2.3724e-01,  2.7154e-01,  1.7937e-01,  4.7647e-01,  7.1320e-01,\n",
            "           9.3642e-01,  4.0525e-01,  5.5776e-01],\n",
            "         [ 4.3534e-01,  8.6901e-01,  7.4526e-01,  3.9208e-01,  1.5214e-01,\n",
            "           3.5202e-01,  6.6508e-01,  7.5205e-01],\n",
            "         [ 7.5917e-01,  8.7956e-01,  5.9733e-01,  1.9365e-01,  2.6972e-02,\n",
            "           3.0961e-01,  9.8672e-01,  4.7090e-01]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([8, 8])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[ 0.0826,  0.0636,  0.0210,  0.0643,  0.0668, -0.0086,  0.0388,  0.0642],\n",
            "        [ 0.0166,  0.0442,  0.0661,  0.0191,  0.0108,  0.0810,  0.0235, -0.0043],\n",
            "        [ 0.0307,  0.0138,  0.0300,  0.0420,  0.0431, -0.0144,  0.1323,  0.0144],\n",
            "        [ 0.0350,  0.0796,  0.0596,  0.0500,  0.0473,  0.0529,  0.0407, -0.0039],\n",
            "        [ 0.0710,  0.0589,  0.0806,  0.0233,  0.0635,  0.0546,  0.0153,  0.0254],\n",
            "        [-0.0171,  0.0215,  0.0359,  0.0873,  0.0173,  0.0797, -0.0014,  0.0597],\n",
            "        [-0.0016,  0.0716,  0.1015,  0.0425, -0.0102,  0.0582,  0.0189,  0.1286],\n",
            "        [ 0.1019,  0.0157,  0.0409,  0.0378,  0.0360,  0.0562,  0.0654, -0.0038]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 1, 3\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([8, 8]) por self.weight.data[:,:,1,3].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[0.4399, 0.4320, 0.1499, 0.2570, 0.6827, 0.4068, 0.7761, 0.8873],\n",
            "        [0.8265, 0.3689, 0.7347, 0.6853, 0.1683, 0.9723, 0.1683, 0.6429],\n",
            "        [0.2383, 0.3689, 0.4727, 0.4298, 0.4436, 0.8295, 0.4351, 0.2455],\n",
            "        [0.9128, 0.3634, 0.3227, 0.5017, 0.8008, 0.7480, 0.3820, 0.6495],\n",
            "        [0.9152, 0.6807, 0.3895, 0.2321, 0.9395, 0.9187, 0.8010, 0.3563],\n",
            "        [0.2799, 0.4354, 0.9764, 0.7306, 0.5367, 0.5033, 0.7527, 0.2609],\n",
            "        [0.6690, 0.3629, 0.1336, 0.7523, 0.3409, 0.8371, 0.8204, 0.2216],\n",
            "        [0.5900, 0.3046, 0.1279, 0.7824, 0.4059, 0.0704, 0.1030, 0.1145]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[-0.1218],\n",
            "        [ 0.7023]])\n",
            "[self.weight.data[:,:,1,3].view(2,)[i] for i in range(2)] = \n",
            "-0.12179325520992279\n",
            "\n",
            "produto.shape: torch.Size([2, 8, 8]) produto: tensor([[[-0.0536, -0.0526, -0.0183, -0.0313, -0.0831, -0.0496, -0.0945,\n",
            "          -0.1081],\n",
            "         [-0.1007, -0.0449, -0.0895, -0.0835, -0.0205, -0.1184, -0.0205,\n",
            "          -0.0783],\n",
            "         [-0.0290, -0.0449, -0.0576, -0.0524, -0.0540, -0.1010, -0.0530,\n",
            "          -0.0299],\n",
            "         [-0.1112, -0.0443, -0.0393, -0.0611, -0.0975, -0.0911, -0.0465,\n",
            "          -0.0791],\n",
            "         [-0.1115, -0.0829, -0.0474, -0.0283, -0.1144, -0.1119, -0.0976,\n",
            "          -0.0434],\n",
            "         [-0.0341, -0.0530, -0.1189, -0.0890, -0.0654, -0.0613, -0.0917,\n",
            "          -0.0318],\n",
            "         [-0.0815, -0.0442, -0.0163, -0.0916, -0.0415, -0.1020, -0.0999,\n",
            "          -0.0270],\n",
            "         [-0.0719, -0.0371, -0.0156, -0.0953, -0.0494, -0.0086, -0.0125,\n",
            "          -0.0139]],\n",
            "\n",
            "        [[ 0.3090,  0.3033,  0.1053,  0.1805,  0.4794,  0.2857,  0.5450,\n",
            "           0.6231],\n",
            "         [ 0.5804,  0.2591,  0.5160,  0.4812,  0.1182,  0.6828,  0.1182,\n",
            "           0.4515],\n",
            "         [ 0.1673,  0.2591,  0.3319,  0.3019,  0.3115,  0.5826,  0.3055,\n",
            "           0.1724],\n",
            "         [ 0.6410,  0.2552,  0.2266,  0.3523,  0.5624,  0.5253,  0.2683,\n",
            "           0.4561],\n",
            "         [ 0.6427,  0.4781,  0.2735,  0.1630,  0.6598,  0.6452,  0.5625,\n",
            "           0.2502],\n",
            "         [ 0.1966,  0.3058,  0.6857,  0.5131,  0.3769,  0.3535,  0.5286,\n",
            "           0.1832],\n",
            "         [ 0.4698,  0.2548,  0.0938,  0.5283,  0.2394,  0.5879,  0.5761,\n",
            "           0.1556],\n",
            "         [ 0.4144,  0.2139,  0.0898,  0.5494,  0.2851,  0.0495,  0.0723,\n",
            "           0.0804]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([8, 8])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[ 0.0781,  0.0632,  0.0145,  0.0628,  0.0607, -0.0092,  0.0387,  0.0628],\n",
            "        [ 0.0121,  0.0438,  0.0644,  0.0096,  0.0046,  0.0802,  0.0149, -0.0062],\n",
            "        [ 0.0212,  0.0080,  0.0239,  0.0391,  0.0334, -0.0211,  0.1313,  0.0110],\n",
            "        [ 0.0337,  0.0757,  0.0561,  0.0469,  0.0461,  0.0491,  0.0328, -0.0054],\n",
            "        [ 0.0645,  0.0537,  0.0714,  0.0163,  0.0589,  0.0473,  0.0134,  0.0190],\n",
            "        [-0.0193,  0.0188,  0.0341,  0.0827,  0.0104,  0.0707, -0.0053,  0.0543],\n",
            "        [-0.0057,  0.0632,  0.0943,  0.0387, -0.0117,  0.0548,  0.0125,  0.1214],\n",
            "        [ 0.0946,  0.0072,  0.0352,  0.0359,  0.0357,  0.0532,  0.0559, -0.0083]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 1, 4\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([8, 8]) por self.weight.data[:,:,1,4].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[1.2095e-01, 6.9407e-01, 7.6967e-01, 9.0780e-01, 1.8458e-02, 9.6096e-01,\n",
            "         2.6442e-01, 1.2021e-01],\n",
            "        [7.5343e-01, 1.2102e-01, 6.0274e-01, 1.4519e-01, 2.7941e-02, 2.5698e-01,\n",
            "         9.5139e-01, 8.4507e-04],\n",
            "        [3.8495e-01, 7.5607e-01, 4.8486e-01, 1.4502e-01, 6.6873e-01, 3.5431e-01,\n",
            "         8.0488e-02, 3.7389e-03],\n",
            "        [8.0841e-01, 9.1087e-01, 6.4184e-01, 8.7902e-01, 2.1954e-01, 6.0365e-01,\n",
            "         8.9863e-01, 2.5026e-01],\n",
            "        [1.8161e-01, 3.1517e-01, 6.4266e-01, 3.4562e-01, 1.2437e-01, 6.0086e-01,\n",
            "         7.7884e-02, 4.1765e-01],\n",
            "        [5.1594e-01, 1.7991e-01, 2.3859e-02, 2.2968e-01, 9.2388e-01, 1.9173e-01,\n",
            "         8.9667e-01, 7.5620e-01],\n",
            "        [6.4464e-01, 2.1396e-01, 8.0578e-01, 1.5013e-01, 5.3553e-01, 6.7852e-01,\n",
            "         5.3857e-02, 9.4497e-01],\n",
            "        [6.2026e-01, 7.5173e-01, 2.2876e-01, 1.8643e-01, 1.8861e-01, 9.7840e-01,\n",
            "         1.5359e-01, 3.0090e-01]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[-0.1646],\n",
            "        [ 0.4641]])\n",
            "[self.weight.data[:,:,1,4].view(2,)[i] for i in range(2)] = \n",
            "-0.16463914513587952\n",
            "\n",
            "produto.shape: torch.Size([2, 8, 8]) produto: tensor([[[-1.9914e-02, -1.1427e-01, -1.2672e-01, -1.4946e-01, -3.0389e-03,\n",
            "          -1.5821e-01, -4.3533e-02, -1.9791e-02],\n",
            "         [-1.2404e-01, -1.9924e-02, -9.9234e-02, -2.3904e-02, -4.6003e-03,\n",
            "          -4.2310e-02, -1.5664e-01, -1.3913e-04],\n",
            "         [-6.3378e-02, -1.2448e-01, -7.9828e-02, -2.3877e-02, -1.1010e-01,\n",
            "          -5.8333e-02, -1.3251e-02, -6.1557e-04],\n",
            "         [-1.3310e-01, -1.4996e-01, -1.0567e-01, -1.4472e-01, -3.6145e-02,\n",
            "          -9.9384e-02, -1.4795e-01, -4.1203e-02],\n",
            "         [-2.9901e-02, -5.1890e-02, -1.0581e-01, -5.6902e-02, -2.0477e-02,\n",
            "          -9.8925e-02, -1.2823e-02, -6.8761e-02],\n",
            "         [-8.4944e-02, -2.9621e-02, -3.9281e-03, -3.7815e-02, -1.5211e-01,\n",
            "          -3.1566e-02, -1.4763e-01, -1.2450e-01],\n",
            "         [-1.0613e-01, -3.5227e-02, -1.3266e-01, -2.4717e-02, -8.8169e-02,\n",
            "          -1.1171e-01, -8.8669e-03, -1.5558e-01],\n",
            "         [-1.0212e-01, -1.2376e-01, -3.7662e-02, -3.0693e-02, -3.1052e-02,\n",
            "          -1.6108e-01, -2.5287e-02, -4.9539e-02]],\n",
            "\n",
            "        [[ 5.6135e-02,  3.2212e-01,  3.5721e-01,  4.2131e-01,  8.5664e-03,\n",
            "           4.4598e-01,  1.2272e-01,  5.5788e-02],\n",
            "         [ 3.4967e-01,  5.6165e-02,  2.7973e-01,  6.7383e-02,  1.2968e-02,\n",
            "           1.1927e-01,  4.4154e-01,  3.9220e-04],\n",
            "         [ 1.7866e-01,  3.5090e-01,  2.2503e-01,  6.7306e-02,  3.1036e-01,\n",
            "           1.6444e-01,  3.7355e-02,  1.7352e-03],\n",
            "         [ 3.7519e-01,  4.2274e-01,  2.9788e-01,  4.0796e-01,  1.0189e-01,\n",
            "           2.8015e-01,  4.1706e-01,  1.1615e-01],\n",
            "         [ 8.4288e-02,  1.4627e-01,  2.9826e-01,  1.6040e-01,  5.7722e-02,\n",
            "           2.7886e-01,  3.6146e-02,  1.9383e-01],\n",
            "         [ 2.3945e-01,  8.3499e-02,  1.1073e-02,  1.0660e-01,  4.2878e-01,\n",
            "           8.8982e-02,  4.1615e-01,  3.5096e-01],\n",
            "         [ 2.9918e-01,  9.9301e-02,  3.7397e-01,  6.9675e-02,  2.4854e-01,\n",
            "           3.1490e-01,  2.4995e-02,  4.3856e-01],\n",
            "         [ 2.8786e-01,  3.4888e-01,  1.0617e-01,  8.6522e-02,  8.7532e-02,\n",
            "           4.5408e-01,  7.1281e-02,  1.3965e-01]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([8, 8])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[ 0.0245,  0.0106, -0.0037,  0.0315, -0.0225, -0.0588, -0.0558, -0.0453],\n",
            "        [-0.0886, -0.0012, -0.0251, -0.0738, -0.0159, -0.0382, -0.0056, -0.0845],\n",
            "        [-0.0078, -0.0369, -0.0337, -0.0133, -0.0206, -0.1221,  0.0783, -0.0189],\n",
            "        [-0.0775,  0.0315,  0.0168, -0.0142, -0.0515, -0.0420, -0.0138, -0.0845],\n",
            "        [-0.0470, -0.0292,  0.0240, -0.0120, -0.0555, -0.0646, -0.0841, -0.0244],\n",
            "        [-0.0534, -0.0342, -0.0848, -0.0063, -0.0550,  0.0094, -0.0969,  0.0225],\n",
            "        [-0.0872,  0.0190,  0.0780, -0.0529, -0.0532, -0.0471, -0.0874,  0.0944],\n",
            "        [ 0.0227, -0.0299,  0.0196, -0.0594, -0.0137,  0.0446,  0.0434, -0.0222]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 2, 0\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([8, 8]) por self.weight.data[:,:,2,0].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[0.8571, 0.8098, 0.9163, 0.9266, 0.1591, 0.7066, 0.0516, 0.9275],\n",
            "        [0.4611, 0.4523, 0.1286, 0.3871, 0.0205, 0.2049, 0.3306, 0.9709],\n",
            "        [0.5116, 0.9115, 0.1299, 0.2683, 0.3389, 0.8712, 0.7764, 0.1459],\n",
            "        [0.0120, 0.3525, 0.1869, 0.2484, 0.7236, 0.6868, 0.7427, 0.4488],\n",
            "        [0.1909, 0.0803, 0.8285, 0.7276, 0.1710, 0.8190, 0.7444, 0.4717],\n",
            "        [0.3322, 0.7168, 0.6445, 0.6697, 0.4542, 0.6434, 0.3498, 0.5973],\n",
            "        [0.8868, 0.5220, 0.0838, 0.3141, 0.5135, 0.5044, 0.6873, 0.8737],\n",
            "        [0.9992, 0.0074, 0.1449, 0.7384, 0.7793, 0.2262, 0.3440, 0.6843]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[-0.0247],\n",
            "        [-0.1066]])\n",
            "[self.weight.data[:,:,2,0].view(2,)[i] for i in range(2)] = \n",
            "-0.024726245552301407\n",
            "\n",
            "produto.shape: torch.Size([2, 8, 8]) produto: tensor([[[-0.0212, -0.0200, -0.0227, -0.0229, -0.0039, -0.0175, -0.0013,\n",
            "          -0.0229],\n",
            "         [-0.0114, -0.0112, -0.0032, -0.0096, -0.0005, -0.0051, -0.0082,\n",
            "          -0.0240],\n",
            "         [-0.0127, -0.0225, -0.0032, -0.0066, -0.0084, -0.0215, -0.0192,\n",
            "          -0.0036],\n",
            "         [-0.0003, -0.0087, -0.0046, -0.0061, -0.0179, -0.0170, -0.0184,\n",
            "          -0.0111],\n",
            "         [-0.0047, -0.0020, -0.0205, -0.0180, -0.0042, -0.0203, -0.0184,\n",
            "          -0.0117],\n",
            "         [-0.0082, -0.0177, -0.0159, -0.0166, -0.0112, -0.0159, -0.0086,\n",
            "          -0.0148],\n",
            "         [-0.0219, -0.0129, -0.0021, -0.0078, -0.0127, -0.0125, -0.0170,\n",
            "          -0.0216],\n",
            "         [-0.0247, -0.0002, -0.0036, -0.0183, -0.0193, -0.0056, -0.0085,\n",
            "          -0.0169]],\n",
            "\n",
            "        [[-0.0914, -0.0863, -0.0977, -0.0988, -0.0170, -0.0753, -0.0055,\n",
            "          -0.0989],\n",
            "         [-0.0491, -0.0482, -0.0137, -0.0413, -0.0022, -0.0218, -0.0352,\n",
            "          -0.1035],\n",
            "         [-0.0545, -0.0972, -0.0138, -0.0286, -0.0361, -0.0929, -0.0828,\n",
            "          -0.0155],\n",
            "         [-0.0013, -0.0376, -0.0199, -0.0265, -0.0771, -0.0732, -0.0792,\n",
            "          -0.0478],\n",
            "         [-0.0204, -0.0086, -0.0883, -0.0776, -0.0182, -0.0873, -0.0793,\n",
            "          -0.0503],\n",
            "         [-0.0354, -0.0764, -0.0687, -0.0714, -0.0484, -0.0686, -0.0373,\n",
            "          -0.0637],\n",
            "         [-0.0945, -0.0556, -0.0089, -0.0335, -0.0547, -0.0538, -0.0733,\n",
            "          -0.0931],\n",
            "         [-0.1065, -0.0008, -0.0154, -0.0787, -0.0831, -0.0241, -0.0367,\n",
            "          -0.0729]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([8, 8])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[ 0.0046, -0.1037, -0.1305, -0.1180, -0.0255, -0.2170, -0.0993, -0.0651],\n",
            "        [-0.2126, -0.0211, -0.1244, -0.0977, -0.0205, -0.0805, -0.1622, -0.0847],\n",
            "        [-0.0712, -0.1614, -0.1135, -0.0372, -0.1307, -0.1805,  0.0650, -0.0195],\n",
            "        [-0.2106, -0.1185, -0.0889, -0.1589, -0.0876, -0.1413, -0.1617, -0.1257],\n",
            "        [-0.0769, -0.0811, -0.0818, -0.0689, -0.0760, -0.1636, -0.0970, -0.0931],\n",
            "        [-0.1384, -0.0638, -0.0887, -0.0441, -0.2071, -0.0221, -0.2446, -0.1020],\n",
            "        [-0.1934, -0.0162, -0.0546, -0.0776, -0.1414, -0.1588, -0.0962, -0.0612],\n",
            "        [-0.0794, -0.1537, -0.0181, -0.0901, -0.0447, -0.1164,  0.0181, -0.0718]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 2, 1\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([8, 8]) por self.weight.data[:,:,2,1].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[0.0257, 0.6170, 0.7747, 0.8811, 0.7705, 0.4988, 0.1730, 0.1775],\n",
            "        [0.2826, 0.8467, 0.6807, 0.4767, 0.8683, 0.3977, 0.1937, 0.6138],\n",
            "        [0.8966, 0.5589, 0.0250, 0.9916, 0.9356, 0.8077, 0.6486, 0.9996],\n",
            "        [0.7569, 0.7781, 0.8212, 0.8753, 0.0432, 0.6477, 0.9168, 0.5717],\n",
            "        [0.9689, 0.2396, 0.2859, 0.0510, 0.3667, 0.1408, 0.9772, 0.8233],\n",
            "        [0.2517, 0.9404, 0.9054, 0.1351, 0.4254, 0.0601, 0.0170, 0.1269],\n",
            "        [0.4249, 0.7583, 0.4304, 0.1689, 0.1087, 0.5654, 0.6315, 0.8729],\n",
            "        [0.9132, 0.2083, 0.8692, 0.7390, 0.9747, 0.6692, 0.9779, 0.9358]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[-0.0092],\n",
            "        [ 0.5797]])\n",
            "[self.weight.data[:,:,2,1].view(2,)[i] for i in range(2)] = \n",
            "-0.009192749857902527\n",
            "\n",
            "produto.shape: torch.Size([2, 8, 8]) produto: tensor([[[-2.3646e-04, -5.6719e-03, -7.1220e-03, -8.0999e-03, -7.0835e-03,\n",
            "          -4.5857e-03, -1.5902e-03, -1.6318e-03],\n",
            "         [-2.5977e-03, -7.7832e-03, -6.2574e-03, -4.3826e-03, -7.9817e-03,\n",
            "          -3.6562e-03, -1.7810e-03, -5.6427e-03],\n",
            "         [-8.2423e-03, -5.1374e-03, -2.2992e-04, -9.1153e-03, -8.6010e-03,\n",
            "          -7.4249e-03, -5.9628e-03, -9.1894e-03],\n",
            "         [-6.9583e-03, -7.1532e-03, -7.5491e-03, -8.0464e-03, -3.9681e-04,\n",
            "          -5.9540e-03, -8.4279e-03, -5.2557e-03],\n",
            "         [-8.9071e-03, -2.2024e-03, -2.6279e-03, -4.6873e-04, -3.3708e-03,\n",
            "          -1.2940e-03, -8.9836e-03, -7.5682e-03],\n",
            "         [-2.3141e-03, -8.6452e-03, -8.3229e-03, -1.2420e-03, -3.9104e-03,\n",
            "          -5.5215e-04, -1.5593e-04, -1.1662e-03],\n",
            "         [-3.9060e-03, -6.9706e-03, -3.9568e-03, -1.5522e-03, -9.9884e-04,\n",
            "          -5.1974e-03, -5.8052e-03, -8.0240e-03],\n",
            "         [-8.3944e-03, -1.9148e-03, -7.9907e-03, -6.7930e-03, -8.9604e-03,\n",
            "          -6.1516e-03, -8.9898e-03, -8.6023e-03]],\n",
            "\n",
            "        [[ 1.4910e-02,  3.5764e-01,  4.4908e-01,  5.1074e-01,  4.4665e-01,\n",
            "           2.8916e-01,  1.0027e-01,  1.0290e-01],\n",
            "         [ 1.6380e-01,  4.9077e-01,  3.9457e-01,  2.7634e-01,  5.0329e-01,\n",
            "           2.3054e-01,  1.1230e-01,  3.5581e-01],\n",
            "         [ 5.1972e-01,  3.2394e-01,  1.4497e-02,  5.7477e-01,  5.4234e-01,\n",
            "           4.6818e-01,  3.7598e-01,  5.7944e-01],\n",
            "         [ 4.3876e-01,  4.5105e-01,  4.7601e-01,  5.0737e-01,  2.5021e-02,\n",
            "           3.7543e-01,  5.3142e-01,  3.3140e-01],\n",
            "         [ 5.6164e-01,  1.3887e-01,  1.6570e-01,  2.9556e-02,  2.1255e-01,\n",
            "           8.1596e-02,  5.6646e-01,  4.7721e-01],\n",
            "         [ 1.4592e-01,  5.4513e-01,  5.2481e-01,  7.8313e-02,  2.4657e-01,\n",
            "           3.4816e-02,  9.8319e-03,  7.3533e-02],\n",
            "         [ 2.4629e-01,  4.3954e-01,  2.4950e-01,  9.7876e-02,  6.2982e-02,\n",
            "           3.2772e-01,  3.6605e-01,  5.0596e-01],\n",
            "         [ 5.2931e-01,  1.2074e-01,  5.0386e-01,  4.2834e-01,  5.6500e-01,\n",
            "           3.8789e-01,  5.6685e-01,  5.4242e-01]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([8, 8])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[-0.0166, -0.1237, -0.1531, -0.1409, -0.0295, -0.2345, -0.1006, -0.0880],\n",
            "        [-0.2240, -0.0323, -0.1275, -0.1073, -0.0210, -0.0856, -0.1704, -0.1087],\n",
            "        [-0.0839, -0.1839, -0.1167, -0.0438, -0.1391, -0.2020,  0.0458, -0.0231],\n",
            "        [-0.2109, -0.1272, -0.0935, -0.1651, -0.1055, -0.1583, -0.1801, -0.1368],\n",
            "        [-0.0816, -0.0831, -0.1023, -0.0869, -0.0802, -0.1838, -0.1154, -0.1048],\n",
            "        [-0.1466, -0.0815, -0.1047, -0.0606, -0.2183, -0.0381, -0.2532, -0.1167],\n",
            "        [-0.2153, -0.0291, -0.0567, -0.0854, -0.1541, -0.1713, -0.1132, -0.0828],\n",
            "        [-0.1041, -0.1538, -0.0216, -0.1083, -0.0640, -0.1220,  0.0096, -0.0887]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 2, 2\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([8, 8]) por self.weight.data[:,:,2,2].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[0.7619, 0.9368, 0.8472, 0.7464, 0.4842, 0.7778, 0.3308, 0.4689],\n",
            "        [0.3834, 0.0259, 0.4233, 0.9563, 0.7231, 0.3508, 0.9071, 0.7668],\n",
            "        [0.8308, 0.8239, 0.6655, 0.5703, 0.9790, 0.3568, 0.3112, 0.0596],\n",
            "        [0.6564, 0.8937, 0.1774, 0.8060, 0.7503, 0.7566, 0.5724, 0.4071],\n",
            "        [0.5822, 0.8363, 0.6497, 0.7362, 0.5481, 0.8363, 0.4364, 0.0392],\n",
            "        [0.0749, 0.4429, 0.1784, 0.5577, 0.8631, 0.3182, 0.7369, 0.6650],\n",
            "        [0.1633, 0.7841, 0.5082, 0.0869, 0.6680, 0.4855, 0.5607, 0.3216],\n",
            "        [0.0440, 0.7692, 0.5014, 0.8741, 0.3963, 0.9024, 0.9154, 0.5081]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[-0.0378],\n",
            "        [ 1.3028]])\n",
            "[self.weight.data[:,:,2,2].view(2,)[i] for i in range(2)] = \n",
            "-0.03782135993242264\n",
            "\n",
            "produto.shape: torch.Size([2, 8, 8]) produto: tensor([[[-2.8815e-02, -3.5432e-02, -3.2043e-02, -2.8231e-02, -1.8315e-02,\n",
            "          -2.9418e-02, -1.2512e-02, -1.7735e-02],\n",
            "         [-1.4499e-02, -9.7837e-04, -1.6010e-02, -3.6168e-02, -2.7349e-02,\n",
            "          -1.3267e-02, -3.4308e-02, -2.9001e-02],\n",
            "         [-3.1420e-02, -3.1160e-02, -2.5169e-02, -2.1570e-02, -3.7026e-02,\n",
            "          -1.3496e-02, -1.1769e-02, -2.2529e-03],\n",
            "         [-2.4824e-02, -3.3801e-02, -6.7081e-03, -3.0486e-02, -2.8379e-02,\n",
            "          -2.8617e-02, -2.1648e-02, -1.5398e-02],\n",
            "         [-2.2018e-02, -3.1630e-02, -2.4574e-02, -2.7845e-02, -2.0730e-02,\n",
            "          -3.1629e-02, -1.6505e-02, -1.4833e-03],\n",
            "         [-2.8310e-03, -1.6749e-02, -6.7482e-03, -2.1092e-02, -3.2645e-02,\n",
            "          -1.2035e-02, -2.7872e-02, -2.5150e-02],\n",
            "         [-6.1765e-03, -2.9657e-02, -1.9222e-02, -3.2861e-03, -2.5263e-02,\n",
            "          -1.8362e-02, -2.1205e-02, -1.2162e-02],\n",
            "         [-1.6656e-03, -2.9090e-02, -1.8962e-02, -3.3061e-02, -1.4990e-02,\n",
            "          -3.4131e-02, -3.4623e-02, -1.9216e-02]],\n",
            "\n",
            "        [[ 9.9262e-01,  1.2205e+00,  1.1038e+00,  9.7248e-01,  6.3090e-01,\n",
            "           1.0134e+00,  4.3101e-01,  6.1093e-01],\n",
            "         [ 4.9945e-01,  3.3702e-02,  5.5151e-01,  1.2459e+00,  9.4210e-01,\n",
            "           4.5700e-01,  1.1818e+00,  9.9900e-01],\n",
            "         [ 1.0823e+00,  1.0734e+00,  8.6700e-01,  7.4304e-01,  1.2755e+00,\n",
            "           4.6492e-01,  4.0542e-01,  7.7607e-02],\n",
            "         [ 8.5512e-01,  1.1643e+00,  2.3108e-01,  1.0501e+00,  9.7757e-01,\n",
            "           9.8579e-01,  7.4572e-01,  5.3044e-01],\n",
            "         [ 7.5846e-01,  1.0896e+00,  8.4652e-01,  9.5918e-01,  7.1410e-01,\n",
            "           1.0895e+00,  5.6856e-01,  5.1095e-02],\n",
            "         [ 9.7521e-02,  5.7697e-01,  2.3246e-01,  7.2657e-01,  1.1245e+00,\n",
            "           4.1456e-01,  9.6011e-01,  8.6635e-01],\n",
            "         [ 2.1277e-01,  1.0216e+00,  6.6216e-01,  1.1320e-01,  8.7025e-01,\n",
            "           6.3251e-01,  7.3045e-01,  4.1894e-01],\n",
            "         [ 5.7374e-02,  1.0021e+00,  6.5319e-01,  1.1389e+00,  5.1638e-01,\n",
            "           1.1757e+00,  1.1927e+00,  6.6194e-01]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([8, 8])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[-0.0168, -0.1294, -0.1602, -0.1490, -0.0365, -0.2390, -0.1022, -0.0897],\n",
            "        [-0.2266, -0.0400, -0.1338, -0.1117, -0.0290, -0.0892, -0.1722, -0.1143],\n",
            "        [-0.0921, -0.1891, -0.1169, -0.0529, -0.1477, -0.2094,  0.0399, -0.0323],\n",
            "        [-0.2178, -0.1344, -0.1011, -0.1731, -0.1059, -0.1643, -0.1885, -0.1421],\n",
            "        [-0.0905, -0.0853, -0.1049, -0.0873, -0.0836, -0.1851, -0.1244, -0.1123],\n",
            "        [-0.1489, -0.0902, -0.1130, -0.0619, -0.2222, -0.0386, -0.2534, -0.1179],\n",
            "        [-0.2192, -0.0361, -0.0607, -0.0869, -0.1551, -0.1765, -0.1190, -0.0908],\n",
            "        [-0.1125, -0.1558, -0.0296, -0.1151, -0.0730, -0.1282,  0.0006, -0.0973]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 2, 3\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([8, 8]) por self.weight.data[:,:,2,3].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[0.8098, 0.9163, 0.9266, 0.1591, 0.7066, 0.0516, 0.9275, 0.3373],\n",
            "        [0.4523, 0.1286, 0.3871, 0.0205, 0.2049, 0.3306, 0.9709, 0.9030],\n",
            "        [0.9115, 0.1299, 0.2683, 0.3389, 0.8712, 0.7764, 0.1459, 0.6133],\n",
            "        [0.3525, 0.1869, 0.2484, 0.7236, 0.6868, 0.7427, 0.4488, 0.8968],\n",
            "        [0.0803, 0.8285, 0.7276, 0.1710, 0.8190, 0.7444, 0.4717, 0.2321],\n",
            "        [0.7168, 0.6445, 0.6697, 0.4542, 0.6434, 0.3498, 0.5973, 0.1177],\n",
            "        [0.5220, 0.0838, 0.3141, 0.5135, 0.5044, 0.6873, 0.8737, 0.9365],\n",
            "        [0.0074, 0.1449, 0.7384, 0.7793, 0.2262, 0.3440, 0.6843, 0.7446]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[-0.1679],\n",
            "        [ 1.0332]])\n",
            "[self.weight.data[:,:,2,3].view(2,)[i] for i in range(2)] = \n",
            "-0.1679040640592575\n",
            "\n",
            "produto.shape: torch.Size([2, 8, 8]) produto: tensor([[[-0.1360, -0.1539, -0.1556, -0.0267, -0.1186, -0.0087, -0.1557,\n",
            "          -0.0566],\n",
            "         [-0.0759, -0.0216, -0.0650, -0.0034, -0.0344, -0.0555, -0.1630,\n",
            "          -0.1516],\n",
            "         [-0.1530, -0.0218, -0.0450, -0.0569, -0.1463, -0.1304, -0.0245,\n",
            "          -0.1030],\n",
            "         [-0.0592, -0.0314, -0.0417, -0.1215, -0.1153, -0.1247, -0.0754,\n",
            "          -0.1506],\n",
            "         [-0.0135, -0.1391, -0.1222, -0.0287, -0.1375, -0.1250, -0.0792,\n",
            "          -0.0390],\n",
            "         [-0.1203, -0.1082, -0.1124, -0.0763, -0.1080, -0.0587, -0.1003,\n",
            "          -0.0198],\n",
            "         [-0.0876, -0.0141, -0.0527, -0.0862, -0.0847, -0.1154, -0.1467,\n",
            "          -0.1572],\n",
            "         [-0.0012, -0.0243, -0.1240, -0.1308, -0.0380, -0.0578, -0.1149,\n",
            "          -0.1250]],\n",
            "\n",
            "        [[ 0.8367,  0.9468,  0.9574,  0.1644,  0.7301,  0.0533,  0.9583,\n",
            "           0.3485],\n",
            "         [ 0.4673,  0.1328,  0.3999,  0.0212,  0.2117,  0.3415,  1.0031,\n",
            "           0.9330],\n",
            "         [ 0.9418,  0.1342,  0.2772,  0.3502,  0.9002,  0.8022,  0.1507,\n",
            "           0.6337],\n",
            "         [ 0.3642,  0.1931,  0.2567,  0.7476,  0.7096,  0.7674,  0.4637,\n",
            "           0.9266],\n",
            "         [ 0.0830,  0.8561,  0.7518,  0.1767,  0.8462,  0.7691,  0.4874,\n",
            "           0.2398],\n",
            "         [ 0.7406,  0.6659,  0.6920,  0.4693,  0.6647,  0.3614,  0.6171,\n",
            "           0.1216],\n",
            "         [ 0.5393,  0.0866,  0.3245,  0.5306,  0.5212,  0.7101,  0.9027,\n",
            "           0.9676],\n",
            "         [ 0.0076,  0.1497,  0.7629,  0.8051,  0.2337,  0.3554,  0.7070,\n",
            "           0.7693]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([8, 8])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[-0.0457, -0.1648, -0.1923, -0.1772, -0.0549, -0.2685, -0.1147, -0.1074],\n",
            "        [-0.2411, -0.0410, -0.1498, -0.1479, -0.0564, -0.1025, -0.2065, -0.1433],\n",
            "        [-0.1235, -0.2202, -0.1421, -0.0745, -0.1847, -0.2229,  0.0281, -0.0345],\n",
            "        [-0.2426, -0.1682, -0.1078, -0.2036, -0.1343, -0.1929, -0.2102, -0.1574],\n",
            "        [-0.1126, -0.1169, -0.1295, -0.1152, -0.1043, -0.2167, -0.1409, -0.1138],\n",
            "        [-0.1517, -0.1069, -0.1197, -0.0830, -0.2548, -0.0506, -0.2812, -0.1430],\n",
            "        [-0.2254, -0.0657, -0.0799, -0.0902, -0.1803, -0.1949, -0.1402, -0.1030],\n",
            "        [-0.1142, -0.1849, -0.0486, -0.1482, -0.0880, -0.1623, -0.0340, -0.1165]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 2, 4\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([8, 8]) por self.weight.data[:,:,2,4].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[0.6170, 0.7747, 0.8811, 0.7705, 0.4988, 0.1730, 0.1775, 0.0264],\n",
            "        [0.8467, 0.6807, 0.4767, 0.8683, 0.3977, 0.1937, 0.6138, 0.7455],\n",
            "        [0.5589, 0.0250, 0.9916, 0.9356, 0.8077, 0.6486, 0.9996, 0.2568],\n",
            "        [0.7781, 0.8212, 0.8753, 0.0432, 0.6477, 0.9168, 0.5717, 0.3798],\n",
            "        [0.2396, 0.2859, 0.0510, 0.3667, 0.1408, 0.9772, 0.8233, 0.3299],\n",
            "        [0.9404, 0.9054, 0.1351, 0.4254, 0.0601, 0.0170, 0.1269, 0.8899],\n",
            "        [0.7583, 0.4304, 0.1689, 0.1087, 0.5654, 0.6315, 0.8729, 0.0021],\n",
            "        [0.2083, 0.8692, 0.7390, 0.9747, 0.6692, 0.9779, 0.9358, 0.0274]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[-0.1590],\n",
            "        [ 0.7636]])\n",
            "[self.weight.data[:,:,2,4].view(2,)[i] for i in range(2)] = \n",
            "-0.15897424519062042\n",
            "\n",
            "produto.shape: torch.Size([2, 8, 8]) produto: tensor([[[-9.8086e-02, -1.2316e-01, -1.4007e-01, -1.2250e-01, -7.9303e-02,\n",
            "          -2.7499e-02, -2.8220e-02, -4.1976e-03],\n",
            "         [-1.3460e-01, -1.0821e-01, -7.5790e-02, -1.3803e-01, -6.3228e-02,\n",
            "          -3.0800e-02, -9.7582e-02, -1.1852e-01],\n",
            "         [-8.8844e-02, -3.9760e-03, -1.5764e-01, -1.4874e-01, -1.2840e-01,\n",
            "          -1.0312e-01, -1.5892e-01, -4.0820e-02],\n",
            "         [-1.2370e-01, -1.3055e-01, -1.3915e-01, -6.8621e-03, -1.0297e-01,\n",
            "          -1.4575e-01, -9.0890e-02, -6.0377e-02],\n",
            "         [-3.8087e-02, -4.5445e-02, -8.1060e-03, -5.8293e-02, -2.2378e-02,\n",
            "          -1.5536e-01, -1.3088e-01, -5.2452e-02],\n",
            "         [-1.4951e-01, -1.4393e-01, -2.1478e-02, -6.7623e-02, -9.5486e-03,\n",
            "          -2.6965e-03, -2.0167e-02, -1.4147e-01],\n",
            "         [-1.2055e-01, -6.8428e-02, -2.6843e-02, -1.7273e-02, -8.9880e-02,\n",
            "          -1.0039e-01, -1.3876e-01, -3.3832e-04],\n",
            "         [-3.3113e-02, -1.3819e-01, -1.1747e-01, -1.5496e-01, -1.0638e-01,\n",
            "          -1.5546e-01, -1.4876e-01, -4.3489e-03]],\n",
            "\n",
            "        [[ 4.7116e-01,  5.9162e-01,  6.7285e-01,  5.8842e-01,  3.8094e-01,\n",
            "           1.3209e-01,  1.3556e-01,  2.0163e-02],\n",
            "         [ 6.4654e-01,  5.1980e-01,  3.6406e-01,  6.6303e-01,  3.0372e-01,\n",
            "           1.4795e-01,  4.6874e-01,  5.6930e-01],\n",
            "         [ 4.2676e-01,  1.9099e-02,  7.5721e-01,  7.1448e-01,  6.1678e-01,\n",
            "           4.9532e-01,  7.6336e-01,  1.9608e-01],\n",
            "         [ 5.9421e-01,  6.2710e-01,  6.6841e-01,  3.2963e-02,  4.9460e-01,\n",
            "           7.0010e-01,  4.3659e-01,  2.9002e-01],\n",
            "         [ 1.8295e-01,  2.1830e-01,  3.8937e-02,  2.8001e-01,  1.0750e-01,\n",
            "           7.4626e-01,  6.2869e-01,  2.5195e-01],\n",
            "         [ 7.1815e-01,  6.9138e-01,  1.0317e-01,  3.2483e-01,  4.5867e-02,\n",
            "           1.2953e-02,  9.6873e-02,  6.7956e-01],\n",
            "         [ 5.7905e-01,  3.2869e-01,  1.2894e-01,  8.2973e-02,  4.3174e-01,\n",
            "           4.8224e-01,  6.6655e-01,  1.6251e-03],\n",
            "         [ 1.5906e-01,  6.6379e-01,  5.6429e-01,  7.4434e-01,  5.1101e-01,\n",
            "           7.4678e-01,  7.1459e-01,  2.0890e-02]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([8, 8])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[-0.1816, -0.3187, -0.3479, -0.2039, -0.1735, -0.2771, -0.2705, -0.1640],\n",
            "        [-0.3171, -0.0626, -0.2148, -0.1513, -0.0908, -0.1580, -0.3695, -0.2949],\n",
            "        [-0.2766, -0.2421, -0.1871, -0.1314, -0.3310, -0.3533,  0.0036, -0.1375],\n",
            "        [-0.3018, -0.1996, -0.1495, -0.3251, -0.2496, -0.3176, -0.2855, -0.3080],\n",
            "        [-0.1260, -0.2560, -0.2517, -0.1439, -0.2419, -0.3417, -0.2201, -0.1528],\n",
            "        [-0.2721, -0.2151, -0.2322, -0.1592, -0.3629, -0.1094, -0.3815, -0.1628],\n",
            "        [-0.3130, -0.0798, -0.1326, -0.1764, -0.2650, -0.3103, -0.2869, -0.2602],\n",
            "        [-0.1154, -0.2092, -0.1726, -0.2790, -0.1259, -0.2201, -0.1489, -0.2415]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 3, 0\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([8, 8]) por self.weight.data[:,:,3,0].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[0.0745, 0.9615, 0.2886, 0.2710, 0.0328, 0.7251, 0.0128, 0.0387],\n",
            "        [0.0031, 0.2633, 0.2866, 0.1260, 0.4984, 0.1934, 0.7179, 0.3872],\n",
            "        [0.3059, 0.9682, 0.8170, 0.6575, 0.8604, 0.0079, 0.6977, 0.3461],\n",
            "        [0.3039, 0.0319, 0.6748, 0.0815, 0.5193, 0.2828, 0.8401, 0.2321],\n",
            "        [0.0742, 0.9718, 0.6309, 0.7814, 0.6638, 0.4626, 0.4363, 0.5028],\n",
            "        [0.5733, 0.6602, 0.6306, 0.9485, 0.1835, 0.0933, 0.7540, 0.8554],\n",
            "        [0.9603, 0.1951, 0.8628, 0.9012, 0.2780, 0.9308, 0.9806, 0.7708],\n",
            "        [0.6770, 0.8483, 0.3154, 0.2204, 0.1135, 0.7915, 0.3390, 0.8138]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[0.2313],\n",
            "        [0.3793]])\n",
            "[self.weight.data[:,:,3,0].view(2,)[i] for i in range(2)] = \n",
            "0.2313005030155182\n",
            "\n",
            "produto.shape: torch.Size([2, 8, 8]) produto: tensor([[[0.0172, 0.2224, 0.0667, 0.0627, 0.0076, 0.1677, 0.0030, 0.0090],\n",
            "         [0.0007, 0.0609, 0.0663, 0.0292, 0.1153, 0.0447, 0.1661, 0.0896],\n",
            "         [0.0708, 0.2240, 0.1890, 0.1521, 0.1990, 0.0018, 0.1614, 0.0801],\n",
            "         [0.0703, 0.0074, 0.1561, 0.0188, 0.1201, 0.0654, 0.1943, 0.0537],\n",
            "         [0.0172, 0.2248, 0.1459, 0.1807, 0.1535, 0.1070, 0.1009, 0.1163],\n",
            "         [0.1326, 0.1527, 0.1459, 0.2194, 0.0424, 0.0216, 0.1744, 0.1979],\n",
            "         [0.2221, 0.0451, 0.1996, 0.2085, 0.0643, 0.2153, 0.2268, 0.1783],\n",
            "         [0.1566, 0.1962, 0.0730, 0.0510, 0.0262, 0.1831, 0.0784, 0.1882]],\n",
            "\n",
            "        [[0.0283, 0.3647, 0.1095, 0.1028, 0.0125, 0.2751, 0.0049, 0.0147],\n",
            "         [0.0012, 0.0999, 0.1087, 0.0478, 0.1891, 0.0733, 0.2723, 0.1469],\n",
            "         [0.1160, 0.3673, 0.3099, 0.2494, 0.3264, 0.0030, 0.2646, 0.1313],\n",
            "         [0.1153, 0.0121, 0.2560, 0.0309, 0.1970, 0.1073, 0.3187, 0.0881],\n",
            "         [0.0282, 0.3686, 0.2393, 0.2964, 0.2518, 0.1755, 0.1655, 0.1907],\n",
            "         [0.2175, 0.2504, 0.2392, 0.3598, 0.0696, 0.0354, 0.2860, 0.3245],\n",
            "         [0.3643, 0.0740, 0.3273, 0.3419, 0.1055, 0.3531, 0.3720, 0.2924],\n",
            "         [0.2568, 0.3218, 0.1197, 0.0836, 0.0430, 0.3002, 0.1286, 0.3087]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([8, 8])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[-0.2797, -0.4419, -0.4879, -0.3264, -0.2528, -0.3046, -0.2987, -0.1682],\n",
            "        [-0.4517, -0.1708, -0.2906, -0.2893, -0.1540, -0.1888, -0.4671, -0.4135],\n",
            "        [-0.3654, -0.2460, -0.3448, -0.2801, -0.4594, -0.4564, -0.1553, -0.1783],\n",
            "        [-0.4255, -0.3301, -0.2887, -0.3319, -0.3526, -0.4634, -0.3764, -0.3684],\n",
            "        [-0.1641, -0.3015, -0.2598, -0.2022, -0.2642, -0.4971, -0.3509, -0.2052],\n",
            "        [-0.4216, -0.3591, -0.2537, -0.2269, -0.3724, -0.1121, -0.4017, -0.3043],\n",
            "        [-0.4336, -0.1482, -0.1595, -0.1937, -0.3549, -0.4107, -0.4257, -0.2606],\n",
            "        [-0.1485, -0.3474, -0.2900, -0.4340, -0.2323, -0.3755, -0.2977, -0.2459]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 3, 1\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([8, 8]) por self.weight.data[:,:,3,1].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[0.0971, 0.2299, 0.6110, 0.2675, 0.7964, 0.8869, 0.3534, 0.9173],\n",
            "        [0.9999, 0.5924, 0.5828, 0.4786, 0.5602, 0.5655, 0.9780, 0.0545],\n",
            "        [0.7875, 0.5997, 0.4343, 0.4868, 0.1361, 0.5514, 0.1832, 0.2592],\n",
            "        [0.9221, 0.7618, 0.0791, 0.1211, 0.4020, 0.2669, 0.0866, 0.9298],\n",
            "        [0.0342, 0.5944, 0.8447, 0.7198, 0.4412, 0.8429, 0.1431, 0.6635],\n",
            "        [0.1226, 0.9445, 0.7365, 0.0083, 0.3013, 0.8212, 0.0816, 0.8144],\n",
            "        [0.8089, 0.1788, 0.5481, 0.9201, 0.9250, 0.9606, 0.5618, 0.1229],\n",
            "        [0.6826, 0.9896, 0.6381, 0.4549, 0.8426, 0.4030, 0.6290, 0.5514]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[0.2698],\n",
            "        [1.1530]])\n",
            "[self.weight.data[:,:,3,1].view(2,)[i] for i in range(2)] = \n",
            "0.26980727910995483\n",
            "\n",
            "produto.shape: torch.Size([2, 8, 8]) produto: tensor([[[0.0262, 0.0620, 0.1648, 0.0722, 0.2149, 0.2393, 0.0953, 0.2475],\n",
            "         [0.2698, 0.1598, 0.1572, 0.1291, 0.1511, 0.1526, 0.2639, 0.0147],\n",
            "         [0.2125, 0.1618, 0.1172, 0.1313, 0.0367, 0.1488, 0.0494, 0.0699],\n",
            "         [0.2488, 0.2056, 0.0213, 0.0327, 0.1085, 0.0720, 0.0234, 0.2509],\n",
            "         [0.0092, 0.1604, 0.2279, 0.1942, 0.1190, 0.2274, 0.0386, 0.1790],\n",
            "         [0.0331, 0.2548, 0.1987, 0.0022, 0.0813, 0.2216, 0.0220, 0.2197],\n",
            "         [0.2182, 0.0483, 0.1479, 0.2483, 0.2496, 0.2592, 0.1516, 0.0332],\n",
            "         [0.1842, 0.2670, 0.1722, 0.1227, 0.2273, 0.1087, 0.1697, 0.1488]],\n",
            "\n",
            "        [[0.1120, 0.2651, 0.7045, 0.3084, 0.9183, 1.0225, 0.4075, 1.0577],\n",
            "         [1.1528, 0.6830, 0.6719, 0.5518, 0.6459, 0.6520, 1.1276, 0.0628],\n",
            "         [0.9080, 0.6915, 0.5008, 0.5613, 0.1569, 0.6357, 0.2113, 0.2989],\n",
            "         [1.0632, 0.8784, 0.0912, 0.1396, 0.4635, 0.3077, 0.0999, 1.0720],\n",
            "         [0.0394, 0.6853, 0.9740, 0.8299, 0.5087, 0.9718, 0.1650, 0.7650],\n",
            "         [0.1414, 1.0889, 0.8492, 0.0096, 0.3474, 0.9468, 0.0941, 0.9391],\n",
            "         [0.9326, 0.2062, 0.6319, 1.0609, 1.0665, 1.1076, 0.6478, 0.1418],\n",
            "         [0.7870, 1.1410, 0.7358, 0.5245, 0.9715, 0.4647, 0.7253, 0.6357]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([8, 8])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[-0.2625, -0.2195, -0.4212, -0.2637, -0.2452, -0.1369, -0.2957, -0.1593],\n",
            "        [-0.4509, -0.1099, -0.2243, -0.2602, -0.0387, -0.1441, -0.3011, -0.3239],\n",
            "        [-0.2946, -0.0221, -0.1558, -0.1281, -0.2604, -0.4546,  0.0060, -0.0983],\n",
            "        [-0.3552, -0.3227, -0.1326, -0.3131, -0.2324, -0.3980, -0.1821, -0.3147],\n",
            "        [-0.1470, -0.0767, -0.1138, -0.0215, -0.1107, -0.3901, -0.2500, -0.0889],\n",
            "        [-0.2890, -0.2064, -0.1078, -0.0075, -0.3300, -0.0905, -0.2273, -0.1064],\n",
            "        [-0.2114, -0.1031,  0.0401,  0.0147, -0.2906, -0.1954, -0.1989, -0.0823],\n",
            "        [ 0.0081, -0.1512, -0.2171, -0.3830, -0.2061, -0.1925, -0.2192, -0.0577]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 3, 2\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([8, 8]) por self.weight.data[:,:,3,2].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[0.4206, 0.3241, 0.8021, 0.6637, 0.3069, 0.6115, 0.9266, 0.1197],\n",
            "        [0.5459, 0.1780, 0.3426, 0.9687, 0.4914, 0.1395, 0.9830, 0.5848],\n",
            "        [0.4745, 0.5014, 0.7601, 0.1473, 0.6921, 0.5196, 0.0885, 0.0361],\n",
            "        [0.9685, 0.1817, 0.9459, 0.8094, 0.8446, 0.3802, 0.3048, 0.1362],\n",
            "        [0.4293, 0.0464, 0.1597, 0.6066, 0.1072, 0.5212, 0.1026, 0.8726],\n",
            "        [0.2016, 0.7832, 0.8663, 0.5005, 0.0048, 0.4290, 0.4406, 0.9513],\n",
            "        [0.6245, 0.5764, 0.8148, 0.2774, 0.5879, 0.0225, 0.2621, 0.3504],\n",
            "        [0.2888, 0.1457, 0.6555, 0.0385, 0.8534, 0.8209, 0.8641, 0.3976]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[0.2648],\n",
            "        [1.3851]])\n",
            "[self.weight.data[:,:,3,2].view(2,)[i] for i in range(2)] = \n",
            "0.2648315131664276\n",
            "\n",
            "produto.shape: torch.Size([2, 8, 8]) produto: tensor([[[1.1139e-01, 8.5831e-02, 2.1242e-01, 1.7576e-01, 8.1290e-02,\n",
            "          1.6195e-01, 2.4539e-01, 3.1703e-02],\n",
            "         [1.4457e-01, 4.7152e-02, 9.0725e-02, 2.5655e-01, 1.3015e-01,\n",
            "          3.6937e-02, 2.6034e-01, 1.5488e-01],\n",
            "         [1.2565e-01, 1.3278e-01, 2.0130e-01, 3.9005e-02, 1.8330e-01,\n",
            "          1.3761e-01, 2.3439e-02, 9.5734e-03],\n",
            "         [2.5649e-01, 4.8123e-02, 2.5050e-01, 2.1434e-01, 2.2368e-01,\n",
            "          1.0070e-01, 8.0714e-02, 3.6058e-02],\n",
            "         [1.1370e-01, 1.2294e-02, 4.2298e-02, 1.6064e-01, 2.8402e-02,\n",
            "          1.3802e-01, 2.7167e-02, 2.3110e-01],\n",
            "         [5.3390e-02, 2.0741e-01, 2.2942e-01, 1.3256e-01, 1.2746e-03,\n",
            "          1.1360e-01, 1.1668e-01, 2.5192e-01],\n",
            "         [1.6540e-01, 1.5265e-01, 2.1580e-01, 7.3460e-02, 1.5569e-01,\n",
            "          5.9593e-03, 6.9419e-02, 9.2802e-02],\n",
            "         [7.6474e-02, 3.8587e-02, 1.7361e-01, 1.0205e-02, 2.2601e-01,\n",
            "          2.1740e-01, 2.2884e-01, 1.0530e-01]],\n",
            "\n",
            "        [[5.8261e-01, 4.4891e-01, 1.1110e+00, 9.1928e-01, 4.2516e-01,\n",
            "          8.4704e-01, 1.2834e+00, 1.6581e-01],\n",
            "         [7.5615e-01, 2.4661e-01, 4.7451e-01, 1.3418e+00, 6.8071e-01,\n",
            "          1.9319e-01, 1.3616e+00, 8.1005e-01],\n",
            "         [6.5717e-01, 6.9444e-01, 1.0529e+00, 2.0400e-01, 9.5868e-01,\n",
            "          7.1971e-01, 1.2259e-01, 5.0070e-02],\n",
            "         [1.3415e+00, 2.5169e-01, 1.3101e+00, 1.1210e+00, 1.1699e+00,\n",
            "          5.2667e-01, 4.2215e-01, 1.8859e-01],\n",
            "         [5.9465e-01, 6.4302e-02, 2.2123e-01, 8.4018e-01, 1.4855e-01,\n",
            "          7.2186e-01, 1.4209e-01, 1.2087e+00],\n",
            "         [2.7924e-01, 1.0848e+00, 1.1999e+00, 6.9331e-01, 6.6665e-03,\n",
            "          5.9416e-01, 6.1028e-01, 1.3176e+00],\n",
            "         [8.6506e-01, 7.9837e-01, 1.1287e+00, 3.8421e-01, 8.1427e-01,\n",
            "          3.1168e-02, 3.6307e-01, 4.8537e-01],\n",
            "         [3.9997e-01, 2.0181e-01, 9.0800e-01, 5.3376e-02, 1.1821e+00,\n",
            "          1.1370e+00, 1.1969e+00, 5.5072e-01]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([8, 8])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[-0.2363, -0.1574, -0.2563, -0.1916, -0.0303,  0.1024, -0.2004,  0.0882],\n",
            "        [-0.1812,  0.0499, -0.0671, -0.1311,  0.1124,  0.0085, -0.0372, -0.3092],\n",
            "        [-0.0822,  0.1397, -0.0386,  0.0033, -0.2237, -0.3058,  0.0555, -0.0283],\n",
            "        [-0.1065, -0.1172, -0.1112, -0.2804, -0.1240, -0.3259, -0.1587, -0.0639],\n",
            "        [-0.1377,  0.0836,  0.1141,  0.1727,  0.0083, -0.1627, -0.2114,  0.0901],\n",
            "        [-0.2559,  0.0485,  0.0909, -0.0053, -0.2487,  0.1311, -0.2053,  0.1133],\n",
            "        [ 0.0068, -0.0548,  0.1880,  0.2630, -0.0410,  0.0638, -0.0473, -0.0491],\n",
            "        [ 0.1923,  0.1158, -0.0449, -0.2603,  0.0213, -0.0837, -0.0495,  0.0911]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 3, 3\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([8, 8]) por self.weight.data[:,:,3,3].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[0.9615, 0.2886, 0.2710, 0.0328, 0.7251, 0.0128, 0.0387, 0.3913],\n",
            "        [0.2633, 0.2866, 0.1260, 0.4984, 0.1934, 0.7179, 0.3872, 0.8722],\n",
            "        [0.9682, 0.8170, 0.6575, 0.8604, 0.0079, 0.6977, 0.3461, 0.8626],\n",
            "        [0.0319, 0.6748, 0.0815, 0.5193, 0.2828, 0.8401, 0.2321, 0.7575],\n",
            "        [0.9718, 0.6309, 0.7814, 0.6638, 0.4626, 0.4363, 0.5028, 0.4722],\n",
            "        [0.6602, 0.6306, 0.9485, 0.1835, 0.0933, 0.7540, 0.8554, 0.9368],\n",
            "        [0.1951, 0.8628, 0.9012, 0.2780, 0.9308, 0.9806, 0.7708, 0.8441],\n",
            "        [0.8483, 0.3154, 0.2204, 0.1135, 0.7915, 0.3390, 0.8138, 0.4924]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[0.1012],\n",
            "        [1.1669]])\n",
            "[self.weight.data[:,:,3,3].view(2,)[i] for i in range(2)] = \n",
            "0.10117228329181671\n",
            "\n",
            "produto.shape: torch.Size([2, 8, 8]) produto: tensor([[[9.7282e-02, 2.9195e-02, 2.7416e-02, 3.3221e-03, 7.3360e-02,\n",
            "          1.2963e-03, 3.9165e-03, 3.9591e-02],\n",
            "         [2.6643e-02, 2.9000e-02, 1.2751e-02, 5.0429e-02, 1.9562e-02,\n",
            "          7.2633e-02, 3.9171e-02, 8.8243e-02],\n",
            "         [9.7958e-02, 8.2663e-02, 6.6518e-02, 8.7044e-02, 8.0069e-04,\n",
            "          7.0584e-02, 3.5019e-02, 8.7267e-02],\n",
            "         [3.2319e-03, 6.8269e-02, 8.2440e-03, 5.2539e-02, 2.8608e-02,\n",
            "          8.5000e-02, 2.3486e-02, 7.6636e-02],\n",
            "         [9.8319e-02, 6.3834e-02, 7.9053e-02, 6.7155e-02, 4.6804e-02,\n",
            "          4.4138e-02, 5.0868e-02, 4.7775e-02],\n",
            "         [6.6798e-02, 6.3799e-02, 9.5957e-02, 1.8567e-02, 9.4386e-03,\n",
            "          7.6288e-02, 8.6541e-02, 9.4782e-02],\n",
            "         [1.9743e-02, 8.7293e-02, 9.1181e-02, 2.8126e-02, 9.4169e-02,\n",
            "          9.9207e-02, 7.7983e-02, 8.5403e-02],\n",
            "         [8.5823e-02, 3.1913e-02, 2.2300e-02, 1.1479e-02, 8.0073e-02,\n",
            "          3.4299e-02, 8.2335e-02, 4.9820e-02]],\n",
            "\n",
            "        [[1.1220e+00, 3.3672e-01, 3.1620e-01, 3.8315e-02, 8.4611e-01,\n",
            "          1.4951e-02, 4.5172e-02, 4.5663e-01],\n",
            "         [3.0728e-01, 3.3448e-01, 1.4706e-01, 5.8162e-01, 2.2562e-01,\n",
            "          8.3772e-01, 4.5179e-01, 1.0178e+00],\n",
            "         [1.1298e+00, 9.5340e-01, 7.6720e-01, 1.0039e+00, 9.2348e-03,\n",
            "          8.1408e-01, 4.0390e-01, 1.0065e+00],\n",
            "         [3.7276e-02, 7.8738e-01, 9.5083e-02, 6.0597e-01, 3.2995e-01,\n",
            "          9.8035e-01, 2.7088e-01, 8.8389e-01],\n",
            "         [1.1340e+00, 7.3623e-01, 9.1176e-01, 7.7454e-01, 5.3982e-01,\n",
            "          5.0907e-01, 5.8669e-01, 5.5102e-01],\n",
            "         [7.7042e-01, 7.3583e-01, 1.1067e+00, 2.1414e-01, 1.0886e-01,\n",
            "          8.7987e-01, 9.9813e-01, 1.0932e+00],\n",
            "         [2.2770e-01, 1.0068e+00, 1.0516e+00, 3.2440e-01, 1.0861e+00,\n",
            "          1.1442e+00, 8.9943e-01, 9.8500e-01],\n",
            "         [9.8984e-01, 3.6807e-01, 2.5720e-01, 1.3239e-01, 9.2353e-01,\n",
            "          3.9559e-01, 9.4962e-01, 5.7460e-01]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([8, 8])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[-0.1249, -0.0716, -0.0439, -0.0158,  0.0510,  0.2643,  0.0450,  0.1199],\n",
            "        [-0.0366,  0.0971,  0.0237,  0.1255,  0.2426,  0.0454,  0.2231, -0.1543],\n",
            "        [ 0.0435,  0.2725,  0.1627,  0.0423, -0.0404, -0.1682,  0.0789, -0.0187],\n",
            "        [ 0.1500, -0.0690,  0.1393, -0.0661,  0.0997, -0.2252, -0.0780, -0.0278],\n",
            "        [-0.0240,  0.0959,  0.1564,  0.3334,  0.0367, -0.0246, -0.1843,  0.3212],\n",
            "        [-0.2025,  0.2559,  0.3204,  0.1273, -0.2474,  0.2447, -0.0886,  0.3652],\n",
            "        [ 0.1722,  0.0978,  0.4038,  0.3365,  0.1147,  0.0698,  0.0221,  0.0437],\n",
            "        [ 0.2687,  0.1544,  0.1287, -0.2501,  0.2473,  0.1337,  0.1793,  0.1964]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 3, 4\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([8, 8]) por self.weight.data[:,:,3,4].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[0.2299, 0.6110, 0.2675, 0.7964, 0.8869, 0.3534, 0.9173, 0.8494],\n",
            "        [0.5924, 0.5828, 0.4786, 0.5602, 0.5655, 0.9780, 0.0545, 0.5914],\n",
            "        [0.5997, 0.4343, 0.4868, 0.1361, 0.5514, 0.1832, 0.2592, 0.5530],\n",
            "        [0.7618, 0.0791, 0.1211, 0.4020, 0.2669, 0.0866, 0.9298, 0.8210],\n",
            "        [0.5944, 0.8447, 0.7198, 0.4412, 0.8429, 0.1431, 0.6635, 0.6950],\n",
            "        [0.9445, 0.7365, 0.0083, 0.3013, 0.8212, 0.0816, 0.8144, 0.0420],\n",
            "        [0.1788, 0.5481, 0.9201, 0.9250, 0.9606, 0.5618, 0.1229, 0.9065],\n",
            "        [0.9896, 0.6381, 0.4549, 0.8426, 0.4030, 0.6290, 0.5514, 0.7192]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[0.0215],\n",
            "        [0.7618]])\n",
            "[self.weight.data[:,:,3,4].view(2,)[i] for i in range(2)] = \n",
            "0.021521691232919693\n",
            "\n",
            "produto.shape: torch.Size([2, 8, 8]) produto: tensor([[[4.9478e-03, 1.3150e-02, 5.7570e-03, 1.7140e-02, 1.9087e-02,\n",
            "          7.6056e-03, 1.9742e-02, 1.8280e-02],\n",
            "         [1.2749e-02, 1.2542e-02, 1.0301e-02, 1.2056e-02, 1.2170e-02,\n",
            "          2.1048e-02, 1.1724e-03, 1.2728e-02],\n",
            "         [1.2907e-02, 9.3474e-03, 1.0477e-02, 2.9294e-03, 1.1867e-02,\n",
            "          3.9438e-03, 5.5786e-03, 1.1902e-02],\n",
            "         [1.6396e-02, 1.7022e-03, 2.6061e-03, 8.6508e-03, 5.7441e-03,\n",
            "          1.8643e-03, 2.0010e-02, 1.7669e-02],\n",
            "         [1.2792e-02, 1.8180e-02, 1.5490e-02, 9.4956e-03, 1.8140e-02,\n",
            "          3.0791e-03, 1.4280e-02, 1.4957e-02],\n",
            "         [2.0326e-02, 1.5852e-02, 1.7829e-04, 6.4848e-03, 1.7674e-02,\n",
            "          1.7564e-03, 1.7528e-02, 9.0359e-04],\n",
            "         [3.8488e-03, 1.1795e-02, 1.9803e-02, 1.9907e-02, 2.0674e-02,\n",
            "          1.2091e-02, 2.6460e-03, 1.9509e-02],\n",
            "         [2.1298e-02, 1.3734e-02, 9.7909e-03, 1.8134e-02, 8.6736e-03,\n",
            "          1.3538e-02, 1.1866e-02, 1.5479e-02]],\n",
            "\n",
            "        [[1.7515e-01, 4.6548e-01, 2.0379e-01, 6.0676e-01, 6.7565e-01,\n",
            "          2.6923e-01, 6.9886e-01, 6.4708e-01],\n",
            "         [4.5132e-01, 4.4398e-01, 3.6463e-01, 4.2676e-01, 4.3080e-01,\n",
            "          7.4507e-01, 4.1501e-02, 4.5057e-01],\n",
            "         [4.5689e-01, 3.3089e-01, 3.7086e-01, 1.0370e-01, 4.2007e-01,\n",
            "          1.3961e-01, 1.9748e-01, 4.2134e-01],\n",
            "         [5.8041e-01, 6.0255e-02, 9.2255e-02, 3.0623e-01, 2.0333e-01,\n",
            "          6.5993e-02, 7.0833e-01, 6.2548e-01],\n",
            "         [4.5281e-01, 6.4357e-01, 5.4834e-01, 3.3613e-01, 6.4214e-01,\n",
            "          1.0900e-01, 5.0548e-01, 5.2947e-01],\n",
            "         [7.1953e-01, 5.6113e-01, 6.3113e-03, 2.2956e-01, 6.2563e-01,\n",
            "          6.2175e-02, 6.2049e-01, 3.1986e-02],\n",
            "         [1.3624e-01, 4.1754e-01, 7.0100e-01, 7.0468e-01, 7.3182e-01,\n",
            "          4.2802e-01, 9.3664e-02, 6.9059e-01],\n",
            "         [7.5393e-01, 4.8616e-01, 3.4659e-01, 6.4194e-01, 3.0704e-01,\n",
            "          4.7922e-01, 4.2006e-01, 5.4793e-01]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([8, 8])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[-0.0276, -0.0424, -0.0165, -0.0125,  0.1243,  0.2656,  0.0489,  0.1595],\n",
            "        [-0.0099,  0.1261,  0.0364,  0.1759,  0.2621,  0.1181,  0.2623, -0.0661],\n",
            "        [ 0.1414,  0.3552,  0.2292,  0.1293, -0.0396, -0.0976,  0.1139,  0.0685],\n",
            "        [ 0.1533, -0.0008,  0.1475, -0.0135,  0.1283, -0.1402, -0.0545,  0.0488],\n",
            "        [ 0.0743,  0.1598,  0.2354,  0.4005,  0.0835,  0.0195, -0.1334,  0.3689],\n",
            "        [-0.1357,  0.3197,  0.4163,  0.1459, -0.2380,  0.3210, -0.0020,  0.4600],\n",
            "        [ 0.1919,  0.1851,  0.4950,  0.3646,  0.2088,  0.1690,  0.1001,  0.1291],\n",
            "        [ 0.3546,  0.1863,  0.1510, -0.2386,  0.3273,  0.1680,  0.2616,  0.2462]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 4, 0\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([8, 8]) por self.weight.data[:,:,4,0].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[0.3994, 0.8265, 0.3689, 0.7347, 0.6853, 0.1683, 0.9723, 0.1683],\n",
            "        [0.0329, 0.2383, 0.3689, 0.4727, 0.4298, 0.4436, 0.8295, 0.4351],\n",
            "        [0.2981, 0.9128, 0.3634, 0.3227, 0.5017, 0.8008, 0.7480, 0.3820],\n",
            "        [0.8159, 0.9152, 0.6807, 0.3895, 0.2321, 0.9395, 0.9187, 0.8010],\n",
            "        [0.1914, 0.2799, 0.4354, 0.9764, 0.7306, 0.5367, 0.5033, 0.7527],\n",
            "        [0.8904, 0.6690, 0.3629, 0.1336, 0.7523, 0.3409, 0.8371, 0.8204],\n",
            "        [0.3683, 0.5900, 0.3046, 0.1279, 0.7824, 0.4059, 0.0704, 0.1030],\n",
            "        [0.4493, 0.6216, 0.0582, 0.5264, 0.3610, 0.0643, 0.0583, 0.0413]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[0.3418],\n",
            "        [0.0962]])\n",
            "[self.weight.data[:,:,4,0].view(2,)[i] for i in range(2)] = \n",
            "0.34178605675697327\n",
            "\n",
            "produto.shape: torch.Size([2, 8, 8]) produto: tensor([[[0.1365, 0.2825, 0.1261, 0.2511, 0.2342, 0.0575, 0.3323, 0.0575],\n",
            "         [0.0113, 0.0814, 0.1261, 0.1616, 0.1469, 0.1516, 0.2835, 0.1487],\n",
            "         [0.1019, 0.3120, 0.1242, 0.1103, 0.1715, 0.2737, 0.2557, 0.1306],\n",
            "         [0.2789, 0.3128, 0.2327, 0.1331, 0.0793, 0.3211, 0.3140, 0.2738],\n",
            "         [0.0654, 0.0957, 0.1488, 0.3337, 0.2497, 0.1834, 0.1720, 0.2573],\n",
            "         [0.3043, 0.2287, 0.1240, 0.0457, 0.2571, 0.1165, 0.2861, 0.2804],\n",
            "         [0.1259, 0.2017, 0.1041, 0.0437, 0.2674, 0.1387, 0.0241, 0.0352],\n",
            "         [0.1536, 0.2125, 0.0199, 0.1799, 0.1234, 0.0220, 0.0199, 0.0141]],\n",
            "\n",
            "        [[0.0384, 0.0795, 0.0355, 0.0707, 0.0659, 0.0162, 0.0935, 0.0162],\n",
            "         [0.0032, 0.0229, 0.0355, 0.0455, 0.0414, 0.0427, 0.0798, 0.0419],\n",
            "         [0.0287, 0.0878, 0.0350, 0.0310, 0.0483, 0.0770, 0.0720, 0.0367],\n",
            "         [0.0785, 0.0880, 0.0655, 0.0375, 0.0223, 0.0904, 0.0884, 0.0771],\n",
            "         [0.0184, 0.0269, 0.0419, 0.0939, 0.0703, 0.0516, 0.0484, 0.0724],\n",
            "         [0.0857, 0.0644, 0.0349, 0.0129, 0.0724, 0.0328, 0.0805, 0.0789],\n",
            "         [0.0354, 0.0568, 0.0293, 0.0123, 0.0753, 0.0390, 0.0068, 0.0099],\n",
            "         [0.0432, 0.0598, 0.0056, 0.0506, 0.0347, 0.0062, 0.0056, 0.0040]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([8, 8])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[-0.0226, -0.0293, -0.0107,  0.0047,  0.1434,  0.2732,  0.0687,  0.1778],\n",
            "        [ 0.0028,  0.1386,  0.0467,  0.1880,  0.2743,  0.1391,  0.2635, -0.0534],\n",
            "        [ 0.1543,  0.3645,  0.2397,  0.1323, -0.0277, -0.0937,  0.1195,  0.0804],\n",
            "        [ 0.1697,  0.0009,  0.1501, -0.0049,  0.1340, -0.1384, -0.0345,  0.0665],\n",
            "        [ 0.0871,  0.1780,  0.2509,  0.4100,  0.1017,  0.0226, -0.1191,  0.3839],\n",
            "        [-0.1154,  0.3355,  0.4165,  0.1524, -0.2203,  0.3227,  0.0155,  0.4609],\n",
            "        [ 0.1958,  0.1969,  0.5148,  0.3845,  0.2295,  0.1811,  0.1027,  0.1486],\n",
            "        [ 0.3759,  0.2001,  0.1608, -0.2204,  0.3360,  0.1815,  0.2735,  0.2617]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 4, 1\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([8, 8]) por self.weight.data[:,:,4,1].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[0.1294, 0.7534, 0.1210, 0.6027, 0.1452, 0.0279, 0.2570, 0.9514],\n",
            "        [0.6061, 0.3850, 0.7561, 0.4849, 0.1450, 0.6687, 0.3543, 0.0805],\n",
            "        [0.3215, 0.8084, 0.9109, 0.6418, 0.8790, 0.2195, 0.6036, 0.8986],\n",
            "        [0.0257, 0.1816, 0.3152, 0.6427, 0.3456, 0.1244, 0.6009, 0.0779],\n",
            "        [0.8704, 0.5159, 0.1799, 0.0239, 0.2297, 0.9239, 0.1917, 0.8967],\n",
            "        [0.4322, 0.6446, 0.2140, 0.8058, 0.1501, 0.5355, 0.6785, 0.0539],\n",
            "        [0.2075, 0.6203, 0.7517, 0.2288, 0.1864, 0.1886, 0.9784, 0.1536],\n",
            "        [0.0843, 0.1567, 0.6815, 0.6800, 0.8267, 0.1243, 0.5357, 0.9909]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[0.5196],\n",
            "        [0.8732]])\n",
            "[self.weight.data[:,:,4,1].view(2,)[i] for i in range(2)] = \n",
            "0.5196305513381958\n",
            "\n",
            "produto.shape: torch.Size([2, 8, 8]) produto: tensor([[[0.0673, 0.3915, 0.0629, 0.3132, 0.0754, 0.0145, 0.1335, 0.4944],\n",
            "         [0.3150, 0.2000, 0.3929, 0.2520, 0.0754, 0.3475, 0.1841, 0.0418],\n",
            "         [0.1671, 0.4201, 0.4733, 0.3335, 0.4568, 0.1141, 0.3137, 0.4670],\n",
            "         [0.0134, 0.0944, 0.1638, 0.3339, 0.1796, 0.0646, 0.3122, 0.0405],\n",
            "         [0.4523, 0.2681, 0.0935, 0.0124, 0.1193, 0.4801, 0.0996, 0.4659],\n",
            "         [0.2246, 0.3350, 0.1112, 0.4187, 0.0780, 0.2783, 0.3526, 0.0280],\n",
            "         [0.1078, 0.3223, 0.3906, 0.1189, 0.0969, 0.0980, 0.5084, 0.0798],\n",
            "         [0.0438, 0.0814, 0.3541, 0.3533, 0.4296, 0.0646, 0.2784, 0.5149]],\n",
            "\n",
            "        [[0.1130, 0.6579, 0.1057, 0.5263, 0.1268, 0.0244, 0.2244, 0.8307],\n",
            "         [0.5293, 0.3361, 0.6602, 0.4234, 0.1266, 0.5839, 0.3094, 0.0703],\n",
            "         [0.2807, 0.7059, 0.7953, 0.5604, 0.7675, 0.1917, 0.5271, 0.7846],\n",
            "         [0.0224, 0.1586, 0.2752, 0.5611, 0.3018, 0.1086, 0.5246, 0.0680],\n",
            "         [0.7600, 0.4505, 0.1571, 0.0208, 0.2005, 0.8067, 0.1674, 0.7829],\n",
            "         [0.3773, 0.5629, 0.1868, 0.7036, 0.1311, 0.4676, 0.5924, 0.0470],\n",
            "         [0.1811, 0.5416, 0.6564, 0.1997, 0.1628, 0.1647, 0.8543, 0.1341],\n",
            "         [0.0736, 0.1368, 0.5951, 0.5937, 0.7218, 0.1085, 0.4678, 0.8652]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([8, 8])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[ 0.1139,  0.2532,  0.1153,  0.2558,  0.3776,  0.3307,  0.4010,  0.2353],\n",
            "        [ 0.0141,  0.2201,  0.1728,  0.3495,  0.4212,  0.2907,  0.5470,  0.0953],\n",
            "        [ 0.2562,  0.6765,  0.3639,  0.2425,  0.1437,  0.1800,  0.3752,  0.2110],\n",
            "        [ 0.4485,  0.3137,  0.3828,  0.1282,  0.2134,  0.1827,  0.2795,  0.3403],\n",
            "        [ 0.1525,  0.2736,  0.3997,  0.7437,  0.3514,  0.2060,  0.0529,  0.6412],\n",
            "        [ 0.1889,  0.5642,  0.5405,  0.1980,  0.0369,  0.4392,  0.3016,  0.7413],\n",
            "        [ 0.3217,  0.3986,  0.6189,  0.4282,  0.4969,  0.3198,  0.1268,  0.1838],\n",
            "        [ 0.5294,  0.4125,  0.1807, -0.0405,  0.4594,  0.2035,  0.2934,  0.2758]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 4, 2\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([8, 8]) por self.weight.data[:,:,4,2].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[4.5934e-01, 4.4913e-02, 1.8199e-01, 9.7552e-01, 6.3655e-01, 7.4109e-02,\n",
            "         8.8271e-01, 2.0317e-01],\n",
            "        [9.7452e-01, 5.9646e-01, 6.2156e-01, 3.0533e-01, 9.9630e-01, 6.8975e-01,\n",
            "         1.0604e-01, 3.4315e-01],\n",
            "        [1.3247e-01, 3.9760e-01, 3.6575e-01, 3.1287e-01, 1.2604e-01, 3.8633e-01,\n",
            "         8.1289e-01, 1.5036e-01],\n",
            "        [6.7321e-01, 5.3942e-01, 9.3807e-01, 7.2315e-01, 4.7240e-01, 7.5231e-01,\n",
            "         1.9832e-01, 6.4911e-01],\n",
            "        [2.3413e-01, 2.6798e-01, 1.7702e-01, 4.7022e-01, 7.0386e-01, 9.2415e-01,\n",
            "         3.9994e-01, 5.5045e-01],\n",
            "        [4.2963e-01, 8.5763e-01, 7.3549e-01, 3.8694e-01, 1.5015e-01, 3.4740e-01,\n",
            "         6.5637e-01, 7.4219e-01],\n",
            "        [7.4922e-01, 8.6804e-01, 5.8950e-01, 1.9111e-01, 2.6619e-02, 3.0555e-01,\n",
            "         9.7379e-01, 4.6473e-01],\n",
            "        [3.3075e-01, 3.2001e-01, 6.2949e-01, 6.9261e-01, 7.3481e-04, 5.2862e-01,\n",
            "         4.9338e-01, 3.8317e-01]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[0.4717],\n",
            "        [1.1107]])\n",
            "[self.weight.data[:,:,4,2].view(2,)[i] for i in range(2)] = \n",
            "0.471690833568573\n",
            "\n",
            "produto.shape: torch.Size([2, 8, 8]) produto: tensor([[[2.1667e-01, 2.1185e-02, 8.5844e-02, 4.6014e-01, 3.0025e-01,\n",
            "          3.4956e-02, 4.1637e-01, 9.5832e-02],\n",
            "         [4.5967e-01, 2.8135e-01, 2.9318e-01, 1.4402e-01, 4.6995e-01,\n",
            "          3.2535e-01, 5.0018e-02, 1.6186e-01],\n",
            "         [6.2484e-02, 1.8755e-01, 1.7252e-01, 1.4758e-01, 5.9452e-02,\n",
            "          1.8223e-01, 3.8343e-01, 7.0925e-02],\n",
            "         [3.1755e-01, 2.5444e-01, 4.4248e-01, 3.4110e-01, 2.2282e-01,\n",
            "          3.5486e-01, 9.3545e-02, 3.0618e-01],\n",
            "         [1.1044e-01, 1.2641e-01, 8.3500e-02, 2.2180e-01, 3.3200e-01,\n",
            "          4.3591e-01, 1.8865e-01, 2.5964e-01],\n",
            "         [2.0265e-01, 4.0453e-01, 3.4692e-01, 1.8252e-01, 7.0823e-02,\n",
            "          1.6387e-01, 3.0960e-01, 3.5009e-01],\n",
            "         [3.5340e-01, 4.0945e-01, 2.7806e-01, 9.0146e-02, 1.2556e-02,\n",
            "          1.4413e-01, 4.5933e-01, 2.1921e-01],\n",
            "         [1.5601e-01, 1.5095e-01, 2.9693e-01, 3.2670e-01, 3.4660e-04,\n",
            "          2.4934e-01, 2.3272e-01, 1.8074e-01]],\n",
            "\n",
            "        [[5.1021e-01, 4.9887e-02, 2.0215e-01, 1.0836e+00, 7.0704e-01,\n",
            "          8.2316e-02, 9.8046e-01, 2.2567e-01],\n",
            "         [1.0824e+00, 6.6251e-01, 6.9039e-01, 3.3914e-01, 1.1066e+00,\n",
            "          7.6613e-01, 1.1778e-01, 3.8116e-01],\n",
            "         [1.4714e-01, 4.4163e-01, 4.0626e-01, 3.4752e-01, 1.4000e-01,\n",
            "          4.2911e-01, 9.0291e-01, 1.6701e-01],\n",
            "         [7.4777e-01, 5.9916e-01, 1.0420e+00, 8.0323e-01, 5.2471e-01,\n",
            "          8.3562e-01, 2.2028e-01, 7.2099e-01],\n",
            "         [2.6006e-01, 2.9766e-01, 1.9663e-01, 5.2230e-01, 7.8180e-01,\n",
            "          1.0265e+00, 4.4423e-01, 6.1141e-01],\n",
            "         [4.7721e-01, 9.5260e-01, 8.1694e-01, 4.2979e-01, 1.6677e-01,\n",
            "          3.8588e-01, 7.2905e-01, 8.2439e-01],\n",
            "         [8.3219e-01, 9.6417e-01, 6.5478e-01, 2.1228e-01, 2.9567e-02,\n",
            "          3.3939e-01, 1.0816e+00, 5.1620e-01],\n",
            "         [3.6738e-01, 3.5545e-01, 6.9920e-01, 7.6931e-01, 8.1618e-04,\n",
            "          5.8716e-01, 5.4802e-01, 4.2561e-01]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([8, 8])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[0.1811, 0.6447, 0.1782, 0.5690, 0.4531, 0.3452, 0.5345, 0.7297],\n",
            "        [0.3290, 0.4201, 0.5657, 0.6015, 0.4966, 0.6382, 0.7311, 0.1372],\n",
            "        [0.4233, 1.0966, 0.8372, 0.5761, 0.6005, 0.2941, 0.6888, 0.6779],\n",
            "        [0.4619, 0.4081, 0.5466, 0.4622, 0.3930, 0.2474, 0.5917, 0.3807],\n",
            "        [0.6048, 0.5417, 0.4932, 0.7561, 0.4707, 0.6861, 0.1525, 1.1071],\n",
            "        [0.4135, 0.8992, 0.6517, 0.6167, 0.1149, 0.7175, 0.6542, 0.7693],\n",
            "        [0.4295, 0.7209, 1.0095, 0.5471, 0.5938, 0.4178, 0.6352, 0.2636],\n",
            "        [0.5732, 0.4940, 0.5348, 0.3128, 0.8890, 0.2680, 0.5718, 0.7907]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 4, 3\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([8, 8]) por self.weight.data[:,:,4,3].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[0.8265, 0.3689, 0.7347, 0.6853, 0.1683, 0.9723, 0.1683, 0.6429],\n",
            "        [0.2383, 0.3689, 0.4727, 0.4298, 0.4436, 0.8295, 0.4351, 0.2455],\n",
            "        [0.9128, 0.3634, 0.3227, 0.5017, 0.8008, 0.7480, 0.3820, 0.6495],\n",
            "        [0.9152, 0.6807, 0.3895, 0.2321, 0.9395, 0.9187, 0.8010, 0.3563],\n",
            "        [0.2799, 0.4354, 0.9764, 0.7306, 0.5367, 0.5033, 0.7527, 0.2609],\n",
            "        [0.6690, 0.3629, 0.1336, 0.7523, 0.3409, 0.8371, 0.8204, 0.2216],\n",
            "        [0.5900, 0.3046, 0.1279, 0.7824, 0.4059, 0.0704, 0.1030, 0.1145],\n",
            "        [0.6216, 0.0582, 0.5264, 0.3610, 0.0643, 0.0583, 0.0413, 0.8595]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[0.2054],\n",
            "        [0.2899]])\n",
            "[self.weight.data[:,:,4,3].view(2,)[i] for i in range(2)] = \n",
            "0.20540891587734222\n",
            "\n",
            "produto.shape: torch.Size([2, 8, 8]) produto: tensor([[[0.1698, 0.0758, 0.1509, 0.1408, 0.0346, 0.1997, 0.0346, 0.1320],\n",
            "         [0.0489, 0.0758, 0.0971, 0.0883, 0.0911, 0.1704, 0.0894, 0.0504],\n",
            "         [0.1875, 0.0746, 0.0663, 0.1030, 0.1645, 0.1536, 0.0785, 0.1334],\n",
            "         [0.1880, 0.1398, 0.0800, 0.0477, 0.1930, 0.1887, 0.1645, 0.0732],\n",
            "         [0.0575, 0.0894, 0.2006, 0.1501, 0.1102, 0.1034, 0.1546, 0.0536],\n",
            "         [0.1374, 0.0745, 0.0274, 0.1545, 0.0700, 0.1720, 0.1685, 0.0455],\n",
            "         [0.1212, 0.0626, 0.0263, 0.1607, 0.0834, 0.0145, 0.0212, 0.0235],\n",
            "         [0.1277, 0.0119, 0.1081, 0.0742, 0.0132, 0.0120, 0.0085, 0.1765]],\n",
            "\n",
            "        [[0.2396, 0.1070, 0.2130, 0.1987, 0.0488, 0.2819, 0.0488, 0.1864],\n",
            "         [0.0691, 0.1070, 0.1370, 0.1246, 0.1286, 0.2405, 0.1261, 0.0712],\n",
            "         [0.2646, 0.1053, 0.0935, 0.1454, 0.2322, 0.2169, 0.1107, 0.1883],\n",
            "         [0.2653, 0.1974, 0.1129, 0.0673, 0.2724, 0.2664, 0.2322, 0.1033],\n",
            "         [0.0811, 0.1262, 0.2831, 0.2118, 0.1556, 0.1459, 0.2182, 0.0756],\n",
            "         [0.1940, 0.1052, 0.0387, 0.2181, 0.0988, 0.2427, 0.2378, 0.0643],\n",
            "         [0.1711, 0.0883, 0.0371, 0.2268, 0.1177, 0.0204, 0.0299, 0.0332],\n",
            "         [0.1802, 0.0169, 0.1526, 0.1047, 0.0186, 0.0169, 0.0120, 0.2492]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([8, 8])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[0.3978, 0.6659, 0.2641, 1.0291, 0.7533, 0.3802, 0.9509, 0.8255],\n",
            "        [0.7887, 0.7014, 0.8589, 0.7455, 0.9665, 0.9636, 0.7811, 0.2990],\n",
            "        [0.4858, 1.2841, 1.0097, 0.7236, 0.6600, 0.4763, 1.0723, 0.7489],\n",
            "        [0.7794, 0.6625, 0.9890, 0.8033, 0.6158, 0.6022, 0.6853, 0.6869],\n",
            "        [0.7152, 0.6681, 0.5767, 0.9779, 0.8027, 1.1220, 0.3412, 1.3668],\n",
            "        [0.6161, 1.3037, 0.9986, 0.7992, 0.1857, 0.8814, 0.9638, 1.1194],\n",
            "        [0.7829, 1.1303, 1.2875, 0.6372, 0.6063, 0.5619, 1.0945, 0.4828],\n",
            "        [0.7292, 0.6449, 0.8317, 0.6395, 0.8893, 0.5174, 0.8046, 0.9714]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 4, 4\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([8, 8]) por self.weight.data[:,:,4,4].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[7.5343e-01, 1.2102e-01, 6.0274e-01, 1.4519e-01, 2.7941e-02, 2.5698e-01,\n",
            "         9.5139e-01, 8.4507e-04],\n",
            "        [3.8495e-01, 7.5607e-01, 4.8486e-01, 1.4502e-01, 6.6873e-01, 3.5431e-01,\n",
            "         8.0488e-02, 3.7389e-03],\n",
            "        [8.0841e-01, 9.1087e-01, 6.4184e-01, 8.7902e-01, 2.1954e-01, 6.0365e-01,\n",
            "         8.9863e-01, 2.5026e-01],\n",
            "        [1.8161e-01, 3.1517e-01, 6.4266e-01, 3.4562e-01, 1.2437e-01, 6.0086e-01,\n",
            "         7.7884e-02, 4.1765e-01],\n",
            "        [5.1594e-01, 1.7991e-01, 2.3859e-02, 2.2968e-01, 9.2388e-01, 1.9173e-01,\n",
            "         8.9667e-01, 7.5620e-01],\n",
            "        [6.4464e-01, 2.1396e-01, 8.0578e-01, 1.5013e-01, 5.3553e-01, 6.7852e-01,\n",
            "         5.3857e-02, 9.4497e-01],\n",
            "        [6.2026e-01, 7.5173e-01, 2.2876e-01, 1.8643e-01, 1.8861e-01, 9.7840e-01,\n",
            "         1.5359e-01, 3.0090e-01],\n",
            "        [1.5669e-01, 6.8150e-01, 6.7999e-01, 8.2666e-01, 1.2425e-01, 5.3574e-01,\n",
            "         9.9091e-01, 9.4075e-01]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[0.0814],\n",
            "        [0.2800]])\n",
            "[self.weight.data[:,:,4,4].view(2,)[i] for i in range(2)] = \n",
            "0.08136263489723206\n",
            "\n",
            "produto.shape: torch.Size([2, 8, 8]) produto: tensor([[[6.1301e-02, 9.8463e-03, 4.9040e-02, 1.1813e-02, 2.2734e-03,\n",
            "          2.0909e-02, 7.7408e-02, 6.8758e-05],\n",
            "         [3.1321e-02, 6.1516e-02, 3.9450e-02, 1.1800e-02, 5.4410e-02,\n",
            "          2.8828e-02, 6.5487e-03, 3.0421e-04],\n",
            "         [6.5775e-02, 7.4111e-02, 5.2222e-02, 7.1520e-02, 1.7863e-02,\n",
            "          4.9114e-02, 7.3115e-02, 2.0362e-02],\n",
            "         [1.4777e-02, 2.5643e-02, 5.2288e-02, 2.8120e-02, 1.0119e-02,\n",
            "          4.8887e-02, 6.3368e-03, 3.3981e-02],\n",
            "         [4.1978e-02, 1.4638e-02, 1.9412e-03, 1.8688e-02, 7.5170e-02,\n",
            "          1.5600e-02, 7.2956e-02, 6.1527e-02],\n",
            "         [5.2450e-02, 1.7409e-02, 6.5560e-02, 1.2215e-02, 4.3572e-02,\n",
            "          5.5206e-02, 4.3819e-03, 7.6885e-02],\n",
            "         [5.0466e-02, 6.1163e-02, 1.8612e-02, 1.5168e-02, 1.5345e-02,\n",
            "          7.9605e-02, 1.2496e-02, 2.4482e-02],\n",
            "         [1.2749e-02, 5.5449e-02, 5.5326e-02, 6.7259e-02, 1.0109e-02,\n",
            "          4.3589e-02, 8.0623e-02, 7.6542e-02]],\n",
            "\n",
            "        [[2.1093e-01, 3.3880e-02, 1.6874e-01, 4.0647e-02, 7.8225e-03,\n",
            "          7.1945e-02, 2.6635e-01, 2.3659e-04],\n",
            "         [1.0777e-01, 2.1167e-01, 1.3574e-01, 4.0601e-02, 1.8722e-01,\n",
            "          9.9192e-02, 2.2533e-02, 1.0467e-03],\n",
            "         [2.2632e-01, 2.5501e-01, 1.7969e-01, 2.4609e-01, 6.1463e-02,\n",
            "          1.6900e-01, 2.5158e-01, 7.0064e-02],\n",
            "         [5.0844e-02, 8.8236e-02, 1.7992e-01, 9.6759e-02, 3.4819e-02,\n",
            "          1.6822e-01, 2.1804e-02, 1.1692e-01],\n",
            "         [1.4444e-01, 5.0368e-02, 6.6794e-03, 6.4302e-02, 2.5865e-01,\n",
            "          5.3676e-02, 2.5103e-01, 2.1171e-01],\n",
            "         [1.8047e-01, 5.9901e-02, 2.2559e-01, 4.2030e-02, 1.4993e-01,\n",
            "          1.8996e-01, 1.5078e-02, 2.6455e-01],\n",
            "         [1.7365e-01, 2.1045e-01, 6.4042e-02, 5.2192e-02, 5.2802e-02,\n",
            "          2.7391e-01, 4.2998e-02, 8.4238e-02],\n",
            "         [4.3868e-02, 1.9079e-01, 1.9037e-01, 2.3143e-01, 3.4785e-02,\n",
            "          1.4999e-01, 2.7741e-01, 2.6337e-01]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([8, 8])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[0.5676, 0.7417, 0.4150, 1.1699, 0.7879, 0.5799, 0.9855, 0.9576],\n",
            "        [0.8376, 0.7772, 0.9560, 0.8338, 1.0576, 1.1340, 0.8705, 0.3494],\n",
            "        [0.6733, 1.3588, 1.0760, 0.8267, 0.8244, 0.6300, 1.1507, 0.8823],\n",
            "        [0.9674, 0.8024, 1.0690, 0.8509, 0.8088, 0.7909, 0.8498, 0.7601],\n",
            "        [0.7727, 0.7576, 0.7773, 1.1280, 0.9130, 1.2254, 0.4958, 1.4203],\n",
            "        [0.7536, 1.3782, 1.0261, 0.9538, 0.2557, 1.0533, 1.1323, 1.1649],\n",
            "        [0.9041, 1.1929, 1.3138, 0.7979, 0.6897, 0.5764, 1.1157, 0.5063],\n",
            "        [0.8569, 0.6569, 0.9399, 0.7137, 0.9025, 0.5294, 0.8130, 1.1480]])\n",
            " saida: tensor([[[[ 1.2960,  1.3707,  0.9568,  0.5701,  1.0488,  1.0514,  0.9977,\n",
            "            1.0565],\n",
            "          [ 1.0170,  0.8913,  0.6951,  0.8855,  0.4905,  0.7058,  0.6912,\n",
            "            1.0043],\n",
            "          [ 1.3996,  1.1027,  1.0317,  1.3359,  0.8241,  0.6065,  1.1243,\n",
            "            0.9825],\n",
            "          [ 1.0504,  1.0370,  1.3179,  0.8934,  0.8234,  1.1928,  1.0846,\n",
            "            0.8570],\n",
            "          [ 1.0078,  0.5273,  1.4000,  1.2233,  0.2194, -0.0107,  0.7460,\n",
            "            0.7443],\n",
            "          [ 1.3521,  0.6544,  0.9676,  1.3075,  1.3656,  1.5439,  0.7227,\n",
            "            0.8242],\n",
            "          [ 1.2382,  1.2499,  1.2640,  1.1563,  0.7438,  0.8311,  1.3492,\n",
            "            0.6070],\n",
            "          [ 0.6820,  1.0651,  0.7608,  1.0999,  0.9963,  0.5582,  0.8632,\n",
            "            0.8195]],\n",
            "\n",
            "         [[ 8.1306,  8.2085,  6.6376,  6.4993,  8.7737,  6.2563,  6.8758,\n",
            "            7.0522],\n",
            "          [ 8.1540,  6.7141,  6.4779,  5.5644,  7.4591,  7.0201,  6.6524,\n",
            "            6.0285],\n",
            "          [ 8.0824,  7.5677,  7.2700,  6.7938,  6.1937,  5.3806,  6.2774,\n",
            "            7.9848],\n",
            "          [ 7.9627,  8.0688,  7.5463,  7.3587,  7.5440,  6.2741,  9.0967,\n",
            "            6.8576],\n",
            "          [ 7.2206,  7.4704,  8.2842,  6.3828,  5.4520,  5.3835,  5.2378,\n",
            "            6.3927],\n",
            "          [ 7.9932,  5.7704,  6.3570,  7.5929,  7.1687,  6.8795,  6.1833,\n",
            "            7.5615],\n",
            "          [ 7.3105,  8.1571,  7.8837,  6.8040,  6.1649,  6.0057,  7.1289,\n",
            "            5.5837],\n",
            "          [ 7.3959,  5.8161,  6.4507,  6.7670,  7.9863,  6.4772,  6.4156,\n",
            "            6.6068]]],\n",
            "\n",
            "\n",
            "        [[[ 0.6289,  0.7515,  0.4640,  1.1817,  0.7902,  0.6008,  1.0629,\n",
            "            0.9576],\n",
            "          [ 0.8690,  0.8387,  0.9954,  0.8456,  1.1120,  1.1628,  0.8771,\n",
            "            0.3497],\n",
            "          [ 0.7391,  1.4329,  1.1282,  0.8982,  0.8423,  0.6791,  1.2239,\n",
            "            0.9026],\n",
            "          [ 0.9822,  0.8280,  1.1213,  0.8791,  0.8189,  0.8398,  0.8562,\n",
            "            0.7941],\n",
            "          [ 0.8147,  0.7722,  0.7792,  1.1467,  0.9882,  1.2410,  0.5688,\n",
            "            1.4819],\n",
            "          [ 0.8060,  1.3956,  1.0916,  0.9660,  0.2993,  1.1085,  1.1367,\n",
            "            1.2418],\n",
            "          [ 0.9545,  1.2540,  1.3324,  0.8131,  0.7051,  0.6560,  1.1282,\n",
            "            0.5308],\n",
            "          [ 0.8697,  0.7123,  0.9952,  0.7809,  0.9126,  0.5730,  0.8936,\n",
            "            1.2245]],\n",
            "\n",
            "         [[ 6.3512,  6.5978,  7.6058,  7.1244,  7.5907,  4.9802,  6.6569,\n",
            "            5.5157],\n",
            "          [ 7.7765,  4.8501,  6.2308,  7.7800,  6.4499,  6.2490,  8.1628,\n",
            "            6.5871],\n",
            "          [ 8.5883,  7.3253,  7.7840,  6.7436,  8.0589,  7.0630,  5.4053,\n",
            "            5.2739],\n",
            "          [ 7.8289,  6.9361,  6.4189,  7.4354,  6.7464,  7.5988,  6.7158,\n",
            "            6.9703],\n",
            "          [ 6.4678,  7.0289,  7.0990,  6.7577,  6.8426,  9.0539,  5.7644,\n",
            "            6.9768],\n",
            "          [ 6.1412,  8.5574,  7.0315,  5.6101,  5.2799,  6.3348,  7.2617,\n",
            "            8.0863],\n",
            "          [ 6.6750,  7.6242,  8.1483,  5.6211,  6.5911,  7.5230,  8.4991,\n",
            "            6.7773],\n",
            "          [ 6.1184,  6.9565,  7.5487,  6.9417,  6.4022,  7.0902,  9.3942,\n",
            "            7.0570]]]])\n",
            "\n",
            "ndx_amostra: 0\n",
            "\n",
            "ndx_amostra: 1\n",
            " saida apos somar bias: tensor([[[[1.4540, 1.5286, 1.1148, 0.7281, 1.2067, 1.2093, 1.1557, 1.2144],\n",
            "          [1.1749, 1.0492, 0.8531, 1.0434, 0.6484, 0.8637, 0.8491, 1.1623],\n",
            "          [1.5575, 1.2606, 1.1896, 1.4939, 0.9820, 0.7644, 1.2823, 1.1405],\n",
            "          [1.2083, 1.1950, 1.4759, 1.0513, 0.9813, 1.3507, 1.2426, 1.0150],\n",
            "          [1.1658, 0.6853, 1.5579, 1.3813, 0.3773, 0.1473, 0.9040, 0.9023],\n",
            "          [1.5100, 0.8123, 1.1256, 1.4654, 1.5235, 1.7018, 0.8806, 0.9821],\n",
            "          [1.3962, 1.4078, 1.4219, 1.3143, 0.9017, 0.9890, 1.5071, 0.7649],\n",
            "          [0.8400, 1.2230, 0.9188, 1.2579, 1.1542, 0.7162, 1.0211, 0.9775]],\n",
            "\n",
            "         [[8.1278, 8.2057, 6.6347, 6.4964, 8.7709, 6.2534, 6.8729, 7.0494],\n",
            "          [8.1511, 6.7113, 6.4751, 5.5616, 7.4563, 7.0172, 6.6496, 6.0256],\n",
            "          [8.0795, 7.5649, 7.2672, 6.7910, 6.1909, 5.3777, 6.2746, 7.9820],\n",
            "          [7.9598, 8.0660, 7.5434, 7.3559, 7.5411, 6.2713, 9.0939, 6.8548],\n",
            "          [7.2178, 7.4675, 8.2813, 6.3800, 5.4491, 5.3806, 5.2349, 6.3898],\n",
            "          [7.9904, 5.7676, 6.3542, 7.5901, 7.1659, 6.8766, 6.1804, 7.5587],\n",
            "          [7.3076, 8.1543, 7.8809, 6.8011, 6.1621, 6.0029, 7.1260, 5.5809],\n",
            "          [7.3931, 5.8132, 6.4479, 6.7642, 7.9835, 6.4744, 6.4127, 6.6039]]],\n",
            "\n",
            "\n",
            "        [[[0.7868, 0.9095, 0.6220, 1.3397, 0.9481, 0.7588, 1.2208, 1.1156],\n",
            "          [1.0269, 0.9967, 1.1534, 1.0035, 1.2700, 1.3207, 1.0350, 0.5077],\n",
            "          [0.8970, 1.5908, 1.2862, 1.0561, 1.0003, 0.8371, 1.3818, 1.0606],\n",
            "          [1.1401, 0.9860, 1.2793, 1.0370, 0.9768, 0.9978, 1.0141, 0.9520],\n",
            "          [0.9726, 0.9301, 0.9372, 1.3047, 1.1461, 1.3989, 0.7267, 1.6398],\n",
            "          [0.9639, 1.5536, 1.2496, 1.1239, 0.4572, 1.2665, 1.2946, 1.3998],\n",
            "          [1.1125, 1.4120, 1.4904, 0.9711, 0.8630, 0.8140, 1.2861, 0.6888],\n",
            "          [1.0276, 0.8702, 1.1531, 0.9389, 1.0706, 0.7309, 1.0516, 1.3825]],\n",
            "\n",
            "         [[6.3483, 6.5949, 7.6030, 7.1216, 7.5879, 4.9774, 6.6541, 5.5129],\n",
            "          [7.7736, 4.8473, 6.2279, 7.7771, 6.4471, 6.2461, 8.1600, 6.5842],\n",
            "          [8.5854, 7.3224, 7.7812, 6.7407, 8.0561, 7.0601, 5.4025, 5.2711],\n",
            "          [7.8260, 6.9333, 6.4160, 7.4325, 6.7436, 7.5959, 6.7129, 6.9674],\n",
            "          [6.4650, 7.0260, 7.0961, 6.7549, 6.8397, 9.0511, 5.7616, 6.9739],\n",
            "          [6.1384, 8.5545, 7.0287, 5.6073, 5.2771, 6.3320, 7.2588, 8.0834],\n",
            "          [6.6722, 7.6213, 8.1455, 5.6183, 6.5883, 7.5202, 8.4963, 6.7745],\n",
            "          [6.1155, 6.9537, 7.5458, 6.9389, 6.3994, 7.0874, 9.3914, 7.0542]]]],\n",
            "       grad_fn=<CopySlices>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Usa os mesmos pesos para minha implementação e a do pytorch\n",
        "pytorch_conv_layer = torch.nn.Conv2d( in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=0)\n",
        "pytorch_conv_layer.load_state_dict(dict(weight=initial_conv_weight, bias=initial_conv_bias))\n",
        "\n",
        "target_out = pytorch_conv_layer(x)"
      ],
      "metadata": {
        "id": "FuaDIHAT8RyS"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ed449b6-dfeb-4d7d-c08b-d39fc4fa1557",
        "id": "QSiZ5Hq28RyS"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2, 8, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert torch.allclose(out, target_out, atol=1e-6)"
      ],
      "metadata": {
        "id": "jJrDVrSb8RyS"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TnW2GGE8RyT"
      },
      "source": [
        "## Modelo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inicializa_seed(123)"
      ],
      "metadata": {
        "id": "qhs1q_yg8RyT"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-20T21:03:10.802708Z",
          "start_time": "2018-08-20T21:03:10.793287Z"
        },
        "id": "5jnLq2S08RyT"
      },
      "source": [
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, height_in: int, width_in: int, in_channels: int, out_channels: int, kernel_size: int, stride: int):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv_layer = MyConv2dForKernel(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride)\n",
        "   \n",
        "        height_out = (height_in - kernel_size) // stride + 1\n",
        "        width_out = (width_in - kernel_size) // stride + 1\n",
        "        self.classification_layer = torch.nn.Linear(out_channels * height_out * width_out, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        hidden = self.conv_layer(x)\n",
        "        hidden = torch.nn.functional.relu(hidden)\n",
        "        hidden = hidden.reshape(x.shape[0], -1)\n",
        "        logits = self.classification_layer(hidden)\n",
        "        return logits"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9L2RsHsz8RyT"
      },
      "source": [
        "## Treinamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lI9vFPe8RyT"
      },
      "source": [
        "### Definição dos hiperparâmetros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-20T21:03:14.146259Z",
          "start_time": "2018-08-20T21:03:14.139515Z"
        },
        "id": "yiu5TpoO8RyT"
      },
      "source": [
        "n_epochs = 50\n",
        "lr = 0.1"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaqIQzZO8RyT"
      },
      "source": [
        "### Laço de treinamento"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net(height_in=height_in, width_in=width_in, in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride)\n",
        "\n",
        "# Usa pesos iniciais pré-difinidos\n",
        "model.classification_layer.load_state_dict(dict(weight=initial_classification_weight, bias=initial_classification_bias))\n",
        "model.conv_layer.weight.data = initial_conv_weight\n",
        "model.conv_layer.bias.data = initial_conv_bias\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr)\n"
      ],
      "metadata": {
        "id": "DeoV5v6n8RyT"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "epochs = []\n",
        "loss_history = []\n",
        "loss_epoch_end = []\n",
        "total_trained_samples = 0\n",
        "for i in range(n_epochs):\n",
        "    for x_train, y_train in loader_train:\n",
        "        # predict da rede\n",
        "        outputs = model(x_train)\n",
        "\n",
        "        # calcula a perda\n",
        "        loss = criterion(outputs, y_train)\n",
        "\n",
        "        # zero, backpropagation, ajusta parâmetros pelo gradiente descendente\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_trained_samples += x_train.size(0)\n",
        "        epochs.append(total_trained_samples / len(dataset_train))\n",
        "        loss_history.append(loss.item())\n",
        "\n",
        "    loss_epoch_end.append(loss.item())\n",
        "    print(f'Epoch: {i:d}/{n_epochs - 1:d} Loss: {loss.item()}  time: {time.strftime(\"[%Y-%b-%d %H:%M:%S]\")}')    \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb868b5c-5ee1-45bd-b4bb-c4594e4168d7",
        "id": "to5mBHzi8RyT"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0/49 Loss: 0.5739676356315613  time: [2022-May-04 17:18:24]\n",
            "Epoch: 1/49 Loss: 0.4902600944042206  time: [2022-May-04 17:18:27]\n",
            "Epoch: 2/49 Loss: 0.40528053045272827  time: [2022-May-04 17:18:29]\n",
            "Epoch: 3/49 Loss: 0.3625572621822357  time: [2022-May-04 17:18:31]\n",
            "Epoch: 4/49 Loss: 0.33306068181991577  time: [2022-May-04 17:18:33]\n",
            "Epoch: 5/49 Loss: 0.31152594089508057  time: [2022-May-04 17:18:35]\n",
            "Epoch: 6/49 Loss: 0.29212135076522827  time: [2022-May-04 17:18:38]\n",
            "Epoch: 7/49 Loss: 0.27452996373176575  time: [2022-May-04 17:18:40]\n",
            "Epoch: 8/49 Loss: 0.2589237093925476  time: [2022-May-04 17:18:42]\n",
            "Epoch: 9/49 Loss: 0.2453676462173462  time: [2022-May-04 17:18:44]\n",
            "Epoch: 10/49 Loss: 0.23356309533119202  time: [2022-May-04 17:18:46]\n",
            "Epoch: 11/49 Loss: 0.22321251034736633  time: [2022-May-04 17:18:48]\n",
            "Epoch: 12/49 Loss: 0.21420606970787048  time: [2022-May-04 17:18:51]\n",
            "Epoch: 13/49 Loss: 0.2062845677137375  time: [2022-May-04 17:18:53]\n",
            "Epoch: 14/49 Loss: 0.19916236400604248  time: [2022-May-04 17:18:55]\n",
            "Epoch: 15/49 Loss: 0.19274964928627014  time: [2022-May-04 17:18:57]\n",
            "Epoch: 16/49 Loss: 0.18694593012332916  time: [2022-May-04 17:18:59]\n",
            "Epoch: 17/49 Loss: 0.18163436651229858  time: [2022-May-04 17:19:01]\n",
            "Epoch: 18/49 Loss: 0.17670288681983948  time: [2022-May-04 17:19:03]\n",
            "Epoch: 19/49 Loss: 0.17207756638526917  time: [2022-May-04 17:19:06]\n",
            "Epoch: 20/49 Loss: 0.16768980026245117  time: [2022-May-04 17:19:08]\n",
            "Epoch: 21/49 Loss: 0.16348180174827576  time: [2022-May-04 17:19:10]\n",
            "Epoch: 22/49 Loss: 0.1594243198633194  time: [2022-May-04 17:19:12]\n",
            "Epoch: 23/49 Loss: 0.15556588768959045  time: [2022-May-04 17:19:14]\n",
            "Epoch: 24/49 Loss: 0.15192030370235443  time: [2022-May-04 17:19:17]\n",
            "Epoch: 25/49 Loss: 0.14838916063308716  time: [2022-May-04 17:19:19]\n",
            "Epoch: 26/49 Loss: 0.14500516653060913  time: [2022-May-04 17:19:21]\n",
            "Epoch: 27/49 Loss: 0.1417863965034485  time: [2022-May-04 17:19:23]\n",
            "Epoch: 28/49 Loss: 0.1386725753545761  time: [2022-May-04 17:19:25]\n",
            "Epoch: 29/49 Loss: 0.13560903072357178  time: [2022-May-04 17:19:28]\n",
            "Epoch: 30/49 Loss: 0.13261042535305023  time: [2022-May-04 17:19:30]\n",
            "Epoch: 31/49 Loss: 0.1296902894973755  time: [2022-May-04 17:19:32]\n",
            "Epoch: 32/49 Loss: 0.12683135271072388  time: [2022-May-04 17:19:34]\n",
            "Epoch: 33/49 Loss: 0.12409193813800812  time: [2022-May-04 17:19:36]\n",
            "Epoch: 34/49 Loss: 0.12144283205270767  time: [2022-May-04 17:19:38]\n",
            "Epoch: 35/49 Loss: 0.11883187294006348  time: [2022-May-04 17:19:41]\n",
            "Epoch: 36/49 Loss: 0.11627564579248428  time: [2022-May-04 17:19:43]\n",
            "Epoch: 37/49 Loss: 0.11379501223564148  time: [2022-May-04 17:19:45]\n",
            "Epoch: 38/49 Loss: 0.11138947308063507  time: [2022-May-04 17:19:47]\n",
            "Epoch: 39/49 Loss: 0.10906356573104858  time: [2022-May-04 17:19:49]\n",
            "Epoch: 40/49 Loss: 0.10676994919776917  time: [2022-May-04 17:19:51]\n",
            "Epoch: 41/49 Loss: 0.10455039143562317  time: [2022-May-04 17:19:53]\n",
            "Epoch: 42/49 Loss: 0.10238028317689896  time: [2022-May-04 17:19:56]\n",
            "Epoch: 43/49 Loss: 0.10024499893188477  time: [2022-May-04 17:19:58]\n",
            "Epoch: 44/49 Loss: 0.09814105927944183  time: [2022-May-04 17:20:00]\n",
            "Epoch: 45/49 Loss: 0.09612743556499481  time: [2022-May-04 17:20:03]\n",
            "Epoch: 46/49 Loss: 0.09423573315143585  time: [2022-May-04 17:20:05]\n",
            "Epoch: 47/49 Loss: 0.09242112934589386  time: [2022-May-04 17:20:07]\n",
            "Epoch: 48/49 Loss: 0.09062910825014114  time: [2022-May-04 17:20:09]\n",
            "Epoch: 49/49 Loss: 0.0888780951499939  time: [2022-May-04 17:20:11]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ee2U8imq8RyU"
      },
      "source": [
        "### Visualização usual da perda, somente no final de cada minibatch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-20T21:03:55.246851Z",
          "start_time": "2018-08-20T21:03:54.994428Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "e211a725-471c-4b9b-852b-f3abb77e1c1f",
        "id": "ZKfz9EWv8RyU"
      },
      "source": [
        "n_batches_train = len(loader_train)\n",
        "plt.plot(epochs[::n_batches_train], loss_history[::n_batches_train])\n",
        "plt.xlabel('época')"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'época')"
            ]
          },
          "metadata": {},
          "execution_count": 105
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_epoch_end"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3c303d9-e394-4507-e83f-e14f77d3dcf5",
        "id": "iNhKEAOs8RyU"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5739676356315613,\n",
              " 0.4902600944042206,\n",
              " 0.40528053045272827,\n",
              " 0.3625572621822357,\n",
              " 0.33306068181991577,\n",
              " 0.31152594089508057,\n",
              " 0.29212135076522827,\n",
              " 0.27452996373176575,\n",
              " 0.2589237093925476,\n",
              " 0.2453676462173462,\n",
              " 0.23356309533119202,\n",
              " 0.22321251034736633,\n",
              " 0.21420606970787048,\n",
              " 0.2062845677137375,\n",
              " 0.19916236400604248,\n",
              " 0.19274964928627014,\n",
              " 0.18694593012332916,\n",
              " 0.18163436651229858,\n",
              " 0.17670288681983948,\n",
              " 0.17207756638526917,\n",
              " 0.16768980026245117,\n",
              " 0.16348180174827576,\n",
              " 0.1594243198633194,\n",
              " 0.15556588768959045,\n",
              " 0.15192030370235443,\n",
              " 0.14838916063308716,\n",
              " 0.14500516653060913,\n",
              " 0.1417863965034485,\n",
              " 0.1386725753545761,\n",
              " 0.13560903072357178,\n",
              " 0.13261042535305023,\n",
              " 0.1296902894973755,\n",
              " 0.12683135271072388,\n",
              " 0.12409193813800812,\n",
              " 0.12144283205270767,\n",
              " 0.11883187294006348,\n",
              " 0.11627564579248428,\n",
              " 0.11379501223564148,\n",
              " 0.11138947308063507,\n",
              " 0.10906356573104858,\n",
              " 0.10676994919776917,\n",
              " 0.10455039143562317,\n",
              " 0.10238028317689896,\n",
              " 0.10024499893188477,\n",
              " 0.09814105927944183,\n",
              " 0.09612743556499481,\n",
              " 0.09423573315143585,\n",
              " 0.09242112934589386,\n",
              " 0.09062910825014114,\n",
              " 0.0888780951499939]"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-20T21:03:48.786969Z",
          "start_time": "2018-08-20T21:03:48.781787Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "ipadObV28RyU",
        "outputId": "4cbb7c40-1752-490c-828c-a10d67a78067"
      },
      "source": [
        "# Assert do histórico de losses\n",
        "target_loss_epoch_end = np.array([\n",
        "    2.303267478942871,\n",
        "    2.227701187133789,\n",
        "    1.0923893451690674,\n",
        "    0.5867354869842529,\n",
        "    0.5144089460372925,\n",
        "    0.45026642084121704,\n",
        "    0.4075140357017517,\n",
        "    0.37713879346847534,\n",
        "    0.3534485101699829,\n",
        "    0.3341451585292816,\n",
        "    0.3181140422821045,\n",
        "    0.30457887053489685,\n",
        "    0.29283496737480164,\n",
        "    0.2827608287334442,\n",
        "    0.2738332152366638,\n",
        "    0.2657742500305176,\n",
        "    0.2583288848400116,\n",
        "    0.25117507576942444,\n",
        "    0.24439716339111328,\n",
        "    0.23789969086647034,\n",
        "    0.23167723417282104,\n",
        "    0.22562651336193085,\n",
        "    0.21984536945819855,\n",
        "    0.2142913043498993,\n",
        "    0.20894232392311096,\n",
        "    0.203872948884964,\n",
        "    0.19903430342674255,\n",
        "    0.19439971446990967,\n",
        "    0.18994088470935822,\n",
        "    0.18563991785049438,\n",
        "    0.18147490918636322,\n",
        "    0.17744913697242737,\n",
        "    0.17347246408462524,\n",
        "    0.16947467625141144,\n",
        "    0.16547319293022156,\n",
        "    0.16150487959384918,\n",
        "    0.1574639081954956,\n",
        "    0.1534043848514557,\n",
        "    0.14926929771900177,\n",
        "    0.1452063024044037,\n",
        "    0.1412365883588791,\n",
        "    0.13712672889232635,\n",
        "    0.1331038922071457,\n",
        "    0.1291467249393463,\n",
        "    0.1251506358385086,\n",
        "    0.12116757035255432,\n",
        "    0.11731722950935364,\n",
        "    0.11364627629518509,\n",
        "    0.11001908034086227,\n",
        "    0.10655981302261353])\n",
        "\n",
        "assert np.allclose(np.array(loss_epoch_end), target_loss_epoch_end, atol=1e-6)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-107-b715972200f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m     0.10655981302261353])\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_epoch_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_loss_epoch_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vjVZn3mR8RyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rascunho"
      ],
      "metadata": {
        "id": "yy2fvfxRnWDY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raise Exception(\"Execução abaixo depende de contexto apropriado\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "u_spC95IesPc",
        "outputId": "76a2685e-a038-40ae-9b67-332fcf3a72cd"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-1c3a674b2fc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Execução abaixo depende de contexto apropriado\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mException\u001b[0m: Execução abaixo depende de contexto apropriado"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Execução com queda maior na loss"
      ],
      "metadata": {
        "id": "BXOsrCloekqY"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-20T21:03:40.796410Z",
          "start_time": "2018-08-20T21:03:39.771981Z"
        },
        "id": "L5T_jZZPQT2P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "029019a6-2a0b-445b-83b9-55e699399619"
      },
      "source": [
        "model = Net(height_in=height_in, width_in=width_in, in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride)\n",
        "\n",
        "# Usa pesos iniciais pré-difinidos\n",
        "model.classification_layer.load_state_dict(dict(weight=initial_classification_weight, bias=initial_classification_bias))\n",
        "model.conv_layer.weight.data = initial_conv_weight\n",
        "model.conv_layer.bias.data = initial_conv_bias\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr)\n",
        "\n",
        "epochs = []\n",
        "loss_history = []\n",
        "loss_epoch_end = []\n",
        "total_trained_samples = 0\n",
        "for i in range(n_epochs):\n",
        "    for x_train, y_train in loader_train:\n",
        "        # predict da rede\n",
        "        outputs = model(x_train)\n",
        "\n",
        "        # calcula a perda\n",
        "        loss = criterion(outputs, y_train)\n",
        "\n",
        "        # zero, backpropagation, ajusta parâmetros pelo gradiente descendente\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_trained_samples += x_train.size(0)\n",
        "        epochs.append(total_trained_samples / len(dataset_train))\n",
        "        loss_history.append(loss.item())\n",
        "\n",
        "    loss_epoch_end.append(loss.item())\n",
        "    print(f'Epoch: {i:d}/{n_epochs - 1:d} Loss: {loss.item()}')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0/49 Loss: 0.9586364030838013\n",
            "Epoch: 1/49 Loss: 0.565815269947052\n",
            "Epoch: 2/49 Loss: 0.4770318567752838\n",
            "Epoch: 3/49 Loss: 0.42453765869140625\n",
            "Epoch: 4/49 Loss: 0.38708603382110596\n",
            "Epoch: 5/49 Loss: 0.35843756794929504\n",
            "Epoch: 6/49 Loss: 0.336288183927536\n",
            "Epoch: 7/49 Loss: 0.31845659017562866\n",
            "Epoch: 8/49 Loss: 0.3037392497062683\n",
            "Epoch: 9/49 Loss: 0.2910858988761902\n",
            "Epoch: 10/49 Loss: 0.2799944579601288\n",
            "Epoch: 11/49 Loss: 0.270416259765625\n",
            "Epoch: 12/49 Loss: 0.2619065046310425\n",
            "Epoch: 13/49 Loss: 0.25361135601997375\n",
            "Epoch: 14/49 Loss: 0.24582411348819733\n",
            "Epoch: 15/49 Loss: 0.23841428756713867\n",
            "Epoch: 16/49 Loss: 0.23117700219154358\n",
            "Epoch: 17/49 Loss: 0.2241152971982956\n",
            "Epoch: 18/49 Loss: 0.2175927609205246\n",
            "Epoch: 19/49 Loss: 0.21121275424957275\n",
            "Epoch: 20/49 Loss: 0.2050437331199646\n",
            "Epoch: 21/49 Loss: 0.19928722083568573\n",
            "Epoch: 22/49 Loss: 0.1938953399658203\n",
            "Epoch: 23/49 Loss: 0.1882905215024948\n",
            "Epoch: 24/49 Loss: 0.1828724443912506\n",
            "Epoch: 25/49 Loss: 0.1776149421930313\n",
            "Epoch: 26/49 Loss: 0.17248651385307312\n",
            "Epoch: 27/49 Loss: 0.16733810305595398\n",
            "Epoch: 28/49 Loss: 0.16254152357578278\n",
            "Epoch: 29/49 Loss: 0.15758882462978363\n",
            "Epoch: 30/49 Loss: 0.1527339220046997\n",
            "Epoch: 31/49 Loss: 0.14789022505283356\n",
            "Epoch: 32/49 Loss: 0.14303667843341827\n",
            "Epoch: 33/49 Loss: 0.1380799561738968\n",
            "Epoch: 34/49 Loss: 0.13330009579658508\n",
            "Epoch: 35/49 Loss: 0.12855049967765808\n",
            "Epoch: 36/49 Loss: 0.12378916144371033\n",
            "Epoch: 37/49 Loss: 0.119150809943676\n",
            "Epoch: 38/49 Loss: 0.11474869400262833\n",
            "Epoch: 39/49 Loss: 0.110462486743927\n",
            "Epoch: 40/49 Loss: 0.10636704415082932\n",
            "Epoch: 41/49 Loss: 0.10245434939861298\n",
            "Epoch: 42/49 Loss: 0.09870947152376175\n",
            "Epoch: 43/49 Loss: 0.09508325904607773\n",
            "Epoch: 44/49 Loss: 0.09160909056663513\n",
            "Epoch: 45/49 Loss: 0.08813302963972092\n",
            "Epoch: 46/49 Loss: 0.08475378155708313\n",
            "Epoch: 47/49 Loss: 0.08139956742525101\n",
            "Epoch: 48/49 Loss: 0.07817484438419342\n",
            "Epoch: 49/49 Loss: 0.07505226880311966\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_epoch_end"
      ],
      "metadata": {
        "id": "ToktJu4CK94z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecd61d51-0172-464c-cc0b-d023eabc5622"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9586364030838013,\n",
              " 0.565815269947052,\n",
              " 0.4770318567752838,\n",
              " 0.42453765869140625,\n",
              " 0.38708603382110596,\n",
              " 0.35843756794929504,\n",
              " 0.336288183927536,\n",
              " 0.31845659017562866,\n",
              " 0.3037392497062683,\n",
              " 0.2910858988761902,\n",
              " 0.2799944579601288,\n",
              " 0.270416259765625,\n",
              " 0.2619065046310425,\n",
              " 0.25361135601997375,\n",
              " 0.24582411348819733,\n",
              " 0.23841428756713867,\n",
              " 0.23117700219154358,\n",
              " 0.2241152971982956,\n",
              " 0.2175927609205246,\n",
              " 0.21121275424957275,\n",
              " 0.2050437331199646,\n",
              " 0.19928722083568573,\n",
              " 0.1938953399658203,\n",
              " 0.1882905215024948,\n",
              " 0.1828724443912506,\n",
              " 0.1776149421930313,\n",
              " 0.17248651385307312,\n",
              " 0.16733810305595398,\n",
              " 0.16254152357578278,\n",
              " 0.15758882462978363,\n",
              " 0.1527339220046997,\n",
              " 0.14789022505283356,\n",
              " 0.14303667843341827,\n",
              " 0.1380799561738968,\n",
              " 0.13330009579658508,\n",
              " 0.12855049967765808,\n",
              " 0.12378916144371033,\n",
              " 0.119150809943676,\n",
              " 0.11474869400262833,\n",
              " 0.110462486743927,\n",
              " 0.10636704415082932,\n",
              " 0.10245434939861298,\n",
              " 0.09870947152376175,\n",
              " 0.09508325904607773,\n",
              " 0.09160909056663513,\n",
              " 0.08813302963972092,\n",
              " 0.08475378155708313,\n",
              " 0.08139956742525101,\n",
              " 0.07817484438419342,\n",
              " 0.07505226880311966]"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Outros testes de convolução"
      ],
      "metadata": {
        "id": "sAAKJ6rnet3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "in_channels_dummy = 1\n",
        "out_channels_dummy = 2\n",
        "kernel_size_dummy = 3\n",
        "stride_dummy = 2\n",
        "num_amostras_dummy = 1\n",
        "x = torch.arange(30).float().reshape(num_amostras_dummy, 1, 5, 6)"
      ],
      "metadata": {
        "id": "eHg1E0xkGn-F"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70db7342-22c9-4356-969b-d5bbf28ec4b6",
        "id": "GLcaZY0nGn-F"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[ 0.,  1.,  2.,  3.,  4.,  5.],\n",
            "          [ 6.,  7.,  8.,  9., 10., 11.],\n",
            "          [12., 13., 14., 15., 16., 17.],\n",
            "          [18., 19., 20., 21., 22., 23.],\n",
            "          [24., 25., 26., 27., 28., 29.]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "conv_layer = MyConv2dForKernel( in_channels=in_channels_dummy,out_channels=out_channels_dummy, kernel_size=kernel_size_dummy, stride=stride_dummy, verbose=True)\n",
        "\n",
        "# Usa os mesmos pesos para minha implementação e a do pytorch\n",
        "initial_weights_dummy = torch.arange(in_channels_dummy * out_channels_dummy * kernel_size_dummy * kernel_size_dummy).float()\n",
        "initial_weights_dummy = initial_weights_dummy.reshape(out_channels_dummy, in_channels_dummy,  kernel_size_dummy, kernel_size_dummy)\n",
        "initial_bias_dummy = torch.arange(out_channels_dummy,).float()\n",
        "conv_layer.weight.data = initial_weights_dummy\n",
        "conv_layer.bias.data = initial_bias_dummy\n",
        "print(f\"conv_layer.bias.data.shape {conv_layer.bias.data.shape}, conv_layer.bias.data {conv_layer.bias.data}\")\n",
        "print(f\"conv_layer.weight.data.shape {conv_layer.weight.data.shape}, conv_layer.weight.data \\n{conv_layer.weight.data}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7164faa9-ef5e-401b-a78d-03572c7d676a",
        "id": "m5oMLsHsGn-G"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inicializado MyConv2d\n",
            "in_channels: 1 \n",
            "out_channels: 2 \n",
            "kernel_size: 3 \n",
            "stride: 2 \n",
            "weight.shape: torch.Size([2, 1, 3, 3]) \n",
            "weight: Parameter containing:\n",
            "tensor([[[[-0.0056,  0.0015, -0.0048],\n",
            "          [ 0.0051,  0.0006,  0.0063],\n",
            "          [-0.0085,  0.0028,  0.0063]]],\n",
            "\n",
            "\n",
            "        [[[-0.0088,  0.0098, -0.0020],\n",
            "          [-0.0017,  0.0016, -0.0099],\n",
            "          [ 0.0036, -0.0057,  0.0079]]]], requires_grad=True) \n",
            "bias.shape: torch.Size([2]) \n",
            "bias: Parameter containing:\n",
            "tensor([-0.0015,  0.0052], requires_grad=True) \n",
            "conv_layer.bias.data.shape torch.Size([2]), conv_layer.bias.data tensor([0., 1.])\n",
            "conv_layer.weight.data.shape torch.Size([2, 1, 3, 3]), conv_layer.weight.data \n",
            "tensor([[[[ 0.,  1.,  2.],\n",
            "          [ 3.,  4.,  5.],\n",
            "          [ 6.,  7.,  8.]]],\n",
            "\n",
            "\n",
            "        [[[ 9., 10., 11.],\n",
            "          [12., 13., 14.],\n",
            "          [15., 16., 17.]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dW1S0eXhYQ21",
        "outputId": "0394add7-cb8c-4f0b-f9b8-f62c3dbaaf2d"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[ 0.,  1.,  2.,  3.,  4.,  5.],\n",
            "          [ 6.,  7.,  8.,  9., 10., 11.],\n",
            "          [12., 13., 14., 15., 16., 17.],\n",
            "          [18., 19., 20., 21., 22., 23.],\n",
            "          [24., 25., 26., 27., 28., 29.]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "initial_weights_dummy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhGAQGyyHaO6",
        "outputId": "1f3c1d37-cc03-41ab-da2f-d0db7a6b9385"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 0.,  1.,  2.],\n",
              "          [ 3.,  4.,  5.],\n",
              "          [ 6.,  7.,  8.]]],\n",
              "\n",
              "\n",
              "        [[[ 9., 10., 11.],\n",
              "          [12., 13., 14.],\n",
              "          [15., 16., 17.]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "visao_com_stride= torch.tensor([[ 0.,  2.], [12., 14.]])"
      ],
      "metadata": {
        "id": "B3kP5JK-JOqZ"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_weights_dummy[:,:,0,1].squeeze()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVk4WV56PePO",
        "outputId": "ebe7f476-8365-4ada-cabe-48dd778b2653"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.stack([visao_com_stride * initial_weights_dummy[:,:,0,1][i]  for i in range(2)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7z9GhZ1MKHl",
        "outputId": "78b9a658-8322-4bca-d2f5-09908d9f9ce0"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[  0.,   2.],\n",
              "         [ 12.,  14.]],\n",
              "\n",
              "        [[  0.,  20.],\n",
              "         [120., 140.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = conv_layer(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVysHnpYX4O2",
        "outputId": "3d726a8a-9673-4e21-adec-08852d163d7a"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " num_amostras: 1, self.out_channels: 2, num_linhas_entrada: 5, num_colunas_entrada: 6, num_linhas_saida: 2, num_colunas_saida: 2\n",
            "saida.shape: torch.Size([1, 2, 2, 2])\n",
            "\n",
            "ndx_amostra: 0\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 0, 0\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([2, 2]) por self.weight.data[:,:,0,0].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[ 0.,  2.],\n",
            "        [12., 14.]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[0.],\n",
            "        [9.]])\n",
            "\n",
            "produto.shape: torch.Size([2, 2, 2]) produto: tensor([[[  0.,   0.],\n",
            "         [  0.,   0.]],\n",
            "\n",
            "        [[  0.,  18.],\n",
            "         [108., 126.]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([2, 2])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[0., 0.],\n",
            "        [0., 0.]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 0, 1\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([2, 2]) por self.weight.data[:,:,0,1].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[ 1.,  3.],\n",
            "        [13., 15.]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[ 1.],\n",
            "        [10.]])\n",
            "\n",
            "produto.shape: torch.Size([2, 2, 2]) produto: tensor([[[  1.,   3.],\n",
            "         [ 13.,  15.]],\n",
            "\n",
            "        [[ 10.,  30.],\n",
            "         [130., 150.]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([2, 2])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[0., 0.],\n",
            "        [0., 0.]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 0, 2\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([2, 2]) por self.weight.data[:,:,0,2].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[ 2.,  4.],\n",
            "        [14., 16.]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[ 2.],\n",
            "        [11.]])\n",
            "\n",
            "produto.shape: torch.Size([2, 2, 2]) produto: tensor([[[  4.,   8.],\n",
            "         [ 28.,  32.]],\n",
            "\n",
            "        [[ 22.,  44.],\n",
            "         [154., 176.]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([2, 2])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[ 1.,  3.],\n",
            "        [13., 15.]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 1, 0\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([2, 2]) por self.weight.data[:,:,1,0].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[ 6.,  8.],\n",
            "        [18., 20.]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[ 3.],\n",
            "        [12.]])\n",
            "\n",
            "produto.shape: torch.Size([2, 2, 2]) produto: tensor([[[ 18.,  24.],\n",
            "         [ 54.,  60.]],\n",
            "\n",
            "        [[ 72.,  96.],\n",
            "         [216., 240.]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([2, 2])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[ 5., 11.],\n",
            "        [41., 47.]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 1, 1\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([2, 2]) por self.weight.data[:,:,1,1].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[ 7.,  9.],\n",
            "        [19., 21.]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[ 4.],\n",
            "        [13.]])\n",
            "\n",
            "produto.shape: torch.Size([2, 2, 2]) produto: tensor([[[ 28.,  36.],\n",
            "         [ 76.,  84.]],\n",
            "\n",
            "        [[ 91., 117.],\n",
            "         [247., 273.]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([2, 2])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[ 23.,  35.],\n",
            "        [ 95., 107.]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 1, 2\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([2, 2]) por self.weight.data[:,:,1,2].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[ 8., 10.],\n",
            "        [20., 22.]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[ 5.],\n",
            "        [14.]])\n",
            "\n",
            "produto.shape: torch.Size([2, 2, 2]) produto: tensor([[[ 40.,  50.],\n",
            "         [100., 110.]],\n",
            "\n",
            "        [[112., 140.],\n",
            "         [280., 308.]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([2, 2])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[ 51.,  71.],\n",
            "        [171., 191.]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 2, 0\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([2, 2]) por self.weight.data[:,:,2,0].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[12., 14.],\n",
            "        [24., 26.]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[ 6.],\n",
            "        [15.]])\n",
            "\n",
            "produto.shape: torch.Size([2, 2, 2]) produto: tensor([[[ 72.,  84.],\n",
            "         [144., 156.]],\n",
            "\n",
            "        [[180., 210.],\n",
            "         [360., 390.]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([2, 2])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[ 91., 121.],\n",
            "        [271., 301.]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 2, 1\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([2, 2]) por self.weight.data[:,:,2,1].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[13., 15.],\n",
            "        [25., 27.]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[ 7.],\n",
            "        [16.]])\n",
            "\n",
            "produto.shape: torch.Size([2, 2, 2]) produto: tensor([[[ 91., 105.],\n",
            "         [175., 189.]],\n",
            "\n",
            "        [[208., 240.],\n",
            "         [400., 432.]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([2, 2])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[163., 205.],\n",
            "        [415., 457.]])\n",
            "\n",
            "ndx_linhas_kernel, ndx_colunas_kernel: 2, 2\n",
            "vou multiplicar visao_com_stride.shape: torch.Size([2, 2]) por self.weight.data[:,:,2,2].shape: torch.Size([2, 1])\n",
            "\n",
            "visao_com_stride: tensor([[14., 16.],\n",
            "        [26., 28.]])\n",
            "\n",
            "self.weight.data[:,:,ndx_linhas_kernel,ndx_colunas_kernel]: tensor([[ 8.],\n",
            "        [17.]])\n",
            "\n",
            "produto.shape: torch.Size([2, 2, 2]) produto: tensor([[[112., 128.],\n",
            "         [208., 224.]],\n",
            "\n",
            "        [[238., 272.],\n",
            "         [442., 476.]]])\n",
            "\n",
            "saida[ndx_amostra,0].shape: torch.Size([2, 2])\n",
            "\n",
            "saida[ndx_amostra,0]: tensor([[254., 310.],\n",
            "        [590., 646.]])\n",
            " saida: tensor([[[[ 366.,  438.],\n",
            "          [ 798.,  870.]],\n",
            "\n",
            "         [[ 933., 1167.],\n",
            "          [2337., 2571.]]]])\n",
            "\n",
            "ndx_amostra: 0\n",
            " saida apos somar bias: tensor([[[[ 366.,  438.],\n",
            "          [ 798.,  870.]],\n",
            "\n",
            "         [[ 934., 1168.],\n",
            "          [2338., 2572.]]]], grad_fn=<CopySlices>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ED6gJjl7GonF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2Vcc7RvMGo2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Z8Sp80mDDpzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visao_com_stride = torch.tensor([[0.6388, 0.0862, 0.6818, 0.7976, 0.7167, 0.1387, 0.7145, 0.9017],\n",
        "        [0.5935, 0.7993, 0.5981, 0.3053, 0.3035, 0.3231, 0.6086, 0.7513],\n",
        "        [0.3263, 0.3853, 0.5213, 0.1605, 0.3722, 0.5053, 0.8708, 0.0899],\n",
        "        [0.8270, 0.1591, 0.0369, 0.9067, 0.0512, 0.4896, 0.7371, 0.7653],\n",
        "        [0.1413, 0.5816, 0.4752, 0.0319, 0.4668, 0.6566, 0.8516, 0.3129],\n",
        "        [0.6547, 0.6356, 0.0735, 0.9221, 0.4857, 0.2986, 0.5909, 0.0700],\n",
        "        [0.8468, 0.0488, 0.1779, 0.6481, 0.0972, 0.9084, 0.1469, 0.7641],\n",
        "        [0.0678, 0.1986, 0.5496, 0.0866, 0.5669, 0.2203, 0.0335, 0.9504]])"
      ],
      "metadata": {
        "id": "xsmdsQRqRrV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_conv_weight[:,:,0,0][0,0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOWvighGC1Mt",
        "outputId": "30612d42-c9fb-4c7b-d39f-22fffcfc78a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0.0041)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp = torch.tensor([[-0.0041],  [0]])"
      ],
      "metadata": {
        "id": "_z7JFEjgRRqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zu-6SaclT4Hi",
        "outputId": "16e5ef92-2832-48fd-f3f5-b92157f9f72b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp[1,0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ud6SkqMCd1U",
        "outputId": "8e9b556c-ea9c-49e2-9608-a51d646ebe66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp.view(2,).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2l1fP-jnT6_g",
        "outputId": "e3c80ecc-afb5-4a5f-b783-dc77fbb8a8da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "initial_conv_weight[:,:,0,0].view(2,)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hyk_blA7A0Vl",
        "outputId": "72eef3d5-15f4-4e77-e008-5b5b03769463"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0.0041)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " [initial_conv_weight[:,:,0,0].view(2,)[i]  for i in range(2)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgAeE3AsS8du",
        "outputId": "73496b41-08e1-45f7-9916-bc9a036d0166"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor(-0.0041), tensor(0.0032)]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " [initial_conv_weight[:,:,0,0].view(2,)[i]  for i in range(2)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqDK71Iq9Ouw",
        "outputId": "895ce560-a381-4875-dc2a-f7a5633ff733"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor(-0.0041), tensor(0.0032)]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "produto = torch.stack([visao_com_stride * initial_conv_weight[:,:,0,0][i]  for i in range(2)])"
      ],
      "metadata": {
        "id": "-9k5HtWGTS64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "produto = torch.stack([visao_com_stride * initial_conv_weight[:,:,0,0].view(2,)[i]  for i in range(2)])\n",
        "produto"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtwzSoT0RwXS",
        "outputId": "f8bf29c0-3c0b-437c-b798-4d6daffc6bc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.0026, -0.0004, -0.0028, -0.0033, -0.0029, -0.0006, -0.0029,\n",
              "          -0.0037],\n",
              "         [-0.0024, -0.0033, -0.0024, -0.0012, -0.0012, -0.0013, -0.0025,\n",
              "          -0.0031],\n",
              "         [-0.0013, -0.0016, -0.0021, -0.0007, -0.0015, -0.0021, -0.0036,\n",
              "          -0.0004],\n",
              "         [-0.0034, -0.0006, -0.0002, -0.0037, -0.0002, -0.0020, -0.0030,\n",
              "          -0.0031],\n",
              "         [-0.0006, -0.0024, -0.0019, -0.0001, -0.0019, -0.0027, -0.0035,\n",
              "          -0.0013],\n",
              "         [-0.0027, -0.0026, -0.0003, -0.0038, -0.0020, -0.0012, -0.0024,\n",
              "          -0.0003],\n",
              "         [-0.0035, -0.0002, -0.0007, -0.0026, -0.0004, -0.0037, -0.0006,\n",
              "          -0.0031],\n",
              "         [-0.0003, -0.0008, -0.0022, -0.0004, -0.0023, -0.0009, -0.0001,\n",
              "          -0.0039]],\n",
              "\n",
              "        [[ 0.0020,  0.0003,  0.0022,  0.0025,  0.0023,  0.0004,  0.0023,\n",
              "           0.0029],\n",
              "         [ 0.0019,  0.0025,  0.0019,  0.0010,  0.0010,  0.0010,  0.0019,\n",
              "           0.0024],\n",
              "         [ 0.0010,  0.0012,  0.0017,  0.0005,  0.0012,  0.0016,  0.0028,\n",
              "           0.0003],\n",
              "         [ 0.0026,  0.0005,  0.0001,  0.0029,  0.0002,  0.0016,  0.0023,\n",
              "           0.0024],\n",
              "         [ 0.0004,  0.0018,  0.0015,  0.0001,  0.0015,  0.0021,  0.0027,\n",
              "           0.0010],\n",
              "         [ 0.0021,  0.0020,  0.0002,  0.0029,  0.0015,  0.0009,  0.0019,\n",
              "           0.0002],\n",
              "         [ 0.0027,  0.0002,  0.0006,  0.0021,  0.0003,  0.0029,  0.0005,\n",
              "           0.0024],\n",
              "         [ 0.0002,  0.0006,  0.0017,  0.0003,  0.0018,  0.0007,  0.0001,\n",
              "           0.0030]]])"
            ]
          },
          "metadata": {},
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[temp[i,0]  for i in range(2)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIJw8mUNRVuE",
        "outputId": "18daf58d-0891-4725-f06e-56364c20e2e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor(-0.0041), tensor(0.0032)]"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out.shape"
      ],
      "metadata": {
        "id": "mSTrD1WRnGng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp = torch.tensor([[[[34.]]]])"
      ],
      "metadata": {
        "id": "JZUW6dbGeULx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp.squeeze()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8ATxh3DkQlS",
        "outputId": "6dea88af-1ef6-410b-d2e1-772f55b58de1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(34.)"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp.squeeze().shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijHjn6Fwk_6S",
        "outputId": "fc8bbe28-ae31-472d-d2bd-50cfaa6eae0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([])"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp.squeeze().reshape(1,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrEMRgHxk7UK",
        "outputId": "d9d8d83d-cb40-4844-8e21-c1170d9417b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([34.])"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp.view(1,-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dx_BICd-kVsC",
        "outputId": "7242672c-05da-4aeb-b8bd-e72aadfa04c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[34.]])"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp = torch.tensor([[[[ 46.]], [[134.]]]])"
      ],
      "metadata": {
        "id": "xK5LO9EikKLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp.squeeze()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zgWxyfKeYhZ",
        "outputId": "758c69e0-7669-4021-b5b7-3f364d0222e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 46., 134.])"
            ]
          },
          "metadata": {},
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp.squeeze().shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74ouMw6ClWhp",
        "outputId": "f7e23e94-af1e-4251-b57a-ffc992ddede0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2])"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp.squeeze().reshape(2,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVj0YgbZknZE",
        "outputId": "634e9b79-0ca4-4b6c-cb05-903b27262855"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 46., 134.])"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp.squeeze().shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NKOwsD_eYsI",
        "outputId": "8bade88a-be35-4a88-ba2c-cb85f05613e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2])"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    }
  ]
}