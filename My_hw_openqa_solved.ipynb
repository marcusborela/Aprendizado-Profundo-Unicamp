{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcusborela/Aprendizado-Profundo-Unicamp/blob/main/My_hw_openqa_solved.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0qZfMf4Yreh"
      },
      "source": [
        "# Few-shot OpenQA with ColBERT retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NqUPAnWuYrej"
      },
      "outputs": [],
      "source": [
        "__author__ = \"Christopher Potts and Omar Khattab\"\n",
        "__version__ = \"CS224u, Stanford, Spring 2022\"\n",
        "\n",
        "# fonte: https://github.com/cgpotts/cs224u/blob/master/hw_openqa.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6TRA3gNYrek"
      },
      "source": [
        "## Contents\n",
        "\n",
        "1. [Contents](#Contents)\n",
        "1. [Visão geral](#Overview)\n",
        "1. [Set-up](#Set-up)\n",
        "    1. [Google Colab set-up](#Google-Colab-set-up)\n",
        "    1. [General set-up](#General-set-up)\n",
        "    1. [Language model set-up](#Language-model-set-up)\n",
        "    1. [ColBERT set-up](#ColBERT-set-up)\n",
        "1. [Language models](#Language-models)\n",
        "    1. [Answerhood](#Answerhood)\n",
        "    1. [Eleuther models from Hugging Face](#Eleuther-models-from-Hugging-Face)\n",
        "    1. [GPT-3](#GPT-3)\n",
        "1. [SQuAD](#SQuAD)\n",
        "    1. [SQuAD dev](#SQuAD-dev)\n",
        "    1. [SQuAD dev sample](#SQuAD-dev-sample)\n",
        "    1. [SQuAD train](#SQuAD-train)\n",
        "1. [Evaluation](#Evaluation)\n",
        "1. [Open QA with no context](#Open-QA-with-no-context)\n",
        "1. [Few-shot QA](#Few-shot-QA)\n",
        "1. [ColBERT](#ColBERT)\n",
        "    1. [ColBERT parameters](#ColBERT-parameters)\n",
        "    1. [ColBERT index](#ColBERT-index)\n",
        "    1. [Search](#Search)\n",
        "    1. [Retrieval evaluation](#Retrieval-evaluation)\n",
        "1. [Zero-shot OpenQA with ColBERT retrieval](#Zero-shot-OpenQA-with-ColBERT-retrieval)\n",
        "1. [Homework questions](#Homework-questions)\n",
        "    1. [Few-shot OpenQA with no context [2 points]](#Few-shot-OpenQA-with-no-context-[2-points])\n",
        "    1. [Few-shot OpenQA [2 points]](#Few-shot-OpenQA-[2-points])\n",
        "    1. [Answer scoring [2 points]](#Answer-scoring-[2-points])\n",
        "    1. [Your original system [3 points]](#Your-original-system-[3-points])\n",
        "1. [Bake-off [1 point]](#Bake-off-[1-point])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXqIujoUYrek"
      },
      "source": [
        "## Overview\n",
        "\n",
        "The goal of this homework is to explore few-shot (or, prompt-based) learning in the context of open-domain question answering. This is an exciting area that brings together a number of recent task ideas and modeling innovations.\n",
        "\n",
        "Our core task is __open-domain question answering (OpenQA)__. In this task, all that is given by the dataset is a question text, and the task is to answer that question. By contrast, in modern QA tasks, the dataset provides a text and a gold passage, with a guarantee that the answer will be a substring of the passage. \n",
        "\n",
        "OpenQA is substantially harder than standard QA. The usual strategy is to use a _retriever_ to find passages in a large collection of texts and train a _reader_ to find answers in those passages. This means we have no guarantee that the retrieved passage will contain the answer we need. If we don't retrieve a passage containing the answer, our reader has no hope of succeeding. Although this is challenging, it is much more realistic and widely applicable than standard QA. After all, with the right retriever, an OpenQA system could be deployed over the entire Web.\n",
        "\n",
        "The task posed by this homework is harder even than OpenQA. We are calling this task __few-shot OpenQA__. The defining feature of this task is that the reader is simply a general purpose autoregressive language model. It accepts string inputs (prompts) and produces text in response. It is not trained to answer questions per se, and nothing about its structure ensures that it will respond with a substring of the prompt corresponding to anything like an answer.\n",
        "\n",
        "__Few-shot QA__ (but not OpenQA!) is explored in the famous GPT-3 paper ([Brown et al. 2020](https://arxiv.org/abs/2005.14165)). The authors are able to get traction on the problem using GPT-3, an incredible finding. Our task here – __few-shot OpenQA__ – pushes this even further by retrieving passages to use in the prompt rather than assuming that the gold passage can be used in the prompt. If we can make this work, then it should be a major step towards flexibly and easily deploying QA technologies in new domains.\n",
        "\n",
        "In summary:\n",
        "\n",
        "| Task             | Passage given | Task-specific reader training |Task-specific retriever training  | \n",
        "|-----------------:|:-------------:|:-----------------------------:|:--------------------------------:|\n",
        "| QA               | yes           | yes                           | n/a                              |\n",
        "| OpenQA           | no            | yes                           | maybe                            |\n",
        "| Few-shot QA      | yes           | no                            | n/a                              |\n",
        "| Few-shot OpenQA  | no            | no                            | maybe                            | \n",
        "\n",
        "Just to repeat: your mission (should you choose to accept it!) is to explore the final line in this table. The core notebook and assignment don't address the issue of training the retriever in a task-specific way, but we've given some pointers on this in the context of [the original system question at the bottom of this notebook](#Your-original-system-[3-points]).\n",
        "\n",
        "As usual, this notebook sets up the task and provides starter code. We proceed through a series of approaches:\n",
        "\n",
        "* _Open QA with no context_: the prompt consists of the question, and we just see what comes back. This is not particularly fair to the system since it doesn't unambiguously convey what we want it to do, but it's a start.\n",
        "\n",
        "* _Few-shot QA_: the prompt contains one or more examples formatted so as to indirectly convey what we want the system to do, and it uses the gold passage associated with the example. This is the approach of the GPT-3 paper. It works only for datasets with gold passages.\n",
        "\n",
        "* _Open QA with ColBERT retrieval_: This is roughly as in the previous case, but now we presume no access to a gold passage for our example. Rather, we retrieve a passage from a large corpus using the neural information retrieval model ColBERT.\n",
        "\n",
        "The above examples are followed by some assignment questions aimed at helping you to think creatively about the problem. These problems improve on the above approaches in various ways.\n",
        "\n",
        "All of this culminates in an original system question and some code and unlabeled data (here, just a list of questions) for the bake-off.\n",
        "\n",
        "It is a requirement of the bake-off that a pure autoregressive model be used. In particular, trained QA systems cannot be used at all. See the original system question at the bottom of this message for the full list of allowed models.\n",
        "\n",
        "Note: the models we are working with here are _big_. This poses a challenge that is increasingly common in NLP: you have to pay one way or another. You can pay to use the GPT-3 API, or you can pay to use an Eleuther model on a heavy-duty cluster computer, or you can pay with time by using an Eleuther model on a more modest computer. If none of these options is palatable, you might consider instead doing the [color reference assignment](hw_colors.ipynb)!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKB9zXRBYrel"
      },
      "source": [
        "## Set-up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JwiISlVYrel"
      },
      "source": [
        "### Google Colab set-up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbnxdvg7Yrem"
      },
      "source": [
        "We have sought to make this notebook self-contained so that it can easily be run as a Google Colab. If you are running it in Colab, make sure to select a GPU instance. The notebook will run on a CPU-only instance or CPU-only machine, but it should be much faster with GPU support.\n",
        "\n",
        "The following are all installed as part of course set-up, but you'll want to run this cell if you are working in a Colab:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJJnzz_cnCf5",
        "outputId": "9414eac5-8b98-4ae0-ca2e-9ba9dedadc89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 4.3 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 46.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 81.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.7.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Xq9FL8BnLQX",
        "outputId": "93f48695-4047-4c37-840d-1330aa955698"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.2.2-py3-none-any.whl (346 kB)\n",
            "\u001b[K     |████████████████████████████████| 346 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 71.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 79.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.7.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n",
            "Collecting dill<0.3.5\n",
            "  Downloading dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 6.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 73.6 MB/s \n",
            "\u001b[?25hCollecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.5.18.1)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 53.5 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 50.2 MB/s \n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 2.6 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 80.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.0)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.12.2-py37-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 52.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: multidict, frozenlist, yarl, urllib3, asynctest, async-timeout, aiosignal, fsspec, dill, aiohttp, xxhash, responses, multiprocess, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.5.1\n",
            "    Uninstalling dill-0.3.5.1:\n",
            "      Successfully uninstalled dill-0.3.5.1\n",
            "  Attempting uninstall: multiprocess\n",
            "    Found existing installation: multiprocess 0.70.13\n",
            "    Uninstalling multiprocess-0.70.13:\n",
            "      Successfully uninstalled multiprocess-0.70.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-2.2.2 dill-0.3.4 frozenlist-1.3.0 fsspec-2022.5.0 multidict-6.0.2 multiprocess-0.70.12.2 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ar9ss0KGp1gs",
        "outputId": "bc1b2931-aeeb-4618-fb88-a76cd88f0efd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ujson\n",
            "  Downloading ujson-5.3.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (45 kB)\n",
            "\u001b[K     |████████████████████████████████| 45 kB 1.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: ujson\n",
            "Successfully installed ujson-5.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install ujson"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxrj2Tsatb6R",
        "outputId": "680ac905-6482-488d-c51c-9be4bcc284b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gitpython\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from gitpython) (4.2.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.6 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, gitdb, gitpython\n",
            "Successfully installed gitdb-4.0.9 gitpython-3.1.27 smmap-5.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install gitpython"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2TXnN9HYrem"
      },
      "source": [
        "Se necessário, instalar:\n",
        "\n",
        "* !pip install torch==1.10.0\n",
        "* !pip install spacy\n",
        "* "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlk-FsfZYrem"
      },
      "source": [
        "If you are indeed on a GPU machine, then run the following to ensure complete CUDA support:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fl5wBNCxYrem",
        "outputId": "1695157e-7f9c-4781-a147-d043a159c2dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: cupy-cuda111 in /usr/local/lib/python3.7/dist-packages (9.4.0)\n",
            "Requirement already satisfied: numpy<1.24,>=1.17 in /usr/local/lib/python3.7/dist-packages (from cupy-cuda111) (1.21.6)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.7/dist-packages (from cupy-cuda111) (0.8)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    !pip install cupy-cuda111"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ej8kZeh6Yren"
      },
      "source": [
        "If the above doesn't work, it might be because you don't have CUDA version 11.1. Run "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PojRXsuPYren",
        "outputId": "6ce25b73-3eb3-4474-c602-50eb74eb0d89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    !nvcc --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfZEOAL2Yren"
      },
      "source": [
        "and then install the corresponding `cupy-cuda`. See [this table](https://docs.cupy.dev/en/stable/install.html#installing-cupy-from-pypi) for details on which one to install for different scenarios."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFM54iO7Yren"
      },
      "source": [
        "### General set-up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hL9AAtTzYren"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "from contextlib import nullcontext\n",
        "from collections import namedtuple\n",
        "from datasets import load_dataset\n",
        "import datasets\n",
        "import json\n",
        "import numpy as np\n",
        "import random\n",
        "import re \n",
        "import string\n",
        "import torch\n",
        "from typing import List\n",
        "from getpass import getpass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNXANb8fYreo"
      },
      "source": [
        "Try to set all the seeds for reproducibility (won't extend to GPT-3):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIvsYoIpYreo"
      },
      "outputs": [],
      "source": [
        "seed = 1\n",
        "\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKp57bQZYrep"
      },
      "source": [
        "The following should install the version of [Faiss](https://github.com/facebookresearch/faiss) that will cooperate with your set-up:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGUj1O9wYrep",
        "outputId": "7849a94f-52fa-4b52-fa36-a491dc03cd39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting faiss-gpu==1.7.0\n",
            "  Downloading faiss_gpu-1.7.0-cp37-cp37m-manylinux2014_x86_64.whl (89.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 89.4 MB 168 kB/s \n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.0\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    !pip install faiss-gpu==1.7.0\n",
        "else:\n",
        "    !pip install faiss-cpu==1.7.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mp1C-oyYreq"
      },
      "source": [
        "### Language model set-up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEUY5P8GYreq"
      },
      "source": [
        "To use the GPT-3 API, install the OpenAI library:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        },
        "id": "4FclKZiuYreq",
        "outputId": "f89d70de-2ba7-49b9-b364-ef9f9ccad615"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.19.0.tar.gz (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 916 kB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pandas-stubs>=1.1.0.11\n",
            "  Downloading pandas_stubs-1.2.0.61-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 7.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.2.3 in /usr/local/lib/python3.7/dist-packages (from openai) (1.3.5)\n",
            "Requirement already satisfied: openpyxl>=3.0.7 in /usr/local/lib/python3.7/dist-packages (from openai) (3.0.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from openai) (4.64.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.7/dist-packages (from openai) (2.23.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl>=3.0.7->openai) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from pandas-stubs>=1.1.0.11->openai) (4.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.3->openai) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (3.0.4)\n",
            "Building wheels for collected packages: openai\n",
            "  Building wheel for openai (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.19.0-py3-none-any.whl size=53535 sha256=80b0d0eea1f99a34ee34e62aa3883a6dc4be052023908c06e72464260a829ffc\n",
            "  Stored in directory: /root/.cache/pip/wheels/94/b5/c0/928013bd6418b23b9c5d89fb24cdeb1faae899c11377d69609\n",
            "Successfully built openai\n",
            "Installing collected packages: pandas-stubs, openai\n",
            "Successfully installed openai-0.19.0 pandas-stubs-1.2.0.61\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cbE328hYrer"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import transformers\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKQEIYGDYrer"
      },
      "outputs": [],
      "source": [
        "#datasets.utils.logging.set_verbosity_error()\n",
        "#transformers.utils.logging.set_verbosity_error()\n",
        "datasets.utils.logging.set_verbosity_warning()\n",
        "transformers.utils.logging.set_verbosity_info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axUPfnNmYrer"
      },
      "source": [
        "### ColBERT set-up\n",
        "\n",
        "Our retriever will be a ColbERT-based model ([Khattab and Zaharia 2020](https://arxiv.org/abs/2004.12832)). ColBERT is a powerful neural information retrieval (Neural IR) model that has proven extremely successful in retrieval applications and as a component in a variety of different systems for OpenQA and other knowledge-intensive tasks (e.g., [Khattab et al. 2021a](https://aclanthology.org/2021.tacl-1.55/); [Khattab et al. 2021b](https://proceedings.neurips.cc/paper/2021/hash/e8b1cbd05f6e6a358a81dee52493dd06-Abstract.html); [Santhanam, Khattab, et al. 2021](https://arxiv.org/abs/2112.01488)).\n",
        "\n",
        "The following will clone the ColBERTv2 repository for use in this notebook:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5wP933JYrer",
        "outputId": "4b312ce2-f393-41c9-c865-8005e2b913e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'ColBERT'...\n",
            "remote: Enumerating objects: 772, done.\u001b[K\n",
            "remote: Counting objects: 100% (395/395), done.\u001b[K\n",
            "remote: Compressing objects: 100% (146/146), done.\u001b[K\n",
            "remote: Total 772 (delta 279), reused 324 (delta 249), pack-reused 377\u001b[K\n",
            "Receiving objects: 100% (772/772), 306.28 KiB | 2.55 MiB/s, done.\n",
            "Resolving deltas: 100% (425/425), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone -b cpu_inference https://github.com/stanford-futuredata/ColBERT.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LWz4f-3Yres",
        "outputId": "868bf102-6128-43f0-9092-6bb737f7a01b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['', '/content', '/env/python', '/usr/lib/python37.zip', '/usr/lib/python3.7', '/usr/lib/python3.7/lib-dynload', '/usr/local/lib/python3.7/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.7/dist-packages/IPython/extensions', '/root/.ipython']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "print(sys.path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75Pzq8AzpiQU"
      },
      "outputs": [],
      "source": [
        "sys.path.insert(0, 'ColBERT/')\n",
        "#print(sys.path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3E7axHE5pqaT",
        "outputId": "68ec9b00-c486-47e3-b182-b1c4668ef060"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ColBERT/colbert/indexing/codecs/residual.py:10: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
            "  assert(not torch.cuda.is_available(), \"cupy must be installed in GPU mode\")\n"
          ]
        }
      ],
      "source": [
        "from colbert.infra import Run, RunConfig, ColBERTConfig\n",
        "from colbert.data import Collection\n",
        "from colbert.searcher import Searcher\n",
        "from utility.utils.dpr import has_answer, DPR_normalize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5ganiuNYres"
      },
      "source": [
        "## Language models\n",
        "\n",
        "In few-shot OpenQA, the language model (LM) must read in a prompt and answer the question posed somewhere in the prompt. We propose two basic strategies:\n",
        "\n",
        "* [EleutherAI](https://www.eleuther.ai/) has released GPT-2-style models in a variety of sizes. These are free to use and easy to use via Hugging Face, and the larger ones very effective for our task, with GPT-J competitive with GPT-3 even though it has only 6B parameters (vs. 145B for GPT-3). The downside here is that the larger models in this family might be very slow and very difficult to work with unless you have access to really impressive GPU hardware. In testing with the free version of Google Colab, we were basically able to do everything we needed to do for the 1.3B parameter model, but the larger one caused too many problems to be viable.\n",
        "\n",
        "* OpenAI has outstanding API access to GPT-3. You can sign up for [a free account](https://beta.openai.com/signup), and, as of this writing, you get US$18 in credit when you sign up. This is more than enough for the current assignment provided you are careful about how much testing you do. The benefits here are that the API is blazingly fast and requires nothing of your computer in terms of GPU support, and you're getting responses from a 145B parameter model that is truly exceptional.\n",
        "\n",
        "Our suggestion is to do basic development with `\"gpt-neo-125M\"`, scale up to `\"gpt-neo-1.3B\"` once you have a sense for what your original system will be like, and then do your final bake-off entry with GPT-3. The functions `run_eleuther` and `run_gpt3` defined below are totally interchangeable, so this kind of development path should be easy to take."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fca8-RXjYres"
      },
      "source": [
        "### Answerhood"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6KepnjTYret"
      },
      "outputs": [],
      "source": [
        "def _find_generated_answer(tokens, newline=\"\\n\" ): \n",
        "    \"\"\"Our LMs tend to insert initial newline characters before\n",
        "    they begin generating text. This function ensures that we \n",
        "    properly capture the true first line as the answer while\n",
        "    also ensuring that token probabilities are aligned.\"\"\"        \n",
        "    answer_token_indices = []\n",
        "    char_seen = False            \n",
        "    for i, tok in enumerate(tokens):\n",
        "        # This is the main condition: a newline that isn't an initial\n",
        "        # string of newlines:\n",
        "        if tok == newline and char_seen:\n",
        "            break\n",
        "        # Keep the initial newlines for consistency:\n",
        "        elif tok == newline and not char_seen:\n",
        "            answer_token_indices.append(i)\n",
        "        # Proper tokens:\n",
        "        elif tok != newline:\n",
        "            char_seen = True\n",
        "            answer_token_indices.append(i)\n",
        "    return answer_token_indices "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klW12GkAYret"
      },
      "source": [
        "### Eleuther models from Hugging Face"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "60fc978c38de4b7380486c3628a80580",
            "5f094894e4434ec1b8f3035953a54561",
            "b3ca85c21bc54756a79f47c2a1bd3bf2",
            "3539f428334a48dcbbeb93fd65fd567e",
            "0e8a97bab2294583bf0ebf2cb469b404",
            "850c7b8b9a7348b7a717b6949c19d975",
            "5bad75932665486dab40377b41dcae7e",
            "5b3a6c7f95ff4bcfb6a0f6a53e31c363",
            "5040f8d0972c4e1b885394b67fdc964b",
            "d77e4365e28049ecaef374394eed15ef",
            "e97b339812294939be5d6d9870bcbb79",
            "704775c94eef4ca08e575e08cf6e7549",
            "2d384da8922040e7a85b99c68aeb8e1e",
            "0052cafd45474bfaaf2356a809b8ab8f",
            "482d529f86864da49a84b7634c164b4f",
            "e8152eb7d946460ba1ee26697acd1f28",
            "d70ee10baac34852afabb6c5fe377d32",
            "28a095b67fdb4e64849114da743a211b",
            "746831b8b3b24f79b05eab1ede2931d7",
            "093bf95cbcc9471c9788e4b5e53e74ac",
            "882329f06a884864aed2bbb3ad767bfe",
            "2d2aabaf53864d229a24aa4351cde250",
            "5f28af2204f44951af30da8ff19607c1",
            "9affd2c86dab4c1287d858a12bdca36f",
            "2f7e8f2f019f4110b6ff3d2cb1194207",
            "a0b543ae60ae4d8c89bc65fb5e9c2655",
            "b32f26847ed74c338b6a1154b1cbf025",
            "b077e97c40c14df7b24b3b4de5c1c325",
            "3603bdf6e1cd4a92be658847cd05d140",
            "b995d2d434884b95a6ed27ca35f0701e",
            "65dbec85c4c440dc87a2fe83f2c0c6de",
            "9ebc962deaf241409e2f7807ce42d352",
            "e78bad9898274b59b2b187668e3cf86a",
            "c17cfaba919740b2a0737f6467e401a1",
            "7693bba999da4a5aa00f8b80b93033ce",
            "8dda0783b61e4fa0b15b067a3edde7ed",
            "2d3531fa44f8443b8bf6db4ce70c28bf",
            "2d330683ae74434586f39a079ed602cd",
            "64b8a98caa574e05898dfab287daaebc",
            "39d2bfb749e64f1f895e5a46f9fee71f",
            "ffb346b2be2744568c17588151c53978",
            "c2a9aa86e8c94b38b917584a56d8eb81",
            "c3515c902ab94a57b523e3d5dd1afb10",
            "f85bc8c52a5347f6a6e82504b9eebad8",
            "06101e7ee98b4df49564b6584c68fadc",
            "383379fe15b94faf8b41e8f275d671e4",
            "32b1008c4e8f4e7682c031b30bf389c4",
            "e2301a6c44144aecadfd64fb2fcbf9a1",
            "b0feee66ceaf4132a76d5cc8176e1183",
            "31e5a2f3fc6044ac8a08c5286338307e",
            "3ddcad33566f44c4886629e1b09f0163",
            "fbd037a19b0245f3ae0bea1a42e126da",
            "00ee280de0df457ab2927172e86589a9",
            "b4ee18523e4f4c369b2464abd406057e",
            "271abe49dc054863a07a7d4dea6c0865",
            "a7df7dfb55a9475692c3f4cc52619613",
            "c3ddf5db64aa4914b0a56b749ce504ee",
            "488959fbdb9c4fe999284e4d09e094c4",
            "66d57124c640469aae66a6e4104a87a6",
            "91f38f5c3ccb4195b610db621fc17a85",
            "d27d7971acee4e5ba6d532e743be97f2",
            "78a391fb49444ef5a982e7cceafa9d56",
            "c89addfe272a44d8adc56424f95459f3",
            "73a63281463b47c09aba00b2e086cd71",
            "5912f66fcd664f5193c2912559c34572",
            "170b400de66c4da4af17b5a567b2d326"
          ]
        },
        "id": "1-FkbTaUYret",
        "outputId": "7718b650-14a4-4adb-dae4-823047ed0c65"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpzcb7mssp\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "60fc978c38de4b7380486c3628a80580",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/560 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "storing https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/tokenizer_config.json in cache at /root/.cache/huggingface/transformers/3cc88b3aa29bb2546db2dc21783292e2a086bb7158c7b5ceddeb24158a85c183.e74f7c3643ee79eb023ead36008be72fe726dada60fa3b2a0569925cfefa1e74\n",
            "creating metadata file for /root/.cache/huggingface/transformers/3cc88b3aa29bb2546db2dc21783292e2a086bb7158c7b5ceddeb24158a85c183.e74f7c3643ee79eb023ead36008be72fe726dada60fa3b2a0569925cfefa1e74\n",
            "https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp7sbidvcr\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "704775c94eef4ca08e575e08cf6e7549",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/0.98k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "storing https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/29380fef22a43cbfb3d3a6c8e2f4fd951459584d87c34e4621b30580a54aca84.f0f7ebddfc6e15a23ac33e7fa95cd8cca05edf87cc74f9e3be7905f538a59762\n",
            "creating metadata file for /root/.cache/huggingface/transformers/29380fef22a43cbfb3d3a6c8e2f4fd951459584d87c34e4621b30580a54aca84.f0f7ebddfc6e15a23ac33e7fa95cd8cca05edf87cc74f9e3be7905f538a59762\n",
            "loading configuration file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/29380fef22a43cbfb3d3a6c8e2f4fd951459584d87c34e4621b30580a54aca84.f0f7ebddfc6e15a23ac33e7fa95cd8cca05edf87cc74f9e3be7905f538a59762\n",
            "Model config GPTNeoConfig {\n",
            "  \"_name_or_path\": \"EleutherAI/gpt-neo-125M\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPTNeoForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0,\n",
            "  \"attention_layers\": [\n",
            "    \"global\",\n",
            "    \"local\",\n",
            "    \"global\",\n",
            "    \"local\",\n",
            "    \"global\",\n",
            "    \"local\",\n",
            "    \"global\",\n",
            "    \"local\",\n",
            "    \"global\",\n",
            "    \"local\",\n",
            "    \"global\",\n",
            "    \"local\"\n",
            "  ],\n",
            "  \"attention_types\": [\n",
            "    [\n",
            "      [\n",
            "        \"global\",\n",
            "        \"local\"\n",
            "      ],\n",
            "      6\n",
            "    ]\n",
            "  ],\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embed_dropout\": 0,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": null,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"max_length\": 2000,\n",
            "  \"max_position_embeddings\": 2048,\n",
            "  \"model_type\": \"gpt_neo\",\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"resid_dropout\": 0,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257,\n",
            "  \"window_size\": 256\n",
            "}\n",
            "\n",
            "https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/vocab.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp62sqg5jn\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5f28af2204f44951af30da8ff19607c1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "storing https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/vocab.json in cache at /root/.cache/huggingface/transformers/08c00c4159e921d4c941ac75732643373aba509d9b352a82bbbb043a94058d98.a552555fdda56a1c7c9a285bccfd44ac8e4b9e26c8c9b307831b3ea3ac782b45\n",
            "creating metadata file for /root/.cache/huggingface/transformers/08c00c4159e921d4c941ac75732643373aba509d9b352a82bbbb043a94058d98.a552555fdda56a1c7c9a285bccfd44ac8e4b9e26c8c9b307831b3ea3ac782b45\n",
            "https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/merges.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmphu8tpfxc\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c17cfaba919740b2a0737f6467e401a1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "storing https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/merges.txt in cache at /root/.cache/huggingface/transformers/12305762709d884a770efe7b0c68a7f4bc918da44e956058d43da0d12f7bea20.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "creating metadata file for /root/.cache/huggingface/transformers/12305762709d884a770efe7b0c68a7f4bc918da44e956058d43da0d12f7bea20.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/special_tokens_map.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpispgdkns\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "06101e7ee98b4df49564b6584c68fadc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/357 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "storing https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/special_tokens_map.json in cache at /root/.cache/huggingface/transformers/6c3239a63aaf46ec7625b38abfe41fc2ce0b25f90800aefe6526256340d4ab6d.2b8bf81243d08385c806171bc7ced6d2a0dcc7f896ca637f4e777418f7f0cc3c\n",
            "creating metadata file for /root/.cache/huggingface/transformers/6c3239a63aaf46ec7625b38abfe41fc2ce0b25f90800aefe6526256340d4ab6d.2b8bf81243d08385c806171bc7ced6d2a0dcc7f896ca637f4e777418f7f0cc3c\n",
            "loading file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/08c00c4159e921d4c941ac75732643373aba509d9b352a82bbbb043a94058d98.a552555fdda56a1c7c9a285bccfd44ac8e4b9e26c8c9b307831b3ea3ac782b45\n",
            "loading file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/12305762709d884a770efe7b0c68a7f4bc918da44e956058d43da0d12f7bea20.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "loading file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/tokenizer.json from cache at None\n",
            "loading file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/6c3239a63aaf46ec7625b38abfe41fc2ce0b25f90800aefe6526256340d4ab6d.2b8bf81243d08385c806171bc7ced6d2a0dcc7f896ca637f4e777418f7f0cc3c\n",
            "loading file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/3cc88b3aa29bb2546db2dc21783292e2a086bb7158c7b5ceddeb24158a85c183.e74f7c3643ee79eb023ead36008be72fe726dada60fa3b2a0569925cfefa1e74\n",
            "loading configuration file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/29380fef22a43cbfb3d3a6c8e2f4fd951459584d87c34e4621b30580a54aca84.f0f7ebddfc6e15a23ac33e7fa95cd8cca05edf87cc74f9e3be7905f538a59762\n",
            "Model config GPTNeoConfig {\n",
            "  \"_name_or_path\": \"EleutherAI/gpt-neo-125M\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPTNeoForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0,\n",
            "  \"attention_layers\": [\n",
            "    \"global\",\n",
            "    \"local\",\n",
            "    \"global\",\n",
            "    \"local\",\n",
            "    \"global\",\n",
            "    \"local\",\n",
            "    \"global\",\n",
            "    \"local\",\n",
            "    \"global\",\n",
            "    \"local\",\n",
            "    \"global\",\n",
            "    \"local\"\n",
            "  ],\n",
            "  \"attention_types\": [\n",
            "    [\n",
            "      [\n",
            "        \"global\",\n",
            "        \"local\"\n",
            "      ],\n",
            "      6\n",
            "    ]\n",
            "  ],\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embed_dropout\": 0,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": null,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"max_position_embeddings\": 2048,\n",
            "  \"model_type\": \"gpt_neo\",\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"resid_dropout\": 0,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257,\n",
            "  \"window_size\": 256\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/29380fef22a43cbfb3d3a6c8e2f4fd951459584d87c34e4621b30580a54aca84.f0f7ebddfc6e15a23ac33e7fa95cd8cca05edf87cc74f9e3be7905f538a59762\n",
            "Model config GPTNeoConfig {\n",
            "  \"_name_or_path\": \"EleutherAI/gpt-neo-125M\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPTNeoForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0,\n",
            "  \"attention_layers\": [\n",
            "    \"global\",\n",
            "    \"local\",\n",
            "    \"global\",\n",
            "    \"local\",\n",
            "    \"global\",\n",
            "    \"local\",\n",
            "    \"global\",\n",
            "    \"local\",\n",
            "    \"global\",\n",
            "    \"local\",\n",
            "    \"global\",\n",
            "    \"local\"\n",
            "  ],\n",
            "  \"attention_types\": [\n",
            "    [\n",
            "      [\n",
            "        \"global\",\n",
            "        \"local\"\n",
            "      ],\n",
            "      6\n",
            "    ]\n",
            "  ],\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embed_dropout\": 0,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": null,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"max_position_embeddings\": 2048,\n",
            "  \"model_type\": \"gpt_neo\",\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"resid_dropout\": 0,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257,\n",
            "  \"window_size\": 256\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/29380fef22a43cbfb3d3a6c8e2f4fd951459584d87c34e4621b30580a54aca84.f0f7ebddfc6e15a23ac33e7fa95cd8cca05edf87cc74f9e3be7905f538a59762\n",
            "Model config GPTNeoConfig {\n",
            "  \"_name_or_path\": \"EleutherAI/gpt-neo-125M\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPTNeoForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0,\n",
            "  \"attention_layers\": [\n",
            "    \"global\",\n",
            "    \"local\",\n",
            "    \"global\",\n",
            "    \"local\",\n",
            "    \"global\",\n",
            "    \"local\",\n",
            "    \"global\",\n",
            "    \"local\",\n",
            "    \"global\",\n",
            "    \"local\",\n",
            "    \"global\",\n",
            "    \"local\"\n",
            "  ],\n",
            "  \"attention_types\": [\n",
            "    [\n",
            "      [\n",
            "        \"global\",\n",
            "        \"local\"\n",
            "      ],\n",
            "      6\n",
            "    ]\n",
            "  ],\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embed_dropout\": 0,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": null,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"max_position_embeddings\": 2048,\n",
            "  \"model_type\": \"gpt_neo\",\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"resid_dropout\": 0,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257,\n",
            "  \"window_size\": 256\n",
            "}\n",
            "\n",
            "https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp17xh66e5\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a7df7dfb55a9475692c3f4cc52619613",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/502M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "storing https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/b0ace3b93ace62067a246888f1e54e2d3ec20807d4d3e27ac602eef3b7091c0b.6525df88f1d5a2d33d95ce2458ef6af9658fe7d1393d6707e0e318779ccc68ff\n",
            "creating metadata file for /root/.cache/huggingface/transformers/b0ace3b93ace62067a246888f1e54e2d3ec20807d4d3e27ac602eef3b7091c0b.6525df88f1d5a2d33d95ce2458ef6af9658fe7d1393d6707e0e318779ccc68ff\n",
            "loading weights file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/b0ace3b93ace62067a246888f1e54e2d3ec20807d4d3e27ac602eef3b7091c0b.6525df88f1d5a2d33d95ce2458ef6af9658fe7d1393d6707e0e318779ccc68ff\n",
            "All model checkpoint weights were used when initializing GPTNeoForCausalLM.\n",
            "\n",
            "All the weights of GPTNeoForCausalLM were initialized from the model checkpoint at EleutherAI/gpt-neo-125M.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPTNeoForCausalLM for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "# \"gpt-neo-125M\" \"gpt-neo-1.3B\" \"gpt-neo-2.7B\" \"gpt-j-6B\"\n",
        "eleuther_model_name = \"gpt-neo-125M\"\n",
        "\n",
        "eleuther_tokenizer = AutoTokenizer.from_pretrained(\n",
        "    f\"EleutherAI/{eleuther_model_name}\", \n",
        "    padding_side=\"left\", \n",
        "    padding='longest', \n",
        "    truncation='longest_first', max_length=2000)\n",
        "eleuther_tokenizer.pad_token = eleuther_tokenizer.eos_token\n",
        "\n",
        "eleuther_model = AutoModelForCausalLM.from_pretrained(\n",
        "    f\"EleutherAI/{eleuther_model_name}\")\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "eleuther_model = eleuther_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEo9YKwNYret"
      },
      "outputs": [],
      "source": [
        "def run_eleuther(prompts, temperature=0.1, top_p=0.95, **generate_kwargs): \n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    prompts : iterable of str\n",
        "    temperature : float\n",
        "        It seems best to set it low for this task!\n",
        "    top_p : float\n",
        "       \n",
        "    For options for `generate_kwargs`, see:\n",
        "    \n",
        "    https://huggingface.co/docs/transformers/master/en/main_classes/text_generation#transformers.generation_utils.GenerationMixin.generate\n",
        "    \n",
        "    Options that are likely to be especially relevant include \n",
        "    `temperature`, `length_penalty`, and the parameters that\n",
        "    determine the decoding strategy. With `num_return_sequences > 1`,\n",
        "    the default parameters in this function do multinomial sampling.\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    list of dicts\n",
        "    \n",
        "    {\"prompt\": str, \n",
        "     \"generated_text\": str, \"generated_tokens\": list of str, \"generated_probs\": list of float,\n",
        "     \"answer\": str, \"answer_tokens\": list of str, \"answer_probs\": list of float\n",
        "    }\n",
        "         \n",
        "    \"\"\"\n",
        "    prompt_ids = eleuther_tokenizer(\n",
        "        prompts, return_tensors=\"pt\", padding=True).input_ids.to(device)\n",
        "        \n",
        "    with torch.inference_mode():\n",
        "        # Automatic mixed precision if possible.\n",
        "        with torch.cuda.amp.autocast() if torch.cuda.is_available() else nullcontext():\n",
        "            model_output = eleuther_model.generate(\n",
        "                prompt_ids,\n",
        "                temperature=temperature,\n",
        "                do_sample=True,\n",
        "                top_p=top_p,           \n",
        "                max_new_tokens=16,\n",
        "                num_return_sequences=1,                \n",
        "                pad_token_id=eleuther_tokenizer.eos_token_id, \n",
        "                return_dict_in_generate=True,\n",
        "                output_scores=True,\n",
        "                **generate_kwargs)\n",
        "        \n",
        "    # Converting output scores using the helpful recipe here:\n",
        "    # https://discuss.huggingface.co/t/generation-probabilities-how-to-compute-probabilities-of-output-scores-for-gpt2/3175\n",
        "    gen_ids = model_output.sequences[:, prompt_ids.shape[-1] :]\n",
        "    gen_probs = torch.stack(model_output.scores, dim=1).softmax(-1)\n",
        "    gen_probs = torch.gather(gen_probs, 2, gen_ids[:, :, None]).squeeze(-1)\n",
        "    \n",
        "    # Generated texts, including the prompts:\n",
        "    gen_texts = eleuther_tokenizer.batch_decode(\n",
        "        model_output.sequences, skip_special_tokens=True)\n",
        "    \n",
        "    data = []     \n",
        "    iterator = zip(prompts, gen_ids, gen_texts, gen_probs)    \n",
        "    for prompt, gen_id, gen_text, gen_prob in iterator:       \n",
        "        gen_tokens = eleuther_tokenizer.convert_ids_to_tokens(gen_id)\n",
        "        generated_text = gen_text[len(prompt): ]\n",
        "        gen_prob = [float(x) for x in gen_prob.cpu().numpy()] # float for JSON storage\n",
        "        ans_indices = _find_generated_answer(gen_tokens, newline=\"Ċ\")\n",
        "        answer_tokens = [gen_tokens[i] for i in ans_indices]\n",
        "        answer_probs = [gen_prob[i] for i in ans_indices]\n",
        "        answer = \"\".join(answer_tokens).replace(\"Ġ\", \" \").replace(\"Ċ\", \"\\n\")                                       \n",
        "        data.append({\n",
        "            \"prompt\": prompt,\n",
        "            \"generated_text\": generated_text,\n",
        "            \"generated_tokens\": gen_tokens,\n",
        "            \"generated_probs\": gen_prob,\n",
        "            \"generated_answer\": answer,\n",
        "            \"generated_answer_probs\": answer_probs,\n",
        "            \"generated_answer_tokens\": answer_tokens})                        \n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fIfuTEGYreu",
        "outputId": "ce85529e-5647-41eb-990e-9ccc85bb3536"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'generated_answer': '\\n\\nThe Stanford University Foundation is a non-profit organization that provides scholarships to',\n",
              "  'generated_answer_probs': [1.0,\n",
              "   1.0,\n",
              "   0.9111328125,\n",
              "   1.0,\n",
              "   1.0,\n",
              "   1.0,\n",
              "   1.0,\n",
              "   1.0,\n",
              "   0.85986328125,\n",
              "   1.0,\n",
              "   1.0,\n",
              "   1.0,\n",
              "   1.0,\n",
              "   0.90966796875,\n",
              "   0.7216796875,\n",
              "   0.671875],\n",
              "  'generated_answer_tokens': ['Ċ',\n",
              "   'Ċ',\n",
              "   'The',\n",
              "   'ĠStanford',\n",
              "   'ĠUniversity',\n",
              "   'ĠFoundation',\n",
              "   'Ġis',\n",
              "   'Ġa',\n",
              "   'Ġnon',\n",
              "   '-',\n",
              "   'profit',\n",
              "   'Ġorganization',\n",
              "   'Ġthat',\n",
              "   'Ġprovides',\n",
              "   'Ġscholarships',\n",
              "   'Ġto'],\n",
              "  'generated_probs': [1.0,\n",
              "   1.0,\n",
              "   0.9111328125,\n",
              "   1.0,\n",
              "   1.0,\n",
              "   1.0,\n",
              "   1.0,\n",
              "   1.0,\n",
              "   0.85986328125,\n",
              "   1.0,\n",
              "   1.0,\n",
              "   1.0,\n",
              "   1.0,\n",
              "   0.90966796875,\n",
              "   0.7216796875,\n",
              "   0.671875],\n",
              "  'generated_text': '\\n\\nThe Stanford University Foundation is a non-profit organization that provides scholarships to',\n",
              "  'generated_tokens': ['Ċ',\n",
              "   'Ċ',\n",
              "   'The',\n",
              "   'ĠStanford',\n",
              "   'ĠUniversity',\n",
              "   'ĠFoundation',\n",
              "   'Ġis',\n",
              "   'Ġa',\n",
              "   'Ġnon',\n",
              "   '-',\n",
              "   'profit',\n",
              "   'Ġorganization',\n",
              "   'Ġthat',\n",
              "   'Ġprovides',\n",
              "   'Ġscholarships',\n",
              "   'Ġto'],\n",
              "  'prompt': 'What year was Stanford University founded?'},\n",
              " {'generated_answer': '\\n\\nThe Stanford University School of Law is a private, non-profit,',\n",
              "  'generated_answer_probs': [1.0,\n",
              "   1.0,\n",
              "   0.8818359375,\n",
              "   1.0,\n",
              "   1.0,\n",
              "   1.0,\n",
              "   1.0,\n",
              "   0.07806396484375,\n",
              "   1.0,\n",
              "   1.0,\n",
              "   1.0,\n",
              "   1.0,\n",
              "   1.0,\n",
              "   1.0,\n",
              "   1.0,\n",
              "   1.0],\n",
              "  'generated_answer_tokens': ['Ċ',\n",
              "   'Ċ',\n",
              "   'The',\n",
              "   'ĠStanford',\n",
              "   'ĠUniversity',\n",
              "   'ĠSchool',\n",
              "   'Ġof',\n",
              "   'ĠLaw',\n",
              "   'Ġis',\n",
              "   'Ġa',\n",
              "   'Ġprivate',\n",
              "   ',',\n",
              "   'Ġnon',\n",
              "   '-',\n",
              "   'profit',\n",
              "   ','],\n",
              "  'generated_probs': [1.0,\n",
              "   1.0,\n",
              "   0.8818359375,\n",
              "   1.0,\n",
              "   1.0,\n",
              "   1.0,\n",
              "   1.0,\n",
              "   0.07806396484375,\n",
              "   1.0,\n",
              "   1.0,\n",
              "   1.0,\n",
              "   1.0,\n",
              "   1.0,\n",
              "   1.0,\n",
              "   1.0,\n",
              "   1.0],\n",
              "  'generated_text': '\\n\\nThe Stanford University School of Law is a private, non-profit,',\n",
              "  'generated_tokens': ['Ċ',\n",
              "   'Ċ',\n",
              "   'The',\n",
              "   'ĠStanford',\n",
              "   'ĠUniversity',\n",
              "   'ĠSchool',\n",
              "   'Ġof',\n",
              "   'ĠLaw',\n",
              "   'Ġis',\n",
              "   'Ġa',\n",
              "   'Ġprivate',\n",
              "   ',',\n",
              "   'Ġnon',\n",
              "   '-',\n",
              "   'profit',\n",
              "   ','],\n",
              "  'prompt': 'In which year did Stanford first enroll students?'}]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eleuther_ex = run_eleuther([    \n",
        "    \"What year was Stanford University founded?\", \n",
        "    \"In which year did Stanford first enroll students?\"])\n",
        "\n",
        "eleuther_ex"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiN04KynYreu"
      },
      "source": [
        "### GPT-3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GRXfd5pJ4F93"
      },
      "outputs": [],
      "source": [
        "# Fill this in with the value from your OpenAI account. First\n",
        "# verify that your account is set up with a spending limit that\n",
        "# you are comfortable with. If you just opened your account,\n",
        "# you should have $18 in credit and so won't need to supply any\n",
        "# payment information.\n",
        "openai.api_key = getpass('Informe openai.api_key ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5t5HTfRkYreu"
      },
      "outputs": [],
      "source": [
        "def run_gpt3(prompts, engine=\"text-curie-001\", temperature=0.1, top_p=0.95, **gpt3_kwargs):\n",
        "    \"\"\"To use this function, sign up for an OpenAI account at\n",
        "        \n",
        "    https://beta.openai.com/signup\n",
        "    \n",
        "    That should give you $18 in free credits, which is more than enough\n",
        "    for this assignment assuming you are careful with testing.\n",
        "    \n",
        "    Once your account is set up, you can get your API key from your \n",
        "    account dashboard and paste it in below as the value of \n",
        "    `openai.api_key`.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    prompts : iterable of str\n",
        "    engine : str\n",
        "        This has to be one of the models whose name begins with \"text\".\n",
        "        The \"instruct\" class of models can't be used, since they seem\n",
        "        to depend on some kinds of QA-relevant supervision.        \n",
        "        For options, costs, and other details: \n",
        "        https://beta.openai.com/docs/engines/gpt-3                \n",
        "    temperature : float\n",
        "        It seems best to set it low for this task!\n",
        "    top_p : float\n",
        "        \n",
        "    For information about values for `gpt3_kwargs`, see\n",
        "    \n",
        "    https://beta.openai.com/docs/api-reference/completions\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    list of dicts   \n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    assert engine.startswith(\"text\"), \\\n",
        "        \"Please use an engine whose name begins with 'text'.\"\n",
        "        \n",
        "    response = openai.Completion.create(\n",
        "        engine=engine,       \n",
        "        prompt=prompts,\n",
        "        temperature=temperature,\n",
        "        top_p=top_p,\n",
        "        echo=False,   # This function will not work\n",
        "        logprobs=1,   # properly if any of these\n",
        "        n=1,          # are changed!\n",
        "        **gpt3_kwargs)\n",
        "    \n",
        "    # From here, we parse each example to get the values\n",
        "    # we need:\n",
        "    data = []\n",
        "    for ex, prompt in zip(response[\"choices\"], prompts):\n",
        "        tokens = ex[\"logprobs\"][\"tokens\"]\n",
        "        logprobs = ex[\"logprobs\"][\"token_logprobs\"]        \n",
        "        probs = list(np.exp(logprobs))\n",
        "        if \"<|endoftext|>\" in tokens:\n",
        "            end_i = tokens.index(\"<|endoftext|>\")\n",
        "            tokens = tokens[ : end_i]  # This leaves off the \"<|endoftext|>\"\n",
        "            probs = probs[ : end_i]    # token -- perhaps dubious.\n",
        "        ans_indices = _find_generated_answer(tokens)\n",
        "        answer_tokens = [tokens[i] for i in ans_indices]\n",
        "        answer_probs = [probs[i] for i in ans_indices]\n",
        "        answer = \"\".join(answer_tokens)        \n",
        "        data.append({\n",
        "            \"prompt\": prompt,\n",
        "            \"generated_text\": ex[\"text\"],\n",
        "            \"generated_tokens\": tokens,\n",
        "            \"generated_probs\": probs,\n",
        "            \"generated_answer\": answer,\n",
        "            \"generated_answer_tokens\": answer_tokens,\n",
        "            \"generated_answer_probs\": answer_probs})\n",
        "        \n",
        "    return data             "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "y3jbKTAbYrev",
        "outputId": "2ed00033-9bb0-4f84-ae9d-962ff8e8e790"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'generated_answer': '\\n\\n1891',\n",
              "  'generated_answer_probs': [0.9991431717871095,\n",
              "   0.9997846349243882,\n",
              "   0.5741379962336021,\n",
              "   0.39573849184479504],\n",
              "  'generated_answer_tokens': ['\\n', '\\n', '18', '91'],\n",
              "  'generated_probs': [0.9991431717871095,\n",
              "   0.9997846349243882,\n",
              "   0.5741379962336021,\n",
              "   0.39573849184479504],\n",
              "  'generated_text': '\\n\\n1891',\n",
              "  'generated_tokens': ['\\n', '\\n', '18', '91'],\n",
              "  'prompt': 'What year was Stanford University founded?'},\n",
              " {'generated_answer': '\\n\\nStanford first enrolled students in 1891.',\n",
              "  'generated_answer_probs': [0.9993135207847473,\n",
              "   0.9998701106163566,\n",
              "   0.4383535510647387,\n",
              "   0.9999952788481447,\n",
              "   0.8323608735103043,\n",
              "   0.9814090478885719,\n",
              "   0.9988871687564463,\n",
              "   0.9936751893545676,\n",
              "   0.9917295955365046,\n",
              "   0.6287194545379907,\n",
              "   0.9849397876183434],\n",
              "  'generated_answer_tokens': ['\\n',\n",
              "   '\\n',\n",
              "   'Stan',\n",
              "   'ford',\n",
              "   ' first',\n",
              "   ' enrolled',\n",
              "   ' students',\n",
              "   ' in',\n",
              "   ' 18',\n",
              "   '91',\n",
              "   '.'],\n",
              "  'generated_probs': [0.9993135207847473,\n",
              "   0.9998701106163566,\n",
              "   0.4383535510647387,\n",
              "   0.9999952788481447,\n",
              "   0.8323608735103043,\n",
              "   0.9814090478885719,\n",
              "   0.9988871687564463,\n",
              "   0.9936751893545676,\n",
              "   0.9917295955365046,\n",
              "   0.6287194545379907,\n",
              "   0.9849397876183434],\n",
              "  'generated_text': '\\n\\nStanford first enrolled students in 1891.',\n",
              "  'generated_tokens': ['\\n',\n",
              "   '\\n',\n",
              "   'Stan',\n",
              "   'ford',\n",
              "   ' first',\n",
              "   ' enrolled',\n",
              "   ' students',\n",
              "   ' in',\n",
              "   ' 18',\n",
              "   '91',\n",
              "   '.'],\n",
              "  'prompt': 'In which year did Stanford first enroll students?'}]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gpt3_ex = run_gpt3([\n",
        "     \"What year was Stanford University founded?\",\n",
        "     \"In which year did Stanford first enroll students?\"])\n",
        "\n",
        "gpt3_ex"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGK3hCs9Yrev"
      },
      "source": [
        "## SQuAD\n",
        "\n",
        "Our core development dataset is [SQuAD](https://rajpurkar.github.io/SQuAD-explorer/). We chose this dataset because it is well-known and widely used, and it is large enough to support lots of meaningful development work, without, though, being so large as to require lots of compute power. It is also useful that it has gold passages supporting the standard QA formulation, so we can see how well our LM performs with an \"oracle\" retriever that always retrieves the gold passage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "referenced_widgets": [
            "dcf8888f65804746ab82fe710f4fb802",
            "770f7af20b134e149ef191368d53a7c2",
            "e9716f312dbd400ab0c1f70376de05f2",
            "ab53fad46ce541c491e49f1efadb0de1",
            "87597c08c77b474d8eb8687b332a12bb",
            "fc87e6fce133476489a9ea5aa913da66",
            "ee49908639d442338e3f1b5dcdce3ee9",
            "747ed3afe4be4bc8b2e08c93f132aabf",
            "e8797e81652c47c5b5ea068e9a1c2b23"
          ]
        },
        "id": "YQ_do58EYrev",
        "outputId": "7a8840fb-3bae-449e-bd66-6e60d11f2126"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dcf8888f65804746ab82fe710f4fb802",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/1.97k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "770f7af20b134e149ef191368d53a7c2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading metadata:   0%|          | 0.00/1.02k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset squad/plain_text (download: 33.51 MiB, generated: 85.63 MiB, post-processed: Unknown size, total: 119.14 MiB) to /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e9716f312dbd400ab0c1f70376de05f2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ab53fad46ce541c491e49f1efadb0de1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/8.12M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "87597c08c77b474d8eb8687b332a12bb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/1.05M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fc87e6fce133476489a9ea5aa913da66",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ee49908639d442338e3f1b5dcdce3ee9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/87599 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "747ed3afe4be4bc8b2e08c93f132aabf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split:   0%|          | 0/10570 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset squad downloaded and prepared to /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e8797e81652c47c5b5ea068e9a1c2b23",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "squad = load_dataset(\"squad\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbCUz66GYrev"
      },
      "source": [
        "The following utility just reads a SQuAD split in as a list of `SquadExample` instances:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "B9-0hkxgYrew"
      },
      "outputs": [],
      "source": [
        "SquadExample = namedtuple(\"SquadExample\",  \"id title context question answers\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "g2gt0dkeYrew"
      },
      "outputs": [],
      "source": [
        "def get_squad_split(squad, split=\"validation\"):\n",
        "    \"\"\"\n",
        "    Use `split='train'` for the train split.\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    list of SquadExample named tuples with attributes\n",
        "    id, title, context, question, answers\n",
        "    \n",
        "    \"\"\"    \n",
        "    fields = squad[split].features\n",
        "    data = zip(*[squad[split][field] for field in fields])\n",
        "    return [SquadExample(eid, title, context, question, answers[\"text\"]) \n",
        "            for eid, title, context, question, answers in data]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwHA-A3okTxc"
      },
      "source": [
        "### SQuAD dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NatnOLsDYrew"
      },
      "outputs": [],
      "source": [
        "squad_dev = get_squad_split(squad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jb-ZrSzoYrew",
        "outputId": "bd6d0523-04db-4fac-a53d-da717bc2ff63"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SquadExample(id='56be4db0acb8001400a502ec', title='Super_Bowl_50', context='Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi\\'s Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.', question='Which NFL team represented the AFC at Super Bowl 50?', answers=['Denver Broncos', 'Denver Broncos', 'Denver Broncos'])"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "squad_dev[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFW_T2O2kTxc"
      },
      "source": [
        "### SQuAD dev sample\n",
        "\n",
        "We'll use this fixed but presumably quite random set of examples for exploration and system development:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5xYYmrn4kTxc"
      },
      "outputs": [],
      "source": [
        "dev_exs = sorted(squad_dev, key=lambda x: hash(x.id))[: 200]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzbfGtSZkTxd"
      },
      "source": [
        "### SQuAD train\n",
        "\n",
        "To build few-shot prompts, we will often sample SQuAD train examples, so we load that split here:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QT4lmA01kTxd"
      },
      "outputs": [],
      "source": [
        "squad_train = get_squad_split(squad, \"train\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZpXMk-0Yrew"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "Our evaluation protocols are the standard ones for SQuAD and related tasks: exact match of the answer (EM) and token-level F1.\n",
        "\n",
        "We say further that the predicted answer is the first line of generated text after the prompt.\n",
        "\n",
        "The following evaluation code is taken from the [apple/ml-qrecc](https://github.com/apple/ml-qrecc/blob/main/utils/evaluate_qa.py) repository. It performs very basic string normalization before doing the core comparisons."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nHHntDSSYrew"
      },
      "outputs": [],
      "source": [
        "def normalize_answer(s: str) -> str:\n",
        "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
        "\n",
        "    def remove_articles(text):\n",
        "        regex = re.compile(r'\\b(a|an|the)\\b', re.UNICODE)\n",
        "        return re.sub(regex, ' ', text)\n",
        "\n",
        "    def white_space_fix(text):\n",
        "        return ' '.join(text.split())\n",
        "\n",
        "    def remove_punc(text):\n",
        "        exclude = set(string.punctuation)\n",
        "        return ''.join(ch for ch in text if ch not in exclude)\n",
        "\n",
        "    def lower(text):\n",
        "        return text.lower()\n",
        "\n",
        "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
        "\n",
        "\n",
        "def get_tokens(s: str) -> List[str]:\n",
        "    \"\"\"Normalize string and split string into tokens.\"\"\"\n",
        "    if not s:\n",
        "        return []\n",
        "    return normalize_answer(s).split()\n",
        "\n",
        "\n",
        "def compute_exact(a_gold: str, a_pred: str) -> int:\n",
        "    \"\"\"Compute the Exact Match score.\"\"\"\n",
        "    return int(normalize_answer(a_gold) == normalize_answer(a_pred))\n",
        "\n",
        "\n",
        "def compute_f1_from_tokens(gold_toks: List[str], pred_toks: List[str]) -> float:\n",
        "    \"\"\"Compute the F1 score from tokenized gold answer and prediction.\"\"\"\n",
        "    common = collections.Counter(gold_toks) & collections.Counter(pred_toks)\n",
        "    num_same = sum(common.values())\n",
        "\n",
        "    if len(gold_toks) == 0 or len(pred_toks) == 0:\n",
        "        # If either is no-answer, then F1 is 1 if they agree, 0 otherwise\n",
        "        return int(gold_toks == pred_toks)\n",
        "\n",
        "    if num_same == 0:\n",
        "        return 0\n",
        "\n",
        "    precision = 1.0 * num_same / len(pred_toks)\n",
        "    recall = 1.0 * num_same / len(gold_toks)\n",
        "    f1 = (2 * precision * recall) / (precision + recall)\n",
        "    return f1\n",
        "\n",
        "\n",
        "def compute_f1(a_gold: str, a_pred: str) -> float:\n",
        "    \"\"\"Compute the F1 score.\"\"\"\n",
        "    gold_toks = get_tokens(a_gold)\n",
        "    pred_toks = get_tokens(a_pred)\n",
        "    return compute_f1_from_tokens(gold_toks, pred_toks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJo6C7pgYrex"
      },
      "source": [
        "The following is our general evaluation function. We will make extensive use of it to evaluate different systems:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bJHSxnA6Yrex"
      },
      "outputs": [],
      "source": [
        "def evaluate(examples, prompts, gens):\n",
        "    \"\"\"Generic evalution function.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    examples: iterable of `SquadExample` instances\n",
        "    prompts: list of str\n",
        "    preds: list of LM-generated texts to evaluate as answers\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    dict with keys \"em_per\", \"macro_f1\", \"examples\", where\n",
        "    each \"examples\" value is a dict\n",
        "    \n",
        "    \"\"\"        \n",
        "    results = []\n",
        "    for ex, prompt, gen in zip(examples, prompts, gens):\n",
        "        answers = ex.answers\n",
        "        pred = gen['generated_answer']\n",
        "        # The result is the highest EM from the available answer strings:\n",
        "        em = max([compute_exact(ans, pred) for ans in answers])\n",
        "        f1 = max([compute_f1(ans, pred) for ans in answers])\n",
        "        gen.update({\n",
        "            \"id\": ex.id, \n",
        "            \"question\": ex.question, \n",
        "            \"prediction\": pred, \n",
        "            \"answers\": answers, \n",
        "            \"em\": em,\n",
        "            \"f1\": f1\n",
        "        })\n",
        "        results.append(gen)\n",
        "    data = {}        \n",
        "    data[\"macro_f1\"] = np.mean([d['f1'] for d in results])\n",
        "    data[\"em_per\"] = sum([d['em'] for d in results]) / len(results)\n",
        "    data[\"examples\"] = results\n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fj170C1PYrex"
      },
      "source": [
        "Here is a highly simplified example to help make the logic behind `evaluate` clearer:    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0bgFXLK3Yrex",
        "outputId": "6ef138dc-2d47-4cba-faf8-0bdcdd76a596"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'em_per': 1.0,\n",
              " 'examples': [{'answers': ['NLU', 'CS224u'],\n",
              "   'em': 1,\n",
              "   'f1': 1.0,\n",
              "   'generated_answer': 'NLU',\n",
              "   'generated_text': 'NLU\\nWho am I?',\n",
              "   'id': '0',\n",
              "   'prediction': 'NLU',\n",
              "   'question': 'What is the course to take?'}],\n",
              " 'macro_f1': 1.0}"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ex = namedtuple(\"SquadExample\",  \"id title context question answers\")\n",
        "\n",
        "examples = [\n",
        "    ex(\"0\", \"CS224u\", \n",
        "       \"The course to take is NLU!\", \n",
        "       \"What is the course to take?\", \n",
        "       [\"NLU\", \"CS224u\"])]\n",
        "\n",
        "prompts = [\"Dear model, Please answer this question!\\n\\nQ: What is the course to take?\\n\\nA:\"]\n",
        "\n",
        "gens = [{\"generated_answer\": \"NLU\", \"generated_text\": \"NLU\\nWho am I?\"}]\n",
        "\n",
        "evaluate(examples, prompts, gens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHZHve9NYrex"
      },
      "source": [
        "The bake-off uses `macro_f1` as the primary metric."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3LQv2lbYrex"
      },
      "source": [
        "## Open QA with no context\n",
        "\n",
        "We now have all the pieces we need to begin building few-shot OpenQA systems. Our first system is the simplest and most naive: we simply feed the question text in as the prompt and hope that the model provides an answer as the first line of its generated text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "swF4V0ngYrex"
      },
      "outputs": [],
      "source": [
        "def evaluate_no_context(examples, gen_func=run_eleuther, batch_size=20):\n",
        "    prompts = [] \n",
        "    gens = []\n",
        "    for i in range(0, len(examples), batch_size):\n",
        "        ps = [ex.question for ex in examples[i: i+batch_size]]\n",
        "        gs = gen_func(ps)        \n",
        "        prompts += ps\n",
        "        gens += gs    \n",
        "    return evaluate(examples, prompts, gens)    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aPuq5nzDYrex",
        "outputId": "027aad52-3a7d-461b-9a49-dd42776bdda2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.03770637777255424\n",
            "CPU times: user 2.87 s, sys: 15.2 ms, total: 2.88 s\n",
            "Wall time: 2.85 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "nocontext_results = evaluate_no_context(dev_exs)\n",
        "\n",
        "print(nocontext_results['macro_f1'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lWi1r1-oYrey",
        "outputId": "f59aa808-07e8-4eb7-ba97-c23c7b3b7560"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.09016647774982679\n",
            "CPU times: user 134 ms, sys: 7.1 ms, total: 141 ms\n",
            "Wall time: 5.57 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "nocontext_results_gpt3 = evaluate_no_context(dev_exs, gen_func=run_gpt3)\n",
        "\n",
        "print(nocontext_results_gpt3['macro_f1'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csAimDMGYrey"
      },
      "source": [
        "## Few-shot QA\n",
        "\n",
        "The above formulation is not especially fair to our model, since it doesn't convey anything about the intended structure of the prompt. We want the model to give us an answer to the input question, but we didn't specify that goal unambiguously. Perhaps we were looking for commentary on the question, or a count of the number of tokens it contains, or a passage containing the question string, or something else entirely.\n",
        "\n",
        "In few-shot QA, we construct a prompt that is intended to convey our intentions more clearly. The first part of the prompt gives some examples of what we want, and the final part provides the set-up for our actual question. In the current formulation, we assume access to the gold passage. For example, if our example of interest is\n",
        "\n",
        "```\n",
        "Title: CS224u\n",
        "\n",
        "Background: The course to take is NLU!\n",
        "\n",
        "Q: What is the course to take?\n",
        "```\n",
        "\n",
        "with gold answer ```NLU```, then we would create a prompt with, say, 2 additional examples preceding this, to yield a full prompt like this:\n",
        "\n",
        "```\n",
        "Title: Pragmatics\n",
        "\n",
        "Background: Pragmatics is the study of language use.\n",
        "\n",
        "Q: What is pragmatics?\n",
        "\n",
        "A: The study of language use\n",
        "\n",
        "Title: Bert\n",
        "\n",
        "Background: Bert is a Muppet who is lives with Ernie.\n",
        "\n",
        "Q: Who is Bert?\n",
        "\n",
        "A: Bert is a  Muppet\n",
        "\n",
        "Title: CS224u\n",
        "\n",
        "Background: The course to take is NLU!\n",
        "\n",
        "Q: What is the course to take?\n",
        "\n",
        "A:\n",
        "```\n",
        "This is essentially the formulation used in the GPT-3 paper for SQuAD. The context examples are drawn randomly from the SQuAD train set. We will adopt this same protocol for now. (You might revisit this in the context of your original system.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lhsl9yvHYrey"
      },
      "outputs": [],
      "source": [
        "def build_few_shot_qa_prompt(ex, squad_train, n_context=2, joiner=\"\\n\\n\"):\n",
        "    segs = []\n",
        "    train_exs = random.sample(squad_train, k=n_context)    \n",
        "    for t in train_exs:\n",
        "        segs += [\n",
        "            f\"Title: {t.title}\",\n",
        "            f\"Background: {t.context}\",\n",
        "            f\"Q: {t.question}\",\n",
        "            f\"A: {t.answers[0]}\"\n",
        "        ]\n",
        "    segs += [\n",
        "        f\"Title: {ex.title}\",\n",
        "        f\"Background: {ex.context}\",\n",
        "        f\"Q: {ex.question}\",\n",
        "        f\"A:\"\n",
        "    ]\n",
        "    return joiner.join(segs)                "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzLghzI5Yrez"
      },
      "source": [
        "Here's the sort of output we get with `n_context=1`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VEuVae4xYrez",
        "outputId": "d9b687ed-55c1-4b7f-b95f-2ff7445a8656"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Title: Royal_Institute_of_British_Architects\n",
            "\n",
            "Background: The operational framework is provided by the Byelaws, which are more frequently updated than the Charter. Any revisions to the Charter or Byelaws require the Privy Council's approval. \n",
            "\n",
            "Q: What sets forth the standards by which the Royal Institute functions?\n",
            "\n",
            "A: the Byelaws\n",
            "\n",
            "Title: Martin_Luther\n",
            "\n",
            "Background: Despite the disagreements on the Eucharist, the Marburg Colloquy paved the way for the signing in 1530 of the Augsburg Confession, and for the formation of the Schmalkaldic League the following year by leading Protestant nobles such as John of Saxony, Philip of Hesse, and George, Margrave of Brandenburg-Ansbach. The Swiss cities, however, did not sign these agreements.\n",
            "\n",
            "Q: What did Protestant nobles form the following year after the signing of the Augsburg Confession?\n",
            "\n",
            "A:\n"
          ]
        }
      ],
      "source": [
        "print(build_few_shot_qa_prompt(dev_exs[0], squad_train, n_context=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VUwgM625Yrez"
      },
      "outputs": [],
      "source": [
        "def evaluate_few_shot_qa(examples, squad_train, gen_func=run_eleuther, batch_size=20, n_context=2):\n",
        "    prompts = []\n",
        "    gens = []\n",
        "    for i in range(0, len(examples), batch_size):\n",
        "        batch = examples[i: i+batch_size]\n",
        "        ps = [build_few_shot_qa_prompt(ex, squad_train, n_context=n_context) for ex in batch]        \n",
        "        gs = gen_func(ps)       \n",
        "        prompts += ps\n",
        "        gens += gs\n",
        "    return evaluate(examples, prompts, gens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UelblRFCYrez",
        "outputId": "223e914d-001b-4b9e-f6a0-356fd2ef92ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.06483504088790466\n",
            "CPU times: user 11.1 s, sys: 3.38 ms, total: 11.1 s\n",
            "Wall time: 10.8 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "few_shot_qa_results = evaluate_few_shot_qa(dev_exs, squad_train, n_context=1)\n",
        "\n",
        "print(few_shot_qa_results['macro_f1'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-fdPsEbmYrez",
        "outputId": "dd3eb3ec-77d6-4ac4-9ed5-347aea098912"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6594876021669063\n",
            "CPU times: user 138 ms, sys: 368 µs, total: 138 ms\n",
            "Wall time: 10 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "few_shot_qa_results_gpt3 = evaluate_few_shot_qa(\n",
        "    dev_exs, squad_train, n_context=1, gen_func=run_gpt3)\n",
        "\n",
        "print(few_shot_qa_results_gpt3['macro_f1'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfvVdsGrYre0"
      },
      "source": [
        "## ColBERT\n",
        "\n",
        "It's now just a short step to our core task, few-shot OpenQA. We just need to give up our beloved gold passage and instead try to retrieve the right passage or passages from a corpus. \n",
        "\n",
        "The first step is instantiating the ColBERT retriever and loading in an index. Our ColBERT retriever was initially trained on MS MARCO, and we have pre-indexed a collection of 100K documents that we know to be well-aligned with SQuAD and with the dataset used for the bake-off assessment. (See [the original system question](#Your-original-system-[3-points]) for tips on creating your own index.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9FYJ-fqPkTxg"
      },
      "outputs": [],
      "source": [
        "index_home = os.path.join(\"experiments\", \"notebook\", \"indexes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFYxJPpuYre0"
      },
      "source": [
        "### ColBERT parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5tnUU2UHYre0",
        "outputId": "c3b25bed-aefc-427e-f12e-c1219c0223d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-06-06 16:33:24--  https://downloads.cs.stanford.edu/nlp/data/colbert/colbertv2/colbertv2.0.tar.gz\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 405924985 (387M) [application/octet-stream]\n",
            "Saving to: ‘data/openqa/colbertv2.0.tar.gz’\n",
            "\n",
            "colbertv2.0.tar.gz  100%[===================>] 387.12M  5.00MB/s    in 75s     \n",
            "\n",
            "2022-06-06 16:34:40 (5.13 MB/s) - ‘data/openqa/colbertv2.0.tar.gz’ saved [405924985/405924985]\n",
            "\n",
            "colbertv2.0/\n",
            "colbertv2.0/artifact.metadata\n",
            "colbertv2.0/vocab.txt\n",
            "colbertv2.0/tokenizer.json\n",
            "colbertv2.0/special_tokens_map.json\n",
            "colbertv2.0/tokenizer_config.json\n",
            "colbertv2.0/config.json\n",
            "colbertv2.0/pytorch_model.bin\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(os.path.join(\"data\", \"openqa\", \"colbertv2.0.tar.gz\")):\n",
        "    !mkdir -p data/openqa\n",
        "    # ColBERTv2 checkpoint trained on MS MARCO Passage Ranking (388MB compressed)\n",
        "    !wget https://downloads.cs.stanford.edu/nlp/data/colbert/colbertv2/colbertv2.0.tar.gz -P data/openqa/\n",
        "    !tar -xvzf data/openqa/colbertv2.0.tar.gz -C data/openqa/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjZ1hZJnYre0"
      },
      "source": [
        "If something went wrong with the above, you can just download the file https://downloads.cs.stanford.edu/nlp/data/colbert/colbertv2/colbertv2.0.tar.gz, unarchive it, and move the resulting `colbertv2.0` directory into the `data/openqa` directory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzRjL61eYre0"
      },
      "source": [
        "### ColBERT index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jD0U5Outa9HU",
        "outputId": "6a2e167a-428b-4300-c324-a6e0d5dc6bde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-06-06 16:34:45--  https://web.stanford.edu/class/cs224u/data/cs224u.collection.2bits.tgz\n",
            "Resolving web.stanford.edu (web.stanford.edu)... 171.67.215.200, 2607:f6d0:0:925a::ab43:d7c8\n",
            "Connecting to web.stanford.edu (web.stanford.edu)|171.67.215.200|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 600150346 (572M) [application/x-gzip]\n",
            "Saving to: ‘experiments/notebook/indexes/cs224u.collection.2bits.tgz’\n",
            "\n",
            "cs224u.collection.2 100%[===================>] 572.35M   865KB/s    in 10m 50s \n",
            "\n",
            "2022-06-06 16:45:36 (901 KB/s) - ‘experiments/notebook/indexes/cs224u.collection.2bits.tgz’ saved [600150346/600150346]\n",
            "\n",
            "cs224u.collection.2bits/\n",
            "cs224u.collection.2bits/buckets.pt\n",
            "cs224u.collection.2bits/avg_residual.pt\n",
            "cs224u.collection.2bits/3.codes.pt\n",
            "cs224u.collection.2bits/4.codes.pt\n",
            "cs224u.collection.2bits/4.residuals.pt\n",
            "cs224u.collection.2bits/metadata.json\n",
            "cs224u.collection.2bits/doclens.4.json\n",
            "cs224u.collection.2bits/ivf.pt\n",
            "cs224u.collection.2bits/3.metadata.json\n",
            "cs224u.collection.2bits/1.codes.pt\n",
            "cs224u.collection.2bits/5.metadata.json\n",
            "cs224u.collection.2bits/5.codes.pt\n",
            "cs224u.collection.2bits/0.metadata.json\n",
            "cs224u.collection.2bits/doclens.3.json\n",
            "cs224u.collection.2bits/doclens.1.json\n",
            "cs224u.collection.2bits/0.residuals.pt\n",
            "cs224u.collection.2bits/doclens.0.json\n",
            "cs224u.collection.2bits/4.metadata.json\n",
            "cs224u.collection.2bits/doclens.5.json\n",
            "cs224u.collection.2bits/1.residuals.pt\n",
            "cs224u.collection.2bits/plan.json\n",
            "cs224u.collection.2bits/centroids.pt\n",
            "cs224u.collection.2bits/doclens.2.json\n",
            "cs224u.collection.2bits/2.residuals.pt\n",
            "cs224u.collection.2bits/3.residuals.pt\n",
            "cs224u.collection.2bits/0.codes.pt\n",
            "cs224u.collection.2bits/1.metadata.json\n",
            "cs224u.collection.2bits/5.residuals.pt\n",
            "cs224u.collection.2bits/2.codes.pt\n",
            "cs224u.collection.2bits/cs224u.collection.tsv\n",
            "cs224u.collection.2bits/2.metadata.json\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(os.path.join(index_home, \"cs224u.collection.2bits.tgz\")):\n",
        "    !wget https://web.stanford.edu/class/cs224u/data/cs224u.collection.2bits.tgz -P experiments/notebook/indexes\n",
        "    !tar -xvzf experiments/notebook/indexes/cs224u.collection.2bits.tgz -C experiments/notebook/indexes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61ergQcQYre0"
      },
      "source": [
        "If something went wrong with the above, download the file https://web.stanford.edu/class/cs224u/data/cs224u.collection.2bits.tgz, unarchive it, and move the resulting `cs224u.collection.2bits` directory into the `experiments/notebook/indexes` directory (which you will probably need to create)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XtEGC6MyYre0",
        "outputId": "6b9f7ddf-e717-4f93-f48e-99d6f6751665"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Jun 06, 16:45:44] #> Loading collection...\n",
            "0M \n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Loaded 125,563 passages'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "collection = os.path.join(index_home, \"cs224u.collection.2bits\", \"cs224u.collection.tsv\")\n",
        "\n",
        "collection = Collection(path=collection)\n",
        "\n",
        "f'Loaded {len(collection):,} passages'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BixmAYizYre0"
      },
      "outputs": [],
      "source": [
        "index_name = \"cs224u.collection.2bits\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdGo2VdekTxi"
      },
      "source": [
        "Now we create our `searcher`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "N6wYpChzYre1",
        "outputId": "af4de047-66f4-4af8-9041-81107af322ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Jun 06, 16:45:45] #> Loading collection...\n",
            "0M "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file data/openqa/colbertv2.0/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"/future/u/okhattab/root/unit/experiments/2021.10/none/kld.v3.nway32.l2.ib/checkpoints/colbert-150000/\",\n",
            "  \"architectures\": [\n",
            "    \"HF_ColBERT\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file data/openqa/colbertv2.0/pytorch_model.bin\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint weights were used when initializing HF_ColBERT.\n",
            "\n",
            "All the weights of HF_ColBERT were initialized from the model checkpoint at data/openqa/colbertv2.0.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use HF_ColBERT for predictions without further training.\n",
            "Didn't find file data/openqa/colbertv2.0/added_tokens.json. We won't load it.\n",
            "loading file data/openqa/colbertv2.0/vocab.txt\n",
            "loading file data/openqa/colbertv2.0/tokenizer.json\n",
            "loading file None\n",
            "loading file data/openqa/colbertv2.0/special_tokens_map.json\n",
            "loading file data/openqa/colbertv2.0/tokenizer_config.json\n",
            "Didn't find file data/openqa/colbertv2.0/added_tokens.json. We won't load it.\n",
            "loading file data/openqa/colbertv2.0/vocab.txt\n",
            "loading file data/openqa/colbertv2.0/tokenizer.json\n",
            "loading file None\n",
            "loading file data/openqa/colbertv2.0/special_tokens_map.json\n",
            "loading file data/openqa/colbertv2.0/tokenizer_config.json\n",
            "Didn't find file data/openqa/colbertv2.0/added_tokens.json. We won't load it.\n",
            "loading file data/openqa/colbertv2.0/vocab.txt\n",
            "loading file data/openqa/colbertv2.0/tokenizer.json\n",
            "loading file None\n",
            "loading file data/openqa/colbertv2.0/special_tokens_map.json\n",
            "loading file data/openqa/colbertv2.0/tokenizer_config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Jun 06, 16:45:47] #> Building the emb2pid mapping..\n",
            "[Jun 06, 16:45:48] len(self.emb2pid) = 14968345\n"
          ]
        }
      ],
      "source": [
        "with Run().context(RunConfig(experiment='notebook')):\n",
        "    searcher = Searcher(index=index_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dex5KPUTYre1"
      },
      "source": [
        "### Search\n",
        "\n",
        "Now that the index is loaded, you can do searches over it. The index is limited, but retrieval is very solid!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-v2jKaR8Yre1",
        "outputId": "beaf3628-54d1-4d6d-c489-f5dcdf46d0ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#> linguistics\n",
            "\n",
            "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
            "#> Input: . linguistics, \t\t True, \t\t None\n",
            "#> Output IDs: torch.Size([32]), tensor([  101,     1, 15397,   102,   103,   103,   103,   103,   103,   103,\n",
            "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
            "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
            "          103,   103])\n",
            "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "\n",
            "\t[1]\t24.2\t Linguistics | representation and function of language in the mind; neurolinguistics, which studies language processing in the brain; and language acquisition, which investigates how children and adults acquire a particular language. This is in regards to how children adapt to language, how they learn language, and what influences their ability to learn language. Linguistics also includes non-formal approaches to the study of other aspects of human language, such as social, cultural, historical and political factors. The study of cultural discourses and dialects is the domain of sociolinguistics, which looks at the relation between linguistic variation and social structures, as well as that\n",
            "\t[2]\t24.1\t Linguistics | concerned with how the mind creates meaning through language, and not with the use of language as a tool of communication. Historical linguists study the history of specific languages as well as general characteristics of language change. The study of language change is also referred to as \"diachronic linguistics\" (the study of how one particular language has changed over time), which can be distinguished from \"synchronic linguistics\" (the comparative study of more than one language at a given moment in time without regard to previous stages). Historical linguistics was among the first sub-disciplines to emerge in linguistics, and was the\n",
            "\t[3]\t23.6\t Linguistics | of discourse analysis, which examines the structure of texts and conversations. Research on language through historical and evolutionary linguistics focuses on how languages change, and on the origin and growth of languages, particularly over an extended period of time. Corpus linguistics takes naturally occurring texts and studies the variation of grammatical and other features based on such corpora. Stylistics involves the study of patterns of style: within written, signed, or spoken discourse. Language documentation combines anthropological inquiry with linguistic inquiry to describe languages and their grammars. Lexicography covers the study and construction of dictionaries. Computational linguistics applies computer technology to\n"
          ]
        }
      ],
      "source": [
        "query = \"linguistics\"\n",
        "\n",
        "print(f\"#> {query}\")\n",
        "\n",
        "# Find the top-3 passages for this query\n",
        "results = searcher.search(query, k=3) \n",
        "\n",
        "# Print out the top-k retrieved passages\n",
        "for passage_id, passage_rank, passage_score in zip(*results):\n",
        "    print(f\"\\t[{passage_rank}]\\t{passage_score:.1f}\\t {searcher.collection[passage_id]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9n0_xwdYre1"
      },
      "source": [
        "### Retrieval evaluation\n",
        "\n",
        "For more rigorous evaluations of the retriever alone, we can use Sucess@`k` defined relative to the SQuAD passages and answers. We say that we have a \"success\" if a passage in the top `k` retrieved passages contains any of the answers substrings, and Sucess@`k` is the percentage of such success cases. This is very heuristic (perhaps the answer string happens to occur somewhere in a completely irrelevant passage), but it can still be good guidance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fsNayHzdYre1"
      },
      "outputs": [],
      "source": [
        "def success_at_k(examples, k=20):\n",
        "    scores = []\n",
        "    for ex in examples: \n",
        "        scores.append(evaluate_retrieval_example(ex, k=5))\n",
        "    return sum(scores) / len(scores)\n",
        "        \n",
        "    \n",
        "def evaluate_retrieval_example(ex, k=20):    \n",
        "    results = searcher.search(ex.question, k=k)\n",
        "    for passage_id, passage_rank, passage_score in zip(*results):\n",
        "        passage = searcher.collection[passage_id]\n",
        "        score = has_answer([DPR_normalize(ans) for ans in ex.answers], passage)\n",
        "        if score:\n",
        "            return 1\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2U4v58dYre1"
      },
      "source": [
        "Here is Sucess@20 for the SQuAD dev set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "J2oEmspeYre1",
        "outputId": "a99be5e2-71c7-42b2-e69b-6f20b1863947"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8526017029328288\n",
            "CPU times: user 23min 21s, sys: 5.38 s, total: 23min 26s\n",
            "Wall time: 15min 17s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "if torch.cuda.is_available():\n",
        "    # This will take a few hours on a CPU:\n",
        "    print(success_at_k(squad_dev))\n",
        "else:\n",
        "    # This should be reasonably fast and yields the\n",
        "    # same kind of result:\n",
        "    print(success_at_k(dev_exs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teKobQM8Yre1"
      },
      "source": [
        "## Zero-shot OpenQA with ColBERT retrieval\n",
        "\n",
        "We're now in a position to define a system that does our full few-shot OpenQA task. To get this started, we define just a version that doesn't include any SQuaD-training examples in the prompt. So this is really zero-shot OpenQA. (The homework asks you to move to the true few-shot setting.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jbn4BHr4Yre1"
      },
      "outputs": [],
      "source": [
        "def build_zero_shot_openqa_prompt(question, passage, joiner=\"\\n\\n\"):\n",
        "    title, context = passage.split(\" | \", 1)\n",
        "    segs = [\n",
        "        f\"Title: {title}\",\n",
        "        f\"Background: {context}\",\n",
        "        f\"Q: {question}\",\n",
        "        \"A:\"\n",
        "    ]\n",
        "    return joiner.join(segs)    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Xjz7l_yQYre2"
      },
      "outputs": [],
      "source": [
        "def evaluate_zero_shot_openqa(examples, joiner=\"\\n\\n\", gen_func=run_eleuther, batch_size=20):\n",
        "    prompts = []\n",
        "    gens = []\n",
        "    for i in range(0, len(examples), batch_size):\n",
        "        exs = examples[i: i+batch_size]\n",
        "        results = [searcher.search(ex.question, k=1) for ex in exs]\n",
        "        passages = [searcher.collection[r[0][0]] for r in results]\n",
        "        ps = [build_zero_shot_openqa_prompt(ex.question, psg, joiner=joiner) \n",
        "              for ex, psg in zip(exs, passages)]\n",
        "        gs = gen_func(ps)       \n",
        "        prompts += ps\n",
        "        gens += gs\n",
        "    return evaluate(examples, prompts, gens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "21DfS0hHYre2",
        "outputId": "7904e616-a10d-41b4-d82d-814843a5d6e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.07581967782819177\n",
            "CPU times: user 30.5 s, sys: 181 ms, total: 30.6 s\n",
            "Wall time: 21.4 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "zero_shot_openqa_results = evaluate_zero_shot_openqa(dev_exs)\n",
        "\n",
        "print(zero_shot_openqa_results['macro_f1'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNhMla71Yre2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b563b45-71a1-4c6b-d392-86cab35c5d39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 27.6 s, sys: 141 ms, total: 27.7 s\n",
            "Wall time: 30.5 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "zero_shot_openqa_results_gpt3 = evaluate_zero_shot_openqa(dev_exs, gen_func=run_gpt3)\n",
        "\n",
        "zero_shot_openqa_results_gpt3['macro_f1']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zero_shot_openqa_results_gpt3\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0brt8CqgcHl",
        "outputId": "b5c355ce-7d0c-4512-94a0-e9db5fa01b39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'em_per': 0.12,\n",
              " 'examples': [{'answers': ['Schmalkaldic League',\n",
              "    'Schmalkaldic League',\n",
              "    'Schmalkaldic League'],\n",
              "   'em': 1,\n",
              "   'f1': 1.0,\n",
              "   'generated_answer': ' The Schmalkaldic League.',\n",
              "   'generated_answer_probs': [0.9440218782433071,\n",
              "    0.9951369978699259,\n",
              "    0.9999874111422403,\n",
              "    0.99999813984753,\n",
              "    0.99999813984753,\n",
              "    0.9999939684921896,\n",
              "    0.998709487628201,\n",
              "    0.8731065327030283],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' Sch',\n",
              "    'm',\n",
              "    'alk',\n",
              "    'ald',\n",
              "    'ic',\n",
              "    ' League',\n",
              "    '.'],\n",
              "   'generated_probs': [0.9440218782433071,\n",
              "    0.9951369978699259,\n",
              "    0.9999874111422403,\n",
              "    0.99999813984753,\n",
              "    0.99999813984753,\n",
              "    0.9999939684921896,\n",
              "    0.998709487628201,\n",
              "    0.8731065327030283],\n",
              "   'generated_text': ' The Schmalkaldic League.',\n",
              "   'generated_tokens': [' The',\n",
              "    ' Sch',\n",
              "    'm',\n",
              "    'alk',\n",
              "    'ald',\n",
              "    'ic',\n",
              "    ' League',\n",
              "    '.'],\n",
              "   'id': '56f8907faef23719006261b4',\n",
              "   'prediction': ' The Schmalkaldic League.',\n",
              "   'prompt': 'Title: History of Austria\\n\\nBackground: Lutheran position (Augsburg Confession) (\"Confessio Augustana\") with the Confutatio Augustana, and had Ferdinand elected King of the Romans on 5 January 1531, ensuring his succession as a Catholic monarch. In response, the Protestant princes and estates formed the Schmalkaldic League in February 1531 with French backing. Further Turkish advances in 1532 (which required him to seek Protestant aid) and other wars kept the emperor from taking further action on this front until 1547 when imperial troops defeated the League at the Battle of Mühlberg, allowing him to once more impose Catholicism. In 1541 Ferdinand\\'s appeal to the estates general for\\n\\nQ: What did Protestant nobles form the following year after the signing of the Augsburg Confession?\\n\\nA:',\n",
              "   'question': 'What did Protestant nobles form the following year after the signing of the Augsburg Confession?'},\n",
              "  {'answers': ['20,000', '20,000', '20,000'],\n",
              "   'em': 1,\n",
              "   'f1': 1.0,\n",
              "   'generated_answer': ' 20,000',\n",
              "   'generated_answer_probs': [0.4742887526299265,\n",
              "    0.9999422307507073,\n",
              "    0.9999056317729613],\n",
              "   'generated_answer_tokens': [' 20', ',', '000'],\n",
              "   'generated_probs': [0.4742887526299265,\n",
              "    0.9999422307507073,\n",
              "    0.9999056317729613],\n",
              "   'generated_text': ' 20,000',\n",
              "   'generated_tokens': [' 20', ',', '000'],\n",
              "   'id': '5726ab47f1498d1400e8e6a5',\n",
              "   'prediction': ' 20,000',\n",
              "   'prompt': 'Title: Genghis Khan\\n\\nBackground: Khamag Mongols, and Keraites, that were all prominent and often unfriendly toward each other, as evidenced by random raids, revenge attacks, and plundering. Temüjin began his ascent to power by offering himself as an ally (or, according to other sources, a vassal) to his father\\'s \"anda\" (sworn brother or blood brother) Toghrul, who was Khan of the Keraites, and is better known by the Chinese title \"Wang Khan\", which the Jurchen Jin dynasty granted him in 1197. This relationship was first reinforced when Börte was captured by the Merkits. Temüjin turned to Toghrul for support, and Toghrul offered 20,000 of\\n\\nQ: How many warriors did Toghrul provide Temüjin when his wife was captured?\\n\\nA:',\n",
              "   'question': 'How many warriors did Toghrul provide Temüjin when his wife was captured?'},\n",
              "  {'answers': ['300 acres', '300', '300'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' Woodward Park has a total of .',\n",
              "   'generated_answer_probs': [0.8929827903641664,\n",
              "    0.9999233970391567,\n",
              "    0.7470671985477806,\n",
              "    0.8685146459003876,\n",
              "    0.8276895289086789,\n",
              "    0.8299737128152231,\n",
              "    0.10189993261899963],\n",
              "   'generated_answer_tokens': [' Woodward',\n",
              "    ' Park',\n",
              "    ' has',\n",
              "    ' a',\n",
              "    ' total',\n",
              "    ' of',\n",
              "    ' .'],\n",
              "   'generated_probs': [0.8929827903641664,\n",
              "    0.9999233970391567,\n",
              "    0.7470671985477806,\n",
              "    0.8685146459003876,\n",
              "    0.8276895289086789,\n",
              "    0.8299737128152231,\n",
              "    0.10189993261899963],\n",
              "   'generated_text': ' Woodward Park has a total of .',\n",
              "   'generated_tokens': [' Woodward',\n",
              "    ' Park',\n",
              "    ' has',\n",
              "    ' a',\n",
              "    ' total',\n",
              "    ' of',\n",
              "    ' .'],\n",
              "   'id': '5725f2c838643c19005aceee',\n",
              "   'prediction': ' Woodward Park has a total of .',\n",
              "   'prompt': 'Title: Fresno, California\\n\\nBackground: Fresno Street and State Route 99 Freeway (Kearney Palm Shopping Center, built in the late 1990s) and small corner markets scattered throughout. In the north eastern part of Fresno, Woodward Park was founded by the late Ralph Woodward, a long-time Fresno resident. He bequeathed a major portion of his estate in 1968 to provide a regional park and bird sanctuary in Northeast Fresno. The park lies on the South bank of the San Joaquin River between Highway 41 and Friant Road. The initial , combined with additional acres acquired later by the city, brings the park to a sizable .\\n\\nQ: How many total acres is Woodward Park?\\n\\nA:',\n",
              "   'question': 'How many total acres is Woodward Park?'},\n",
              "  {'answers': ['Rome', 'Rome', 'Rome'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' The Archbishop sent them to the Pope.',\n",
              "   'generated_answer_probs': [0.2642535553046674,\n",
              "    0.5113340112201665,\n",
              "    0.5721280780455462,\n",
              "    0.7738289922877472,\n",
              "    0.9872364114022504,\n",
              "    0.6600271951749701,\n",
              "    0.5571611628845642,\n",
              "    0.775233038492025],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' Archbishop',\n",
              "    ' sent',\n",
              "    ' them',\n",
              "    ' to',\n",
              "    ' the',\n",
              "    ' Pope',\n",
              "    '.'],\n",
              "   'generated_probs': [0.2642535553046674,\n",
              "    0.5113340112201665,\n",
              "    0.5721280780455462,\n",
              "    0.7738289922877472,\n",
              "    0.9872364114022504,\n",
              "    0.6600271951749701,\n",
              "    0.5571611628845642,\n",
              "    0.775233038492025],\n",
              "   'generated_text': ' The Archbishop sent them to the Pope.',\n",
              "   'generated_tokens': [' The',\n",
              "    ' Archbishop',\n",
              "    ' sent',\n",
              "    ' them',\n",
              "    ' to',\n",
              "    ' the',\n",
              "    ' Pope',\n",
              "    '.'],\n",
              "   'id': '56f80fdfaef2371900625d96',\n",
              "   'prediction': ' The Archbishop sent them to the Pope.',\n",
              "   'prompt': 'Title: Martin Luther\\n\\nBackground: Luther\\'s rediscovery of \"Christ and His salvation\" was the first of two points that became the foundation for the Reformation. His railing against the sale of indulgences was based on it. Archbishop Albrecht of Mainz and Magdeburg did not reply to Luther\\'s letter containing the \"Ninety-five Theses\". He had the theses checked for heresy and in December 1517 forwarded them to Rome. He needed the revenue from the indulgences to pay off a papal dispensation for his tenure of more than one bishopric. As Luther later noted, \"the pope had a finger in the pie as well, because one half\\n\\nQ: After Archbishop Albrecht reviewed the Theses, where did he send them?\\n\\nA:',\n",
              "   'question': 'After Archbishop Albrecht reviewed the Theses, where did he send them?'},\n",
              "  {'answers': ['the Common Core', 'Common Core', 'Common Core'],\n",
              "   'em': 0,\n",
              "   'f1': 0.15384615384615385,\n",
              "   'generated_answer': ' The name of the university\\'s core curriculum is typically referred to as the \"liberal',\n",
              "   'generated_answer_probs': [0.8535900206161195,\n",
              "    0.6978379126640121,\n",
              "    0.9952851758435854,\n",
              "    0.998828993863406,\n",
              "    0.9396348938189655,\n",
              "    0.9956619409791704,\n",
              "    0.9992409217457746,\n",
              "    0.9997416605153929,\n",
              "    0.527201294696102,\n",
              "    0.2733049429616489,\n",
              "    0.8596034678171617,\n",
              "    0.999988485878288,\n",
              "    0.9991912741951331,\n",
              "    0.7491835990019455,\n",
              "    0.80322068270217,\n",
              "    0.19361758047961636],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' name',\n",
              "    ' of',\n",
              "    ' the',\n",
              "    ' university',\n",
              "    \"'s\",\n",
              "    ' core',\n",
              "    ' curriculum',\n",
              "    ' is',\n",
              "    ' typically',\n",
              "    ' referred',\n",
              "    ' to',\n",
              "    ' as',\n",
              "    ' the',\n",
              "    ' \"',\n",
              "    'liberal'],\n",
              "   'generated_probs': [0.8535900206161195,\n",
              "    0.6978379126640121,\n",
              "    0.9952851758435854,\n",
              "    0.998828993863406,\n",
              "    0.9396348938189655,\n",
              "    0.9956619409791704,\n",
              "    0.9992409217457746,\n",
              "    0.9997416605153929,\n",
              "    0.527201294696102,\n",
              "    0.2733049429616489,\n",
              "    0.8596034678171617,\n",
              "    0.999988485878288,\n",
              "    0.9991912741951331,\n",
              "    0.7491835990019455,\n",
              "    0.80322068270217,\n",
              "    0.19361758047961636],\n",
              "   'generated_text': ' The name of the university\\'s core curriculum is typically referred to as the \"liberal',\n",
              "   'generated_tokens': [' The',\n",
              "    ' name',\n",
              "    ' of',\n",
              "    ' the',\n",
              "    ' university',\n",
              "    \"'s\",\n",
              "    ' core',\n",
              "    ' curriculum',\n",
              "    ' is',\n",
              "    ' typically',\n",
              "    ' referred',\n",
              "    ' to',\n",
              "    ' as',\n",
              "    ' the',\n",
              "    ' \"',\n",
              "    'liberal'],\n",
              "   'id': '572853e8ff5b5019007da188',\n",
              "   'prediction': ' The name of the university\\'s core curriculum is typically referred to as the \"liberal',\n",
              "   'prompt': 'Title: Curriculum\\n\\nBackground: institutions.\" Simultaneously, however, a set of university administrators, notably then-President Hugo Sonnenschein, argued that reducing the core curriculum had become both a financial and educational imperative, as the university was struggling to attract a commensurate volume of applicants to its undergraduate division compared to peer schools as a result of what was perceived by the pro-change camp as a reaction by “the average eighteen-year-old” to the expanse of the collegiate core. As core curricula began to diminish over the course of the twentieth century at many American schools, some smaller institutions became famous for embracing a core curriculum that covers\\n\\nQ: What is the name of the university\\'s core curriculum?\\n\\nA:',\n",
              "   'question': \"What is the name of the university's core curriculum?\"},\n",
              "  {'answers': ['47°39′N 9°19′E\\ufeff / \\ufeff47.650°N 9.317°E\\ufeff / 47.650; 9.317.',\n",
              "    '47°39′N 9°19′E\\ufeff / \\ufeff47.650°N 9.317°E\\ufeff / 47.650; 9.317',\n",
              "    '47°39′N 9°19′E\\ufeff / \\ufeff47.650°N 9.317°E\\ufeff / 47.650; 9.317'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' The border of Swiss and Austria is located in the Grison Alps, running from',\n",
              "   'generated_answer_probs': [0.9729898806542582,\n",
              "    0.8293974713041334,\n",
              "    0.8667368986674558,\n",
              "    0.7458019847535062,\n",
              "    0.9999622568562904,\n",
              "    0.8798153702996617,\n",
              "    0.8538226982829472,\n",
              "    0.7946281099502622,\n",
              "    0.9284049015767334,\n",
              "    0.8535997857418118,\n",
              "    0.8984717361130875,\n",
              "    0.8505794379824433,\n",
              "    0.9947603540834408,\n",
              "    0.3173813916659319,\n",
              "    0.21308108605732357,\n",
              "    0.33707898474285597],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' border',\n",
              "    ' of',\n",
              "    ' Swiss',\n",
              "    ' and',\n",
              "    ' Austria',\n",
              "    ' is',\n",
              "    ' located',\n",
              "    ' in',\n",
              "    ' the',\n",
              "    ' Gr',\n",
              "    'ison',\n",
              "    ' Alps',\n",
              "    ',',\n",
              "    ' running',\n",
              "    ' from'],\n",
              "   'generated_probs': [0.9729898806542582,\n",
              "    0.8293974713041334,\n",
              "    0.8667368986674558,\n",
              "    0.7458019847535062,\n",
              "    0.9999622568562904,\n",
              "    0.8798153702996617,\n",
              "    0.8538226982829472,\n",
              "    0.7946281099502622,\n",
              "    0.9284049015767334,\n",
              "    0.8535997857418118,\n",
              "    0.8984717361130875,\n",
              "    0.8505794379824433,\n",
              "    0.9947603540834408,\n",
              "    0.3173813916659319,\n",
              "    0.21308108605732357,\n",
              "    0.33707898474285597],\n",
              "   'generated_text': ' The border of Swiss and Austria is located in the Grison Alps, running from',\n",
              "   'generated_tokens': [' The',\n",
              "    ' border',\n",
              "    ' of',\n",
              "    ' Swiss',\n",
              "    ' and',\n",
              "    ' Austria',\n",
              "    ' is',\n",
              "    ' located',\n",
              "    ' in',\n",
              "    ' the',\n",
              "    ' Gr',\n",
              "    'ison',\n",
              "    ' Alps',\n",
              "    ',',\n",
              "    ' running',\n",
              "    ' from'],\n",
              "   'id': '572fe60fb2c2fd140056858e',\n",
              "   'prediction': ' The border of Swiss and Austria is located in the Grison Alps, running from',\n",
              "   'prompt': 'Title: Austria–Switzerland border\\n\\nBackground: Austria–Switzerland border The modern states of Austria and Switzerland share a border with a length of 180\\xa0km in two parts, separated by Liechtenstein, the longer stretch running across the Grison Alps and the shorter one following the Alpine Rhine to its mouth at Lake Constance. The current border was a product of the creation of the Helvetic Republic in 1798.  During the 19th century it was part of the western border of the Austrian Empire and later Austria-Hungary, and in the 20th century of the First Austrian Republic, the Federal State of Austria, of Nazi Germany and Allied-occupied Austria,\\n\\nQ: Where is the border of Swiss and Austria?\\n\\nA:',\n",
              "   'question': 'Where is the border of Swiss and Austria?'},\n",
              "  {'answers': ['polynomial time algorithm',\n",
              "    'polynomial time',\n",
              "    'polynomial time algorithm'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' The term is \"T\"(\"n\").',\n",
              "   'generated_answer_probs': [0.7420615631883342,\n",
              "    0.8622016956637678,\n",
              "    0.6022841108926084,\n",
              "    0.24920640254580165,\n",
              "    0.5900539532953627,\n",
              "    0.7966282624630251,\n",
              "    0.9983920921711438,\n",
              "    0.9996161937724614,\n",
              "    0.7448178627669603],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' term',\n",
              "    ' is',\n",
              "    ' \"',\n",
              "    'T',\n",
              "    '\"',\n",
              "    '(\"',\n",
              "    'n',\n",
              "    '\").'],\n",
              "   'generated_probs': [0.7420615631883342,\n",
              "    0.8622016956637678,\n",
              "    0.6022841108926084,\n",
              "    0.24920640254580165,\n",
              "    0.5900539532953627,\n",
              "    0.7966282624630251,\n",
              "    0.9983920921711438,\n",
              "    0.9996161937724614,\n",
              "    0.7448178627669603],\n",
              "   'generated_text': ' The term is \"T\"(\"n\").',\n",
              "   'generated_tokens': [' The',\n",
              "    ' term',\n",
              "    ' is',\n",
              "    ' \"',\n",
              "    'T',\n",
              "    '\"',\n",
              "    '(\"',\n",
              "    'n',\n",
              "    '\").'],\n",
              "   'id': '56e1a564cd28a01900c67a4c',\n",
              "   'prediction': ' The term is \"T\"(\"n\").',\n",
              "   'prompt': 'Title: Time complexity\\n\\nBackground: time, if \"T\"(\"n\") is upper bounded by 2, where poly(\"n\") is some polynomial in \"n\". More formally, an algorithm is exponential time if \"T\"(\"n\") is bounded by O(2) for some constant \"k\". Problems which admit exponential time algorithms on a deterministic Turing machine form the complexity class known as EXP. Sometimes, exponential time is used to refer to algorithms that have \"T\"(\"n\") = 2, where the exponent is at most a linear function of \"n\". This gives rise to the complexity class E. An algorithm is said to be double exponential time if \"T\"(\"n\") is upper bounded by 2, where\\n\\nQ: Assuming that T represents a polynomial in T(n), what is the term given to the corresponding algorithm?\\n\\nA:',\n",
              "   'question': 'Assuming that T represents a polynomial in T(n), what is the term given to the corresponding algorithm?'},\n",
              "  {'answers': ['32,463', '32,463', '32,463'],\n",
              "   'em': 0,\n",
              "   'f1': 0.25,\n",
              "   'generated_answer': ' There are an estimated 32,463 farms in Victoria.',\n",
              "   'generated_answer_probs': [0.7262469285616265,\n",
              "    0.995960562365556,\n",
              "    0.6405456229316332,\n",
              "    0.9989673373634195,\n",
              "    0.9497674327399411,\n",
              "    0.9998412597205717,\n",
              "    0.9996873009405453,\n",
              "    0.9939360792329616,\n",
              "    0.992344579147995,\n",
              "    0.9896477255052524,\n",
              "    0.9435784214816507],\n",
              "   'generated_answer_tokens': [' There',\n",
              "    ' are',\n",
              "    ' an',\n",
              "    ' estimated',\n",
              "    ' 32',\n",
              "    ',',\n",
              "    '463',\n",
              "    ' farms',\n",
              "    ' in',\n",
              "    ' Victoria',\n",
              "    '.'],\n",
              "   'generated_probs': [0.7262469285616265,\n",
              "    0.995960562365556,\n",
              "    0.6405456229316332,\n",
              "    0.9989673373634195,\n",
              "    0.9497674327399411,\n",
              "    0.9998412597205717,\n",
              "    0.9996873009405453,\n",
              "    0.9939360792329616,\n",
              "    0.992344579147995,\n",
              "    0.9896477255052524,\n",
              "    0.9435784214816507],\n",
              "   'generated_text': ' There are an estimated 32,463 farms in Victoria.',\n",
              "   'generated_tokens': [' There',\n",
              "    ' are',\n",
              "    ' an',\n",
              "    ' estimated',\n",
              "    ' 32',\n",
              "    ',',\n",
              "    '463',\n",
              "    ' farms',\n",
              "    ' in',\n",
              "    ' Victoria',\n",
              "    '.'],\n",
              "   'id': '570d50a5fed7b91900d45e7f',\n",
              "   'prediction': ' There are an estimated 32,463 farms in Victoria.',\n",
              "   'prompt': \"Title: Victoria (Australia)\\n\\nBackground: Victoria's single largest employer and income producer. During 2003–04, the gross value of Victorian agricultural production increased by 17% to $8.7\\xa0billion. This represented 24% of national agricultural production total gross value. As of 2004, an estimated 32,463 farms occupied around 136,000 square kilometres (52,500\\xa0sq\\xa0mi) of Victorian land. This comprises more than 60% of the state's total land surface. Victorian farms range from small horticultural outfits to large-scale livestock and grain productions. A quarter of farmland is used to grow consumable crops. More than 26,000 square kilometres (10,000\\xa0sq\\xa0mi) of Victorian farmland are sown for grain, mostly in the state's west. More\\n\\nQ: How many farms are there in Victoria?\\n\\nA:\",\n",
              "   'question': 'How many farms are there in Victoria?'},\n",
              "  {'answers': ['French irregular forces (Canadian scouts and Indians)',\n",
              "    'French irregular forces',\n",
              "    'French irregular forces',\n",
              "    'French irregular forces',\n",
              "    'French irregular forces'],\n",
              "   'em': 1,\n",
              "   'f1': 1.0,\n",
              "   'generated_answer': ' French irregular forces (Canadian scouts and Indians)',\n",
              "   'generated_answer_probs': [0.39760393792930887,\n",
              "    0.9372755060744434,\n",
              "    0.9282190024674024,\n",
              "    0.9537497514370171,\n",
              "    0.9903861692118814,\n",
              "    0.9990913140053927,\n",
              "    0.9999937300764561,\n",
              "    0.9994051917086302,\n",
              "    0.9220253290022612],\n",
              "   'generated_answer_tokens': [' French',\n",
              "    ' irregular',\n",
              "    ' forces',\n",
              "    ' (',\n",
              "    'Canadian',\n",
              "    ' scouts',\n",
              "    ' and',\n",
              "    ' Indians',\n",
              "    ')'],\n",
              "   'generated_probs': [0.39760393792930887,\n",
              "    0.9372755060744434,\n",
              "    0.9282190024674024,\n",
              "    0.9537497514370171,\n",
              "    0.9903861692118814,\n",
              "    0.9990913140053927,\n",
              "    0.9999937300764561,\n",
              "    0.9994051917086302,\n",
              "    0.9220253290022612],\n",
              "   'generated_text': ' French irregular forces (Canadian scouts and Indians)',\n",
              "   'generated_tokens': [' French',\n",
              "    ' irregular',\n",
              "    ' forces',\n",
              "    ' (',\n",
              "    'Canadian',\n",
              "    ' scouts',\n",
              "    ' and',\n",
              "    ' Indians',\n",
              "    ')'],\n",
              "   'id': '5733ffa7d058e614000b674f',\n",
              "   'prediction': ' French irregular forces (Canadian scouts and Indians)',\n",
              "   'prompt': 'Title: French and Indian War\\n\\nBackground: a fleet outnumbering the British one awaited Loudoun at Louisbourg. Faced with this strength, Loudoun returned to New York amid news that a massacre had occurred at Fort William Henry. French irregular forces (Canadian scouts and Indians) harassed Fort William Henry throughout the first half of 1757. In January they ambushed British rangers near Ticonderoga. In February they launched a daring raid against the position across the frozen Lake George, destroying storehouses and buildings outside the main fortification. In early August, Montcalm and 7,000 troops besieged the fort, which capitulated with an agreement to withdraw under parole. When the withdrawal\\n\\nQ: What troops attacked Fort William Henry in early 1757?\\n\\nA:',\n",
              "   'question': 'What troops attacked Fort William Henry in early 1757?'},\n",
              "  {'answers': ['William of Volpiano and John of Ravenna',\n",
              "    'William of Volpiano and John of Ravenna',\n",
              "    'William of Volpiano and John of Ravenna'],\n",
              "   'em': 1,\n",
              "   'f1': 1.0,\n",
              "   'generated_answer': ' William of Volpiano and John of Ravenna.',\n",
              "   'generated_answer_probs': [0.9285332856404476,\n",
              "    0.999923990228889,\n",
              "    0.999815272934146,\n",
              "    0.9999720325870954,\n",
              "    0.9999907489487913,\n",
              "    0.9890386235376365,\n",
              "    0.9999276863547577,\n",
              "    0.9999759673147897,\n",
              "    0.9998544936170808,\n",
              "    0.999996351716955,\n",
              "    0.529192351390789],\n",
              "   'generated_answer_tokens': [' William',\n",
              "    ' of',\n",
              "    ' Vol',\n",
              "    'p',\n",
              "    'iano',\n",
              "    ' and',\n",
              "    ' John',\n",
              "    ' of',\n",
              "    ' Raven',\n",
              "    'na',\n",
              "    '.'],\n",
              "   'generated_probs': [0.9285332856404476,\n",
              "    0.999923990228889,\n",
              "    0.999815272934146,\n",
              "    0.9999720325870954,\n",
              "    0.9999907489487913,\n",
              "    0.9890386235376365,\n",
              "    0.9999276863547577,\n",
              "    0.9999759673147897,\n",
              "    0.9998544936170808,\n",
              "    0.999996351716955,\n",
              "    0.529192351390789],\n",
              "   'generated_text': ' William of Volpiano and John of Ravenna.',\n",
              "   'generated_tokens': [' William',\n",
              "    ' of',\n",
              "    ' Vol',\n",
              "    'p',\n",
              "    'iano',\n",
              "    ' and',\n",
              "    ' John',\n",
              "    ' of',\n",
              "    ' Raven',\n",
              "    'na',\n",
              "    '.'],\n",
              "   'id': '56de51c64396321400ee27f8',\n",
              "   'prediction': ' William of Volpiano and John of Ravenna.',\n",
              "   'prompt': 'Title: Normans\\n\\nBackground: and Saint-Evroul Abbey were centres of musical production and education. At Fécamp, under two Italian abbots, William of Volpiano and John of Ravenna, the system of denoting notes by letters was developed and taught. It is still the most common form of pitch representation in English- and German-speaking countries today. Also at Fécamp, the staff, around which neumes were oriented, was first developed and taught in the 11th century. Under the German abbot Isembard, La Trinité-du-Mont became a centre of musical composition. At Saint Evroul, a tradition of singing had developed and the choir achieved fame in Normandy. Under the\\n\\nQ: Who were the two abbots at Fécamp Abbey?\\n\\nA:',\n",
              "   'question': 'Who were the two abbots at Fécamp Abbey?'},\n",
              "  {'answers': ['Design Event festival',\n",
              "    'Design Event festival',\n",
              "    'Design Event festival'],\n",
              "   'em': 0,\n",
              "   'f1': 0.5,\n",
              "   'generated_answer': ' The Design Event festival is held in October in Newcastle.',\n",
              "   'generated_answer_probs': [0.9748469145789644,\n",
              "    0.9850390282560774,\n",
              "    0.9974000850484163,\n",
              "    0.7811966564552291,\n",
              "    0.7543075144664708,\n",
              "    0.5204663200172746,\n",
              "    0.9988347166705207,\n",
              "    0.9989035592309156,\n",
              "    0.9578767143023453,\n",
              "    0.9999928937497495,\n",
              "    0.999480178114236],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' Design',\n",
              "    ' Event',\n",
              "    ' festival',\n",
              "    ' is',\n",
              "    ' held',\n",
              "    ' in',\n",
              "    ' October',\n",
              "    ' in',\n",
              "    ' Newcastle',\n",
              "    '.'],\n",
              "   'generated_probs': [0.9748469145789644,\n",
              "    0.9850390282560774,\n",
              "    0.9974000850484163,\n",
              "    0.7811966564552291,\n",
              "    0.7543075144664708,\n",
              "    0.5204663200172746,\n",
              "    0.9988347166705207,\n",
              "    0.9989035592309156,\n",
              "    0.9578767143023453,\n",
              "    0.9999928937497495,\n",
              "    0.999480178114236],\n",
              "   'generated_text': ' The Design Event festival is held in October in Newcastle.',\n",
              "   'generated_tokens': [' The',\n",
              "    ' Design',\n",
              "    ' Event',\n",
              "    ' festival',\n",
              "    ' is',\n",
              "    ' held',\n",
              "    ' in',\n",
              "    ' October',\n",
              "    ' in',\n",
              "    ' Newcastle',\n",
              "    '.'],\n",
              "   'id': '572683e6f1498d1400e8e24f',\n",
              "   'prediction': ' The Design Event festival is held in October in Newcastle.',\n",
              "   'prompt': 'Title: Newcastle upon Tyne\\n\\nBackground: Arts Centre in September. In October, there is the Design Event festival—an annual festival providing the public with an opportunity to see work by regional, national and international designers. The SAMA Festival, an East Asian cultural festival is also held in early October. Newcastle\\'s vernacular music was a mixture of Northumbrian folk music and nineteenth-century songs with dialect lyrics, by writers such as George \"Geordie\" Ridley, whose songs include one which became an unofficial Tyneside national anthem, Blaydon Races. The 1960s saw the internationally successful rock group The Animals, emerge from Newcastle night spots such as Club A-Go-Go on Percy\\n\\nQ: What festival is held in October in Newcastle?\\n\\nA:',\n",
              "   'question': 'What festival is held in October in Newcastle?'},\n",
              "  {'answers': ['phosphorylate adenosine diphosphate',\n",
              "    'phosphorylate adenosine diphosphate',\n",
              "    'energy from the flowing hydrogen ions'],\n",
              "   'em': 0,\n",
              "   'f1': 0.2,\n",
              "   'generated_answer': ' ATP synthase changes ATP into adenosine triphosphate.',\n",
              "   'generated_answer_probs': [0.6436622544895106,\n",
              "    0.9973609249973906,\n",
              "    0.999949383821042,\n",
              "    0.9220038128702348,\n",
              "    0.5481375060835678,\n",
              "    0.9603689811512232,\n",
              "    0.8276279097170546,\n",
              "    0.9999560591954254,\n",
              "    0.9999711981547811,\n",
              "    0.8587712761774524,\n",
              "    0.9999224425077379,\n",
              "    0.9999421106136552,\n",
              "    0.9994969835552132,\n",
              "    0.5082633551932113],\n",
              "   'generated_answer_tokens': [' ATP',\n",
              "    ' synth',\n",
              "    'ase',\n",
              "    ' changes',\n",
              "    ' ATP',\n",
              "    ' into',\n",
              "    ' ad',\n",
              "    'enos',\n",
              "    'ine',\n",
              "    ' tri',\n",
              "    'ph',\n",
              "    'osph',\n",
              "    'ate',\n",
              "    '.'],\n",
              "   'generated_probs': [0.6436622544895106,\n",
              "    0.9973609249973906,\n",
              "    0.999949383821042,\n",
              "    0.9220038128702348,\n",
              "    0.5481375060835678,\n",
              "    0.9603689811512232,\n",
              "    0.8276279097170546,\n",
              "    0.9999560591954254,\n",
              "    0.9999711981547811,\n",
              "    0.8587712761774524,\n",
              "    0.9999224425077379,\n",
              "    0.9999421106136552,\n",
              "    0.9994969835552132,\n",
              "    0.5082633551932113],\n",
              "   'generated_text': ' ATP synthase changes ATP into adenosine triphosphate.',\n",
              "   'generated_tokens': [' ATP',\n",
              "    ' synth',\n",
              "    'ase',\n",
              "    ' changes',\n",
              "    ' ATP',\n",
              "    ' into',\n",
              "    ' ad',\n",
              "    'enos',\n",
              "    'ine',\n",
              "    ' tri',\n",
              "    'ph',\n",
              "    'osph',\n",
              "    'ate',\n",
              "    '.'],\n",
              "   'id': '572975073f37b31900478418',\n",
              "   'prediction': ' ATP synthase changes ATP into adenosine triphosphate.',\n",
              "   'prompt': 'Title: ATP synthase\\n\\nBackground: ATP synthase ATP synthase () is an important enzyme that creates the energy storage molecule adenosine triphosphate (ATP). ATP is the most commonly used \"energy currency\" of cells for most organisms. It is formed from adenosine diphosphate (ADP) and inorganic phosphate (P), and needs energy for its formation. The overall reaction sequence is: ADP + P + Energy → ATP, where ADP and P are joined together by ATP synthase Energy used is available in the form of hydrogen ions (), moving down an electrochemical gradient, such as from the thylakoid lumen through the thylakoid membrane and into the chloroplast\\n\\nQ: What does ATP synthase change into ATP?\\n\\nA:',\n",
              "   'question': 'What does ATP synthase change into ATP?'},\n",
              "  {'answers': ['\"semi-legal\"', 'semi-legal', 'semi-legal'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' The Muslim Brotherhood was described as a terrorist organization by the United States, the European',\n",
              "   'generated_answer_probs': [0.7943402842184905,\n",
              "    0.8989786081094708,\n",
              "    0.999619413081582,\n",
              "    0.7557735384440862,\n",
              "    0.3347753061855248,\n",
              "    0.5603380313230886,\n",
              "    0.9242865410989415,\n",
              "    0.32720296910923113,\n",
              "    0.8606103088256575,\n",
              "    0.9590824047508785,\n",
              "    0.39910653209419983,\n",
              "    0.6089233203225992,\n",
              "    0.9985905749737044,\n",
              "    0.48274071085626113,\n",
              "    0.42472809129323075,\n",
              "    0.7544919878367007],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' Muslim',\n",
              "    ' Brotherhood',\n",
              "    ' was',\n",
              "    ' described',\n",
              "    ' as',\n",
              "    ' a',\n",
              "    ' terrorist',\n",
              "    ' organization',\n",
              "    ' by',\n",
              "    ' the',\n",
              "    ' United',\n",
              "    ' States',\n",
              "    ',',\n",
              "    ' the',\n",
              "    ' European'],\n",
              "   'generated_probs': [0.7943402842184905,\n",
              "    0.8989786081094708,\n",
              "    0.999619413081582,\n",
              "    0.7557735384440862,\n",
              "    0.3347753061855248,\n",
              "    0.5603380313230886,\n",
              "    0.9242865410989415,\n",
              "    0.32720296910923113,\n",
              "    0.8606103088256575,\n",
              "    0.9590824047508785,\n",
              "    0.39910653209419983,\n",
              "    0.6089233203225992,\n",
              "    0.9985905749737044,\n",
              "    0.48274071085626113,\n",
              "    0.42472809129323075,\n",
              "    0.7544919878367007],\n",
              "   'generated_text': ' The Muslim Brotherhood was described as a terrorist organization by the United States, the European',\n",
              "   'generated_tokens': [' The',\n",
              "    ' Muslim',\n",
              "    ' Brotherhood',\n",
              "    ' was',\n",
              "    ' described',\n",
              "    ' as',\n",
              "    ' a',\n",
              "    ' terrorist',\n",
              "    ' organization',\n",
              "    ' by',\n",
              "    ' the',\n",
              "    ' United',\n",
              "    ' States',\n",
              "    ',',\n",
              "    ' the',\n",
              "    ' European'],\n",
              "   'id': '573004bf947a6a140053cf57',\n",
              "   'prediction': ' The Muslim Brotherhood was described as a terrorist organization by the United States, the European',\n",
              "   'prompt': 'Title: Muslim Brotherhood\\n\\nBackground: Brotherhood to death, an act described by Amnesty International as \"the largest single batch of simultaneous death sentences we\\'ve seen in recent years […] anywhere in the world\". By May 2014, approximately 16,000 people (and as high as more than 40,000 by one independent count), mostly Brotherhood members or supporters, have been imprisoned since the 2013 uprising. On 2 February 2015, an Egyptian court sentenced another 183 members of the Muslim Brotherhood to death. \"The New York Times\" reported that \"Leaders of the Muslim Brotherhood, which became the leading political movement in the wake of Egypt’s 2011 popular uprising, are\\n\\nQ: For many years, what was the Brotherhood described as?\\n\\nA:',\n",
              "   'question': 'For many years, what was the Brotherhood described as?'},\n",
              "  {'answers': ['university and military academy',\n",
              "    'the university and military academy',\n",
              "    'university and military academy'],\n",
              "   'em': 0,\n",
              "   'f1': 0.888888888888889,\n",
              "   'generated_answer': ' In the university and military academy.',\n",
              "   'generated_answer_probs': [0.5764133235574277,\n",
              "    0.9017020815554607,\n",
              "    0.8659110407529131,\n",
              "    0.9954632182266595,\n",
              "    0.9962367116854186,\n",
              "    0.9755711037806927,\n",
              "    0.5299997733911123],\n",
              "   'generated_answer_tokens': [' In',\n",
              "    ' the',\n",
              "    ' university',\n",
              "    ' and',\n",
              "    ' military',\n",
              "    ' academy',\n",
              "    '.'],\n",
              "   'generated_probs': [0.5764133235574277,\n",
              "    0.9017020815554607,\n",
              "    0.8659110407529131,\n",
              "    0.9954632182266595,\n",
              "    0.9962367116854186,\n",
              "    0.9755711037806927,\n",
              "    0.5299997733911123],\n",
              "   'generated_text': ' In the university and military academy.',\n",
              "   'generated_tokens': [' In',\n",
              "    ' the',\n",
              "    ' university',\n",
              "    ' and',\n",
              "    ' military',\n",
              "    ' academy',\n",
              "    '.'],\n",
              "   'id': '57302700a23a5019007fce8d',\n",
              "   'prediction': ' In the university and military academy.',\n",
              "   'prompt': 'Title: Islamism\\n\\nBackground: recruited and built a cadre of influential loyalists by placing sympathetic students in the university and military academy while serving as minister of education. After al-Nimeiry was overthrown in 1985 the party did poorly in national elections, but in 1989 it was able to overthrow the elected post-al-Nimeiry government with the help of the military. Turabi was noted for proclaiming his support for the democratic process and a liberal government before coming to power, but strict application of sharia law, torture and mass imprisonment of the opposition, and an intensification of the long-running war in southern Sudan, once in power.\\n\\nQ: Where did Turabi place students sympathetic to his views?\\n\\nA:',\n",
              "   'question': 'Where did Turabi place students sympathetic to his views?'},\n",
              "  {'answers': ['Science', 'Science', 'Science'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' The joint statement was published in 18 specialist journals.',\n",
              "   'generated_answer_probs': [0.8795943444554083,\n",
              "    0.8426547618792549,\n",
              "    0.9999670269116242,\n",
              "    0.9988678570579389,\n",
              "    0.9992458703987693,\n",
              "    0.9997633576942085,\n",
              "    0.9611165792649476,\n",
              "    0.9819142571018927,\n",
              "    0.8827425886153942,\n",
              "    0.7180923765945434],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' joint',\n",
              "    ' statement',\n",
              "    ' was',\n",
              "    ' published',\n",
              "    ' in',\n",
              "    ' 18',\n",
              "    ' specialist',\n",
              "    ' journals',\n",
              "    '.'],\n",
              "   'generated_probs': [0.8795943444554083,\n",
              "    0.8426547618792549,\n",
              "    0.9999670269116242,\n",
              "    0.9988678570579389,\n",
              "    0.9992458703987693,\n",
              "    0.9997633576942085,\n",
              "    0.9611165792649476,\n",
              "    0.9819142571018927,\n",
              "    0.8827425886153942,\n",
              "    0.7180923765945434],\n",
              "   'generated_text': ' The joint statement was published in 18 specialist journals.',\n",
              "   'generated_tokens': [' The',\n",
              "    ' joint',\n",
              "    ' statement',\n",
              "    ' was',\n",
              "    ' published',\n",
              "    ' in',\n",
              "    ' 18',\n",
              "    ' specialist',\n",
              "    ' journals',\n",
              "    '.'],\n",
              "   'id': '57293e983f37b3190047818d',\n",
              "   'prediction': ' The joint statement was published in 18 specialist journals.',\n",
              "   'prompt': \"Title: Scientific misconduct\\n\\nBackground: have focussed attention on the role that journals play in perpetuating scientific fraud as well as how they can deal with it. In the Boldt case, the Editors-in-Chief of 18 specialist journals (generally anaesthesia and intensive care) made a joint statement regarding 88 published clinical trials conducted without Ethics Committee approval. In the Fujii case, involving nearly 200 papers, the journal Anesthesia & Analgesia, which published 24 of Fujii's papers, has accepted that its handling of the issue was inadequate. Following publication of a Letter to the Editor from Kranke and colleagues in April 2000, along with a non-specific response\\n\\nQ: Which journal was the joint statement published in?\\n\\nA:\",\n",
              "   'question': 'Which journal was the joint statement published in?'},\n",
              "  {'answers': ['physically imposing', 'physically imposing', 'stout man'],\n",
              "   'em': 0,\n",
              "   'f1': 0.2666666666666667,\n",
              "   'generated_answer': ' He was shown to be physically imposing, an equal in stature to the secular German',\n",
              "   'generated_answer_probs': [0.47936880021639944,\n",
              "    0.9990836859123854,\n",
              "    0.5286334227493916,\n",
              "    0.8397876472476209,\n",
              "    0.9999969487016552,\n",
              "    0.984113183167871,\n",
              "    0.9997767688697774,\n",
              "    0.9986437435482086,\n",
              "    0.9845958722287556,\n",
              "    0.9999200566396408,\n",
              "    0.9999777544614357,\n",
              "    0.9999970688428959,\n",
              "    0.999996829488026,\n",
              "    0.9988911038801989,\n",
              "    0.9999882465250727,\n",
              "    0.9999863382723223],\n",
              "   'generated_answer_tokens': [' He',\n",
              "    ' was',\n",
              "    ' shown',\n",
              "    ' to',\n",
              "    ' be',\n",
              "    ' physically',\n",
              "    ' imposing',\n",
              "    ',',\n",
              "    ' an',\n",
              "    ' equal',\n",
              "    ' in',\n",
              "    ' stature',\n",
              "    ' to',\n",
              "    ' the',\n",
              "    ' secular',\n",
              "    ' German'],\n",
              "   'generated_probs': [0.47936880021639944,\n",
              "    0.9990836859123854,\n",
              "    0.5286334227493916,\n",
              "    0.8397876472476209,\n",
              "    0.9999969487016552,\n",
              "    0.984113183167871,\n",
              "    0.9997767688697774,\n",
              "    0.9986437435482086,\n",
              "    0.9845958722287556,\n",
              "    0.9999200566396408,\n",
              "    0.9999777544614357,\n",
              "    0.9999970688428959,\n",
              "    0.999996829488026,\n",
              "    0.9988911038801989,\n",
              "    0.9999882465250727,\n",
              "    0.9999863382723223],\n",
              "   'generated_text': ' He was shown to be physically imposing, an equal in stature to the secular German',\n",
              "   'generated_tokens': [' He',\n",
              "    ' was',\n",
              "    ' shown',\n",
              "    ' to',\n",
              "    ' be',\n",
              "    ' physically',\n",
              "    ' imposing',\n",
              "    ',',\n",
              "    ' an',\n",
              "    ' equal',\n",
              "    ' in',\n",
              "    ' stature',\n",
              "    ' to',\n",
              "    ' the',\n",
              "    ' secular',\n",
              "    ' German'],\n",
              "   'id': '56f8cc399e9bad19000a0516',\n",
              "   'prediction': ' He was shown to be physically imposing, an equal in stature to the secular German',\n",
              "   'prompt': 'Title: Martin Luther\\n\\nBackground: apostles. Do not assail this divine Aeneid; nay, rather prostrate revere the ground that it treads. We are beggars: this is true. In the 1530s and 1540s, printed images of Luther that emphasized his monumental size were crucial to the spread of Protestantism. In contrast to images of frail Catholic saints, Luther was presented as a stout man with a \"double chin, strong mouth, piercing deep-set eyes, fleshy face, and squat neck.\" He was shown to be physically imposing, an equal in stature to the secular German princes with whom he would join forces to spread Lutheranism. His large body\\n\\nQ: How was Luther presented as an image to spread Protestantism?\\n\\nA:',\n",
              "   'question': 'How was Luther presented as an image to spread Protestantism?'},\n",
              "  {'answers': [\"Earth's mantle\",\n",
              "    \"The Earth's mantle\",\n",
              "    'mantle',\n",
              "    \"The Earth's mantle\",\n",
              "    'mantle'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' The core region is estimated to be primarily composed of iron (88.8%),',\n",
              "   'generated_answer_probs': [0.9099702029666772,\n",
              "    0.8706748485808611,\n",
              "    0.9340970670271289,\n",
              "    0.7840920067256018,\n",
              "    0.6134538572292633,\n",
              "    0.9999822861768917,\n",
              "    0.9999126663178081,\n",
              "    0.9941685363759777,\n",
              "    0.9999901538444738,\n",
              "    0.999996829488026,\n",
              "    0.999343741981551,\n",
              "    0.8450144763470953,\n",
              "    0.9999337665235336,\n",
              "    0.999997425535114,\n",
              "    0.9999616627178923,\n",
              "    0.9998261208487322],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' core',\n",
              "    ' region',\n",
              "    ' is',\n",
              "    ' estimated',\n",
              "    ' to',\n",
              "    ' be',\n",
              "    ' primarily',\n",
              "    ' composed',\n",
              "    ' of',\n",
              "    ' iron',\n",
              "    ' (',\n",
              "    '88',\n",
              "    '.',\n",
              "    '8',\n",
              "    '%),'],\n",
              "   'generated_probs': [0.9099702029666772,\n",
              "    0.8706748485808611,\n",
              "    0.9340970670271289,\n",
              "    0.7840920067256018,\n",
              "    0.6134538572292633,\n",
              "    0.9999822861768917,\n",
              "    0.9999126663178081,\n",
              "    0.9941685363759777,\n",
              "    0.9999901538444738,\n",
              "    0.999996829488026,\n",
              "    0.999343741981551,\n",
              "    0.8450144763470953,\n",
              "    0.9999337665235336,\n",
              "    0.999997425535114,\n",
              "    0.9999616627178923,\n",
              "    0.9998261208487322],\n",
              "   'generated_text': ' The core region is estimated to be primarily composed of iron (88.8%),',\n",
              "   'generated_tokens': [' The',\n",
              "    ' core',\n",
              "    ' region',\n",
              "    ' is',\n",
              "    ' estimated',\n",
              "    ' to',\n",
              "    ' be',\n",
              "    ' primarily',\n",
              "    ' composed',\n",
              "    ' of',\n",
              "    ' iron',\n",
              "    ' (',\n",
              "    '88',\n",
              "    '.',\n",
              "    '8',\n",
              "    '%),'],\n",
              "   'id': '571ce7f25efbb31900334e40',\n",
              "   'prediction': ' The core region is estimated to be primarily composed of iron (88.8%),',\n",
              "   'prompt': \"Title: Earth\\n\\nBackground: approximately (5,970 Yg). It is composed mostly of iron (32.1%), oxygen (30.1%), silicon (15.1%), magnesium (13.9%), sulfur (2.9%), nickel (1.8%), calcium (1.5%), and aluminium (1.4%), with the remaining 1.2% consisting of trace amounts of other elements. Due to mass segregation, the core region is estimated to be primarily composed of iron (88.8%), with smaller amounts of nickel (5.8%), sulfur (4.5%), and less than 1% trace elements. A little more than 47% of Earth's crust consists of oxygen. The most common rock constituents of the crust are nearly all oxides: chlorine, sulfur, and fluorine are the important exceptions to this and\\n\\nQ: What part of the Earth is composed of mostly of silicates of iron and magnesium?\\n\\nA:\",\n",
              "   'question': 'What part of the Earth is composed of mostly of silicates of iron and magnesium?'},\n",
              "  {'answers': ['Great Khan', 'Great Khan', 'Great Khan'],\n",
              "   'em': 1,\n",
              "   'f1': 1.0,\n",
              "   'generated_answer': ' Great Khan',\n",
              "   'generated_answer_probs': [0.43284598807060803, 0.9392729691963285],\n",
              "   'generated_answer_tokens': [' Great', ' Khan'],\n",
              "   'generated_probs': [0.43284598807060803, 0.9392729691963285],\n",
              "   'generated_text': ' Great Khan',\n",
              "   'generated_tokens': [' Great', ' Khan'],\n",
              "   'id': '57286192ff5b5019007da1e0',\n",
              "   'prediction': ' Great Khan',\n",
              "   'prompt': \"Title: Yuan dynasty\\n\\nBackground: since Yuan emperors held the nominal title of Great Khan. Nevertheless, both terms can also refer to the khanate within the Mongol Empire directly ruled by Great Khans before the actual establishment of the Yuan dynasty by Kublai Khan in 1271. Genghis Khan united the Mongol and Turkic tribes of the steppes and became Great Khan in 1206. He and his successors expanded the Mongol empire across Asia. Under the reign of Genghis' third son, Ögedei Khan, the Mongols destroyed the weakened Jin dynasty in 1234, conquering most of northern China. Ögedei offered his nephew Kublai a position in Xingzhou,\\n\\nQ: What nominal title did Yuan emperors have?\\n\\nA:\",\n",
              "   'question': 'What nominal title did Yuan emperors have?'},\n",
              "  {'answers': ['1596', '1596', '1596'],\n",
              "   'em': 1,\n",
              "   'f1': 1.0,\n",
              "   'generated_answer': ' 1596',\n",
              "   'generated_answer_probs': [0.7939318044703673, 0.999939725644572],\n",
              "   'generated_answer_tokens': [' 15', '96'],\n",
              "   'generated_probs': [0.7939318044703673, 0.999939725644572],\n",
              "   'generated_text': ' 1596',\n",
              "   'generated_tokens': [' 15', '96'],\n",
              "   'id': '5733266d4776f41900660716',\n",
              "   'prediction': ' 1596',\n",
              "   'prompt': 'Title: Warsaw\\n\\nBackground: when King Sigismund III Vasa moved his court from Kraków to Warsaw in 1596. After the Third Partition of Poland in 1795, Warsaw was incorporated into the Kingdom of Prussia. In 1806 during the Napoleonic Wars, the city became the official capital of the Grand Duchy of Warsaw, a puppet state of the First French Empire established by Napoleon Bonaparte. In accordance with the decisions of the Congress of Vienna, the Russian Empire annexed Warsaw in 1815 and it became part of the \"Congress Kingdom\". Only in 1918 did it regain independence from the foreign rule and emerge as a\\n\\nQ: What year did King Sigismund III Vasa move his court to Warsaw?\\n\\nA:',\n",
              "   'question': 'What year did King Sigismund III Vasa move his court to Warsaw?'},\n",
              "  {'answers': ['avoid prohibitively costly dowry demands',\n",
              "    'to avoid prohibitively costly dowry demands',\n",
              "    'avoid prohibitively costly dowry demands'],\n",
              "   'em': 0,\n",
              "   'f1': 0.1,\n",
              "   'generated_answer': ' One of the main reasons the Muslim Brotherhood has facilitated inexpensive mass marriage ceremonies is to',\n",
              "   'generated_answer_probs': [0.16674913193284235,\n",
              "    0.4590351602516122,\n",
              "    0.9989656691892557,\n",
              "    0.45693823061102234,\n",
              "    0.34651790077440625,\n",
              "    0.7096322932022038,\n",
              "    0.9916154515499895,\n",
              "    0.999649809570987,\n",
              "    0.541881286570739,\n",
              "    0.9846256143654761,\n",
              "    0.978207326625002,\n",
              "    0.9999275662234527,\n",
              "    0.9942168173549348,\n",
              "    0.9999689351265232,\n",
              "    0.9985973697066703,\n",
              "    0.7460209992842194],\n",
              "   'generated_answer_tokens': [' One',\n",
              "    ' of',\n",
              "    ' the',\n",
              "    ' main',\n",
              "    ' reasons',\n",
              "    ' the',\n",
              "    ' Muslim',\n",
              "    ' Brotherhood',\n",
              "    ' has',\n",
              "    ' facilitated',\n",
              "    ' inexpensive',\n",
              "    ' mass',\n",
              "    ' marriage',\n",
              "    ' ceremonies',\n",
              "    ' is',\n",
              "    ' to'],\n",
              "   'generated_probs': [0.16674913193284235,\n",
              "    0.4590351602516122,\n",
              "    0.9989656691892557,\n",
              "    0.45693823061102234,\n",
              "    0.34651790077440625,\n",
              "    0.7096322932022038,\n",
              "    0.9916154515499895,\n",
              "    0.999649809570987,\n",
              "    0.541881286570739,\n",
              "    0.9846256143654761,\n",
              "    0.978207326625002,\n",
              "    0.9999275662234527,\n",
              "    0.9942168173549348,\n",
              "    0.9999689351265232,\n",
              "    0.9985973697066703,\n",
              "    0.7460209992842194],\n",
              "   'generated_text': ' One of the main reasons the Muslim Brotherhood has facilitated inexpensive mass marriage ceremonies is to',\n",
              "   'generated_tokens': [' One',\n",
              "    ' of',\n",
              "    ' the',\n",
              "    ' main',\n",
              "    ' reasons',\n",
              "    ' the',\n",
              "    ' Muslim',\n",
              "    ' Brotherhood',\n",
              "    ' has',\n",
              "    ' facilitated',\n",
              "    ' inexpensive',\n",
              "    ' mass',\n",
              "    ' marriage',\n",
              "    ' ceremonies',\n",
              "    ' is',\n",
              "    ' to'],\n",
              "   'id': '572ffe6fb2c2fd14005686f1',\n",
              "   'prediction': ' One of the main reasons the Muslim Brotherhood has facilitated inexpensive mass marriage ceremonies is to',\n",
              "   'prompt': 'Title: Islamism\\n\\nBackground:  Islamist movements such as the Muslim Brotherhood, \"are well known for providing shelters, educational assistance, free or low cost medical clinics, housing assistance to students from out of town, student advisory groups, facilitation of inexpensive mass marriage ceremonies to avoid prohibitively costly dowry demands, legal assistance, sports facilities, and women\\'s groups.\" All this compares very favourably against incompetent, inefficient, or neglectful governments whose commitment to social justice is limited to rhetoric. Islamism can also be described as part of identity politics, specifically the religiously-oriented nationalism that emerged in the Third World in the 1970s: \"resurgent Hinduism in India, Religious\\n\\nQ: Why has the Muslim Brotherhood facilitated inexpensive mass marriage ceremonies?\\n\\nA:',\n",
              "   'question': 'Why has the Muslim Brotherhood facilitated inexpensive mass marriage ceremonies?'},\n",
              "  {'answers': ['coronary thrombosis',\n",
              "    'coronary thrombosis',\n",
              "    'coronary thrombosis'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' Leukemia',\n",
              "   'generated_answer_probs': [0.7883879168404914, 0.9999406801934893],\n",
              "   'generated_answer_tokens': [' Le', 'ukemia'],\n",
              "   'generated_probs': [0.7883879168404914, 0.9999406801934893],\n",
              "   'generated_text': ' Leukemia',\n",
              "   'generated_tokens': [' Le', 'ukemia'],\n",
              "   'id': '56e110c3cd28a01900c67535',\n",
              "   'prediction': ' Leukemia',\n",
              "   'prompt': 'Title: Leukemia\\n\\nBackground: it is the ninth most common cause of cancer death (around 4,800 people died in 2012). Leukemia was first described by anatomist and surgeon Alfred-Armand-Louis-Marie Velpeau in 1827. A more complete description was given by pathologist Rudolf Virchow in 1845. Observing an abnormally large number of white blood cells in a blood sample from a patient, Virchow called the condition \"Leukämie\" in German, which he formed from the two Greek words \"leukos\" (λευκός), meaning \"white\", and \"haima\" (αἷμα), meaning \"blood\". Around ten years after Virchow\\'s findings, pathologist Franz Ernst Christian Neumann found that one deceased leukemia patient\\'s bone marrow was\\n\\nQ: What was given as the cause of death?\\n\\nA:',\n",
              "   'question': 'What was given as the cause of death?'},\n",
              "  {'answers': ['constant factors and smaller terms',\n",
              "    'constant factors and smaller terms',\n",
              "    'constant factors and smaller terms'],\n",
              "   'em': 1,\n",
              "   'f1': 1.0,\n",
              "   'generated_answer': ' Constant factors and smaller terms.',\n",
              "   'generated_answer_probs': [0.7888629611318093,\n",
              "    0.9649473313929896,\n",
              "    0.948842650219428,\n",
              "    0.9876290857530678,\n",
              "    0.9979178756344808,\n",
              "    0.8513352156825892],\n",
              "   'generated_answer_tokens': [' Constant',\n",
              "    ' factors',\n",
              "    ' and',\n",
              "    ' smaller',\n",
              "    ' terms',\n",
              "    '.'],\n",
              "   'generated_probs': [0.7888629611318093,\n",
              "    0.9649473313929896,\n",
              "    0.948842650219428,\n",
              "    0.9876290857530678,\n",
              "    0.9979178756344808,\n",
              "    0.8513352156825892],\n",
              "   'generated_text': ' Constant factors and smaller terms.',\n",
              "   'generated_tokens': [' Constant',\n",
              "    ' factors',\n",
              "    ' and',\n",
              "    ' smaller',\n",
              "    ' terms',\n",
              "    '.'],\n",
              "   'id': '56e1bd4acd28a01900c67afd',\n",
              "   'prediction': ' Constant factors and smaller terms.',\n",
              "   'prompt': 'Title: Computational complexity theory\\n\\nBackground: the algorithms known today, but any algorithm that might be discovered in the future. To show a lower bound of \"T\"(\"n\") for a problem requires showing that no algorithm can have time complexity lower than \"T\"(\"n\"). Upper and lower bounds are usually stated using the big O notation, which hides constant factors and smaller terms. This makes the bounds independent of the specific details of the computational model used. For instance, if \"T\"(\"n\")\\xa0=\\xa07\"n\"\\xa0+\\xa015\"n\"\\xa0+\\xa040, in big O notation one would write \"T\"(\"n\")\\xa0=\\xa0O(\"n\"). A complexity class is a set of problems of related complexity. Simpler complexity classes are defined by the following\\n\\nQ: What does a big O notation hide?\\n\\nA:',\n",
              "   'question': 'What does a big O notation hide?'},\n",
              "  {'answers': ['1854', '1854', '1854'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' The armed protest at Ballarat about mining taxes took place in 1851.',\n",
              "   'generated_answer_probs': [0.3262942165086831,\n",
              "    0.6467485952061978,\n",
              "    0.9985360362419429,\n",
              "    0.8367515303256935,\n",
              "    0.9995405544774334,\n",
              "    0.9998053804808361,\n",
              "    0.950299947510055,\n",
              "    0.999290036203645,\n",
              "    0.9998729712688326,\n",
              "    0.6464292320164794,\n",
              "    0.9999700042268822,\n",
              "    0.6862585961300378,\n",
              "    0.98780068837397,\n",
              "    0.9769991499511189,\n",
              "    0.9850513078291421],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' armed',\n",
              "    ' protest',\n",
              "    ' at',\n",
              "    ' Ball',\n",
              "    'arat',\n",
              "    ' about',\n",
              "    ' mining',\n",
              "    ' taxes',\n",
              "    ' took',\n",
              "    ' place',\n",
              "    ' in',\n",
              "    ' 18',\n",
              "    '51',\n",
              "    '.'],\n",
              "   'generated_probs': [0.3262942165086831,\n",
              "    0.6467485952061978,\n",
              "    0.9985360362419429,\n",
              "    0.8367515303256935,\n",
              "    0.9995405544774334,\n",
              "    0.9998053804808361,\n",
              "    0.950299947510055,\n",
              "    0.999290036203645,\n",
              "    0.9998729712688326,\n",
              "    0.6464292320164794,\n",
              "    0.9999700042268822,\n",
              "    0.6862585961300378,\n",
              "    0.98780068837397,\n",
              "    0.9769991499511189,\n",
              "    0.9850513078291421],\n",
              "   'generated_text': ' The armed protest at Ballarat about mining taxes took place in 1851.',\n",
              "   'generated_tokens': [' The',\n",
              "    ' armed',\n",
              "    ' protest',\n",
              "    ' at',\n",
              "    ' Ball',\n",
              "    'arat',\n",
              "    ' about',\n",
              "    ' mining',\n",
              "    ' taxes',\n",
              "    ' took',\n",
              "    ' place',\n",
              "    ' in',\n",
              "    ' 18',\n",
              "    '51',\n",
              "    '.'],\n",
              "   'id': '570d4c3bfed7b91900d45e31',\n",
              "   'prediction': ' The armed protest at Ballarat about mining taxes took place in 1851.',\n",
              "   'prompt': 'Title: Colonial forces of Australia\\n\\nBackground: Victorian Government faced their first crisis. Three years earlier, in 1851, gold had been discovered in Ballarat, and soon after in Bendigo, triggering the Victorian gold rush. The government imposed heavy mining taxes, which caused a miners revolt, culminating in the Eureka Stockade. About 1,000 miners fortified a position, and at 3:00\\xa0am on 3 December 1854, a party of 276 members from the 1st/12th and 2nd/40th Regiments supported by Victorian police, under the command of Captain John Thomas, approached the Eureka Stockade and a battle ensued. The police took up holding positions on two sides of the stockade, with a\\n\\nQ: When was there a armed protest at Ballarat about mining taxes?\\n\\nA:',\n",
              "   'question': 'When was there a armed protest at Ballarat about mining taxes?'},\n",
              "  {'answers': ['four', 'four', 'four'],\n",
              "   'em': 0,\n",
              "   'f1': 0.33333333333333337,\n",
              "   'generated_answer': ' Most species have four auricles.',\n",
              "   'generated_answer_probs': [0.9290648317544381,\n",
              "    0.9941199602014842,\n",
              "    0.9872977443821777,\n",
              "    0.9705233993991494,\n",
              "    0.9995471107852948,\n",
              "    0.9999319785035669,\n",
              "    0.9937938611314311],\n",
              "   'generated_answer_tokens': [' Most',\n",
              "    ' species',\n",
              "    ' have',\n",
              "    ' four',\n",
              "    ' aur',\n",
              "    'icles',\n",
              "    '.'],\n",
              "   'generated_probs': [0.9290648317544381,\n",
              "    0.9941199602014842,\n",
              "    0.9872977443821777,\n",
              "    0.9705233993991494,\n",
              "    0.9995471107852948,\n",
              "    0.9999319785035669,\n",
              "    0.9937938611314311],\n",
              "   'generated_text': ' Most species have four auricles.',\n",
              "   'generated_tokens': [' Most',\n",
              "    ' species',\n",
              "    ' have',\n",
              "    ' four',\n",
              "    ' aur',\n",
              "    'icles',\n",
              "    '.'],\n",
              "   'id': '57265aaf5951b619008f706d',\n",
              "   'prediction': ' Most species have four auricles.',\n",
              "   'prompt': 'Title: Ctenophora\\n\\nBackground: out over the inner surface of the lobes (rather than trailing far behind, as in the Cydippida). Between the lobes on either side of the mouth, many species of lobates have four auricles, gelatinous projections edged with cilia that produce water currents that help direct microscopic prey toward the mouth. This combination of structures enables lobates to feed continuously on suspended planktonic prey. Lobates have eight comb-rows, originating at the aboral pole and usually not extending beyond the body to the lobes; in species with (four) auricles, the cilia edging the auricles are extensions of cilia in four of the\\n\\nQ: How many auricles do most species have?\\n\\nA:',\n",
              "   'question': 'How many auricles do most species have?'},\n",
              "  {'answers': ['After 1971', '1973–1974', '1971', 'After 1971', '1971'],\n",
              "   'em': 0,\n",
              "   'f1': 0.19999999999999998,\n",
              "   'generated_answer': ' OPEC started to readjust oil prices in September 1971.',\n",
              "   'generated_answer_probs': [0.7883163896496765,\n",
              "    0.6103301431145286,\n",
              "    0.9958384319239058,\n",
              "    0.9784983171243141,\n",
              "    0.9997792698344884,\n",
              "    0.9757434770563717,\n",
              "    0.9999655973937832,\n",
              "    0.5554636325513155,\n",
              "    0.7132499350147453,\n",
              "    0.9956999677274702,\n",
              "    0.4000126729504124],\n",
              "   'generated_answer_tokens': [' OPEC',\n",
              "    ' started',\n",
              "    ' to',\n",
              "    ' read',\n",
              "    'just',\n",
              "    ' oil',\n",
              "    ' prices',\n",
              "    ' in',\n",
              "    ' September',\n",
              "    ' 1971',\n",
              "    '.'],\n",
              "   'generated_probs': [0.7883163896496765,\n",
              "    0.6103301431145286,\n",
              "    0.9958384319239058,\n",
              "    0.9784983171243141,\n",
              "    0.9997792698344884,\n",
              "    0.9757434770563717,\n",
              "    0.9999655973937832,\n",
              "    0.5554636325513155,\n",
              "    0.7132499350147453,\n",
              "    0.9956999677274702,\n",
              "    0.4000126729504124],\n",
              "   'generated_text': ' OPEC started to readjust oil prices in September 1971.',\n",
              "   'generated_tokens': [' OPEC',\n",
              "    ' started',\n",
              "    ' to',\n",
              "    ' read',\n",
              "    'just',\n",
              "    ' oil',\n",
              "    ' prices',\n",
              "    ' in',\n",
              "    ' September',\n",
              "    ' 1971',\n",
              "    '.'],\n",
              "   'id': '5725b92e38643c19005acbd4',\n",
              "   'prediction': ' OPEC started to readjust oil prices in September 1971.',\n",
              "   'prompt': 'Title: 1973 oil crisis\\n\\nBackground: (by expanding their money supplies) in amounts far greater than before. The result was a depreciation of the\\xa0dollar and other industrialized nations\\' currencies. Because oil was priced in dollars, oil producers\\' real income decreased. In September 1971, OPEC issued a joint communiqué stating that, from then on, they would price oil in terms of a fixed amount of gold. This contributed to the \"Oil Shock\". After 1971, OPEC was slow to readjust prices to reflect this depreciation. From 1947 to 1967, the dollar price of oil had risen by less than two percent per year. Until the oil shock, the\\n\\nQ: When did OPEC start to readjust oil prices?\\n\\nA:',\n",
              "   'question': 'When did OPEC start to readjust oil prices?'},\n",
              "  {'answers': ['British', 'British', 'British'],\n",
              "   'em': 1,\n",
              "   'f1': 1.0,\n",
              "   'generated_answer': ' British',\n",
              "   'generated_answer_probs': [0.5258935569161075],\n",
              "   'generated_answer_tokens': [' British'],\n",
              "   'generated_probs': [0.5258935569161075],\n",
              "   'generated_text': ' British',\n",
              "   'generated_tokens': [' British'],\n",
              "   'id': '56bec7353aeaaa14008c940e',\n",
              "   'prediction': ' British',\n",
              "   'prompt': 'Title: Post-Britpop\\n\\nBackground: from Northern Ireland and Elbow, Embrace, Starsailor, Doves and Keane from England. The most commercially successful band in the milieu were Coldplay, whose first two albums \"Parachutes\" (2000) and \"A Rush of Blood to the Head\" (2002) going multi-platinum, establishing them as one of the most popular acts in the world by the time of their third album \"X&Y\" (2005). Bands like Coldplay, Starsailor and Elbow, with introspective lyrics and even tempos, began to be criticised at the beginning of the new millennium as bland and sterile, and the wave of garage rock or post punk revival bands, like The\\n\\nQ: What nationality is the band Coldplay?\\n\\nA:',\n",
              "   'question': 'What nationality is the band Coldplay?'},\n",
              "  {'answers': [\"St. George's Church\",\n",
              "    \"St. George's Church\",\n",
              "    \"St. George's Church\"],\n",
              "   'em': 1,\n",
              "   'f1': 1.0,\n",
              "   'generated_answer': \" St. George's Church\",\n",
              "   'generated_answer_probs': [0.6619081558875681,\n",
              "    0.941413989322151,\n",
              "    0.9959919741622852,\n",
              "    0.9936297694997409,\n",
              "    0.9861538096355963],\n",
              "   'generated_answer_tokens': [' St', '.', ' George', \"'s\", ' Church'],\n",
              "   'generated_probs': [0.6619081558875681,\n",
              "    0.941413989322151,\n",
              "    0.9959919741622852,\n",
              "    0.9936297694997409,\n",
              "    0.9861538096355963],\n",
              "   'generated_text': \" St. George's Church\",\n",
              "   'generated_tokens': [' St', '.', ' George', \"'s\", ' Church'],\n",
              "   'id': '57309cd6069b5314008321c4',\n",
              "   'prediction': \" St. George's Church\",\n",
              "   'prompt': \"Title: United Methodist Church\\n\\nBackground: use in the United States, beginning in 1769. The congregation was founded in 1767, meeting initially in a sail loft on Dock Street, and in 1769 it purchased the shell of a building which had been erected in 1763 by a German Reformed congregation. At this time, Methodists had not yet broken away from the Anglican Church and the Methodist Episcopal Church was not founded until 1784. Richard Allen and Absalom Jones became the first African Americans ordained by the Methodist Church. They were licensed by St. George's Church in 1784. Three years later, protesting racial segregation in the worship\\n\\nQ: Richard Allen and Absalom Jones were licensed by what church?\\n\\nA:\",\n",
              "   'question': 'Richard Allen and Absalom Jones were licensed by what church?'},\n",
              "  {'answers': ['half a million', 'half a million', 'half a million'],\n",
              "   'em': 0,\n",
              "   'f1': 0.3636363636363636,\n",
              "   'generated_answer': ' A square mm of a leaf can contain half a million chloroplasts.',\n",
              "   'generated_answer_probs': [0.229079081724691,\n",
              "    0.750163347124442,\n",
              "    0.854524786350917,\n",
              "    0.9995343565855607,\n",
              "    0.599584897917306,\n",
              "    0.9991646271583352,\n",
              "    0.9617510746117056,\n",
              "    0.9969520916324337,\n",
              "    0.8455890025582321,\n",
              "    0.999722230934972,\n",
              "    0.9997672925205868,\n",
              "    0.9992788310973837,\n",
              "    0.999998499344226,\n",
              "    0.9999952788481447,\n",
              "    0.9803687074335584],\n",
              "   'generated_answer_tokens': [' A',\n",
              "    ' square',\n",
              "    ' mm',\n",
              "    ' of',\n",
              "    ' a',\n",
              "    ' leaf',\n",
              "    ' can',\n",
              "    ' contain',\n",
              "    ' half',\n",
              "    ' a',\n",
              "    ' million',\n",
              "    ' chlor',\n",
              "    'opl',\n",
              "    'asts',\n",
              "    '.'],\n",
              "   'generated_probs': [0.229079081724691,\n",
              "    0.750163347124442,\n",
              "    0.854524786350917,\n",
              "    0.9995343565855607,\n",
              "    0.599584897917306,\n",
              "    0.9991646271583352,\n",
              "    0.9617510746117056,\n",
              "    0.9969520916324337,\n",
              "    0.8455890025582321,\n",
              "    0.999722230934972,\n",
              "    0.9997672925205868,\n",
              "    0.9992788310973837,\n",
              "    0.999998499344226,\n",
              "    0.9999952788481447,\n",
              "    0.9803687074335584],\n",
              "   'generated_text': ' A square mm of a leaf can contain half a million chloroplasts.',\n",
              "   'generated_tokens': [' A',\n",
              "    ' square',\n",
              "    ' mm',\n",
              "    ' of',\n",
              "    ' a',\n",
              "    ' leaf',\n",
              "    ' can',\n",
              "    ' contain',\n",
              "    ' half',\n",
              "    ' a',\n",
              "    ' million',\n",
              "    ' chlor',\n",
              "    'opl',\n",
              "    'asts',\n",
              "    '.'],\n",
              "   'id': '572972f46aef051400154ef4',\n",
              "   'prediction': ' A square mm of a leaf can contain half a million chloroplasts.',\n",
              "   'prompt': 'Title: Chloroplast\\n\\nBackground: A typical chlorenchyma cell of a land plant contains about 10 to 100 chloroplasts. In some plants such as cacti, chloroplasts are found in the stems, though in most plants, chloroplasts are concentrated in the leaves. One square millimeter of leaf tissue can contain half a million chloroplasts. Within a leaf, chloroplasts are mainly found in the mesophyll layers of a leaf, and the guard cells of stomata. Palisade mesophyll cells can contain 30–70 chloroplasts per cell, while stomatal guard cells contain only around 8–15 per cell, as well as much less chlorophyll. Chloroplasts can also be found in the\\n\\nQ: How many chloroplasts are in a square mm of a leaf?\\n\\nA:',\n",
              "   'question': 'How many chloroplasts are in a square mm of a leaf?'},\n",
              "  {'answers': ['attacks on Jews', 'ideal underpinning', 'antisemitism'],\n",
              "   'em': 0,\n",
              "   'f1': 0.16666666666666669,\n",
              "   'generated_answer': \" Luther's rhetoric contributed significantly to the development of antisemitism in Germany, and\",\n",
              "   'generated_answer_probs': [0.6992287059941084,\n",
              "    0.9680123679299927,\n",
              "    0.3229240896318091,\n",
              "    0.241234569845055,\n",
              "    0.7950103623581382,\n",
              "    0.9999359130736548,\n",
              "    0.9988766779990461,\n",
              "    0.9975033804515513,\n",
              "    0.9991237998277458,\n",
              "    0.9977325630276674,\n",
              "    0.9999987377612967,\n",
              "    0.9999731063796399,\n",
              "    0.9950397244998883,\n",
              "    0.992347856470614,\n",
              "    0.6867992788320938,\n",
              "    0.984868083657149],\n",
              "   'generated_answer_tokens': [' Luther',\n",
              "    \"'s\",\n",
              "    ' rhetoric',\n",
              "    ' contributed',\n",
              "    ' significantly',\n",
              "    ' to',\n",
              "    ' the',\n",
              "    ' development',\n",
              "    ' of',\n",
              "    ' antis',\n",
              "    'em',\n",
              "    'itism',\n",
              "    ' in',\n",
              "    ' Germany',\n",
              "    ',',\n",
              "    ' and'],\n",
              "   'generated_probs': [0.6992287059941084,\n",
              "    0.9680123679299927,\n",
              "    0.3229240896318091,\n",
              "    0.241234569845055,\n",
              "    0.7950103623581382,\n",
              "    0.9999359130736548,\n",
              "    0.9988766779990461,\n",
              "    0.9975033804515513,\n",
              "    0.9991237998277458,\n",
              "    0.9977325630276674,\n",
              "    0.9999987377612967,\n",
              "    0.9999731063796399,\n",
              "    0.9950397244998883,\n",
              "    0.992347856470614,\n",
              "    0.6867992788320938,\n",
              "    0.984868083657149],\n",
              "   'generated_text': \" Luther's rhetoric contributed significantly to the development of antisemitism in Germany, and\",\n",
              "   'generated_tokens': [' Luther',\n",
              "    \"'s\",\n",
              "    ' rhetoric',\n",
              "    ' contributed',\n",
              "    ' significantly',\n",
              "    ' to',\n",
              "    ' the',\n",
              "    ' development',\n",
              "    ' of',\n",
              "    ' antis',\n",
              "    'em',\n",
              "    'itism',\n",
              "    ' in',\n",
              "    ' Germany',\n",
              "    ',',\n",
              "    ' and'],\n",
              "   'id': '56f8b4d79b226e1400dd0e77',\n",
              "   'prediction': \" Luther's rhetoric contributed significantly to the development of antisemitism in Germany, and\",\n",
              "   'prompt': 'Title: Martin Luther\\n\\nBackground: and within Germany he acquired the status of a prophet. According to the prevailing view among historians, his anti-Jewish rhetoric contributed significantly to the development of antisemitism in Germany, and in the 1930s and 1940s provided an \"ideal underpinning\" for the Nazis\\' attacks on Jews. Reinhold Lewin writes that anybody who \"wrote against the Jews for whatever reason believed he had the right to justify himself by triumphantly referring to Luther.\" According to Michael, just about every anti-Jewish book printed in the Third Reich contained references to and quotations from Luther. Heinrich Himmler wrote admiringly of his writings and sermons\\n\\nQ: What later actions by the Nazis could be traced back to Luther\\'s rhetoric?\\n\\nA:',\n",
              "   'question': \"What later actions by the Nazis could be traced back to Luther's rhetoric?\"},\n",
              "  {'answers': ['Tesla coil', 'the Tesla coil', 'Tesla coil'],\n",
              "   'em': 0,\n",
              "   'f1': 0.1818181818181818,\n",
              "   'generated_answer': ' Tesla patented his three-phase induction motor design in 1891.',\n",
              "   'generated_answer_probs': [0.6255366485401112,\n",
              "    0.8195930765544573,\n",
              "    0.43795384538125437,\n",
              "    0.5747383415092465,\n",
              "    0.9533732977482973,\n",
              "    0.9997460738447048,\n",
              "    0.990271727789049,\n",
              "    0.9979250844196681,\n",
              "    0.6793303604872118,\n",
              "    0.9757056901704267,\n",
              "    0.998486207142043,\n",
              "    0.9999924159807588,\n",
              "    0.9973205110560225],\n",
              "   'generated_answer_tokens': [' Tesla',\n",
              "    ' patented',\n",
              "    ' his',\n",
              "    ' three',\n",
              "    '-',\n",
              "    'phase',\n",
              "    ' induction',\n",
              "    ' motor',\n",
              "    ' design',\n",
              "    ' in',\n",
              "    ' 18',\n",
              "    '91',\n",
              "    '.'],\n",
              "   'generated_probs': [0.6255366485401112,\n",
              "    0.8195930765544573,\n",
              "    0.43795384538125437,\n",
              "    0.5747383415092465,\n",
              "    0.9533732977482973,\n",
              "    0.9997460738447048,\n",
              "    0.990271727789049,\n",
              "    0.9979250844196681,\n",
              "    0.6793303604872118,\n",
              "    0.9757056901704267,\n",
              "    0.998486207142043,\n",
              "    0.9999924159807588,\n",
              "    0.9973205110560225],\n",
              "   'generated_text': ' Tesla patented his three-phase induction motor design in 1891.',\n",
              "   'generated_tokens': [' Tesla',\n",
              "    ' patented',\n",
              "    ' his',\n",
              "    ' three',\n",
              "    '-',\n",
              "    'phase',\n",
              "    ' induction',\n",
              "    ' motor',\n",
              "    ' design',\n",
              "    ' in',\n",
              "    ' 18',\n",
              "    '91',\n",
              "    '.'],\n",
              "   'id': '56e08a1f7aa994140058e5dd',\n",
              "   'prediction': ' Tesla patented his three-phase induction motor design in 1891.',\n",
              "   'prompt': \"Title: AC motor\\n\\nBackground: to the Royal Academy of Sciences in Turin, where he detailed the foundations of motor operation; Tesla, in the same year, was granted a United States patent for his own motor. Working from Ferraris's experiments, Mikhail Dolivo-Dobrovolsky introduced the first three-phase induction motor in 1890, a much more capable design that became the prototype used in Europe and the U.S. He also invented the first three-phase generator and transformer and combined them into the first complete AC three-phase system in 1891. The three-phase motor design was also worked on by the Swiss engineer Charles Eugene Lancelot Brown, and other three-phase\\n\\nQ: what did he patent in 1891? \\n\\nA:\",\n",
              "   'question': 'what did he patent in 1891? '},\n",
              "  {'answers': ['the statistical behaviour',\n",
              "    'distribution',\n",
              "    'statistical',\n",
              "    'statistical',\n",
              "    'statistical'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' The prime number theorem states that the probability that a given, randomly chosen number is',\n",
              "   'generated_answer_probs': [0.6795180038566514,\n",
              "    0.9228416678361467,\n",
              "    0.9989686482092196,\n",
              "    0.9999556997112867,\n",
              "    0.8508922875850978,\n",
              "    0.9995003215808632,\n",
              "    0.9495016480768721,\n",
              "    0.9982709150927144,\n",
              "    0.574607390803802,\n",
              "    0.9926762155765737,\n",
              "    0.9696271944297624,\n",
              "    0.7191783494030316,\n",
              "    0.997557087479335,\n",
              "    0.9993198401436533,\n",
              "    0.994843144767826,\n",
              "    0.999446859768495],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' prime',\n",
              "    ' number',\n",
              "    ' theorem',\n",
              "    ' states',\n",
              "    ' that',\n",
              "    ' the',\n",
              "    ' probability',\n",
              "    ' that',\n",
              "    ' a',\n",
              "    ' given',\n",
              "    ',',\n",
              "    ' randomly',\n",
              "    ' chosen',\n",
              "    ' number',\n",
              "    ' is'],\n",
              "   'generated_probs': [0.6795180038566514,\n",
              "    0.9228416678361467,\n",
              "    0.9989686482092196,\n",
              "    0.9999556997112867,\n",
              "    0.8508922875850978,\n",
              "    0.9995003215808632,\n",
              "    0.9495016480768721,\n",
              "    0.9982709150927144,\n",
              "    0.574607390803802,\n",
              "    0.9926762155765737,\n",
              "    0.9696271944297624,\n",
              "    0.7191783494030316,\n",
              "    0.997557087479335,\n",
              "    0.9993198401436533,\n",
              "    0.994843144767826,\n",
              "    0.999446859768495],\n",
              "   'generated_text': ' The prime number theorem states that the probability that a given, randomly chosen number is',\n",
              "   'generated_tokens': [' The',\n",
              "    ' prime',\n",
              "    ' number',\n",
              "    ' theorem',\n",
              "    ' states',\n",
              "    ' that',\n",
              "    ' the',\n",
              "    ' probability',\n",
              "    ' that',\n",
              "    ' a',\n",
              "    ' given',\n",
              "    ',',\n",
              "    ' randomly',\n",
              "    ' chosen',\n",
              "    ' number',\n",
              "    ' is'],\n",
              "   'id': '572970c11d04691400779465',\n",
              "   'prediction': ' The prime number theorem states that the probability that a given, randomly chosen number is',\n",
              "   'prompt': 'Title: Prime number\\n\\nBackground: primes, that is to say, the statistical behaviour of primes in the large, can be modelled. The first result in that direction is the prime number theorem, proven at the end of the 19th century, which says that the probability that a given, randomly chosen number is prime is inversely proportional to its number of digits, or to the logarithm of \"n\". Many questions regarding prime numbers remain open, such as Goldbach\\'s conjecture (that every even integer greater than 2 can be expressed as the sum of two primes), and the twin prime conjecture (that there are infinitely many pairs\\n\\nQ: What type of behavior in primes is it possible to determine?\\n\\nA:',\n",
              "   'question': 'What type of behavior in primes is it possible to determine?'},\n",
              "  {'answers': ['subsequent long-run economic growth',\n",
              "    'subsequent long-run economic growth',\n",
              "    'long-run economic growth'],\n",
              "   'em': 0,\n",
              "   'f1': 0.5714285714285715,\n",
              "   'generated_answer': ' Persistent unemployment has a negative effect on subsequent long-run economic growth.',\n",
              "   'generated_answer_probs': [0.5663101684961563,\n",
              "    0.9996870653942511,\n",
              "    0.9947300147532164,\n",
              "    0.9454489452139364,\n",
              "    0.9989133339496288,\n",
              "    0.9687296974549976,\n",
              "    0.998460935077028,\n",
              "    0.9956591989299607,\n",
              "    0.9185434904679021,\n",
              "    0.9929049780582053,\n",
              "    0.9963917454521649,\n",
              "    0.9849054561705156,\n",
              "    0.998828993863406,\n",
              "    0.9997537041358076,\n",
              "    0.9514375800755182],\n",
              "   'generated_answer_tokens': [' Pers',\n",
              "    'istent',\n",
              "    ' unemployment',\n",
              "    ' has',\n",
              "    ' a',\n",
              "    ' negative',\n",
              "    ' effect',\n",
              "    ' on',\n",
              "    ' subsequent',\n",
              "    ' long',\n",
              "    '-',\n",
              "    'run',\n",
              "    ' economic',\n",
              "    ' growth',\n",
              "    '.'],\n",
              "   'generated_probs': [0.5663101684961563,\n",
              "    0.9996870653942511,\n",
              "    0.9947300147532164,\n",
              "    0.9454489452139364,\n",
              "    0.9989133339496288,\n",
              "    0.9687296974549976,\n",
              "    0.998460935077028,\n",
              "    0.9956591989299607,\n",
              "    0.9185434904679021,\n",
              "    0.9929049780582053,\n",
              "    0.9963917454521649,\n",
              "    0.9849054561705156,\n",
              "    0.998828993863406,\n",
              "    0.9997537041358076,\n",
              "    0.9514375800755182],\n",
              "   'generated_text': ' Persistent unemployment has a negative effect on subsequent long-run economic growth.',\n",
              "   'generated_tokens': [' Pers',\n",
              "    'istent',\n",
              "    ' unemployment',\n",
              "    ' has',\n",
              "    ' a',\n",
              "    ' negative',\n",
              "    ' effect',\n",
              "    ' on',\n",
              "    ' subsequent',\n",
              "    ' long',\n",
              "    '-',\n",
              "    'run',\n",
              "    ' economic',\n",
              "    ' growth',\n",
              "    '.'],\n",
              "   'id': '572a0ecb1d04691400779719',\n",
              "   'prediction': ' Persistent unemployment has a negative effect on subsequent long-run economic growth.',\n",
              "   'prompt': 'Title: Tax policy and economic inequality in the United States\\n\\nBackground: not have access to the productive resources of the economy. Voters may internalize such issues. High unemployment rates have a significant negative effect when interacting with increases in inequality. Increasing inequality harms growth in countries with high levels of urbanization. High and persistent unemployment also has a negative effect on subsequent long-run economic growth. Unemployment may seriously harm growth because it is a waste of resources, generates redistributive pressures and distortions, depreciates existing human capital and deters its accumulation, drives people to poverty, results in liquidity constraints that limit labor mobility, and because it erodes individual self-esteem and promotes social\\n\\nQ: What was persistent unemployment have a negative effect on?\\n\\nA:',\n",
              "   'question': 'What was persistent unemployment have a negative effect on?'},\n",
              "  {'answers': ['Hyde Park', 'Hyde Park', 'Hyde Park', 'Hyde Park'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' The urban renewal project was intended to help the residents of the Hill District.',\n",
              "   'generated_answer_probs': [0.8134546993361529,\n",
              "    0.7825237387244,\n",
              "    0.999931026778762,\n",
              "    0.9983510247561151,\n",
              "    0.9830028731509749,\n",
              "    0.9743801526743615,\n",
              "    0.9999444955904268,\n",
              "    0.9969498277561945,\n",
              "    0.9953188536787952,\n",
              "    0.9997823713845435,\n",
              "    0.9991577141620276,\n",
              "    0.9114041834744576,\n",
              "    0.42394431708674857,\n",
              "    0.9817380055662257,\n",
              "    0.785900158052371],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' urban',\n",
              "    ' renewal',\n",
              "    ' project',\n",
              "    ' was',\n",
              "    ' intended',\n",
              "    ' to',\n",
              "    ' help',\n",
              "    ' the',\n",
              "    ' residents',\n",
              "    ' of',\n",
              "    ' the',\n",
              "    ' Hill',\n",
              "    ' District',\n",
              "    '.'],\n",
              "   'generated_probs': [0.8134546993361529,\n",
              "    0.7825237387244,\n",
              "    0.999931026778762,\n",
              "    0.9983510247561151,\n",
              "    0.9830028731509749,\n",
              "    0.9743801526743615,\n",
              "    0.9999444955904268,\n",
              "    0.9969498277561945,\n",
              "    0.9953188536787952,\n",
              "    0.9997823713845435,\n",
              "    0.9991577141620276,\n",
              "    0.9114041834744576,\n",
              "    0.42394431708674857,\n",
              "    0.9817380055662257,\n",
              "    0.785900158052371],\n",
              "   'generated_text': ' The urban renewal project was intended to help the residents of the Hill District.',\n",
              "   'generated_tokens': [' The',\n",
              "    ' urban',\n",
              "    ' renewal',\n",
              "    ' project',\n",
              "    ' was',\n",
              "    ' intended',\n",
              "    ' to',\n",
              "    ' help',\n",
              "    ' the',\n",
              "    ' residents',\n",
              "    ' of',\n",
              "    ' the',\n",
              "    ' Hill',\n",
              "    ' District',\n",
              "    '.'],\n",
              "   'id': '57284618ff5b5019007da0ab',\n",
              "   'prediction': ' The urban renewal project was intended to help the residents of the Hill District.',\n",
              "   'prompt': 'Title: Urban renewal\\n\\nBackground: the Golden Triangle in what was universally recognized as a major success. Other neighborhoods were also subjected to urban renewal, but with mixed results. Some areas did improve, while other areas, such as East Liberty and the Hill District, declined following ambitious projects that shifted traffic patterns, blocked streets to vehicular traffic, isolated or divided neighborhoods with highways, and removed large numbers of ethnic and minority residents. An entire neighborhood was destroyed (to be replaced by the Civic Arena), displacing 8000 residents (most of whom were poor and black). Because of the ways in which it targeted the most disadvantaged\\n\\nQ: The urban renewal project was intended to help the residents of what neighborhood?\\n\\nA:',\n",
              "   'question': 'The urban renewal project was intended to help the residents of what neighborhood?'},\n",
              "  {'answers': ['religious', 'religious', 'religious'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' Radical Islamist organizations like al-Qaeda and the Egyptian Islamic Jihad, and groups such',\n",
              "   'generated_answer_probs': [0.48559629937151444,\n",
              "    0.833701695385339,\n",
              "    0.9352611592393922,\n",
              "    0.7376901156916998,\n",
              "    0.9955532203327885,\n",
              "    0.9976458373974598,\n",
              "    0.999499251176562,\n",
              "    0.9991744635428744,\n",
              "    0.9996724008523231,\n",
              "    0.9999363898832093,\n",
              "    0.9999658329887057,\n",
              "    0.9999163605479741,\n",
              "    0.9983174656506324,\n",
              "    0.9999411560633723,\n",
              "    0.9998689168221506,\n",
              "    0.9997755751870168],\n",
              "   'generated_answer_tokens': [' Radical',\n",
              "    ' Islamist',\n",
              "    ' organizations',\n",
              "    ' like',\n",
              "    ' al',\n",
              "    '-',\n",
              "    'Qaeda',\n",
              "    ' and',\n",
              "    ' the',\n",
              "    ' Egyptian',\n",
              "    ' Islamic',\n",
              "    ' Jihad',\n",
              "    ',',\n",
              "    ' and',\n",
              "    ' groups',\n",
              "    ' such'],\n",
              "   'generated_probs': [0.48559629937151444,\n",
              "    0.833701695385339,\n",
              "    0.9352611592393922,\n",
              "    0.7376901156916998,\n",
              "    0.9955532203327885,\n",
              "    0.9976458373974598,\n",
              "    0.999499251176562,\n",
              "    0.9991744635428744,\n",
              "    0.9996724008523231,\n",
              "    0.9999363898832093,\n",
              "    0.9999658329887057,\n",
              "    0.9999163605479741,\n",
              "    0.9983174656506324,\n",
              "    0.9999411560633723,\n",
              "    0.9998689168221506,\n",
              "    0.9997755751870168],\n",
              "   'generated_text': ' Radical Islamist organizations like al-Qaeda and the Egyptian Islamic Jihad, and groups such',\n",
              "   'generated_tokens': [' Radical',\n",
              "    ' Islamist',\n",
              "    ' organizations',\n",
              "    ' like',\n",
              "    ' al',\n",
              "    '-',\n",
              "    'Qaeda',\n",
              "    ' and',\n",
              "    ' the',\n",
              "    ' Egyptian',\n",
              "    ' Islamic',\n",
              "    ' Jihad',\n",
              "    ',',\n",
              "    ' and',\n",
              "    ' groups',\n",
              "    ' such'],\n",
              "   'id': '572ff760b2c2fd140056867b',\n",
              "   'prediction': ' Radical Islamist organizations like al-Qaeda and the Egyptian Islamic Jihad, and groups such',\n",
              "   'prompt': 'Title: Islamism\\n\\nBackground: participate in democratic and political process as well as armed attacks, seeking to abolish the state of Israel. Radical Islamist organizations like al-Qaeda and the Egyptian Islamic Jihad, and groups such as the Taliban, entirely reject democracy, often declaring as \"kuffar\" those Muslims who support it (see \"takfirism\"), as well as calling for violent/offensive jihad or urging and conducting attacks on a religious basis. Another major division within Islamism is between what Graham E. Fuller has described as the fundamentalist \"guardians of the tradition\" (Salafis, such as those in the Wahhabi movement) and the \"vanguard of change and Islamic reform\"\\n\\nQ: On what basis do the radical Islamist organizations conduct their attacks?\\n\\nA:',\n",
              "   'question': 'On what basis do the radical Islamist organizations conduct their attacks?'},\n",
              "  {'answers': ['the early 1960s', 'early 1960s', '1960s'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' The Amazon rainforest was restricted before the era of human occupation.',\n",
              "   'generated_answer_probs': [0.7187365716261696,\n",
              "    0.9641697246055612,\n",
              "    0.9992673306333725,\n",
              "    0.999532688464065,\n",
              "    0.9493817839087123,\n",
              "    0.8688901598822382,\n",
              "    0.9892089160310408,\n",
              "    0.9862959690220224,\n",
              "    0.38042109312225064,\n",
              "    0.9820592150376479,\n",
              "    0.36477852149358425,\n",
              "    0.3388807172636941,\n",
              "    0.9854727704094033],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' Amazon',\n",
              "    ' rain',\n",
              "    'forest',\n",
              "    ' was',\n",
              "    ' restricted',\n",
              "    ' before',\n",
              "    ' the',\n",
              "    ' era',\n",
              "    ' of',\n",
              "    ' human',\n",
              "    ' occupation',\n",
              "    '.'],\n",
              "   'generated_probs': [0.7187365716261696,\n",
              "    0.9641697246055612,\n",
              "    0.9992673306333725,\n",
              "    0.999532688464065,\n",
              "    0.9493817839087123,\n",
              "    0.8688901598822382,\n",
              "    0.9892089160310408,\n",
              "    0.9862959690220224,\n",
              "    0.38042109312225064,\n",
              "    0.9820592150376479,\n",
              "    0.36477852149358425,\n",
              "    0.3388807172636941,\n",
              "    0.9854727704094033],\n",
              "   'generated_text': ' The Amazon rainforest was restricted before the era of human occupation.',\n",
              "   'generated_tokens': [' The',\n",
              "    ' Amazon',\n",
              "    ' rain',\n",
              "    'forest',\n",
              "    ' was',\n",
              "    ' restricted',\n",
              "    ' before',\n",
              "    ' the',\n",
              "    ' era',\n",
              "    ' of',\n",
              "    ' human',\n",
              "    ' occupation',\n",
              "    '.'],\n",
              "   'id': '5729fd56af94a219006aa730',\n",
              "   'prediction': ' The Amazon rainforest was restricted before the era of human occupation.',\n",
              "   'prompt': 'Title: Amazon rainforest\\n\\nBackground: during the last 34 million years have allowed savanna regions to expand into the tropics. During the Oligocene, for example, the rainforest spanned a relatively narrow band. It expanded again during the Middle Miocene, then retracted to a mostly inland formation at the last glacial maximum. However, the rainforest still managed to thrive during these glacial periods, allowing for the survival and evolution of a broad diversity of species. During the mid-Eocene, it is believed that the drainage basin of the Amazon was split along the middle of the continent by the Purus Arch. Water on the eastern side flowed\\n\\nQ: Acessing the Amazon rainforest was restricted before what era?\\n\\nA:',\n",
              "   'question': 'Acessing the Amazon rainforest was restricted before what era?'},\n",
              "  {'answers': ['63 days', '63', '63 days'],\n",
              "   'em': 1,\n",
              "   'f1': 1.0,\n",
              "   'generated_answer': ' 63 days',\n",
              "   'generated_answer_probs': [0.6868309272720369, 0.8695718020902863],\n",
              "   'generated_answer_tokens': [' 63', ' days'],\n",
              "   'generated_probs': [0.6868309272720369, 0.8695718020902863],\n",
              "   'generated_text': ' 63 days',\n",
              "   'generated_tokens': [' 63', ' days'],\n",
              "   'id': '57332e48d058e614000b5765',\n",
              "   'prediction': ' 63 days',\n",
              "   'prompt': 'Title: Warsaw\\n\\nBackground: to escape or hide. By July 1944, the Red Army was deep into Polish territory and pursuing the Germans toward Warsaw. Knowing that Stalin was hostile to the idea of an independent Poland, the Polish government-in-exile in London gave orders to the underground Home Army (AK) to try to seize control of Warsaw from the Germans before the Red Army arrived. Thus, on 1 August 1944, as the Red Army was nearing the city, the Warsaw Uprising began. The armed struggle, planned to last 48 hours, was partially successful, however it went on for 63 days. Eventually the Home Army\\n\\nQ: How many days did the Warsaw Uprising last?\\n\\nA:',\n",
              "   'question': 'How many days did the Warsaw Uprising last?'},\n",
              "  {'answers': ['Richard Dean Adams',\n",
              "    'Richard Dean Adams',\n",
              "    'Richard Dean Adams'],\n",
              "   'em': 0,\n",
              "   'f1': 0.3333333333333333,\n",
              "   'generated_answer': ' Edward Dean Adam.',\n",
              "   'generated_answer_probs': [0.42556401319184783,\n",
              "    0.9981997448068368,\n",
              "    0.947680890301694,\n",
              "    0.5310498726619725],\n",
              "   'generated_answer_tokens': [' Edward', ' Dean', ' Adam', '.'],\n",
              "   'generated_probs': [0.42556401319184783,\n",
              "    0.9981997448068368,\n",
              "    0.947680890301694,\n",
              "    0.5310498726619725],\n",
              "   'generated_text': ' Edward Dean Adam.',\n",
              "   'generated_tokens': [' Edward', ' Dean', ' Adam', '.'],\n",
              "   'id': '56e0812c231d4119001ac213',\n",
              "   'prediction': ' Edward Dean Adam.',\n",
              "   'prompt': 'Title: Niagara Falls Hydraulic Power and Manufacturing Company\\n\\nBackground: solved. On December 20, 1892, the Evershed tunnel and the Edward Dean Adam\\'s power house inlet canal are completed. Therefore, the \"Cataract Construction Company\" sponsored the \"International Niagara Commission\", which met in London in June 1890 and was headed by Lord Kelvin. The commissioners offered a $100,000 () prize for a solution to the problem. The commission received seventeen submissions from experts around the world only to reject them all. The schemes ranged from a system using pneumatic pressure to one requiring ropes, springs and pulleys. Some proposed transmitting direct current electricity, including one endorsed by Thomas Edison. On May\\n\\nQ: Who headed the Niagara Falls Cataract Construction Company in 1893?\\n\\nA:',\n",
              "   'question': 'Who headed the Niagara Falls Cataract Construction Company in 1893?'},\n",
              "  {'answers': ['flammable cabin and space suit materials',\n",
              "    'flammable cabin',\n",
              "    'flammable',\n",
              "    'flammable cabin and space suit materials',\n",
              "    'flammable cabin and space suit materials.'],\n",
              "   'em': 0,\n",
              "   'f1': 0.21052631578947367,\n",
              "   'generated_answer': ' All materials that could potentially create a hazardous fire were removed from the cabin. This',\n",
              "   'generated_answer_probs': [0.20265028896042567,\n",
              "    0.8148476383726717,\n",
              "    0.6780405056362131,\n",
              "    0.7736708145955373,\n",
              "    0.4407484387358726,\n",
              "    0.6698205622526524,\n",
              "    0.8836119529234502,\n",
              "    0.41116928649778317,\n",
              "    0.3524409459444523,\n",
              "    0.5177250599134641,\n",
              "    0.9823995575165877,\n",
              "    0.8326195698446088,\n",
              "    0.9730807786955843,\n",
              "    0.40134769802536824,\n",
              "    0.31202158839272276,\n",
              "    0.6690943081198909],\n",
              "   'generated_answer_tokens': [' All',\n",
              "    ' materials',\n",
              "    ' that',\n",
              "    ' could',\n",
              "    ' potentially',\n",
              "    ' create',\n",
              "    ' a',\n",
              "    ' hazardous',\n",
              "    ' fire',\n",
              "    ' were',\n",
              "    ' removed',\n",
              "    ' from',\n",
              "    ' the',\n",
              "    ' cabin',\n",
              "    '.',\n",
              "    ' This'],\n",
              "   'generated_probs': [0.20265028896042567,\n",
              "    0.8148476383726717,\n",
              "    0.6780405056362131,\n",
              "    0.7736708145955373,\n",
              "    0.4407484387358726,\n",
              "    0.6698205622526524,\n",
              "    0.8836119529234502,\n",
              "    0.41116928649778317,\n",
              "    0.3524409459444523,\n",
              "    0.5177250599134641,\n",
              "    0.9823995575165877,\n",
              "    0.8326195698446088,\n",
              "    0.9730807786955843,\n",
              "    0.40134769802536824,\n",
              "    0.31202158839272276,\n",
              "    0.6690943081198909],\n",
              "   'generated_text': ' All materials that could potentially create a hazardous fire were removed from the cabin. This',\n",
              "   'generated_tokens': [' All',\n",
              "    ' materials',\n",
              "    ' that',\n",
              "    ' could',\n",
              "    ' potentially',\n",
              "    ' create',\n",
              "    ' a',\n",
              "    ' hazardous',\n",
              "    ' fire',\n",
              "    ' were',\n",
              "    ' removed',\n",
              "    ' from',\n",
              "    ' the',\n",
              "    ' cabin',\n",
              "    '.',\n",
              "    ' This'],\n",
              "   'id': '5725de30ec44d21400f3d6ee',\n",
              "   'prediction': ' All materials that could potentially create a hazardous fire were removed from the cabin. This',\n",
              "   'prompt': 'Title: Writing in space\\n\\nBackground: more comfortable and more productive \"in shirtsleeves\". Paul C. Fisher of Fisher Pen Company recounts that pencils were \\'too dangerous to use in space.\\' Even before the Apollo 1 fire, the CM crew cabin was reviewed for hazardous materials such as paper, velcro, and even low-temperature plastics. A directive was issued but poorly enforced. When combined with high oxygen content, the Apollo 1 cabin burned within seconds, killing all three crew. Cosmonaut Anatoly Solovyev flew with Space Pens starting in the \\'80s and states \"pencil lead breaks...and is not good in space capsule; very dangerous to have metal lead particles\\n\\nQ: What type of materials inside the cabin were removed to help prevent more fire hazards in the future?\\n\\nA:',\n",
              "   'question': 'What type of materials inside the cabin were removed to help prevent more fire hazards in the future?'},\n",
              "  {'answers': ['Von Miller', 'Von Miller', 'Miller'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' Peyton Manning was given the esteemed status of MVP for Super Bowl 50.',\n",
              "   'generated_answer_probs': [0.9408765916113148,\n",
              "    0.999995041369894,\n",
              "    0.8130526755164974,\n",
              "    0.814910294416367,\n",
              "    0.9893113756827758,\n",
              "    0.796799739216764,\n",
              "    0.9978671502633272,\n",
              "    0.9988528960273333,\n",
              "    0.9997934582526842,\n",
              "    0.9993599531874037,\n",
              "    0.9998814340444986,\n",
              "    0.999931026778762,\n",
              "    0.9999975456765119,\n",
              "    0.998587714215523],\n",
              "   'generated_answer_tokens': [' Peyton',\n",
              "    ' Manning',\n",
              "    ' was',\n",
              "    ' given',\n",
              "    ' the',\n",
              "    ' esteemed',\n",
              "    ' status',\n",
              "    ' of',\n",
              "    ' MVP',\n",
              "    ' for',\n",
              "    ' Super',\n",
              "    ' Bowl',\n",
              "    ' 50',\n",
              "    '.'],\n",
              "   'generated_probs': [0.9408765916113148,\n",
              "    0.999995041369894,\n",
              "    0.8130526755164974,\n",
              "    0.814910294416367,\n",
              "    0.9893113756827758,\n",
              "    0.796799739216764,\n",
              "    0.9978671502633272,\n",
              "    0.9988528960273333,\n",
              "    0.9997934582526842,\n",
              "    0.9993599531874037,\n",
              "    0.9998814340444986,\n",
              "    0.999931026778762,\n",
              "    0.9999975456765119,\n",
              "    0.998587714215523],\n",
              "   'generated_text': ' Peyton Manning was given the esteemed status of MVP for Super Bowl 50.',\n",
              "   'generated_tokens': [' Peyton',\n",
              "    ' Manning',\n",
              "    ' was',\n",
              "    ' given',\n",
              "    ' the',\n",
              "    ' esteemed',\n",
              "    ' status',\n",
              "    ' of',\n",
              "    ' MVP',\n",
              "    ' for',\n",
              "    ' Super',\n",
              "    ' Bowl',\n",
              "    ' 50',\n",
              "    '.'],\n",
              "   'id': '56bf17653aeaaa14008c9511',\n",
              "   'prediction': ' Peyton Manning was given the esteemed status of MVP for Super Bowl 50.',\n",
              "   'prompt': \"Title: Super Bowl 50\\n\\nBackground: Bart Starr (MVP of Super Bowls I and II) and Chuck Howley (MVP of Super Bowl V) appeared via video. The late Harvey Martin, co-MVP of Super Bowl XII who died in 2001, was acknowledged when the other co-MVP of Super Bowl XII, Randy White, was introduced. Peyton Manning (MVP of Super Bowl XLI and the Broncos' starting quarterback for the game) was shown in the locker room preparing for the game. This ceremony continued a ten-year tradition (starting with Super Bowl XX and then repeated in Super Bowl XXX and Super Bowl XL) in which past Super Bowl MVPs\\n\\nQ: Who was given the esteemed status of MVP for Super Bowl 50?\\n\\nA:\",\n",
              "   'question': 'Who was given the esteemed status of MVP for Super Bowl 50?'},\n",
              "  {'answers': ['the University of Chicago College Bowl Team',\n",
              "    'University of Chicago College Bowl Team',\n",
              "    'University of Chicago College Bowl Team'],\n",
              "   'em': 0,\n",
              "   'f1': 0.25,\n",
              "   'generated_answer': ' The Chicago Cubs',\n",
              "   'generated_answer_probs': [0.9636870442246497,\n",
              "    0.586844382954551,\n",
              "    0.6691458035993645],\n",
              "   'generated_answer_tokens': [' The', ' Chicago', ' Cubs'],\n",
              "   'generated_probs': [0.9636870442246497,\n",
              "    0.586844382954551,\n",
              "    0.6691458035993645],\n",
              "   'generated_text': ' The Chicago Cubs',\n",
              "   'generated_tokens': [' The', ' Chicago', ' Cubs'],\n",
              "   'id': '5728659f4b864d190016498c',\n",
              "   'prediction': ' The Chicago Cubs',\n",
              "   'prompt': 'Title: History of baseball in the United States\\n\\nBackground: won seven championships, establishing themselves as the first true dynasty in the sport, although, the New York Mutuals were widely considered to be one of the best teams of the era as well. By the end of 1865, almost 100 clubs were members of the NABBP. By 1867, it ballooned to over 400 members, including some clubs from as far away as San Francisco and Louisiana. One of these clubs, the Chicago White Stockings, won the championship in 1870. Today known as the Chicago Cubs, they are the oldest team in American organized sports. Because of this growth, regional and\\n\\nQ: What club won 118 tournaments and 15 national championships?\\n\\nA:',\n",
              "   'question': 'What club won 118 tournaments and 15 national championships?'},\n",
              "  {'answers': ['city council', 'the city council', 'city council'],\n",
              "   'em': 0,\n",
              "   'f1': 0.1818181818181818,\n",
              "   'generated_answer': ' The NFL reimbursed the city of San Francisco for city services.',\n",
              "   'generated_answer_probs': [0.7948950067742832,\n",
              "    0.8632839459985845,\n",
              "    0.2521767622154564,\n",
              "    0.9996676913267624,\n",
              "    0.6952425371348244,\n",
              "    0.6932630571305544,\n",
              "    0.9258684472805381,\n",
              "    0.9995647552264993,\n",
              "    0.9997022040100308,\n",
              "    0.9257869651841651,\n",
              "    0.30977272362045105,\n",
              "    0.986593156159591,\n",
              "    0.46491278970769795],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' NFL',\n",
              "    ' reimb',\n",
              "    'ursed',\n",
              "    ' the',\n",
              "    ' city',\n",
              "    ' of',\n",
              "    ' San',\n",
              "    ' Francisco',\n",
              "    ' for',\n",
              "    ' city',\n",
              "    ' services',\n",
              "    '.'],\n",
              "   'generated_probs': [0.7948950067742832,\n",
              "    0.8632839459985845,\n",
              "    0.2521767622154564,\n",
              "    0.9996676913267624,\n",
              "    0.6952425371348244,\n",
              "    0.6932630571305544,\n",
              "    0.9258684472805381,\n",
              "    0.9995647552264993,\n",
              "    0.9997022040100308,\n",
              "    0.9257869651841651,\n",
              "    0.30977272362045105,\n",
              "    0.986593156159591,\n",
              "    0.46491278970769795],\n",
              "   'generated_text': ' The NFL reimbursed the city of San Francisco for city services.',\n",
              "   'generated_tokens': [' The',\n",
              "    ' NFL',\n",
              "    ' reimb',\n",
              "    'ursed',\n",
              "    ' the',\n",
              "    ' city',\n",
              "    ' of',\n",
              "    ' San',\n",
              "    ' Francisco',\n",
              "    ' for',\n",
              "    ' city',\n",
              "    ' services',\n",
              "    '.'],\n",
              "   'id': '56bf555e3aeaaa14008c95d5',\n",
              "   'prediction': ' The NFL reimbursed the city of San Francisco for city services.',\n",
              "   'prompt': 'Title: Super Bowl 50\\n\\nBackground: the festivities in San Francisco during Super Bowl Week. San Francisco mayor Ed Lee said of the highly visible homeless presence in this area \"they are going to have to leave\". San Francisco city supervisor Jane Kim unsuccessfully lobbied for the NFL to reimburse San Francisco for city services in the amount of $5\\xa0million. In addition, there are $2\\xa0million worth of other ancillary events, including a week-long event at the Santa Clara Convention Center, a beer, wine and food festival at Bellomy Field at Santa Clara University, and a pep rally. A professional fundraiser will aid in finding business sponsors\\n\\nQ: Which government entity helped to pay for the festivities, beyond businesses and individuals?\\n\\nA:',\n",
              "   'question': 'Which government entity helped to pay for the festivities, beyond businesses and individuals?'},\n",
              "  {'answers': ['each state', 'each state', 'each state'],\n",
              "   'em': 0,\n",
              "   'f1': 0.2666666666666667,\n",
              "   'generated_answer': ' Each state determines the requirements for getting a license to teach in public schools. Teaching',\n",
              "   'generated_answer_probs': [0.5376735969792928,\n",
              "    0.9979507765312744,\n",
              "    0.8303442127541641,\n",
              "    0.9901748106768734,\n",
              "    0.9957146319071571,\n",
              "    0.999077128967653,\n",
              "    0.9870922261821039,\n",
              "    0.9999577280454842,\n",
              "    0.9990736723066374,\n",
              "    0.9999664299534866,\n",
              "    0.9998969322718433,\n",
              "    0.9975043343644902,\n",
              "    0.999150681125622,\n",
              "    0.9989529129785883,\n",
              "    0.9963751748977542,\n",
              "    0.7495527752318619],\n",
              "   'generated_answer_tokens': [' Each',\n",
              "    ' state',\n",
              "    ' determines',\n",
              "    ' the',\n",
              "    ' requirements',\n",
              "    ' for',\n",
              "    ' getting',\n",
              "    ' a',\n",
              "    ' license',\n",
              "    ' to',\n",
              "    ' teach',\n",
              "    ' in',\n",
              "    ' public',\n",
              "    ' schools',\n",
              "    '.',\n",
              "    ' Teaching'],\n",
              "   'generated_probs': [0.5376735969792928,\n",
              "    0.9979507765312744,\n",
              "    0.8303442127541641,\n",
              "    0.9901748106768734,\n",
              "    0.9957146319071571,\n",
              "    0.999077128967653,\n",
              "    0.9870922261821039,\n",
              "    0.9999577280454842,\n",
              "    0.9990736723066374,\n",
              "    0.9999664299534866,\n",
              "    0.9998969322718433,\n",
              "    0.9975043343644902,\n",
              "    0.999150681125622,\n",
              "    0.9989529129785883,\n",
              "    0.9963751748977542,\n",
              "    0.7495527752318619],\n",
              "   'generated_text': ' Each state determines the requirements for getting a license to teach in public schools. Teaching',\n",
              "   'generated_tokens': [' Each',\n",
              "    ' state',\n",
              "    ' determines',\n",
              "    ' the',\n",
              "    ' requirements',\n",
              "    ' for',\n",
              "    ' getting',\n",
              "    ' a',\n",
              "    ' license',\n",
              "    ' to',\n",
              "    ' teach',\n",
              "    ' in',\n",
              "    ' public',\n",
              "    ' schools',\n",
              "    '.',\n",
              "    ' Teaching'],\n",
              "   'id': '56e7796637bdd419002c3ffd',\n",
              "   'prediction': ' Each state determines the requirements for getting a license to teach in public schools. Teaching',\n",
              "   'prompt': \"Title: Teacher\\n\\nBackground: younger than in previous years. A growing cause of concern are that attacks on teachers in Welsh schools which reached an all-time high between 2005 and 2010. In the United States, each state determines the requirements for getting a license to teach in public schools. Teaching certification generally lasts three years, but teachers can receive certificates that last as long as ten years. Public school teachers are required to have a bachelor's degree and the majority must be certified by the state in which they teach. Many charter schools do not require that their teachers be certified, provided they meet\\n\\nQ: In the US, who decides on the requirements for teachers?\\n\\nA:\",\n",
              "   'question': 'In the US, who decides on the requirements for teachers?'},\n",
              "  {'answers': ['Metropolitan Statistical Areas',\n",
              "    'Metropolitan Statistical Areas',\n",
              "    'Metropolitan Statistical Areas'],\n",
              "   'em': 0,\n",
              "   'f1': 0.125,\n",
              "   'generated_answer': ' Southern California is the name given to the eight areas that make up a part of',\n",
              "   'generated_answer_probs': [0.5735385648202714,\n",
              "    0.9993252646763254,\n",
              "    0.675805179825427,\n",
              "    0.2922786064295618,\n",
              "    0.8662267575059055,\n",
              "    0.4375858341871124,\n",
              "    0.9995667827656965,\n",
              "    0.9605768188417152,\n",
              "    0.9254027600181646,\n",
              "    0.920164923804694,\n",
              "    0.9671105639416875,\n",
              "    0.9902564084039158,\n",
              "    0.9998614076748037,\n",
              "    0.9617775404419185,\n",
              "    0.9955784941658656,\n",
              "    0.998643504472925],\n",
              "   'generated_answer_tokens': [' Southern',\n",
              "    ' California',\n",
              "    ' is',\n",
              "    ' the',\n",
              "    ' name',\n",
              "    ' given',\n",
              "    ' to',\n",
              "    ' the',\n",
              "    ' eight',\n",
              "    ' areas',\n",
              "    ' that',\n",
              "    ' make',\n",
              "    ' up',\n",
              "    ' a',\n",
              "    ' part',\n",
              "    ' of'],\n",
              "   'generated_probs': [0.5735385648202714,\n",
              "    0.9993252646763254,\n",
              "    0.675805179825427,\n",
              "    0.2922786064295618,\n",
              "    0.8662267575059055,\n",
              "    0.4375858341871124,\n",
              "    0.9995667827656965,\n",
              "    0.9605768188417152,\n",
              "    0.9254027600181646,\n",
              "    0.920164923804694,\n",
              "    0.9671105639416875,\n",
              "    0.9902564084039158,\n",
              "    0.9998614076748037,\n",
              "    0.9617775404419185,\n",
              "    0.9955784941658656,\n",
              "    0.998643504472925],\n",
              "   'generated_text': ' Southern California is the name given to the eight areas that make up a part of',\n",
              "   'generated_tokens': [' Southern',\n",
              "    ' California',\n",
              "    ' is',\n",
              "    ' the',\n",
              "    ' name',\n",
              "    ' given',\n",
              "    ' to',\n",
              "    ' the',\n",
              "    ' eight',\n",
              "    ' areas',\n",
              "    ' that',\n",
              "    ' make',\n",
              "    ' up',\n",
              "    ' a',\n",
              "    ' part',\n",
              "    ' of'],\n",
              "   'id': '5706074552bb8914006897d4',\n",
              "   'prediction': ' Southern California is the name given to the eight areas that make up a part of',\n",
              "   'prompt': \"Title: Southern California\\n\\nBackground: area form the Southern Border Region. North of Greater Los Angeles are the Santa Barbara, San Luis Obispo, and Bakersfield metropolitan areas. Los Angeles (at 3.7 million people) and San Diego (at 1.3 million people) are the two largest cities in all of California and are in the top eight largest cities in the United States. In Southern California, there are also 12 cities with more than 200,000 residents and 34 cities over 100,000 residents. Many of Southern California's most developed cities lie along or in close proximity to the coast, with the exception of San Bernardino and Riverside.\\n\\nQ: What is the name associated with the eight areas that make up a part of southern California?\\n\\nA:\",\n",
              "   'question': 'What is the name associated with the eight areas that make up a part of southern California?'},\n",
              "  {'answers': ['DIC Entertainment', 'DIC Entertainment', 'DIC Entertainment'],\n",
              "   'em': 1,\n",
              "   'f1': 1.0,\n",
              "   'generated_answer': ' DIC Entertainment.',\n",
              "   'generated_answer_probs': [0.917377144932508,\n",
              "    0.9972547070277389,\n",
              "    0.9998432878206366,\n",
              "    0.8306576687205055],\n",
              "   'generated_answer_tokens': [' D', 'IC', ' Entertainment', '.'],\n",
              "   'generated_probs': [0.917377144932508,\n",
              "    0.9972547070277389,\n",
              "    0.9998432878206366,\n",
              "    0.8306576687205055],\n",
              "   'generated_text': ' DIC Entertainment.',\n",
              "   'generated_tokens': [' D', 'IC', ' Entertainment', '.'],\n",
              "   'id': '57275cb3f1498d1400e8f6db',\n",
              "   'prediction': ' DIC Entertainment.',\n",
              "   'prompt': \"Title: American Broadcasting Company\\n\\nBackground: coming out of series star Ellen DeGeneres (as well as her character in the series) as a lesbian. In 1993, the FCC repealed the Financial Interest and Syndication Rules, once again allowing networks to hold interests in television production studios. That same year, Capital Cities/ABC purchased the French animation studio DIC Entertainment; it also signed an agreement with Time Warner Cable to carry its owned-and-operated television stations on the provider's systems in ABC O&O markets. By that year, ABC had a total viewership share of 23.63% of American households, just below the limit of 25% imposed by the FCC. Daniel\\n\\nQ: What French animation studio did ABC purchase in 1993?\\n\\nA:\",\n",
              "   'question': 'What French animation studio did ABC purchase in 1993?'},\n",
              "  {'answers': ['friendly and supportive',\n",
              "    'friendly and supportive',\n",
              "    'friendly and supportive'],\n",
              "   'em': 0,\n",
              "   'f1': 0.35294117647058826,\n",
              "   'generated_answer': ' Students show more interest in classes taught by teachers who are friendly and supportive.',\n",
              "   'generated_answer_probs': [0.754934317655732,\n",
              "    0.8832822239704567,\n",
              "    0.9953194480833921,\n",
              "    0.9998649834555542,\n",
              "    0.9996446844395305,\n",
              "    0.9840822451039365,\n",
              "    0.9990615730981928,\n",
              "    0.99999813984753,\n",
              "    0.5549290950854863,\n",
              "    0.7181377901924021,\n",
              "    0.9782539989881462,\n",
              "    0.6392461292320493,\n",
              "    0.9906837160010535,\n",
              "    0.9983689638875086,\n",
              "    0.7538437353495028],\n",
              "   'generated_answer_tokens': [' Students',\n",
              "    ' show',\n",
              "    ' more',\n",
              "    ' interest',\n",
              "    ' in',\n",
              "    ' classes',\n",
              "    ' taught',\n",
              "    ' by',\n",
              "    ' teachers',\n",
              "    ' who',\n",
              "    ' are',\n",
              "    ' friendly',\n",
              "    ' and',\n",
              "    ' supportive',\n",
              "    '.'],\n",
              "   'generated_probs': [0.754934317655732,\n",
              "    0.8832822239704567,\n",
              "    0.9953194480833921,\n",
              "    0.9998649834555542,\n",
              "    0.9996446844395305,\n",
              "    0.9840822451039365,\n",
              "    0.9990615730981928,\n",
              "    0.99999813984753,\n",
              "    0.5549290950854863,\n",
              "    0.7181377901924021,\n",
              "    0.9782539989881462,\n",
              "    0.6392461292320493,\n",
              "    0.9906837160010535,\n",
              "    0.9983689638875086,\n",
              "    0.7538437353495028],\n",
              "   'generated_text': ' Students show more interest in classes taught by teachers who are friendly and supportive.',\n",
              "   'generated_tokens': [' Students',\n",
              "    ' show',\n",
              "    ' more',\n",
              "    ' interest',\n",
              "    ' in',\n",
              "    ' classes',\n",
              "    ' taught',\n",
              "    ' by',\n",
              "    ' teachers',\n",
              "    ' who',\n",
              "    ' are',\n",
              "    ' friendly',\n",
              "    ' and',\n",
              "    ' supportive',\n",
              "    '.'],\n",
              "   'id': '56e765ba00c9c71400d770a2',\n",
              "   'prediction': ' Students show more interest in classes taught by teachers who are friendly and supportive.',\n",
              "   'prompt': 'Title: Teacher\\n\\nBackground: receive this positive influence show stronger self-confidence and greater personal and academic success than those without these teacher interactions. Students are likely to build stronger relations with teachers who are friendly and supportive and will show more interest in courses taught by these teachers. Teachers that spend more time interacting and working directly with students are perceived as supportive and effective teachers. Effective teachers have been shown to invite student participation and decision making, allow humor into their classroom, and demonstrate a willingness to play. The way a teacher promotes the course they are teaching, the more the student will\\n\\nQ: Students show more interest in classes taught by what type of teachers?\\n\\nA:',\n",
              "   'question': 'Students show more interest in classes taught by what type of teachers?'},\n",
              "  {'answers': ['Super Bowl XLVII', 'Super Bowl XLVII', 'XLVII'],\n",
              "   'em': 1,\n",
              "   'f1': 1.0,\n",
              "   'generated_answer': ' Super Bowl XLVII',\n",
              "   'generated_answer_probs': [0.6495387132187261,\n",
              "    0.9993642447780462,\n",
              "    0.9995258920746981,\n",
              "    0.998934375581382],\n",
              "   'generated_answer_tokens': [' Super', ' Bowl', ' XL', 'VII'],\n",
              "   'generated_probs': [0.6495387132187261,\n",
              "    0.9993642447780462,\n",
              "    0.9995258920746981,\n",
              "    0.998934375581382],\n",
              "   'generated_text': ' Super Bowl XLVII',\n",
              "   'generated_tokens': [' Super', ' Bowl', ' XL', 'VII'],\n",
              "   'id': '56be5333acb8001400a5030e',\n",
              "   'prediction': ' Super Bowl XLVII',\n",
              "   'prompt': \"Title: Super Bowl XLVII halftime show\\n\\nBackground: Super Bowl XLVII halftime show The Super Bowl XLVII halftime show occurred on February 3, 2013 at the Mercedes-Benz Superdome in New Orleans as part of Super Bowl XLVII and featured American entertainer Beyoncé with special guests Kelly Rowland and Michelle Williams from Destiny's Child. The show was produced by Ricky Kirshner and directed by Hamish Hamilton. It received acclaim from music critics who commented that Knowles once more proved her abilities during live performances. It became the then second most watched show in Super Bowl history by garnering 110.8 million viewers. The performance, and the stadium blackout that followed,\\n\\nQ: At which Super Bowl did Beyonce headline the halftime show?\\n\\nA:\",\n",
              "   'question': 'At which Super Bowl did Beyonce headline the halftime show?'},\n",
              "  {'answers': ['his last statement', 'his last statement', 'last statement'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' After translating the New Testament, Luther also began to write theological works. These include',\n",
              "   'generated_answer_probs': [0.240472918684285,\n",
              "    0.8858181976130548,\n",
              "    0.9924894769959213,\n",
              "    0.9734029957236909,\n",
              "    0.9999077792025992,\n",
              "    0.5831287363157408,\n",
              "    0.9352705717550625,\n",
              "    0.46746247539952757,\n",
              "    0.7140028678885423,\n",
              "    0.7063697877008013,\n",
              "    0.833750443348601,\n",
              "    0.24004124889796133,\n",
              "    0.6270641192632678,\n",
              "    0.28748384834282487,\n",
              "    0.2381625155246074,\n",
              "    0.5382161519953633],\n",
              "   'generated_answer_tokens': [' After',\n",
              "    ' translating',\n",
              "    ' the',\n",
              "    ' New',\n",
              "    ' Testament',\n",
              "    ',',\n",
              "    ' Luther',\n",
              "    ' also',\n",
              "    ' began',\n",
              "    ' to',\n",
              "    ' write',\n",
              "    ' theological',\n",
              "    ' works',\n",
              "    '.',\n",
              "    ' These',\n",
              "    ' include'],\n",
              "   'generated_probs': [0.240472918684285,\n",
              "    0.8858181976130548,\n",
              "    0.9924894769959213,\n",
              "    0.9734029957236909,\n",
              "    0.9999077792025992,\n",
              "    0.5831287363157408,\n",
              "    0.9352705717550625,\n",
              "    0.46746247539952757,\n",
              "    0.7140028678885423,\n",
              "    0.7063697877008013,\n",
              "    0.833750443348601,\n",
              "    0.24004124889796133,\n",
              "    0.6270641192632678,\n",
              "    0.28748384834282487,\n",
              "    0.2381625155246074,\n",
              "    0.5382161519953633],\n",
              "   'generated_text': ' After translating the New Testament, Luther also began to write theological works. These include',\n",
              "   'generated_tokens': [' After',\n",
              "    ' translating',\n",
              "    ' the',\n",
              "    ' New',\n",
              "    ' Testament',\n",
              "    ',',\n",
              "    ' Luther',\n",
              "    ' also',\n",
              "    ' began',\n",
              "    ' to',\n",
              "    ' write',\n",
              "    ' theological',\n",
              "    ' works',\n",
              "    '.',\n",
              "    ' These',\n",
              "    ' include'],\n",
              "   'id': '56f8ca289b226e1400dd1007',\n",
              "   'prediction': ' After translating the New Testament, Luther also began to write theological works. These include',\n",
              "   'prompt': \"Title: Luther Bible\\n\\nBackground: Luther Bible The Luther Bible is a German language Bible translation from Hebrew and ancient Greek by Martin Luther. The New Testament was first published in 1522 and the complete Bible, containing the Old and New Testaments and Apocrypha, in 1534. The project absorbed Luther's later years. Thanks to the then recently invented printing press, the result was widely disseminated and contributed significantly to the development of today's modern High German language. While he was sequestered in the Wartburg Castle (1521–22) Luther began to translate the New Testament from Koine Greek into German in order to make it more accessible\\n\\nQ: What was later discovered written by Luther?\\n\\nA:\",\n",
              "   'question': 'What was later discovered written by Luther?'},\n",
              "  {'answers': ['tear huge areas of land into the sea.',\n",
              "    'tidal currents',\n",
              "    'tear huge areas of land into the sea'],\n",
              "   'em': 0,\n",
              "   'f1': 0.7058823529411764,\n",
              "   'generated_answer': ' A high tide risks tearing huge areas of land into the sea.',\n",
              "   'generated_answer_probs': [0.6307223935981572,\n",
              "    0.9977964601662976,\n",
              "    0.9996882552225045,\n",
              "    0.4666360786243879,\n",
              "    0.2323545827890687,\n",
              "    0.5723669913878201,\n",
              "    0.9970164673061304,\n",
              "    0.9995330440378868,\n",
              "    0.9995754831327948,\n",
              "    0.9975777659547659,\n",
              "    0.9999737014648126,\n",
              "    0.9958219796139106,\n",
              "    0.5861297485533504],\n",
              "   'generated_answer_tokens': [' A',\n",
              "    ' high',\n",
              "    ' tide',\n",
              "    ' risks',\n",
              "    ' tearing',\n",
              "    ' huge',\n",
              "    ' areas',\n",
              "    ' of',\n",
              "    ' land',\n",
              "    ' into',\n",
              "    ' the',\n",
              "    ' sea',\n",
              "    '.'],\n",
              "   'generated_probs': [0.6307223935981572,\n",
              "    0.9977964601662976,\n",
              "    0.9996882552225045,\n",
              "    0.4666360786243879,\n",
              "    0.2323545827890687,\n",
              "    0.5723669913878201,\n",
              "    0.9970164673061304,\n",
              "    0.9995330440378868,\n",
              "    0.9995754831327948,\n",
              "    0.9975777659547659,\n",
              "    0.9999737014648126,\n",
              "    0.9958219796139106,\n",
              "    0.5861297485533504],\n",
              "   'generated_text': ' A high tide risks tearing huge areas of land into the sea.',\n",
              "   'generated_tokens': [' A',\n",
              "    ' high',\n",
              "    ' tide',\n",
              "    ' risks',\n",
              "    ' tearing',\n",
              "    ' huge',\n",
              "    ' areas',\n",
              "    ' of',\n",
              "    ' land',\n",
              "    ' into',\n",
              "    ' the',\n",
              "    ' sea',\n",
              "    '.'],\n",
              "   'id': '572ff935b2c2fd140056869d',\n",
              "   'prediction': ' A high tide risks tearing huge areas of land into the sea.',\n",
              "   'prompt': 'Title: Rhine\\n\\nBackground: sedimentation of the rivers, but also by tidal currents. This meant that high tide formed a serious risk because strong tidal currents could tear huge areas of land into the sea. Before the construction of the Delta Works, tidal influence was palpable up to Nijmegen, and even today, after the regulatory action of the Delta Works, the tide acts far inland. At the Waal, for example, the most landward tidal influence can be detected between Brakel and Zaltbommel. The Rhine flows from the Alps to the North Sea Basin; the geography and geology of its present-day watershed has been developing,\\n\\nQ: What does a high tide risk near lands? \\n\\nA:',\n",
              "   'question': 'What does a high tide risk near lands? '},\n",
              "  {'answers': ['differences in value added by labor, capital and land',\n",
              "    'differences in value added by labor, capital and land',\n",
              "    'differences in value added by different classifications of workers'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': '\\n\\nThere is no one answer to this question as income inequality can be attributed',\n",
              "   'generated_answer_probs': [0.19556890625389164,\n",
              "    0.9989461796590663,\n",
              "    0.8171171777400541,\n",
              "    0.7752933772274623,\n",
              "    0.9511211978715733,\n",
              "    0.6456388869673512,\n",
              "    0.5039754108988721,\n",
              "    0.9638427953817054,\n",
              "    0.9976272407540264,\n",
              "    0.99990217599508,\n",
              "    0.7329563343616483,\n",
              "    0.5138741077925486,\n",
              "    0.999619292987313,\n",
              "    0.6797677046384931,\n",
              "    0.9879902338997258,\n",
              "    0.9827192754699777],\n",
              "   'generated_answer_tokens': ['\\n',\n",
              "    '\\n',\n",
              "    'There',\n",
              "    ' is',\n",
              "    ' no',\n",
              "    ' one',\n",
              "    ' answer',\n",
              "    ' to',\n",
              "    ' this',\n",
              "    ' question',\n",
              "    ' as',\n",
              "    ' income',\n",
              "    ' inequality',\n",
              "    ' can',\n",
              "    ' be',\n",
              "    ' attributed'],\n",
              "   'generated_probs': [0.19556890625389164,\n",
              "    0.9989461796590663,\n",
              "    0.8171171777400541,\n",
              "    0.7752933772274623,\n",
              "    0.9511211978715733,\n",
              "    0.6456388869673512,\n",
              "    0.5039754108988721,\n",
              "    0.9638427953817054,\n",
              "    0.9976272407540264,\n",
              "    0.99990217599508,\n",
              "    0.7329563343616483,\n",
              "    0.5138741077925486,\n",
              "    0.999619292987313,\n",
              "    0.6797677046384931,\n",
              "    0.9879902338997258,\n",
              "    0.9827192754699777],\n",
              "   'generated_text': '\\n\\nThere is no one answer to this question as income inequality can be attributed',\n",
              "   'generated_tokens': ['\\n',\n",
              "    '\\n',\n",
              "    'There',\n",
              "    ' is',\n",
              "    ' no',\n",
              "    ' one',\n",
              "    ' answer',\n",
              "    ' to',\n",
              "    ' this',\n",
              "    ' question',\n",
              "    ' as',\n",
              "    ' income',\n",
              "    ' inequality',\n",
              "    ' can',\n",
              "    ' be',\n",
              "    ' attributed'],\n",
              "   'id': '5727e9523acd2414000def96',\n",
              "   'prediction': '\\n\\nThere is no one answer to this question as income inequality can be attributed',\n",
              "   'prompt': 'Title: Causes of income inequality in the United States\\n\\nBackground: elevated the financial interests of business owners and stockholders above the well-being, financial or otherwise, or ordinary citizens.\" So overall, while cutting capital gains taxes adversely affects income inequality, its economic benefits are debatable. Rising inequality has also been attributed to President Bush\\'s veto of tax harmonization, as this would have prohibited offshore tax havens. One study found reductions of total effective tax rates were most significant for individuals with highest incomes. (see \"Federal Tax Rate by Income Group\" chart) For those with incomes in the top 0.01 percent, overall rates of Federal tax fell from 74.6% in 1970, to\\n\\nQ: What is income inequality attributed to?\\n\\nA:',\n",
              "   'question': 'What is income inequality attributed to?'},\n",
              "  {'answers': ['the Calvin cycle', 'Calvin cycle', 'Calvin cycle'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' The process of turning CO2 into organic molecules is called photosynthesis.',\n",
              "   'generated_answer_probs': [0.70191257482364,\n",
              "    0.9961318068085823,\n",
              "    0.9913406178064487,\n",
              "    0.9830735054278831,\n",
              "    0.9972040431882392,\n",
              "    0.9998492482641851,\n",
              "    0.9998676056948996,\n",
              "    0.9995928268774844,\n",
              "    0.999946284557726,\n",
              "    0.9989673373634195,\n",
              "    0.9882541059949091,\n",
              "    0.43214538845839057,\n",
              "    0.9999921813175661,\n",
              "    0.9946003742695412],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' process',\n",
              "    ' of',\n",
              "    ' turning',\n",
              "    ' CO',\n",
              "    '2',\n",
              "    ' into',\n",
              "    ' organic',\n",
              "    ' molecules',\n",
              "    ' is',\n",
              "    ' called',\n",
              "    ' photos',\n",
              "    'ynthesis',\n",
              "    '.'],\n",
              "   'generated_probs': [0.70191257482364,\n",
              "    0.9961318068085823,\n",
              "    0.9913406178064487,\n",
              "    0.9830735054278831,\n",
              "    0.9972040431882392,\n",
              "    0.9998492482641851,\n",
              "    0.9998676056948996,\n",
              "    0.9995928268774844,\n",
              "    0.999946284557726,\n",
              "    0.9989673373634195,\n",
              "    0.9882541059949091,\n",
              "    0.43214538845839057,\n",
              "    0.9999921813175661,\n",
              "    0.9946003742695412],\n",
              "   'generated_text': ' The process of turning CO2 into organic molecules is called photosynthesis.',\n",
              "   'generated_tokens': [' The',\n",
              "    ' process',\n",
              "    ' of',\n",
              "    ' turning',\n",
              "    ' CO',\n",
              "    '2',\n",
              "    ' into',\n",
              "    ' organic',\n",
              "    ' molecules',\n",
              "    ' is',\n",
              "    ' called',\n",
              "    ' photos',\n",
              "    'ynthesis',\n",
              "    '.'],\n",
              "   'id': '572953013f37b31900478250',\n",
              "   'prediction': ' The process of turning CO2 into organic molecules is called photosynthesis.',\n",
              "   'prompt': 'Title: Metabolism\\n\\nBackground: be fixed by the Calvin\\xa0– Benson cycle, a reversed citric acid cycle, or the carboxylation of acetyl-CoA. Prokaryotic chemoautotrophs also fix CO through the Calvin\\xa0– Benson cycle, but use energy from inorganic compounds to drive the reaction. In carbohydrate anabolism, simple organic acids can be converted into monosaccharides such as glucose and then used to assemble polysaccharides such as starch. The generation of glucose from compounds like pyruvate, lactate, glycerol, glycerate 3-phosphate and amino acids is called gluconeogenesis. Gluconeogenesis converts pyruvate to glucose-6-phosphate through a series of intermediates, many of which are shared with glycolysis. However, this pathway is not\\n\\nQ: What is the process of turning CO2 into organic molecules called?\\n\\nA:',\n",
              "   'question': 'What is the process of turning CO2 into organic molecules called?'},\n",
              "  {'answers': ['igneous, sedimentary, and metamorphic',\n",
              "    'igneous, sedimentary, and metamorphic',\n",
              "    'igneous, sedimentary, and metamorphic',\n",
              "    'igneous, sedimentary, and metamorphic'],\n",
              "   'em': 1,\n",
              "   'f1': 1.0,\n",
              "   'generated_answer': ' igneous, sedimentary, and metamorphic.',\n",
              "   'generated_answer_probs': [0.6990983399639914,\n",
              "    0.9999999317236823,\n",
              "    0.9882521383829429,\n",
              "    0.9999640449263991,\n",
              "    0.99999813984753,\n",
              "    0.9993694312920622,\n",
              "    0.9911431490421582,\n",
              "    0.9998506785695547,\n",
              "    0.9999977840931551,\n",
              "    0.9999889608319321,\n",
              "    0.9514658914733658],\n",
              "   'generated_answer_tokens': [' ign',\n",
              "    'eous',\n",
              "    ',',\n",
              "    ' sediment',\n",
              "    'ary',\n",
              "    ',',\n",
              "    ' and',\n",
              "    ' met',\n",
              "    'amorph',\n",
              "    'ic',\n",
              "    '.'],\n",
              "   'generated_probs': [0.6990983399639914,\n",
              "    0.9999999317236823,\n",
              "    0.9882521383829429,\n",
              "    0.9999640449263991,\n",
              "    0.99999813984753,\n",
              "    0.9993694312920622,\n",
              "    0.9911431490421582,\n",
              "    0.9998506785695547,\n",
              "    0.9999977840931551,\n",
              "    0.9999889608319321,\n",
              "    0.9514658914733658],\n",
              "   'generated_text': ' igneous, sedimentary, and metamorphic.',\n",
              "   'generated_tokens': [' ign',\n",
              "    'eous',\n",
              "    ',',\n",
              "    ' sediment',\n",
              "    'ary',\n",
              "    ',',\n",
              "    ' and',\n",
              "    ' met',\n",
              "    'amorph',\n",
              "    'ic',\n",
              "    '.'],\n",
              "   'id': '572657d9dd62a815002e8233',\n",
              "   'prediction': ' igneous, sedimentary, and metamorphic.',\n",
              "   'prompt': 'Title: Geology\\n\\nBackground: exploitation, evaluating water resources, understanding of natural hazards, the remediation of environmental problems, and for providing insights into past climate change. Geology also plays a role in geotechnical engineering and is a major academic discipline. The majority of geological data comes from research on solid Earth materials. These typically fall into one of two categories: rock and unconsolidated material. There are three major types of rock: igneous, sedimentary, and metamorphic. The rock cycle is an important concept in geology which illustrates the relationships between these three types of rock, and magma. When a rock crystallizes from melt (magma and/or lava),\\n\\nQ: What are the three major types of rock? \\n\\nA:',\n",
              "   'question': 'What are the three major types of rock? '},\n",
              "  {'answers': ['optimisation of a drug treatment for an individual',\n",
              "    'optimisation of a drug treatment',\n",
              "    'optimisation of a drug treatment for an individual'],\n",
              "   'em': 0,\n",
              "   'f1': 0.5333333333333333,\n",
              "   'generated_answer': ' Pharmacists are important for optimising drug treatment for an individual.',\n",
              "   'generated_answer_probs': [0.8672642690963535,\n",
              "    0.9967807871133141,\n",
              "    0.9197568659568509,\n",
              "    0.958992039468692,\n",
              "    0.9808796381122432,\n",
              "    0.48178226469092916,\n",
              "    0.8078578614360743,\n",
              "    0.60490747290168,\n",
              "    0.9079972763498911,\n",
              "    0.9957127244184639,\n",
              "    0.915529932640581,\n",
              "    0.9999274507718225,\n",
              "    0.9791859135495371],\n",
              "   'generated_answer_tokens': [' Pharm',\n",
              "    'acists',\n",
              "    ' are',\n",
              "    ' important',\n",
              "    ' for',\n",
              "    ' optim',\n",
              "    'ising',\n",
              "    ' drug',\n",
              "    ' treatment',\n",
              "    ' for',\n",
              "    ' an',\n",
              "    ' individual',\n",
              "    '.'],\n",
              "   'generated_probs': [0.8672642690963535,\n",
              "    0.9967807871133141,\n",
              "    0.9197568659568509,\n",
              "    0.958992039468692,\n",
              "    0.9808796381122432,\n",
              "    0.48178226469092916,\n",
              "    0.8078578614360743,\n",
              "    0.60490747290168,\n",
              "    0.9079972763498911,\n",
              "    0.9957127244184639,\n",
              "    0.915529932640581,\n",
              "    0.9999274507718225,\n",
              "    0.9791859135495371],\n",
              "   'generated_text': ' Pharmacists are important for optimising drug treatment for an individual.',\n",
              "   'generated_tokens': [' Pharm',\n",
              "    'acists',\n",
              "    ' are',\n",
              "    ' important',\n",
              "    ' for',\n",
              "    ' optim',\n",
              "    'ising',\n",
              "    ' drug',\n",
              "    ' treatment',\n",
              "    ' for',\n",
              "    ' an',\n",
              "    ' individual',\n",
              "    '.'],\n",
              "   'id': '5726d9935951b619008f7fef',\n",
              "   'prediction': ' Pharmacists are important for optimising drug treatment for an individual.',\n",
              "   'prompt': 'Title: Pharmacy\\n\\nBackground: play an important role in optimisation of a drug treatment for an individual. Pharmacists are represented internationally by the International Pharmaceutical Federation (FIP). They are represented at the national level by professional organisations such as the Royal Pharmaceutical Society in the UK, the Pharmaceutical Society of Australia (PSA), the Canadian Pharmacists Association (CPhA),the Pakistan Pharmacists Association (PPA), and the American Pharmacists Association (APhA), \"See also: List of pharmacy associations.\" In some cases, the representative body is also the registering body, which is responsible for the regulation and ethics of the profession. In the United States, specializations in pharmacy practice recognized\\n\\nQ: What type of treatment are pharmacists important for?\\n\\nA:',\n",
              "   'question': 'What type of treatment are pharmacists important for?'},\n",
              "  {'answers': ['a yellow chlorophyll precursor',\n",
              "    'yellow chlorophyll precursor',\n",
              "    'yellow chlorophyll precursor'],\n",
              "   'em': 0,\n",
              "   'f1': 0.6666666666666666,\n",
              "   'generated_answer': ' Etioplasts have a yellow chlorophyll precursor stocked.',\n",
              "   'generated_answer_probs': [0.5869530179036903,\n",
              "    0.9999958767602006,\n",
              "    0.9900110770269359,\n",
              "    0.9999958767602006,\n",
              "    0.6325067920621098,\n",
              "    0.9949285600957025,\n",
              "    0.999118910887165,\n",
              "    0.9995850205078178,\n",
              "    0.999931740099813,\n",
              "    0.9999995722265915,\n",
              "    0.9995075962705274,\n",
              "    0.8986807629193074,\n",
              "    0.9587461096886613],\n",
              "   'generated_answer_tokens': [' Et',\n",
              "    'iop',\n",
              "    'l',\n",
              "    'asts',\n",
              "    ' have',\n",
              "    ' a',\n",
              "    ' yellow',\n",
              "    ' chlor',\n",
              "    'ophy',\n",
              "    'll',\n",
              "    ' precursor',\n",
              "    ' stocked',\n",
              "    '.'],\n",
              "   'generated_probs': [0.5869530179036903,\n",
              "    0.9999958767602006,\n",
              "    0.9900110770269359,\n",
              "    0.9999958767602006,\n",
              "    0.6325067920621098,\n",
              "    0.9949285600957025,\n",
              "    0.999118910887165,\n",
              "    0.9995850205078178,\n",
              "    0.999931740099813,\n",
              "    0.9999995722265915,\n",
              "    0.9995075962705274,\n",
              "    0.8986807629193074,\n",
              "    0.9587461096886613],\n",
              "   'generated_text': ' Etioplasts have a yellow chlorophyll precursor stocked.',\n",
              "   'generated_tokens': [' Et',\n",
              "    'iop',\n",
              "    'l',\n",
              "    'asts',\n",
              "    ' have',\n",
              "    ' a',\n",
              "    ' yellow',\n",
              "    ' chlor',\n",
              "    'ophy',\n",
              "    'll',\n",
              "    ' precursor',\n",
              "    ' stocked',\n",
              "    '.'],\n",
              "   'id': '5729779b6aef051400154f65',\n",
              "   'prediction': ' Etioplasts have a yellow chlorophyll precursor stocked.',\n",
              "   'prompt': 'Title: Chloroplast\\n\\nBackground: the leaf matures, if exposed to the required light. This process involves invaginations of the inner plastid membrane, forming sheets of membrane that project into the internal stroma. These membrane sheets then fold to form thylakoids and grana. If angiosperm shoots are not exposed to the required light for chloroplast formation, proplastids may develop into an etioplast stage before becoming chloroplasts. An etioplast is a plastid that lacks chlorophyll, and has inner membrane invaginations that form a lattice of tubes in their stroma, called a prolamellar body. While etioplasts lack chlorophyll, they have a yellow chlorophyll precursor stocked. Within a\\n\\nQ: What do etioplasts have instead of chlorophyll?\\n\\nA:',\n",
              "   'question': 'What do etioplasts have instead of chlorophyll?'},\n",
              "  {'answers': ['Telenet was incorporated in 1973 and started operations in 1975. It went public in 1979 and was then sold to GTE',\n",
              "    'GTE',\n",
              "    'GTE'],\n",
              "   'em': 1,\n",
              "   'f1': 1.0,\n",
              "   'generated_answer': ' GTE',\n",
              "   'generated_answer_probs': [0.9935760090256658, 0.9999951615107056],\n",
              "   'generated_answer_tokens': [' GT', 'E'],\n",
              "   'generated_probs': [0.9935760090256658, 0.9999951615107056],\n",
              "   'generated_text': ' GTE',\n",
              "   'generated_tokens': [' GT', 'E'],\n",
              "   'id': '57264228ec44d21400f3dcf9',\n",
              "   'prediction': ' GTE',\n",
              "   'prompt': 'Title: Packet switching\\n\\nBackground: protocols and helped standardize them in the CCITT. Telenet was incorporated in 1973 and started operations in 1975. It went public in 1979 and was then sold to GTE. Tymnet was an international data communications network headquartered in San Jose, CA that utilized virtual call packet switched technology and used X.25, SNA/SDLC, BSC and ASCII interfaces to connect host computers (servers)at thousands of large companies, educational institutions, and government agencies. Users typically connected via dial-up connections or dedicated async connections. The business consisted of a large public network that supported dial-up users and a private network business that allowed government\\n\\nQ: Telnet was sold to \\n\\nA:',\n",
              "   'question': 'Telnet was sold to '},\n",
              "  {'answers': ['North American',\n",
              "    'North American',\n",
              "    'North American',\n",
              "    'North American'],\n",
              "   'em': 0,\n",
              "   'f1': 0.2857142857142857,\n",
              "   'generated_answer': ' North American Aviation tested Apollo 1 at their facility in Downey, California.',\n",
              "   'generated_answer_probs': [0.6856284130172754,\n",
              "    0.9990162142348308,\n",
              "    0.4309066507171972,\n",
              "    0.20617181591205302,\n",
              "    0.6729286989813382,\n",
              "    0.9554184308242779,\n",
              "    0.8514535850458811,\n",
              "    0.6792609228867791,\n",
              "    0.42449642285151895,\n",
              "    0.9904669939634536,\n",
              "    0.801598435800598,\n",
              "    0.9987510911366216,\n",
              "    0.9928647450728699,\n",
              "    0.8187838249254363,\n",
              "    0.9841485242909555],\n",
              "   'generated_answer_tokens': [' North',\n",
              "    ' American',\n",
              "    ' Aviation',\n",
              "    ' tested',\n",
              "    ' Apollo',\n",
              "    ' 1',\n",
              "    ' at',\n",
              "    ' their',\n",
              "    ' facility',\n",
              "    ' in',\n",
              "    ' Down',\n",
              "    'ey',\n",
              "    ',',\n",
              "    ' California',\n",
              "    '.'],\n",
              "   'generated_probs': [0.6856284130172754,\n",
              "    0.9990162142348308,\n",
              "    0.4309066507171972,\n",
              "    0.20617181591205302,\n",
              "    0.6729286989813382,\n",
              "    0.9554184308242779,\n",
              "    0.8514535850458811,\n",
              "    0.6792609228867791,\n",
              "    0.42449642285151895,\n",
              "    0.9904669939634536,\n",
              "    0.801598435800598,\n",
              "    0.9987510911366216,\n",
              "    0.9928647450728699,\n",
              "    0.8187838249254363,\n",
              "    0.9841485242909555],\n",
              "   'generated_text': ' North American Aviation tested Apollo 1 at their facility in Downey, California.',\n",
              "   'generated_tokens': [' North',\n",
              "    ' American',\n",
              "    ' Aviation',\n",
              "    ' tested',\n",
              "    ' Apollo',\n",
              "    ' 1',\n",
              "    ' at',\n",
              "    ' their',\n",
              "    ' facility',\n",
              "    ' in',\n",
              "    ' Down',\n",
              "    'ey',\n",
              "    ',',\n",
              "    ' California',\n",
              "    '.'],\n",
              "   'id': '5725db4aec44d21400f3d6c0',\n",
              "   'prediction': ' North American Aviation tested Apollo 1 at their facility in Downey, California.',\n",
              "   'prompt': 'Title: Apollo program\\n\\nBackground: long after the first manned CSM flights. Grissom, White, and Chaffee decided to name their flight Apollo 1 as a motivational focus on the first manned flight. They trained and conducted tests of their spacecraft at North American, and in the altitude chamber at the Kennedy Space Center. A \"plugs-out\" test was planned for January, which would simulate a launch countdown on LC-34 with the spacecraft transferring from pad-supplied to internal power. If successful, this would be followed by a more rigorous countdown simulation test closer to the February 21 launch, with both spacecraft and launch vehicle fueled. The plugs-out\\n\\nQ: What other location did Apollo 1 test at besides Kennedy Space Center?\\n\\nA:',\n",
              "   'question': 'What other location did Apollo 1 test at besides Kennedy Space Center?'},\n",
              "  {'answers': ['Bishop Martin Sasse', 'Martin Sasse', 'Sasse'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' Kristallnacht sparked international outrage. It discredited pro-Nazi movements in Europe',\n",
              "   'generated_answer_probs': [0.26214979551353623,\n",
              "    0.9999174351986608,\n",
              "    0.9994218233085971,\n",
              "    0.9999783504973538,\n",
              "    0.5223915377213443,\n",
              "    0.9981043779652475,\n",
              "    0.9991423380724205,\n",
              "    0.8206387980432651,\n",
              "    0.5524188357508465,\n",
              "    0.9967217186373347,\n",
              "    0.9999498606320202,\n",
              "    0.999990869089687,\n",
              "    0.9994694474627982,\n",
              "    0.9998777409042524,\n",
              "    0.9989741317629734,\n",
              "    0.999943063290956],\n",
              "   'generated_answer_tokens': [' Krist',\n",
              "    'all',\n",
              "    'n',\n",
              "    'acht',\n",
              "    ' sparked',\n",
              "    ' international',\n",
              "    ' outrage',\n",
              "    '.',\n",
              "    ' It',\n",
              "    ' discredited',\n",
              "    ' pro',\n",
              "    '-',\n",
              "    'Nazi',\n",
              "    ' movements',\n",
              "    ' in',\n",
              "    ' Europe'],\n",
              "   'generated_probs': [0.26214979551353623,\n",
              "    0.9999174351986608,\n",
              "    0.9994218233085971,\n",
              "    0.9999783504973538,\n",
              "    0.5223915377213443,\n",
              "    0.9981043779652475,\n",
              "    0.9991423380724205,\n",
              "    0.8206387980432651,\n",
              "    0.5524188357508465,\n",
              "    0.9967217186373347,\n",
              "    0.9999498606320202,\n",
              "    0.999990869089687,\n",
              "    0.9994694474627982,\n",
              "    0.9998777409042524,\n",
              "    0.9989741317629734,\n",
              "    0.999943063290956],\n",
              "   'generated_text': ' Kristallnacht sparked international outrage. It discredited pro-Nazi movements in Europe',\n",
              "   'generated_tokens': [' Krist',\n",
              "    'all',\n",
              "    'n',\n",
              "    'acht',\n",
              "    ' sparked',\n",
              "    ' international',\n",
              "    ' outrage',\n",
              "    '.',\n",
              "    ' It',\n",
              "    ' discredited',\n",
              "    ' pro',\n",
              "    '-',\n",
              "    'Nazi',\n",
              "    ' movements',\n",
              "    ' in',\n",
              "    ' Europe'],\n",
              "   'id': '56f8b7189e9bad19000a038c',\n",
              "   'prediction': ' Kristallnacht sparked international outrage. It discredited pro-Nazi movements in Europe',\n",
              "   'prompt': 'Title: Kristallnacht\\n\\nBackground: writings shortly after the \"Kristallnacht\"; Sasse \"applauded the burning of the synagogues\" and the coincidence of the day, writing in the introduction, \"On 10 November 1938, on Luther\\'s birthday, the synagogues are burning in Germany.\" The German people, he urged, ought to heed these words \"of the greatest anti-Semite of his time, the warner of his people against the Jews.\" Diarmaid MacCulloch argued that Luther\\'s 1543 pamphlet, \"On the Jews and Their Lies\" was a \"blueprint\" for the \"Kristallnacht\". \"Kristallnacht\" sparked international outrage. It discredited pro-Nazi movements in Europe and North America, leading to eventual decline of their support. Many\\n\\nQ: Who agreed with the burning of synagogues?\\n\\nA:',\n",
              "   'question': 'Who agreed with the burning of synagogues?'},\n",
              "  {'answers': ['damage',\n",
              "    'the likelihood of damage',\n",
              "    'the likelihood of damage to the existing electrical, water, sewage, phone, and cable facilities'],\n",
              "   'em': 0,\n",
              "   'f1': 0.6,\n",
              "   'generated_answer': ' Damage to the existing electrical, gas, and water lines.',\n",
              "   'generated_answer_probs': [0.8542916781543575,\n",
              "    0.9999264962315344,\n",
              "    0.9101251240202501,\n",
              "    0.9975855746250483,\n",
              "    0.994813997385007,\n",
              "    0.7334412720324047,\n",
              "    0.5696403056865136,\n",
              "    0.940939890272292,\n",
              "    0.9249020767930679,\n",
              "    0.9753158789926274,\n",
              "    0.9442512930469876,\n",
              "    0.97042111744604],\n",
              "   'generated_answer_tokens': [' Damage',\n",
              "    ' to',\n",
              "    ' the',\n",
              "    ' existing',\n",
              "    ' electrical',\n",
              "    ',',\n",
              "    ' gas',\n",
              "    ',',\n",
              "    ' and',\n",
              "    ' water',\n",
              "    ' lines',\n",
              "    '.'],\n",
              "   'generated_probs': [0.8542916781543575,\n",
              "    0.9999264962315344,\n",
              "    0.9101251240202501,\n",
              "    0.9975855746250483,\n",
              "    0.994813997385007,\n",
              "    0.7334412720324047,\n",
              "    0.5696403056865136,\n",
              "    0.940939890272292,\n",
              "    0.9249020767930679,\n",
              "    0.9753158789926274,\n",
              "    0.9442512930469876,\n",
              "    0.97042111744604],\n",
              "   'generated_text': ' Damage to the existing electrical, gas, and water lines.',\n",
              "   'generated_tokens': [' Damage',\n",
              "    ' to',\n",
              "    ' the',\n",
              "    ' existing',\n",
              "    ' electrical',\n",
              "    ',',\n",
              "    ' gas',\n",
              "    ',',\n",
              "    ' and',\n",
              "    ' water',\n",
              "    ' lines',\n",
              "    '.'],\n",
              "   'id': '572754fff1498d1400e8f661',\n",
              "   'prediction': ' Damage to the existing electrical, gas, and water lines.',\n",
              "   'prompt': 'Title: Construction\\n\\nBackground: industry. Among solutions, there are for example: Procore, GenieBelt, PlanGrid, etc. In construction, the authority having jurisdiction (AHJ) is the governmental agency or sub-agency that regulates the construction process. In most cases, this is the municipality where the building is located. However, construction performed for supra-municipal authorities are usually regulated directly by the owning authority, which becomes the AHJ. Before the foundation can be dug, contractors are typically required to verify and have existing utility lines marked, either by the utilities themselves or through a company specializing in such services. This lessens the likelihood of damage to the existing electrical,\\n\\nQ: Having existing utility lines marked lessens the likelihood of what?\\n\\nA:',\n",
              "   'question': 'Having existing utility lines marked lessens the likelihood of what?'},\n",
              "  {'answers': ['29.7%', '29.7%', '29.7%'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' In Jacksonville, 0.9% of households have only one person.',\n",
              "   'generated_answer_probs': [0.28493875971388744,\n",
              "    0.8970991840133714,\n",
              "    0.9984596230003754,\n",
              "    0.09024738114266298,\n",
              "    0.998603449185963,\n",
              "    0.5706381402943203,\n",
              "    0.9998629553114814,\n",
              "    0.9988008002154276,\n",
              "    0.9771410684071576,\n",
              "    0.9882347947101054,\n",
              "    0.9955006475509461,\n",
              "    0.9996337202768024,\n",
              "    0.999295639728241,\n",
              "    0.9796357461622633],\n",
              "   'generated_answer_tokens': [' In',\n",
              "    ' Jacksonville',\n",
              "    ',',\n",
              "    ' 0',\n",
              "    '.',\n",
              "    '9',\n",
              "    '%',\n",
              "    ' of',\n",
              "    ' households',\n",
              "    ' have',\n",
              "    ' only',\n",
              "    ' one',\n",
              "    ' person',\n",
              "    '.'],\n",
              "   'generated_probs': [0.28493875971388744,\n",
              "    0.8970991840133714,\n",
              "    0.9984596230003754,\n",
              "    0.09024738114266298,\n",
              "    0.998603449185963,\n",
              "    0.5706381402943203,\n",
              "    0.9998629553114814,\n",
              "    0.9988008002154276,\n",
              "    0.9771410684071576,\n",
              "    0.9882347947101054,\n",
              "    0.9955006475509461,\n",
              "    0.9996337202768024,\n",
              "    0.999295639728241,\n",
              "    0.9796357461622633],\n",
              "   'generated_text': ' In Jacksonville, 0.9% of households have only one person.',\n",
              "   'generated_tokens': [' In',\n",
              "    ' Jacksonville',\n",
              "    ',',\n",
              "    ' 0',\n",
              "    '.',\n",
              "    '9',\n",
              "    '%',\n",
              "    ' of',\n",
              "    ' households',\n",
              "    ' have',\n",
              "    ' only',\n",
              "    ' one',\n",
              "    ' person',\n",
              "    '.'],\n",
              "   'id': '572827fc3acd2414000df5bb',\n",
              "   'prediction': ' In Jacksonville, 0.9% of households have only one person.',\n",
              "   'prompt': 'Title: Jacksonville, Florida\\n\\nBackground: Other Asian, 0.5% Vietnamese, 0.3% Chinese, 0.2% Korean, and 0.1% were Japanese. In 2010, 6.7% of the population considered themselves to be of only American ancestry (regardless of race or ethnicity.) And 0.9% were of Arab ancestry, . , there were 366,273 households out of which 11.8% were vacant. 23.9% of households had children under the age of 18 living with them, 43.8% were married couples, 15.2% had a female householder with no husband present, and 36.4% were non-families. 29.7% of all households were made up of individuals and 7.9% had someone living alone who was 65 years of age\\n\\nQ: What portion of households in Jacksonville have only one person?\\n\\nA:',\n",
              "   'question': 'What portion of households in Jacksonville have only one person?'},\n",
              "  {'answers': ['Super Bowl XLIV', 'Super Bowl XLIV', '2010'],\n",
              "   'em': 0,\n",
              "   'f1': 0.4,\n",
              "   'generated_answer': ' Super Bowl XLIV was the most recent Super Bowl hosted in the South Florida/',\n",
              "   'generated_answer_probs': [0.8152188697128051,\n",
              "    0.9997435683042292,\n",
              "    0.9938180026651275,\n",
              "    0.9989294895056203,\n",
              "    0.6370109714066355,\n",
              "    0.5090932382163003,\n",
              "    0.9985743020742865,\n",
              "    0.999819085986914,\n",
              "    0.9019563523014893,\n",
              "    0.9999200566396408,\n",
              "    0.8935834964569783,\n",
              "    0.9951972592202094,\n",
              "    0.9958941029395599,\n",
              "    0.9975482041732687,\n",
              "    0.999875355148815,\n",
              "    0.9997886890293088],\n",
              "   'generated_answer_tokens': [' Super',\n",
              "    ' Bowl',\n",
              "    ' XL',\n",
              "    'IV',\n",
              "    ' was',\n",
              "    ' the',\n",
              "    ' most',\n",
              "    ' recent',\n",
              "    ' Super',\n",
              "    ' Bowl',\n",
              "    ' hosted',\n",
              "    ' in',\n",
              "    ' the',\n",
              "    ' South',\n",
              "    ' Florida',\n",
              "    '/'],\n",
              "   'generated_probs': [0.8152188697128051,\n",
              "    0.9997435683042292,\n",
              "    0.9938180026651275,\n",
              "    0.9989294895056203,\n",
              "    0.6370109714066355,\n",
              "    0.5090932382163003,\n",
              "    0.9985743020742865,\n",
              "    0.999819085986914,\n",
              "    0.9019563523014893,\n",
              "    0.9999200566396408,\n",
              "    0.8935834964569783,\n",
              "    0.9951972592202094,\n",
              "    0.9958941029395599,\n",
              "    0.9975482041732687,\n",
              "    0.999875355148815,\n",
              "    0.9997886890293088],\n",
              "   'generated_text': ' Super Bowl XLIV was the most recent Super Bowl hosted in the South Florida/',\n",
              "   'generated_tokens': [' Super',\n",
              "    ' Bowl',\n",
              "    ' XL',\n",
              "    'IV',\n",
              "    ' was',\n",
              "    ' the',\n",
              "    ' most',\n",
              "    ' recent',\n",
              "    ' Super',\n",
              "    ' Bowl',\n",
              "    ' hosted',\n",
              "    ' in',\n",
              "    ' the',\n",
              "    ' South',\n",
              "    ' Florida',\n",
              "    '/'],\n",
              "   'id': '56be54bdacb8001400a50324',\n",
              "   'prediction': ' Super Bowl XLIV was the most recent Super Bowl hosted in the South Florida/',\n",
              "   'prompt': 'Title: Super Bowl 50\\n\\nBackground: game for us as a league\". Cities included in early discussions or that submitted bids included:  The league eventually narrowed the bids to three sites: New Orleans\\' Mercedes-Benz Superdome, Miami\\'s Sun Life Stadium, and the San Francisco Bay Area\\'s Levi\\'s Stadium. The league announced on October 16, 2012, that the two finalists were Sun Life Stadium and Levi\\'s Stadium. The South Florida/Miami area has previously hosted the event 10 times (tied for most with New Orleans), with the most recent one being Super Bowl XLIV in 2010. The San Francisco Bay Area last hosted in 1985 (Super Bowl XIX),\\n\\nQ: What was the most recent Super Bowl hosted in the South Florida/Miami area?\\n\\nA:',\n",
              "   'question': 'What was the most recent Super Bowl hosted in the South Florida/Miami area?'},\n",
              "  {'answers': ['shipbuilding', 'shipbuilding', 'shipbuilding'],\n",
              "   'em': 0,\n",
              "   'f1': 0.16666666666666669,\n",
              "   'generated_answer': ' Tyneside has a rich maritime history, with shipbuilding and fishing being its',\n",
              "   'generated_answer_probs': [0.6257681023772487,\n",
              "    0.9998710632430582,\n",
              "    0.9999562957250596,\n",
              "    0.907362254535091,\n",
              "    0.990674478909149,\n",
              "    0.5627392511248089,\n",
              "    0.8422340788422453,\n",
              "    0.5194288689262186,\n",
              "    0.6010127920887404,\n",
              "    0.7958217025492156,\n",
              "    0.4286024841482232,\n",
              "    0.9930143528631331,\n",
              "    0.5871543538338224,\n",
              "    0.302049006981263,\n",
              "    0.5278877566378196,\n",
              "    0.25752159456660956],\n",
              "   'generated_answer_tokens': [' T',\n",
              "    'ynes',\n",
              "    'ide',\n",
              "    ' has',\n",
              "    ' a',\n",
              "    ' rich',\n",
              "    ' maritime',\n",
              "    ' history',\n",
              "    ',',\n",
              "    ' with',\n",
              "    ' ship',\n",
              "    'building',\n",
              "    ' and',\n",
              "    ' fishing',\n",
              "    ' being',\n",
              "    ' its'],\n",
              "   'generated_probs': [0.6257681023772487,\n",
              "    0.9998710632430582,\n",
              "    0.9999562957250596,\n",
              "    0.907362254535091,\n",
              "    0.990674478909149,\n",
              "    0.5627392511248089,\n",
              "    0.8422340788422453,\n",
              "    0.5194288689262186,\n",
              "    0.6010127920887404,\n",
              "    0.7958217025492156,\n",
              "    0.4286024841482232,\n",
              "    0.9930143528631331,\n",
              "    0.5871543538338224,\n",
              "    0.302049006981263,\n",
              "    0.5278877566378196,\n",
              "    0.25752159456660956],\n",
              "   'generated_text': ' Tyneside has a rich maritime history, with shipbuilding and fishing being its',\n",
              "   'generated_tokens': [' T',\n",
              "    'ynes',\n",
              "    'ide',\n",
              "    ' has',\n",
              "    ' a',\n",
              "    ' rich',\n",
              "    ' maritime',\n",
              "    ' history',\n",
              "    ',',\n",
              "    ' with',\n",
              "    ' ship',\n",
              "    'building',\n",
              "    ' and',\n",
              "    ' fishing',\n",
              "    ' being',\n",
              "    ' its'],\n",
              "   'id': '57268692dd62a815002e8828',\n",
              "   'prediction': ' Tyneside has a rich maritime history, with shipbuilding and fishing being its',\n",
              "   'prompt': \"Title: Newcastle upon Tyne\\n\\nBackground: education and teaching suites. There are several museums and galleries in Newcastle, including the Centre for Life with its Science Village; the Discovery Museum a museum highlighting life on Tyneside, including Tyneside's shipbuilding heritage, and inventions which changed the world; the Great North Museum; in 2009 the Newcastle on Tyne Museum of Antiquities merged with the Great North Museum (Hancock Museum); Seven Stories a museum dedicated to children's books, the Side Gallery historical and contemporary photography from around the world and Northern England and the Newburn Hall Motor Museum. The Laing Art Gallery, like other art galleries and museums around\\n\\nQ: What type of heritage does Tyneside have?\\n\\nA:\",\n",
              "   'question': 'What type of heritage does Tyneside have?'},\n",
              "  {'answers': ['Acute oxygen toxicity',\n",
              "    'Acute oxygen toxicity',\n",
              "    'seizures',\n",
              "    'seizures',\n",
              "    'seizures'],\n",
              "   'em': 0,\n",
              "   'f1': 0.4,\n",
              "   'generated_answer': ' Acute oxygen toxicity is the most feared condition that divers want to avoid.',\n",
              "   'generated_answer_probs': [0.8357770651004036,\n",
              "    0.999958920081803,\n",
              "    0.9953094352201092,\n",
              "    0.999751437846692,\n",
              "    0.46001388737916377,\n",
              "    0.9881153421316301,\n",
              "    0.9921907994863478,\n",
              "    0.9969280730528891,\n",
              "    0.9866748751085231,\n",
              "    0.803921613663153,\n",
              "    0.9992501632681745,\n",
              "    0.9990672353456569,\n",
              "    0.9999809720970328,\n",
              "    0.9998401870014579,\n",
              "    0.9910375280493342],\n",
              "   'generated_answer_tokens': [' Ac',\n",
              "    'ute',\n",
              "    ' oxygen',\n",
              "    ' toxicity',\n",
              "    ' is',\n",
              "    ' the',\n",
              "    ' most',\n",
              "    ' feared',\n",
              "    ' condition',\n",
              "    ' that',\n",
              "    ' divers',\n",
              "    ' want',\n",
              "    ' to',\n",
              "    ' avoid',\n",
              "    '.'],\n",
              "   'generated_probs': [0.8357770651004036,\n",
              "    0.999958920081803,\n",
              "    0.9953094352201092,\n",
              "    0.999751437846692,\n",
              "    0.46001388737916377,\n",
              "    0.9881153421316301,\n",
              "    0.9921907994863478,\n",
              "    0.9969280730528891,\n",
              "    0.9866748751085231,\n",
              "    0.803921613663153,\n",
              "    0.9992501632681745,\n",
              "    0.9990672353456569,\n",
              "    0.9999809720970328,\n",
              "    0.9998401870014579,\n",
              "    0.9910375280493342],\n",
              "   'generated_text': ' Acute oxygen toxicity is the most feared condition that divers want to avoid.',\n",
              "   'generated_tokens': [' Ac',\n",
              "    'ute',\n",
              "    ' oxygen',\n",
              "    ' toxicity',\n",
              "    ' is',\n",
              "    ' the',\n",
              "    ' most',\n",
              "    ' feared',\n",
              "    ' condition',\n",
              "    ' that',\n",
              "    ' divers',\n",
              "    ' want',\n",
              "    ' to',\n",
              "    ' avoid',\n",
              "    '.'],\n",
              "   'id': '571ce3745efbb31900334e23',\n",
              "   'prediction': ' Acute oxygen toxicity is the most feared condition that divers want to avoid.',\n",
              "   'prompt': \"Title: Oxygen\\n\\nBackground: normal), and the resulting partial pressure in the astronaut's arterial blood is only marginally more than normal sea-level partial pressure (for more information on this, see space suit and arterial blood gas). Oxygen toxicity to the lungs and central nervous system can also occur in deep scuba diving and surface supplied diving. Prolonged breathing of an air mixture with an partial pressure more than 60\\xa0kPa can eventually lead to permanent pulmonary fibrosis. Exposure to a partial pressures greater than 160\\xa0kPa (about 1.6 atm) may lead to convulsions (normally fatal for divers). Acute oxygen toxicity (causing seizures, its most feared effect\\n\\nQ: What is the most feared condition that divers want to avoid?\\n\\nA:\",\n",
              "   'question': 'What is the most feared condition that divers want to avoid?'},\n",
              "  {'answers': ['9th', '9th', '9th'],\n",
              "   'em': 0,\n",
              "   'f1': 0.16666666666666669,\n",
              "   'generated_answer': ' Warsaw ranks as the 9th most populous capital city in the European Union.',\n",
              "   'generated_answer_probs': [0.8923023468199289,\n",
              "    0.9687632993960386,\n",
              "    0.5733809035365468,\n",
              "    0.9920037157386452,\n",
              "    0.9644518385442526,\n",
              "    0.9999830004784935,\n",
              "    0.9775755804091496,\n",
              "    0.8055907256460485,\n",
              "    0.7681943176996453,\n",
              "    0.9824951614339575,\n",
              "    0.9791807268154902,\n",
              "    0.9992310284103091,\n",
              "    0.8971749382667691,\n",
              "    0.9999458068115039,\n",
              "    0.7262347640274514],\n",
              "   'generated_answer_tokens': [' Warsaw',\n",
              "    ' ranks',\n",
              "    ' as',\n",
              "    ' the',\n",
              "    ' 9',\n",
              "    'th',\n",
              "    ' most',\n",
              "    ' populous',\n",
              "    ' capital',\n",
              "    ' city',\n",
              "    ' in',\n",
              "    ' the',\n",
              "    ' European',\n",
              "    ' Union',\n",
              "    '.'],\n",
              "   'generated_probs': [0.8923023468199289,\n",
              "    0.9687632993960386,\n",
              "    0.5733809035365468,\n",
              "    0.9920037157386452,\n",
              "    0.9644518385442526,\n",
              "    0.9999830004784935,\n",
              "    0.9775755804091496,\n",
              "    0.8055907256460485,\n",
              "    0.7681943176996453,\n",
              "    0.9824951614339575,\n",
              "    0.9791807268154902,\n",
              "    0.9992310284103091,\n",
              "    0.8971749382667691,\n",
              "    0.9999458068115039,\n",
              "    0.7262347640274514],\n",
              "   'generated_text': ' Warsaw ranks as the 9th most populous capital city in the European Union.',\n",
              "   'generated_tokens': [' Warsaw',\n",
              "    ' ranks',\n",
              "    ' as',\n",
              "    ' the',\n",
              "    ' 9',\n",
              "    'th',\n",
              "    ' most',\n",
              "    ' populous',\n",
              "    ' capital',\n",
              "    ' city',\n",
              "    ' in',\n",
              "    ' the',\n",
              "    ' European',\n",
              "    ' Union',\n",
              "    '.'],\n",
              "   'id': '573166ede6313a140071cef6',\n",
              "   'prediction': ' Warsaw ranks as the 9th most populous capital city in the European Union.',\n",
              "   'prompt': 'Title: Warsaw\\n\\nBackground: Warsaw Warsaw ( ; see also other names) is the capital and largest city of Poland. It stands on the Vistula River in east-central Poland, roughly from the Baltic Sea and from the Carpathian Mountains. Its population is estimated at 1.750 million residents within a greater metropolitan area of 3.105 million residents, which makes Warsaw the 9th most-populous capital city in the European Union. The city limits cover , while the metropolitan area covers . In 2012 the Economist Intelligence Unit ranked Warsaw as the 32nd most liveable city in the world. It was also ranked as one of the\\n\\nQ: Where does Warsaw rank in terms of population in the EU?\\n\\nA:',\n",
              "   'question': 'Where does Warsaw rank in terms of population in the EU?'},\n",
              "  {'answers': ['in commerce, schooling and government',\n",
              "    'commerce, schooling and government.',\n",
              "    'commerce, schooling and government'],\n",
              "   'em': 0,\n",
              "   'f1': 0.12500000000000003,\n",
              "   'generated_answer': ' English is spoken the most in the United Kingdom, United States, Canada, Australia',\n",
              "   'generated_answer_probs': [0.9375297052870786,\n",
              "    0.9987013807367096,\n",
              "    0.9288600940022231,\n",
              "    0.5111137350811114,\n",
              "    0.9992931362459755,\n",
              "    0.9716120672051989,\n",
              "    0.9778101817256075,\n",
              "    0.9938396373247091,\n",
              "    0.992100572765568,\n",
              "    0.9943112316723677,\n",
              "    0.6677387131118441,\n",
              "    0.9999920621045053,\n",
              "    0.9996800305411495,\n",
              "    0.9998809563262605,\n",
              "    0.9999846721884721,\n",
              "    0.9956800001605328],\n",
              "   'generated_answer_tokens': [' English',\n",
              "    ' is',\n",
              "    ' spoken',\n",
              "    ' the',\n",
              "    ' most',\n",
              "    ' in',\n",
              "    ' the',\n",
              "    ' United',\n",
              "    ' Kingdom',\n",
              "    ',',\n",
              "    ' United',\n",
              "    ' States',\n",
              "    ',',\n",
              "    ' Canada',\n",
              "    ',',\n",
              "    ' Australia'],\n",
              "   'generated_probs': [0.9375297052870786,\n",
              "    0.9987013807367096,\n",
              "    0.9288600940022231,\n",
              "    0.5111137350811114,\n",
              "    0.9992931362459755,\n",
              "    0.9716120672051989,\n",
              "    0.9778101817256075,\n",
              "    0.9938396373247091,\n",
              "    0.992100572765568,\n",
              "    0.9943112316723677,\n",
              "    0.6677387131118441,\n",
              "    0.9999920621045053,\n",
              "    0.9996800305411495,\n",
              "    0.9998809563262605,\n",
              "    0.9999846721884721,\n",
              "    0.9956800001605328],\n",
              "   'generated_text': ' English is spoken the most in the United Kingdom, United States, Canada, Australia',\n",
              "   'generated_tokens': [' English',\n",
              "    ' is',\n",
              "    ' spoken',\n",
              "    ' the',\n",
              "    ' most',\n",
              "    ' in',\n",
              "    ' the',\n",
              "    ' United',\n",
              "    ' Kingdom',\n",
              "    ',',\n",
              "    ' United',\n",
              "    ' States',\n",
              "    ',',\n",
              "    ' Canada',\n",
              "    ',',\n",
              "    ' Australia'],\n",
              "   'id': '572921646aef051400154a7a',\n",
              "   'prediction': ' English is spoken the most in the United Kingdom, United States, Canada, Australia',\n",
              "   'prompt': 'Title: English language\\n\\nBackground: is the most commonly spoken language in the United Kingdom, the United States, Canada, Australia, Ireland, and New Zealand, and is widely spoken in some areas of the Caribbean, Africa, and South Asia. It is the third most common native language in the world, after Mandarin and Spanish. It is the most widely learned second language and an official language of the United Nations, of the European Union, and of many other world and regional international organisations. It is the most widely spoken Germanic language, accounting for at least 70% of speakers of this Indo-European branch. English has developed over\\n\\nQ: Where is English spoken the most?\\n\\nA:',\n",
              "   'question': 'Where is English spoken the most?'},\n",
              "  {'answers': ['North', 'North Sea', 'the North Sea'],\n",
              "   'em': 1,\n",
              "   'f1': 1.0,\n",
              "   'generated_answer': ' The North Sea.',\n",
              "   'generated_answer_probs': [0.9332230212406458,\n",
              "    0.9712546797854211,\n",
              "    0.9992720955510724,\n",
              "    0.6427238874208714],\n",
              "   'generated_answer_tokens': [' The', ' North', ' Sea', '.'],\n",
              "   'generated_probs': [0.9332230212406458,\n",
              "    0.9712546797854211,\n",
              "    0.9992720955510724,\n",
              "    0.6427238874208714],\n",
              "   'generated_text': ' The North Sea.',\n",
              "   'generated_tokens': [' The', ' North', ' Sea', '.'],\n",
              "   'id': '572fad30a23a5019007fc86d',\n",
              "   'prediction': ' The North Sea.',\n",
              "   'prompt': 'Title: North Sea\\n\\nBackground: reapportioned after protracted negotiations and a judgement of the International Court of Justice. As early as 1859, oil was discovered in onshore areas around the North Sea and natural gas as early as 1910. Test drilling began in 1966 and then, in 1969, Phillips Petroleum Company discovered the Ekofisk oil field distinguished by valuable, low-sulphur oil. Commercial exploitation began in 1971 with tankers and, after 1975, by a pipeline, first to Teesside, England and then, after 1977, also to Emden, Germany. The exploitation of the North Sea oil reserves began just before the 1973 oil crisis, and the climb of\\n\\nQ: Which sea was oil discovered in?\\n\\nA:',\n",
              "   'question': 'Which sea was oil discovered in?'},\n",
              "  {'answers': ['left Graz',\n",
              "    'left Graz',\n",
              "    'left Graz and severed all relations with his family'],\n",
              "   'em': 0,\n",
              "   'f1': 0.4444444444444445,\n",
              "   'generated_answer': ' Tesla left Graz, Austria for the United States.',\n",
              "   'generated_answer_probs': [0.5940037004055043,\n",
              "    0.9950507513922061,\n",
              "    0.999736298455366,\n",
              "    0.99999813984753,\n",
              "    0.4935419592072574,\n",
              "    0.962452206151104,\n",
              "    0.5368414389760657,\n",
              "    0.8828684025231878,\n",
              "    0.9630431310240544,\n",
              "    0.9999951615107056,\n",
              "    0.9125721346305405],\n",
              "   'generated_answer_tokens': [' Tesla',\n",
              "    ' left',\n",
              "    ' G',\n",
              "    'raz',\n",
              "    ',',\n",
              "    ' Austria',\n",
              "    ' for',\n",
              "    ' the',\n",
              "    ' United',\n",
              "    ' States',\n",
              "    '.'],\n",
              "   'generated_probs': [0.5940037004055043,\n",
              "    0.9950507513922061,\n",
              "    0.999736298455366,\n",
              "    0.99999813984753,\n",
              "    0.4935419592072574,\n",
              "    0.962452206151104,\n",
              "    0.5368414389760657,\n",
              "    0.8828684025231878,\n",
              "    0.9630431310240544,\n",
              "    0.9999951615107056,\n",
              "    0.9125721346305405],\n",
              "   'generated_text': ' Tesla left Graz, Austria for the United States.',\n",
              "   'generated_tokens': [' Tesla',\n",
              "    ' left',\n",
              "    ' G',\n",
              "    'raz',\n",
              "    ',',\n",
              "    ' Austria',\n",
              "    ' for',\n",
              "    ' the',\n",
              "    ' United',\n",
              "    ' States',\n",
              "    '.'],\n",
              "   'id': '56dfa7887aa994140058dfa9',\n",
              "   'prediction': ' Tesla left Graz, Austria for the United States.',\n",
              "   'prompt': 'Title: Nikola Tesla\\n\\nBackground: end of his second year, Tesla lost his scholarship and became addicted to gambling. During his third year, Tesla gambled away his allowance and his tuition money, later gambling back his initial losses and returning the balance to his family. Tesla said that he \"conquered [his] passion then and there,\" but later in the US he was again known to play billiards. When examination time came, Tesla was unprepared and asked for an extension to study, but was denied. He never graduated from the university and did not receive grades for the last semester. In December 1878 Tesla left Graz\\n\\nQ: What did Tesla do in December 1878?\\n\\nA:',\n",
              "   'question': 'What did Tesla do in December 1878?'},\n",
              "  {'answers': ['10–15% of the population',\n",
              "    '10–15% of the population',\n",
              "    '10–15% of the population'],\n",
              "   'em': 0,\n",
              "   'f1': 0.6666666666666666,\n",
              "   'generated_answer': ' 10-15% of the population.',\n",
              "   'generated_answer_probs': [0.3578499551962991,\n",
              "    0.858793930862532,\n",
              "    0.9999213687765968,\n",
              "    0.9933920676421586,\n",
              "    0.9898190295475403,\n",
              "    0.9989576820910743,\n",
              "    0.992184138931867,\n",
              "    0.5544282923673016],\n",
              "   'generated_answer_tokens': [' 10',\n",
              "    '-',\n",
              "    '15',\n",
              "    '%',\n",
              "    ' of',\n",
              "    ' the',\n",
              "    ' population',\n",
              "    '.'],\n",
              "   'generated_probs': [0.3578499551962991,\n",
              "    0.858793930862532,\n",
              "    0.9999213687765968,\n",
              "    0.9933920676421586,\n",
              "    0.9898190295475403,\n",
              "    0.9989576820910743,\n",
              "    0.992184138931867,\n",
              "    0.5544282923673016],\n",
              "   'generated_text': ' 10-15% of the population.',\n",
              "   'generated_tokens': [' 10',\n",
              "    '-',\n",
              "    '15',\n",
              "    '%',\n",
              "    ' of',\n",
              "    ' the',\n",
              "    ' population',\n",
              "    '.'],\n",
              "   'id': '5726559edd62a815002e81ca',\n",
              "   'prediction': ' 10-15% of the population.',\n",
              "   'prompt': 'Title: Black Death\\n\\nBackground: really died out in England. Over the next few hundred years, further outbreaks occurred in 1361–1362, 1369, 1379–1383, 1389–1393, and throughout the first half of the 15th\\xa0century. An outbreak in 1471 took as much as 10–15% of the population, while the death rate of the plague of 1479–1480 could have been as high as 20%. The most general outbreaks in Tudor and Stuart England seem to have begun in 1498, 1535, 1543, 1563, 1589, 1603, 1625, and 1636, and ended with the Great Plague of London in 1665. In 1466, perhaps 40,000\\xa0people died of the plague in Paris. During the\\n\\nQ: How many people died in the outbreak of 1471?\\n\\nA:',\n",
              "   'question': 'How many people died in the outbreak of 1471?'},\n",
              "  {'answers': ['1707', '1707', '1707'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' The earliest that Bach began using Luther hymns is unknown, but it is',\n",
              "   'generated_answer_probs': [0.7791385598950609,\n",
              "    0.9993302699693405,\n",
              "    0.5813143956512081,\n",
              "    0.9993617420433208,\n",
              "    0.8245153168643278,\n",
              "    0.9993290777690396,\n",
              "    0.9883967386487975,\n",
              "    0.9999768026890618,\n",
              "    0.9999694128877953,\n",
              "    0.9998673682463688,\n",
              "    0.5679811599007022,\n",
              "    0.6412611081475126,\n",
              "    0.6217768703142824,\n",
              "    0.9703141276231906,\n",
              "    0.7919804039192595,\n",
              "    0.7530886342063025],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' earliest',\n",
              "    ' that',\n",
              "    ' Bach',\n",
              "    ' began',\n",
              "    ' using',\n",
              "    ' Luther',\n",
              "    ' hy',\n",
              "    'm',\n",
              "    'ns',\n",
              "    ' is',\n",
              "    ' unknown',\n",
              "    ',',\n",
              "    ' but',\n",
              "    ' it',\n",
              "    ' is'],\n",
              "   'generated_probs': [0.7791385598950609,\n",
              "    0.9993302699693405,\n",
              "    0.5813143956512081,\n",
              "    0.9993617420433208,\n",
              "    0.8245153168643278,\n",
              "    0.9993290777690396,\n",
              "    0.9883967386487975,\n",
              "    0.9999768026890618,\n",
              "    0.9999694128877953,\n",
              "    0.9998673682463688,\n",
              "    0.5679811599007022,\n",
              "    0.6412611081475126,\n",
              "    0.6217768703142824,\n",
              "    0.9703141276231906,\n",
              "    0.7919804039192595,\n",
              "    0.7530886342063025],\n",
              "   'generated_text': ' The earliest that Bach began using Luther hymns is unknown, but it is',\n",
              "   'generated_tokens': [' The',\n",
              "    ' earliest',\n",
              "    ' that',\n",
              "    ' Bach',\n",
              "    ' began',\n",
              "    ' using',\n",
              "    ' Luther',\n",
              "    ' hy',\n",
              "    'm',\n",
              "    'ns',\n",
              "    ' is',\n",
              "    ' unknown',\n",
              "    ',',\n",
              "    ' but',\n",
              "    ' it',\n",
              "    ' is'],\n",
              "   'id': '56f881e3a6d7ea1400e176f5',\n",
              "   'prediction': ' The earliest that Bach began using Luther hymns is unknown, but it is',\n",
              "   'prompt': 'Title: Martin Luther\\n\\nBackground: spread the ideas of the Reformation. He supplied four of eight songs of the First Lutheran hymnal \"Achtliederbuch\", 18 of 26 songs of the \"Erfurt Enchiridion\", and 24 of the 32 songs in the first choral hymnal with settings by Johann Walter, \"Eyn geystlich Gesangk Buchleyn\", all published in 1524. Luther\\'s hymns inspired composers to write music. Johann Sebastian Bach included several verses as chorales in his cantatas and based chorale cantatas entirely on them, namely \"Christ lag in Todes Banden\", BWV 4, as early as possibly 1707, in his second annual cycle (1724 to 1725) \"Ach Gott, vom Himmel\\n\\nQ: What is the earliest that Bach began using Luther hymns?\\n\\nA:',\n",
              "   'question': 'What is the earliest that Bach began using Luther hymns?'},\n",
              "  {'answers': ['one of the poorest countries on earth',\n",
              "    'one of the poorest countries on earth',\n",
              "    'one of the poorest countries on earth'],\n",
              "   'em': 0,\n",
              "   'f1': 0.11764705882352942,\n",
              "   'generated_answer': \" The civil war left the state of Afghanistan's economy in a very poor state.\",\n",
              "   'generated_answer_probs': [0.6119095386858444,\n",
              "    0.972853028549758,\n",
              "    0.9999261367620232,\n",
              "    0.9507848381849795,\n",
              "    0.9746064124726795,\n",
              "    0.9901972215569753,\n",
              "    0.9999324553112452,\n",
              "    0.9983401750356393,\n",
              "    0.9985198871490716,\n",
              "    0.9999419914075635,\n",
              "    0.9942808315683512,\n",
              "    0.8411433093655516,\n",
              "    0.3220513738647643,\n",
              "    0.38796168276338766,\n",
              "    0.7413618101836659,\n",
              "    0.9561298727506014],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' civil',\n",
              "    ' war',\n",
              "    ' left',\n",
              "    ' the',\n",
              "    ' state',\n",
              "    ' of',\n",
              "    ' Afghanistan',\n",
              "    \"'s\",\n",
              "    ' economy',\n",
              "    ' in',\n",
              "    ' a',\n",
              "    ' very',\n",
              "    ' poor',\n",
              "    ' state',\n",
              "    '.'],\n",
              "   'generated_probs': [0.6119095386858444,\n",
              "    0.972853028549758,\n",
              "    0.9999261367620232,\n",
              "    0.9507848381849795,\n",
              "    0.9746064124726795,\n",
              "    0.9901972215569753,\n",
              "    0.9999324553112452,\n",
              "    0.9983401750356393,\n",
              "    0.9985198871490716,\n",
              "    0.9999419914075635,\n",
              "    0.9942808315683512,\n",
              "    0.8411433093655516,\n",
              "    0.3220513738647643,\n",
              "    0.38796168276338766,\n",
              "    0.7413618101836659,\n",
              "    0.9561298727506014],\n",
              "   'generated_text': \" The civil war left the state of Afghanistan's economy in a very poor state.\",\n",
              "   'generated_tokens': [' The',\n",
              "    ' civil',\n",
              "    ' war',\n",
              "    ' left',\n",
              "    ' the',\n",
              "    ' state',\n",
              "    ' of',\n",
              "    ' Afghanistan',\n",
              "    \"'s\",\n",
              "    ' economy',\n",
              "    ' in',\n",
              "    ' a',\n",
              "    ' very',\n",
              "    ' poor',\n",
              "    ' state',\n",
              "    '.'],\n",
              "   'id': '573028fa04bcaa1900d77289',\n",
              "   'prediction': \" The civil war left the state of Afghanistan's economy in a very poor state.\",\n",
              "   'prompt': 'Title: Russia\\n\\nBackground: industry and weapons to light industry and consumer goods but was stifled by the conservative Communist leadership. In 1979, after a Communist-led revolution in Afghanistan, Soviet forces entered that country at the request of the new regime. The occupation drained economic resources and dragged on without achieving meaningful political results. Ultimately, the Soviet Army was withdrawn from Afghanistan in 1989 due to international opposition, persistent anti-Soviet guerilla warfare, and a lack of support by Soviet citizens. From 1985 onwards, the last Soviet leader Mikhail Gorbachev, who sought to enact liberal reforms in the Soviet system, introduced the policies of \"glasnost\"\\n\\nQ: What did the civil war leave the state of Afghanistan\\'s economy in?\\n\\nA:',\n",
              "   'question': \"What did the civil war leave the state of Afghanistan's economy in?\"},\n",
              "  {'answers': ['Darian Stewart', 'Darian Stewart', 'Stewart'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' Danny Trevathan',\n",
              "   'generated_answer_probs': [0.6920090675876194,\n",
              "    0.999925898361662,\n",
              "    0.9999636891852536,\n",
              "    0.9999971861801588],\n",
              "   'generated_answer_tokens': [' Danny', ' Tre', 'v', 'athan'],\n",
              "   'generated_probs': [0.6920090675876194,\n",
              "    0.999925898361662,\n",
              "    0.9999636891852536,\n",
              "    0.9999971861801588],\n",
              "   'generated_text': ' Danny Trevathan',\n",
              "   'generated_tokens': [' Danny', ' Tre', 'v', 'athan'],\n",
              "   'id': '56bec9133aeaaa14008c9445',\n",
              "   'prediction': ' Danny Trevathan',\n",
              "   'prompt': \"Title: Super Bowl 50\\n\\nBackground: could not get the ball into the end zone, so McManus kicked a 33-yard field goal that increased their lead to 13–7. On Carolina's next possession, fullback Mike Tolbert lost a fumble while being tackled by safety Darian Stewart, which linebacker Danny Trevathan recovered on the Broncos 40-yard line. However, the Panthers soon took the ball back when defensive end Kony Ealy tipped a Manning pass to himself and then intercepted it, returning the ball 19 yards to the Panthers 39-yard line with 1:55 left on the clock. The Panthers could not gain any yards with their possession and had\\n\\nQ: Who tackled Mike Tolbert and caused a fumble?\\n\\nA:\",\n",
              "   'question': 'Who tackled Mike Tolbert and caused a fumble?'},\n",
              "  {'answers': ['air', 'air', 'air', 'air'],\n",
              "   'em': 0,\n",
              "   'f1': 0.18181818181818182,\n",
              "   'generated_answer': ' Da Vinci thought a part of air was consumed during combustion.',\n",
              "   'generated_answer_probs': [0.4040001620125112,\n",
              "    0.9971987388746,\n",
              "    0.9999467585533761,\n",
              "    0.813894938086077,\n",
              "    0.7384574835713146,\n",
              "    0.9685961275575409,\n",
              "    0.8991024689242664,\n",
              "    0.936373213130486,\n",
              "    0.9968756808747573,\n",
              "    0.9997578716677972,\n",
              "    0.9995508083168059,\n",
              "    0.9998192060951882,\n",
              "    0.8813048373601549],\n",
              "   'generated_answer_tokens': [' Da',\n",
              "    ' Vin',\n",
              "    'ci',\n",
              "    ' thought',\n",
              "    ' a',\n",
              "    ' part',\n",
              "    ' of',\n",
              "    ' air',\n",
              "    ' was',\n",
              "    ' consumed',\n",
              "    ' during',\n",
              "    ' combustion',\n",
              "    '.'],\n",
              "   'generated_probs': [0.4040001620125112,\n",
              "    0.9971987388746,\n",
              "    0.9999467585533761,\n",
              "    0.813894938086077,\n",
              "    0.7384574835713146,\n",
              "    0.9685961275575409,\n",
              "    0.8991024689242664,\n",
              "    0.936373213130486,\n",
              "    0.9968756808747573,\n",
              "    0.9997578716677972,\n",
              "    0.9995508083168059,\n",
              "    0.9998192060951882,\n",
              "    0.8813048373601549],\n",
              "   'generated_text': ' Da Vinci thought a part of air was consumed during combustion.',\n",
              "   'generated_tokens': [' Da',\n",
              "    ' Vin',\n",
              "    'ci',\n",
              "    ' thought',\n",
              "    ' a',\n",
              "    ' part',\n",
              "    ' of',\n",
              "    ' air',\n",
              "    ' was',\n",
              "    ' consumed',\n",
              "    ' during',\n",
              "    ' combustion',\n",
              "    '.'],\n",
              "   'id': '571c7abfdd7acb1400e4c0be',\n",
              "   'prediction': ' Da Vinci thought a part of air was consumed during combustion.',\n",
              "   'prompt': 'Title: Oxygen\\n\\nBackground: built on Philo\\'s work by observing that a portion of air is consumed during combustion and respiration. Oxygen was discovered by the Polish alchemist Sendivogius, who considered it the philosopher\\'s stone. In the late 17th\\xa0century, Robert Boyle proved that air is necessary for combustion. English chemist John Mayow (1641–1679) refined this work by showing that fire requires only a part of air that he called \"spiritus nitroaereus\". In one experiment, he found that placing either a mouse or a lit candle in a closed container over water caused the water to rise and replace one-fourteenth of the air\\'s volume before\\n\\nQ: Of what did da Vinci think a part  was consumed during combustion?\\n\\nA:',\n",
              "   'question': 'Of what did da Vinci think a part  was consumed during combustion?'},\n",
              "  {'answers': ['glasses with one darkened lens',\n",
              "    'glasses with one darkened lens',\n",
              "    'one darkened lens'],\n",
              "   'em': 0,\n",
              "   'f1': 0.11764705882352941,\n",
              "   'generated_answer': ' The 3D effects in Dimension in Time were created with lenses from the 3D',\n",
              "   'generated_answer_probs': [0.49802126602887437,\n",
              "    0.64010443900275,\n",
              "    0.9996042710013836,\n",
              "    0.7001436714990239,\n",
              "    0.9681353917265495,\n",
              "    0.9873299890657481,\n",
              "    0.9984944323059007,\n",
              "    0.9998785715030368,\n",
              "    0.6735518097218698,\n",
              "    0.5733340487636218,\n",
              "    0.5905961077652947,\n",
              "    0.6983004253557115,\n",
              "    0.9249399245604103,\n",
              "    0.9800067868346696,\n",
              "    0.9990289673576157,\n",
              "    0.9999797819093883],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' 3',\n",
              "    'D',\n",
              "    ' effects',\n",
              "    ' in',\n",
              "    ' Dimension',\n",
              "    ' in',\n",
              "    ' Time',\n",
              "    ' were',\n",
              "    ' created',\n",
              "    ' with',\n",
              "    ' lenses',\n",
              "    ' from',\n",
              "    ' the',\n",
              "    ' 3',\n",
              "    'D'],\n",
              "   'generated_probs': [0.49802126602887437,\n",
              "    0.64010443900275,\n",
              "    0.9996042710013836,\n",
              "    0.7001436714990239,\n",
              "    0.9681353917265495,\n",
              "    0.9873299890657481,\n",
              "    0.9984944323059007,\n",
              "    0.9998785715030368,\n",
              "    0.6735518097218698,\n",
              "    0.5733340487636218,\n",
              "    0.5905961077652947,\n",
              "    0.6983004253557115,\n",
              "    0.9249399245604103,\n",
              "    0.9800067868346696,\n",
              "    0.9990289673576157,\n",
              "    0.9999797819093883],\n",
              "   'generated_text': ' The 3D effects in Dimension in Time were created with lenses from the 3D',\n",
              "   'generated_tokens': [' The',\n",
              "    ' 3',\n",
              "    'D',\n",
              "    ' effects',\n",
              "    ' in',\n",
              "    ' Dimension',\n",
              "    ' in',\n",
              "    ' Time',\n",
              "    ' were',\n",
              "    ' created',\n",
              "    ' with',\n",
              "    ' lenses',\n",
              "    ' from',\n",
              "    ' the',\n",
              "    ' 3',\n",
              "    'D'],\n",
              "   'id': '5728303e4b864d19001646ad',\n",
              "   'prediction': ' The 3D effects in Dimension in Time were created with lenses from the 3D',\n",
              "   'prompt': 'Title: 3D film\\n\\nBackground: lenses from the 3D glasses to cut out the \"pointy, pointy 3D stereoscopic vision\", although this technique still does not improve the huge brightness loss from a 3D film. Versions of these \"2-D glasses\" are being marketed. As pointed out in the article \"Virtual Space - the movies of the future\" in real life the 3D effect, or stereoscopic vision, depends on the distance between the eyes, which is only about 2 1/2 inches. The depth perception this affords is only noticeable near to the head - at about arms length. It is only useful for such tasks as threading\\n\\nQ: What type of lenses were needed to see the 3D effects in Dimension in Time?\\n\\nA:',\n",
              "   'question': 'What type of lenses were needed to see the 3D effects in Dimension in Time?'},\n",
              "  {'answers': ['self-starting', 'self-starting', 'induction'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' a printed armature or pancake motor has the windings shaped as a disc',\n",
              "   'generated_answer_probs': [0.40131708037741093,\n",
              "    0.6330237739248631,\n",
              "    0.9996142862566796,\n",
              "    0.9999925361213549,\n",
              "    0.7281382463365546,\n",
              "    0.9988728629966352,\n",
              "    0.9999999317236823,\n",
              "    0.9998296974431271,\n",
              "    0.9144997358478257,\n",
              "    0.9998122932691133,\n",
              "    0.9999003880356012,\n",
              "    0.9999905095960342,\n",
              "    0.9973798779273919,\n",
              "    0.999674666032576,\n",
              "    0.9999838349316561,\n",
              "    0.9999174351986608],\n",
              "   'generated_answer_tokens': [' a',\n",
              "    ' printed',\n",
              "    ' arm',\n",
              "    'ature',\n",
              "    ' or',\n",
              "    ' panc',\n",
              "    'ake',\n",
              "    ' motor',\n",
              "    ' has',\n",
              "    ' the',\n",
              "    ' wind',\n",
              "    'ings',\n",
              "    ' shaped',\n",
              "    ' as',\n",
              "    ' a',\n",
              "    ' disc'],\n",
              "   'generated_probs': [0.40131708037741093,\n",
              "    0.6330237739248631,\n",
              "    0.9996142862566796,\n",
              "    0.9999925361213549,\n",
              "    0.7281382463365546,\n",
              "    0.9988728629966352,\n",
              "    0.9999999317236823,\n",
              "    0.9998296974431271,\n",
              "    0.9144997358478257,\n",
              "    0.9998122932691133,\n",
              "    0.9999003880356012,\n",
              "    0.9999905095960342,\n",
              "    0.9973798779273919,\n",
              "    0.999674666032576,\n",
              "    0.9999838349316561,\n",
              "    0.9999174351986608],\n",
              "   'generated_text': ' a printed armature or pancake motor has the windings shaped as a disc',\n",
              "   'generated_tokens': [' a',\n",
              "    ' printed',\n",
              "    ' arm',\n",
              "    'ature',\n",
              "    ' or',\n",
              "    ' panc',\n",
              "    'ake',\n",
              "    ' motor',\n",
              "    ' has',\n",
              "    ' the',\n",
              "    ' wind',\n",
              "    'ings',\n",
              "    ' shaped',\n",
              "    ' as',\n",
              "    ' a',\n",
              "    ' disc'],\n",
              "   'id': '56dfb6d17aa994140058e057',\n",
              "   'prediction': ' a printed armature or pancake motor has the windings shaped as a disc',\n",
              "   'prompt': 'Title: Electric motor\\n\\nBackground: a \"voice coil\" structure, because some earlier rigid-disk-drive heads moved in straight lines, and had a drive structure much like that of a loudspeaker. A rather unusual motor design, the printed armature or pancake motor has the windings shaped as a disc running between arrays of high-flux magnets. The magnets are arranged in a circle facing the rotor with space in between to form an axial air gap. This design is commonly known as the pancake motor because of its extremely flat profile, although the technology has had many brand names since its inception, such as ServoDisc. The printed armature\\n\\nQ: what sort of design was this motor?\\n\\nA:',\n",
              "   'question': 'what sort of design was this motor?'},\n",
              "  {'answers': ['UMC', 'the UMC', 'the UMC'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' The United Methodist Church is generally considered one of the more moderate and tolerant denominations with',\n",
              "   'generated_answer_probs': [0.8810076497967003,\n",
              "    0.9880392275741836,\n",
              "    0.9992056370734135,\n",
              "    0.998759555687863,\n",
              "    0.4855377205675028,\n",
              "    0.9832197130924631,\n",
              "    0.9998827433151025,\n",
              "    0.9526733345568416,\n",
              "    0.9999006273677872,\n",
              "    0.9999920621045053,\n",
              "    0.999971318293328,\n",
              "    0.9999167190740489,\n",
              "    0.9945939386291807,\n",
              "    0.9992796649659378,\n",
              "    0.9999567734772931,\n",
              "    0.9729270557530296],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' United',\n",
              "    ' Methodist',\n",
              "    ' Church',\n",
              "    ' is',\n",
              "    ' generally',\n",
              "    ' considered',\n",
              "    ' one',\n",
              "    ' of',\n",
              "    ' the',\n",
              "    ' more',\n",
              "    ' moderate',\n",
              "    ' and',\n",
              "    ' tolerant',\n",
              "    ' denominations',\n",
              "    ' with'],\n",
              "   'generated_probs': [0.8810076497967003,\n",
              "    0.9880392275741836,\n",
              "    0.9992056370734135,\n",
              "    0.998759555687863,\n",
              "    0.4855377205675028,\n",
              "    0.9832197130924631,\n",
              "    0.9998827433151025,\n",
              "    0.9526733345568416,\n",
              "    0.9999006273677872,\n",
              "    0.9999920621045053,\n",
              "    0.999971318293328,\n",
              "    0.9999167190740489,\n",
              "    0.9945939386291807,\n",
              "    0.9992796649659378,\n",
              "    0.9999567734772931,\n",
              "    0.9729270557530296],\n",
              "   'generated_text': ' The United Methodist Church is generally considered one of the more moderate and tolerant denominations with',\n",
              "   'generated_tokens': [' The',\n",
              "    ' United',\n",
              "    ' Methodist',\n",
              "    ' Church',\n",
              "    ' is',\n",
              "    ' generally',\n",
              "    ' considered',\n",
              "    ' one',\n",
              "    ' of',\n",
              "    ' the',\n",
              "    ' more',\n",
              "    ' moderate',\n",
              "    ' and',\n",
              "    ' tolerant',\n",
              "    ' denominations',\n",
              "    ' with'],\n",
              "   'id': '5730b07c8ab72b1400f9c698',\n",
              "   'prediction': ' The United Methodist Church is generally considered one of the more moderate and tolerant denominations with',\n",
              "   'prompt': 'Title: United Methodist Church\\n\\nBackground: Church believes in \"prima scriptura\", seeing the Holy Bible as the primary authority in the Church and using sacred tradition, reason, and experience to interpret it, with the aid of the Holy Spirit (see Wesleyan Quadrilateral). Therefore, according to \"The Book of Discipline,\" United Methodist theology is at once \"catholic, evangelical, and reformed.\" Today, the UMC is generally considered one of the more moderate and tolerant denominations with respect to race, gender, and ideology, though the denomination itself actually includes a very wide spectrum of attitudes. Comparatively, the UMC stands to the right of liberal and progressive Protestant groups such\\n\\nQ: Today, which church is generally considered one of the more moderate and tolerant denominations?\\n\\nA:',\n",
              "   'question': 'Today, which church is generally considered one of the more moderate and tolerant denominations?'},\n",
              "  {'answers': ['1986', '1986', '1986'],\n",
              "   'em': 0,\n",
              "   'f1': 0.2222222222222222,\n",
              "   'generated_answer': ' The gallery of Japanese art opened in December 1986.',\n",
              "   'generated_answer_probs': [0.9532634506854313,\n",
              "    0.7730506102718339,\n",
              "    0.9995958077577022,\n",
              "    0.9999865776240809,\n",
              "    0.9997438076228732,\n",
              "    0.9987817865252137,\n",
              "    0.9995814429194648,\n",
              "    0.9962321211368512,\n",
              "    0.9995486616638041,\n",
              "    0.9499854692793014],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' gallery',\n",
              "    ' of',\n",
              "    ' Japanese',\n",
              "    ' art',\n",
              "    ' opened',\n",
              "    ' in',\n",
              "    ' December',\n",
              "    ' 1986',\n",
              "    '.'],\n",
              "   'generated_probs': [0.9532634506854313,\n",
              "    0.7730506102718339,\n",
              "    0.9995958077577022,\n",
              "    0.9999865776240809,\n",
              "    0.9997438076228732,\n",
              "    0.9987817865252137,\n",
              "    0.9995814429194648,\n",
              "    0.9962321211368512,\n",
              "    0.9995486616638041,\n",
              "    0.9499854692793014],\n",
              "   'generated_text': ' The gallery of Japanese art opened in December 1986.',\n",
              "   'generated_tokens': [' The',\n",
              "    ' gallery',\n",
              "    ' of',\n",
              "    ' Japanese',\n",
              "    ' art',\n",
              "    ' opened',\n",
              "    ' in',\n",
              "    ' December',\n",
              "    ' 1986',\n",
              "    '.'],\n",
              "   'id': '5726c4b5dd62a815002e8fd9',\n",
              "   'prediction': ' The gallery of Japanese art opened in December 1986.',\n",
              "   'prompt': 'Title: Victoria and Albert Museum\\n\\nBackground: manufacturing are displayed that include lacquer, silk, porcelain, jade and cloisonné enamel. Two large ancestor portraits of a husband and wife painted in watercolour on silk date from the 18th century. There is a unique Chinese lacquerware table, made in the imperial workshops during the reign of the Xuande Emperor in the Ming dynasty. Examples of clothing are also displayed. One of the largest objects is a bed from the mid-17th century. The work of contemporary Chinese designers is also displayed. The Toshiba gallery of Japanese art opened in December 1986. The majority of exhibits date from 1550 to 1900,\\n\\nQ: In which year did the gallery of Japanese art open?\\n\\nA:',\n",
              "   'question': 'In which year did the gallery of Japanese art open?'},\n",
              "  {'answers': ['an algorithm', 'an algorithm', 'an algorithm'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' algorithms.',\n",
              "   'generated_answer_probs': [0.2826112219103837, 0.6121836559908124],\n",
              "   'generated_answer_tokens': [' algorithms', '.'],\n",
              "   'generated_probs': [0.2826112219103837, 0.6121836559908124],\n",
              "   'generated_text': ' algorithms.',\n",
              "   'generated_tokens': [' algorithms', '.'],\n",
              "   'id': '56e1aba0e3433e1400423095',\n",
              "   'prediction': ' algorithms.',\n",
              "   'prompt': 'Title: Computational complexity theory\\n\\nBackground: computing machine. It is a theoretical device that manipulates symbols contained on a strip of tape. Turing machines are not intended as a practical computing technology, but rather as a thought experiment representing a computing machine—anything from an advanced supercomputer to a mathematician with a pencil and paper. It is believed that if a problem can be solved by an algorithm, there exists a Turing machine that solves the problem. Indeed, this is the statement of the Church–Turing thesis. Furthermore, it is known that everything that can be computed on other models of computation known to us today, such as\\n\\nQ: It is generally assumed that a Turing machine can solve anything capable of also being solved using what?\\n\\nA:',\n",
              "   'question': 'It is generally assumed that a Turing machine can solve anything capable of also being solved using what?'},\n",
              "  {'answers': ['Oliver', 'Oliver', 'Oliver'],\n",
              "   'em': 0,\n",
              "   'f1': 0.19999999999999998,\n",
              "   'generated_answer': ' Oliver on \"Coupling\" is portrayed as a \"Doctor Who\" collector',\n",
              "   'generated_answer_probs': [0.6925403814898751,\n",
              "    0.7662116055013762,\n",
              "    0.8832335917900611,\n",
              "    0.9999794242856829,\n",
              "    0.9999871717882822,\n",
              "    0.9999906297369012,\n",
              "    0.9890995403023727,\n",
              "    0.9628610945571946,\n",
              "    0.5747033984803616,\n",
              "    0.9999926553342722,\n",
              "    0.9998946647281494,\n",
              "    0.9881715536597919,\n",
              "    0.9997534657745578,\n",
              "    0.999976324927259,\n",
              "    0.9999928937497495,\n",
              "    0.9995917563241361],\n",
              "   'generated_answer_tokens': [' Oliver',\n",
              "    ' on',\n",
              "    ' \"',\n",
              "    'C',\n",
              "    'ou',\n",
              "    'pling',\n",
              "    '\"',\n",
              "    ' is',\n",
              "    ' portrayed',\n",
              "    ' as',\n",
              "    ' a',\n",
              "    ' \"',\n",
              "    'Doctor',\n",
              "    ' Who',\n",
              "    '\"',\n",
              "    ' collector'],\n",
              "   'generated_probs': [0.6925403814898751,\n",
              "    0.7662116055013762,\n",
              "    0.8832335917900611,\n",
              "    0.9999794242856829,\n",
              "    0.9999871717882822,\n",
              "    0.9999906297369012,\n",
              "    0.9890995403023727,\n",
              "    0.9628610945571946,\n",
              "    0.5747033984803616,\n",
              "    0.9999926553342722,\n",
              "    0.9998946647281494,\n",
              "    0.9881715536597919,\n",
              "    0.9997534657745578,\n",
              "    0.999976324927259,\n",
              "    0.9999928937497495,\n",
              "    0.9995917563241361],\n",
              "   'generated_text': ' Oliver on \"Coupling\" is portrayed as a \"Doctor Who\" collector',\n",
              "   'generated_tokens': [' Oliver',\n",
              "    ' on',\n",
              "    ' \"',\n",
              "    'C',\n",
              "    'ou',\n",
              "    'pling',\n",
              "    '\"',\n",
              "    ' is',\n",
              "    ' portrayed',\n",
              "    ' as',\n",
              "    ' a',\n",
              "    ' \"',\n",
              "    'Doctor',\n",
              "    ' Who',\n",
              "    '\"',\n",
              "    ' collector'],\n",
              "   'id': '572833662ca10214002da089',\n",
              "   'prediction': ' Oliver on \"Coupling\" is portrayed as a \"Doctor Who\" collector',\n",
              "   'prompt': 'Title: Doctor Who\\n\\nBackground: of Oliver on \"Coupling\" (created and written by current show runner Steven Moffat) is portrayed as a \"Doctor Who\" collector and enthusiast. References to \"Doctor Who\" have also appeared in the young adult fantasy novels \"Brisingr\" and \"High Wizardry\", the video game \"Rock Band\", the soap opera \"EastEnders\", the Adult Swim comedy show \"Robot Chicken\", the \"Family Guy\" episodes \"Blue Harvest\" and \"420\", and the game \"RuneScape\". It has also be referenced in \"Destroy All Humans! 2\", by civilians in the game\\'s variation of England, and in \"\". \"Doctor Who\" has been a reference in several political cartoons, from a\\n\\nQ: What character on Coupling is a Doctor Who fan?\\n\\nA:',\n",
              "   'question': 'What character on Coupling is a Doctor Who fan?'},\n",
              "  {'answers': ['1968', '1968', '1968'],\n",
              "   'em': 0,\n",
              "   'f1': 0.16666666666666669,\n",
              "   'generated_answer': ' The UMC was formed in 1968 when the Methodist Church and the Evangelical United',\n",
              "   'generated_answer_probs': [0.8236504501982729,\n",
              "    0.5066708486142869,\n",
              "    0.9998256431519223,\n",
              "    0.9790811854251839,\n",
              "    0.9599251608567306,\n",
              "    0.649788710308565,\n",
              "    0.9981404979202156,\n",
              "    0.39484306374619493,\n",
              "    0.9919513809871607,\n",
              "    0.9952784402739494,\n",
              "    0.9982880225081429,\n",
              "    0.9677248403022767,\n",
              "    0.9997347482454688,\n",
              "    0.9995753639534171,\n",
              "    0.9999937300764561,\n",
              "    0.9999646428180798],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' U',\n",
              "    'MC',\n",
              "    ' was',\n",
              "    ' formed',\n",
              "    ' in',\n",
              "    ' 1968',\n",
              "    ' when',\n",
              "    ' the',\n",
              "    ' Methodist',\n",
              "    ' Church',\n",
              "    ' and',\n",
              "    ' the',\n",
              "    ' Evangel',\n",
              "    'ical',\n",
              "    ' United'],\n",
              "   'generated_probs': [0.8236504501982729,\n",
              "    0.5066708486142869,\n",
              "    0.9998256431519223,\n",
              "    0.9790811854251839,\n",
              "    0.9599251608567306,\n",
              "    0.649788710308565,\n",
              "    0.9981404979202156,\n",
              "    0.39484306374619493,\n",
              "    0.9919513809871607,\n",
              "    0.9952784402739494,\n",
              "    0.9982880225081429,\n",
              "    0.9677248403022767,\n",
              "    0.9997347482454688,\n",
              "    0.9995753639534171,\n",
              "    0.9999937300764561,\n",
              "    0.9999646428180798],\n",
              "   'generated_text': ' The UMC was formed in 1968 when the Methodist Church and the Evangelical United',\n",
              "   'generated_tokens': [' The',\n",
              "    ' U',\n",
              "    'MC',\n",
              "    ' was',\n",
              "    ' formed',\n",
              "    ' in',\n",
              "    ' 1968',\n",
              "    ' when',\n",
              "    ' the',\n",
              "    ' Methodist',\n",
              "    ' Church',\n",
              "    ' and',\n",
              "    ' the',\n",
              "    ' Evangel',\n",
              "    'ical',\n",
              "    ' United'],\n",
              "   'id': '5730ab288ab72b1400f9c655',\n",
              "   'prediction': ' The UMC was formed in 1968 when the Methodist Church and the Evangelical United',\n",
              "   'prompt': \"Title: United Methodist Church\\n\\nBackground: United Methodist Church The United Methodist Church (UMC) is a mainline Protestant denomination, and a major part of Methodism. In the 19th century, its main predecessor—the Methodist Church—was a leader in Evangelicalism. It was founded in 1968 in Dallas, Texas, United States, by union of the Methodist Church and the Evangelical United Brethren Church. The UMC traces its roots back to the revival movement of John and Charles Wesley in England as well as the Great Awakening in the United States. As such, the church's theological orientation is decidedly Wesleyan. It embraces both liturgical and evangelical elements. It has a\\n\\nQ: When was the UMC formed?\\n\\nA:\",\n",
              "   'question': 'When was the UMC formed?'},\n",
              "  {'answers': ['the assassination of John F. Kennedy',\n",
              "    'the assassination of John F. Kennedy',\n",
              "    'the assassination of John F. Kennedy'],\n",
              "   'em': 0,\n",
              "   'f1': 0.1111111111111111,\n",
              "   'generated_answer': ' The first episode of Doctor Who premiered the day after the death of Queen Elizabeth II',\n",
              "   'generated_answer_probs': [0.880340310313506,\n",
              "    0.8350519754671872,\n",
              "    0.9983528099091785,\n",
              "    0.9989983929435425,\n",
              "    0.9939859094794812,\n",
              "    0.9999388959169305,\n",
              "    0.9725978612670619,\n",
              "    0.6422916018015266,\n",
              "    0.9998901352855698,\n",
              "    0.9997576351751006,\n",
              "    0.9021577636005518,\n",
              "    0.3215583688982324,\n",
              "    0.999951051724006,\n",
              "    0.5098117189277453,\n",
              "    0.9734620071487748,\n",
              "    0.8736007023672536],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' first',\n",
              "    ' episode',\n",
              "    ' of',\n",
              "    ' Doctor',\n",
              "    ' Who',\n",
              "    ' premiered',\n",
              "    ' the',\n",
              "    ' day',\n",
              "    ' after',\n",
              "    ' the',\n",
              "    ' death',\n",
              "    ' of',\n",
              "    ' Queen',\n",
              "    ' Elizabeth',\n",
              "    ' II'],\n",
              "   'generated_probs': [0.880340310313506,\n",
              "    0.8350519754671872,\n",
              "    0.9983528099091785,\n",
              "    0.9989983929435425,\n",
              "    0.9939859094794812,\n",
              "    0.9999388959169305,\n",
              "    0.9725978612670619,\n",
              "    0.6422916018015266,\n",
              "    0.9998901352855698,\n",
              "    0.9997576351751006,\n",
              "    0.9021577636005518,\n",
              "    0.3215583688982324,\n",
              "    0.999951051724006,\n",
              "    0.5098117189277453,\n",
              "    0.9734620071487748,\n",
              "    0.8736007023672536],\n",
              "   'generated_text': ' The first episode of Doctor Who premiered the day after the death of Queen Elizabeth II',\n",
              "   'generated_tokens': [' The',\n",
              "    ' first',\n",
              "    ' episode',\n",
              "    ' of',\n",
              "    ' Doctor',\n",
              "    ' Who',\n",
              "    ' premiered',\n",
              "    ' the',\n",
              "    ' day',\n",
              "    ' after',\n",
              "    ' the',\n",
              "    ' death',\n",
              "    ' of',\n",
              "    ' Queen',\n",
              "    ' Elizabeth',\n",
              "    ' II'],\n",
              "   'id': '57282036ff5b5019007d9d9c',\n",
              "   'prediction': ' The first episode of Doctor Who premiered the day after the death of Queen Elizabeth II',\n",
              "   'prompt': 'Title: Whose Doctor Who\\n\\nBackground: Whose Doctor Who Whose Doctor Who (a.k.a. \\'Whose Dr. Who\\') was a 60-minute television documentary, (part of the BBC\\'s The Lively Arts series) which was first transmitted on Sunday, 3 April 1977, on BBC 2. The programme was the first in-depth documentary chronicling the long-running BBC TV series \"Doctor Who\", being first broadcast the day after the final episode of the show\\'s fourteenth season was transmitted on BBC1. Introduced by Melvyn Bragg, the programme features many clips from episodes of the show transmitted to date, along with interviews of cast and fans, including families, children, students, teachers, psychologists and educationalists.\\n\\nQ: The first episode of Doctor Who premiered the day after what famous event in history?\\n\\nA:',\n",
              "   'question': 'The first episode of Doctor Who premiered the day after what famous event in history?'},\n",
              "  {'answers': ['Ogedei', 'Ogedei', 'Ogedei'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' Genghis Khan',\n",
              "   'generated_answer_probs': [0.6929535219046832,\n",
              "    0.9999989771165232,\n",
              "    0.9999948020155096,\n",
              "    0.9997197254542509],\n",
              "   'generated_answer_tokens': [' Gen', 'gh', 'is', ' Khan'],\n",
              "   'generated_probs': [0.6929535219046832,\n",
              "    0.9999989771165232,\n",
              "    0.9999948020155096,\n",
              "    0.9997197254542509],\n",
              "   'generated_text': ' Genghis Khan',\n",
              "   'generated_tokens': [' Gen', 'gh', 'is', ' Khan'],\n",
              "   'id': '572867d72ca10214002da2fc',\n",
              "   'prediction': ' Genghis Khan',\n",
              "   'prompt': 'Title: Kaidu\\n\\nBackground: great-grandson of Genghis Khan and Börte. His mother\\'s name was Shabkana Khatun from the Bekrin (Mekrin) tribe of mountaineers that were \"neither Mongols, nor Uighurs\". In 1260, Marco Polo described Yarkand, part of the area under Kaidu as \"five days\\' journey in extent\"; that its inhabitants were mostly Muslim although there were also some Nestorian and Jacobite Assyrians; and that it had plenty of food and other necessities, \"especially cotton.\" In the Toluid Civil War between 1260 and 1264, Kublai Khan was warring with his own brother Ariq Böke, who was proclaimed Great Khan at Karakorum, Kaidu began to have\\n\\nQ: Who was Kaidu\\'s grandfather?\\n\\nA:',\n",
              "   'question': \"Who was Kaidu's grandfather?\"},\n",
              "  {'answers': ['Chris Chibnall', 'Chris Chibnall', 'Chris Chibnall'],\n",
              "   'em': 1,\n",
              "   'f1': 1.0,\n",
              "   'generated_answer': ' Chris Chibnall',\n",
              "   'generated_answer_probs': [0.9761059881978367,\n",
              "    0.9999257791645025,\n",
              "    0.9999964709302271,\n",
              "    0.999988721478603,\n",
              "    0.9999771565609153],\n",
              "   'generated_answer_tokens': [' Chris', ' Ch', 'ib', 'n', 'all'],\n",
              "   'generated_probs': [0.9761059881978367,\n",
              "    0.9999257791645025,\n",
              "    0.9999964709302271,\n",
              "    0.999988721478603,\n",
              "    0.9999771565609153],\n",
              "   'generated_text': ' Chris Chibnall',\n",
              "   'generated_tokens': [' Chris', ' Ch', 'ib', 'n', 'all'],\n",
              "   'id': '5727f746ff5b5019007d9964',\n",
              "   'prediction': ' Chris Chibnall',\n",
              "   'prompt': 'Title: Doctor Who\\n\\nBackground: Moffat replaced Davies as head writer and executive producer. In January 2016, Moffat announced that he would step down after the 2017 finale, to be replaced by Chris Chibnall in 2018. In addition, Series 10 will debut in Spring 2017, with a Christmas special broadcast in 2016. The 2005 version of \"Doctor Who\" is a direct plot continuation of the original 1963–1989 series and the 1996 telefilm. This is similar to the 1988 continuation of , but differs from most other series relaunches which have either been reboots (for example, \"Battlestar Galactica\" and \"Bionic Woman\") or set in the same\\n\\nQ: Who will be the new executive producer of Doctor Who in 2018?\\n\\nA:',\n",
              "   'question': 'Who will be the new executive producer of Doctor Who in 2018?'},\n",
              "  {'answers': ['the crust and rigid uppermost portion of the upper mantle',\n",
              "    'crust and rigid uppermost portion of the upper mantle',\n",
              "    'crust and rigid uppermost portion of the upper mantle',\n",
              "    'crust and rigid uppermost portion of the upper mantle'],\n",
              "   'em': 0,\n",
              "   'f1': 0.888888888888889,\n",
              "   'generated_answer': ' The lithosphere includes the crust and rigid uppermost portion of the upper mantle.',\n",
              "   'generated_answer_probs': [0.9829198424051327,\n",
              "    0.9988769171301515,\n",
              "    0.9999334089132849,\n",
              "    0.48513542510531266,\n",
              "    0.9878630966294218,\n",
              "    0.9718869605646011,\n",
              "    0.960811366539116,\n",
              "    0.7329458898083012,\n",
              "    0.9984809025983094,\n",
              "    0.9994679557857451,\n",
              "    0.9948238937443955,\n",
              "    0.9999324553112452,\n",
              "    0.9999765642766208,\n",
              "    0.9981009809227781,\n",
              "    0.9999541538159684,\n",
              "    0.988789952141041],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' lith',\n",
              "    'osphere',\n",
              "    ' includes',\n",
              "    ' the',\n",
              "    ' crust',\n",
              "    ' and',\n",
              "    ' rigid',\n",
              "    ' upper',\n",
              "    'most',\n",
              "    ' portion',\n",
              "    ' of',\n",
              "    ' the',\n",
              "    ' upper',\n",
              "    ' mantle',\n",
              "    '.'],\n",
              "   'generated_probs': [0.9829198424051327,\n",
              "    0.9988769171301515,\n",
              "    0.9999334089132849,\n",
              "    0.48513542510531266,\n",
              "    0.9878630966294218,\n",
              "    0.9718869605646011,\n",
              "    0.960811366539116,\n",
              "    0.7329458898083012,\n",
              "    0.9984809025983094,\n",
              "    0.9994679557857451,\n",
              "    0.9948238937443955,\n",
              "    0.9999324553112452,\n",
              "    0.9999765642766208,\n",
              "    0.9981009809227781,\n",
              "    0.9999541538159684,\n",
              "    0.988789952141041],\n",
              "   'generated_text': ' The lithosphere includes the crust and rigid uppermost portion of the upper mantle.',\n",
              "   'generated_tokens': [' The',\n",
              "    ' lith',\n",
              "    'osphere',\n",
              "    ' includes',\n",
              "    ' the',\n",
              "    ' crust',\n",
              "    ' and',\n",
              "    ' rigid',\n",
              "    ' upper',\n",
              "    'most',\n",
              "    ' portion',\n",
              "    ' of',\n",
              "    ' the',\n",
              "    ' upper',\n",
              "    ' mantle',\n",
              "    '.'],\n",
              "   'id': '57265d08708984140094c398',\n",
              "   'prediction': ' The lithosphere includes the crust and rigid uppermost portion of the upper mantle.',\n",
              "   'prompt': \"Title: Geology\\n\\nBackground: sedimentology, and paleoclimatology. In the 1960s, it was discovered that the Earth's lithosphere, including the crust and rigid uppermost portion of the upper mantle, is separated into a number of tectonic plates that move across the plastically deforming, solid, upper mantle, which is called the asthenosphere. This theory is supported by a number of observations, including seafloor spreading, and the global distribution of mountain terrain and seismicity. There is an intimate coupling between the movement of the plates on the surface and the convection of the mantle: oceanic plate motions and mantle convection currents always move in the same direction,\\n\\nQ: Which parts of the Earth are included in the lithosphere? \\n\\nA:\",\n",
              "   'question': 'Which parts of the Earth are included in the lithosphere? '},\n",
              "  {'answers': ['Ming dynasty', 'Ming dynasty', 'the Ming dynasty'],\n",
              "   'em': 1,\n",
              "   'f1': 1.0,\n",
              "   'generated_answer': ' The Ming dynasty.',\n",
              "   'generated_answer_probs': [0.9906659522106037,\n",
              "    0.9949460230360562,\n",
              "    0.9858310538898727,\n",
              "    0.7821556948348258],\n",
              "   'generated_answer_tokens': [' The', ' Ming', ' dynasty', '.'],\n",
              "   'generated_probs': [0.9906659522106037,\n",
              "    0.9949460230360562,\n",
              "    0.9858310538898727,\n",
              "    0.7821556948348258],\n",
              "   'generated_text': ' The Ming dynasty.',\n",
              "   'generated_tokens': [' The', ' Ming', ' dynasty', '.'],\n",
              "   'id': '572860e03acd2414000df979',\n",
              "   'prediction': ' The Ming dynasty.',\n",
              "   'prompt': \"Title: Yuan dynasty\\n\\nBackground: 1368, after which its Genghisid rulers returned to their Mongolian homeland and continued to rule the Northern Yuan dynasty. Some of the Mongolian Emperors of the Yuan mastered the Chinese language, while others only used their native language (i.e. Mongolian) and the 'Phags-pa script. The Yuan dynasty is considered both a successor to the Mongol Empire and an imperial Chinese dynasty. It was the khanate ruled by the successors of Möngke Khan after the division of the Mongol Empire. In official Chinese histories, the Yuan dynasty bore the Mandate of Heaven, following the Song dynasty and preceding the Ming dynasty.\\n\\nQ: What dynasty came after the Yuan?\\n\\nA:\",\n",
              "   'question': 'What dynasty came after the Yuan?'},\n",
              "  {'answers': ['The Cestida', 'Cestida', 'Cestida'],\n",
              "   'em': 0,\n",
              "   'f1': 0.25,\n",
              "   'generated_answer': ' The Cestida (\"belt animals\") are ribbon-shaped planktonic animals',\n",
              "   'generated_answer_probs': [0.6094817884491456,\n",
              "    0.6736435941445932,\n",
              "    0.9997551342845042,\n",
              "    0.9752193226238882,\n",
              "    0.6019300960102616,\n",
              "    0.9949957332735748,\n",
              "    0.9998168251785565,\n",
              "    0.994164482860868,\n",
              "    0.9991915105038973,\n",
              "    0.9966821419957718,\n",
              "    0.9998324368902664,\n",
              "    0.9998038282741898,\n",
              "    0.9996433708073138,\n",
              "    0.9999934907225855,\n",
              "    0.99999909445401,\n",
              "    0.9996389626196861],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' C',\n",
              "    'est',\n",
              "    'ida',\n",
              "    ' (\"',\n",
              "    'belt',\n",
              "    ' animals',\n",
              "    '\")',\n",
              "    ' are',\n",
              "    ' ribbon',\n",
              "    '-',\n",
              "    'shaped',\n",
              "    ' plank',\n",
              "    'ton',\n",
              "    'ic',\n",
              "    ' animals'],\n",
              "   'generated_probs': [0.6094817884491456,\n",
              "    0.6736435941445932,\n",
              "    0.9997551342845042,\n",
              "    0.9752193226238882,\n",
              "    0.6019300960102616,\n",
              "    0.9949957332735748,\n",
              "    0.9998168251785565,\n",
              "    0.994164482860868,\n",
              "    0.9991915105038973,\n",
              "    0.9966821419957718,\n",
              "    0.9998324368902664,\n",
              "    0.9998038282741898,\n",
              "    0.9996433708073138,\n",
              "    0.9999934907225855,\n",
              "    0.99999909445401,\n",
              "    0.9996389626196861],\n",
              "   'generated_text': ' The Cestida (\"belt animals\") are ribbon-shaped planktonic animals',\n",
              "   'generated_tokens': [' The',\n",
              "    ' C',\n",
              "    'est',\n",
              "    'ida',\n",
              "    ' (\"',\n",
              "    'belt',\n",
              "    ' animals',\n",
              "    '\")',\n",
              "    ' are',\n",
              "    ' ribbon',\n",
              "    '-',\n",
              "    'shaped',\n",
              "    ' plank',\n",
              "    'ton',\n",
              "    'ic',\n",
              "    ' animals'],\n",
              "   'id': '57265e97708984140094c3c3',\n",
              "   'prediction': ' The Cestida (\"belt animals\") are ribbon-shaped planktonic animals',\n",
              "   'prompt': 'Title: Ctenophora\\n\\nBackground: than oval in cross-section, and the pharynx extends over the inner surfaces of the lobes. The Thalassocalycida, only discovered in 1978 and known from only one species, are medusa-like, with bodies that are shortened in the oral-aboral direction, and short comb-rows on the surface furthest from the mouth, originating from near the aboral pole. They capture prey by movements of the bell and possibly by using two short tentacles. The Cestida (\"belt animals\") are ribbon-shaped planktonic animals, with the mouth and aboral organ aligned in the middle of opposite edges of the ribbon. There is a pair of comb-rows along\\n\\nQ: Which species are ribbon-shaped planktonic animals?\\n\\nA:',\n",
              "   'question': 'Which species are ribbon-shaped planktonic animals?'},\n",
              "  {'answers': ['8 November 2010', '8 November 2010', '8 November 2010'],\n",
              "   'em': 0,\n",
              "   'f1': 0.26666666666666666,\n",
              "   'generated_answer': ' The soundtrack for series 5 of \"Doctor Who\" was released on November 8,',\n",
              "   'generated_answer_probs': [0.9441094913150544,\n",
              "    0.9984865642007745,\n",
              "    0.9542222921854974,\n",
              "    0.9966914991906495,\n",
              "    0.999392555669055,\n",
              "    0.755274008808875,\n",
              "    0.9900908875117009,\n",
              "    0.9991296415818041,\n",
              "    0.9999247054247788,\n",
              "    0.9998401870014579,\n",
              "    0.9998459100030833,\n",
              "    0.9995106970477531,\n",
              "    0.9995042563215241,\n",
              "    0.991181771669746,\n",
              "    0.999852108846975,\n",
              "    0.9900200772585477],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' soundtrack',\n",
              "    ' for',\n",
              "    ' series',\n",
              "    ' 5',\n",
              "    ' of',\n",
              "    ' \"',\n",
              "    'Doctor',\n",
              "    ' Who',\n",
              "    '\"',\n",
              "    ' was',\n",
              "    ' released',\n",
              "    ' on',\n",
              "    ' November',\n",
              "    ' 8',\n",
              "    ','],\n",
              "   'generated_probs': [0.9441094913150544,\n",
              "    0.9984865642007745,\n",
              "    0.9542222921854974,\n",
              "    0.9966914991906495,\n",
              "    0.999392555669055,\n",
              "    0.755274008808875,\n",
              "    0.9900908875117009,\n",
              "    0.9991296415818041,\n",
              "    0.9999247054247788,\n",
              "    0.9998401870014579,\n",
              "    0.9998459100030833,\n",
              "    0.9995106970477531,\n",
              "    0.9995042563215241,\n",
              "    0.991181771669746,\n",
              "    0.999852108846975,\n",
              "    0.9900200772585477],\n",
              "   'generated_text': ' The soundtrack for series 5 of \"Doctor Who\" was released on November 8,',\n",
              "   'generated_tokens': [' The',\n",
              "    ' soundtrack',\n",
              "    ' for',\n",
              "    ' series',\n",
              "    ' 5',\n",
              "    ' of',\n",
              "    ' \"',\n",
              "    'Doctor',\n",
              "    ' Who',\n",
              "    '\"',\n",
              "    ' was',\n",
              "    ' released',\n",
              "    ' on',\n",
              "    ' November',\n",
              "    ' 8',\n",
              "    ','],\n",
              "   'id': '57281cb22ca10214002d9e22',\n",
              "   'prediction': ' The soundtrack for series 5 of \"Doctor Who\" was released on November 8,',\n",
              "   'prompt': 'Title: Doctor Who: Series 5 (soundtrack)\\n\\nBackground: Doctor Who: Series 5 (soundtrack) The soundtrack for series 5 of \"Doctor Who\" was released on November 8, 2010, and is the second 2 disc edition to be released by Silva Screen Records since the series was revived in 2005. As with the Specials soundtrack, iTunes UK offered two bonus tracks and a digital book download. Series 5 introduced several new themes, most of which were introduced in \"The Eleventh Hour\". Such new material included two new themes for the Doctor, entitled \"I Am the Doctor\" and \"The Mad Man with a Box\"; along with multiple themes associated with Amelia\\n\\nQ: When was the soundtrack for series 5 released?\\n\\nA:',\n",
              "   'question': 'When was the soundtrack for series 5 released?'},\n",
              "  {'answers': ['a river', 'a river', 'a river'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' Legend says that Genghis Khan used his army to obliterate the Kharez',\n",
              "   'generated_answer_probs': [0.5032909231669205,\n",
              "    0.5453137019525751,\n",
              "    0.5938863784422485,\n",
              "    0.9349453599099832,\n",
              "    0.9999995722265915,\n",
              "    0.9999969487016552,\n",
              "    0.9990519160158886,\n",
              "    0.8903168841676546,\n",
              "    0.42715578338724486,\n",
              "    0.49841107033897664,\n",
              "    0.9650693451170993,\n",
              "    0.9558263640402319,\n",
              "    0.9999932532447594,\n",
              "    0.9992558847911395,\n",
              "    0.869560228166625,\n",
              "    0.9996643517824708],\n",
              "   'generated_answer_tokens': [' Legend',\n",
              "    ' says',\n",
              "    ' that',\n",
              "    ' Gen',\n",
              "    'gh',\n",
              "    'is',\n",
              "    ' Khan',\n",
              "    ' used',\n",
              "    ' his',\n",
              "    ' army',\n",
              "    ' to',\n",
              "    ' obliter',\n",
              "    'ate',\n",
              "    ' the',\n",
              "    ' Kh',\n",
              "    'arez'],\n",
              "   'generated_probs': [0.5032909231669205,\n",
              "    0.5453137019525751,\n",
              "    0.5938863784422485,\n",
              "    0.9349453599099832,\n",
              "    0.9999995722265915,\n",
              "    0.9999969487016552,\n",
              "    0.9990519160158886,\n",
              "    0.8903168841676546,\n",
              "    0.42715578338724486,\n",
              "    0.49841107033897664,\n",
              "    0.9650693451170993,\n",
              "    0.9558263640402319,\n",
              "    0.9999932532447594,\n",
              "    0.9992558847911395,\n",
              "    0.869560228166625,\n",
              "    0.9996643517824708],\n",
              "   'generated_text': ' Legend says that Genghis Khan used his army to obliterate the Kharez',\n",
              "   'generated_tokens': [' Legend',\n",
              "    ' says',\n",
              "    ' that',\n",
              "    ' Gen',\n",
              "    'gh',\n",
              "    'is',\n",
              "    ' Khan',\n",
              "    ' used',\n",
              "    ' his',\n",
              "    ' army',\n",
              "    ' to',\n",
              "    ' obliter',\n",
              "    'ate',\n",
              "    ' the',\n",
              "    ' Kh',\n",
              "    'arez'],\n",
              "   'id': '5726c4c8708984140094d0f7',\n",
              "   'prediction': ' Legend says that Genghis Khan used his army to obliterate the Kharez',\n",
              "   'prompt': \"Title: Genghis Khan\\n\\nBackground: the legend that the princess hid a small dagger and stabbed him, though some Mongol authors have doubted this version and suspected it to be an invention by the rival Oirads. Years before his death, Genghis Khan asked to be buried without markings, according to the customs of his tribe. After he died, his body was returned to Mongolia and presumably to his birthplace in Khentii Aimag, where many assume he is buried somewhere close to the Onon River and the Burkhan Khaldun mountain (part of the Kentii mountain range). According to legend, the funeral escort killed anyone and anything\\n\\nQ: What does legend say Genghis Khan used to obliterate the Kharezmid emporer's place of birth?\\n\\nA:\",\n",
              "   'question': \"What does legend say Genghis Khan used to obliterate the Kharezmid emporer's place of birth?\"},\n",
              "  {'answers': ['energy content',\n",
              "    'its energy content',\n",
              "    'energy content',\n",
              "    'energy content',\n",
              "    'its energy content'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' Oxygen is necessary for life because it is a gas and it helps to form',\n",
              "   'generated_answer_probs': [0.9328934090989827,\n",
              "    0.9999837175965598,\n",
              "    0.9580120143641389,\n",
              "    0.8875142601384656,\n",
              "    0.839630227013638,\n",
              "    0.7274360409654785,\n",
              "    0.9932800110923476,\n",
              "    0.9919282549022462,\n",
              "    0.9095881393897975,\n",
              "    0.7537924606424969,\n",
              "    0.5628834996795349,\n",
              "    0.7008681766914955,\n",
              "    0.7136973971444972,\n",
              "    0.14475121048113876,\n",
              "    0.6215281968711107,\n",
              "    0.4937106806817718],\n",
              "   'generated_answer_tokens': [' Oxy',\n",
              "    'gen',\n",
              "    ' is',\n",
              "    ' necessary',\n",
              "    ' for',\n",
              "    ' life',\n",
              "    ' because',\n",
              "    ' it',\n",
              "    ' is',\n",
              "    ' a',\n",
              "    ' gas',\n",
              "    ' and',\n",
              "    ' it',\n",
              "    ' helps',\n",
              "    ' to',\n",
              "    ' form'],\n",
              "   'generated_probs': [0.9328934090989827,\n",
              "    0.9999837175965598,\n",
              "    0.9580120143641389,\n",
              "    0.8875142601384656,\n",
              "    0.839630227013638,\n",
              "    0.7274360409654785,\n",
              "    0.9932800110923476,\n",
              "    0.9919282549022462,\n",
              "    0.9095881393897975,\n",
              "    0.7537924606424969,\n",
              "    0.5628834996795349,\n",
              "    0.7008681766914955,\n",
              "    0.7136973971444972,\n",
              "    0.14475121048113876,\n",
              "    0.6215281968711107,\n",
              "    0.4937106806817718],\n",
              "   'generated_text': ' Oxygen is necessary for life because it is a gas and it helps to form',\n",
              "   'generated_tokens': [' Oxy',\n",
              "    'gen',\n",
              "    ' is',\n",
              "    ' necessary',\n",
              "    ' for',\n",
              "    ' life',\n",
              "    ' because',\n",
              "    ' it',\n",
              "    ' is',\n",
              "    ' a',\n",
              "    ' gas',\n",
              "    ' and',\n",
              "    ' it',\n",
              "    ' helps',\n",
              "    ' to',\n",
              "    ' form'],\n",
              "   'id': '571c91c8dd7acb1400e4c10d',\n",
              "   'prediction': ' Oxygen is necessary for life because it is a gas and it helps to form',\n",
              "   'prompt': \"Title: Abundance of the chemical elements\\n\\nBackground: composed of carbon-containing organic molecules. Oxygen therefore contributes a majority of a human body's mass, followed by carbon. Almost 99% of the mass of the human body is made up of six elements: oxygen, carbon, hydrogen, nitrogen, calcium, and phosphorus. The next 0.75% is made up of the next five elements: potassium, sulfur, chlorine, sodium, and magnesium. Only 17 elements are known for certain to be necessary to human life, with one additional element (fluorine) thought to be helpful for tooth enamel strength. A few more trace elements may play some role in the health of mammals. Boron and silicon\\n\\nQ: What characteristic of oxygen makes it necessary to life?\\n\\nA:\",\n",
              "   'question': 'What characteristic of oxygen makes it necessary to life?'},\n",
              "  {'answers': ['the general number field sieve',\n",
              "    'RSA',\n",
              "    'general number field sieve'],\n",
              "   'em': 0,\n",
              "   'f1': 0.14285714285714288,\n",
              "   'generated_answer': ' The most well-known algorithm associated with the integer factorization problem is the general',\n",
              "   'generated_answer_probs': [0.992426535904648,\n",
              "    0.6885379586113798,\n",
              "    0.99693635815776,\n",
              "    0.9982823600348809,\n",
              "    0.9999200566396408,\n",
              "    0.9966858373013318,\n",
              "    0.510519287757528,\n",
              "    0.9999653580450464,\n",
              "    0.992259284545503,\n",
              "    0.9968853954756017,\n",
              "    0.9998708239039504,\n",
              "    0.9999926553342722,\n",
              "    0.9999193433229246,\n",
              "    0.9993060102623496,\n",
              "    0.9732200744742574,\n",
              "    0.990705712395792],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' most',\n",
              "    ' well',\n",
              "    '-',\n",
              "    'known',\n",
              "    ' algorithm',\n",
              "    ' associated',\n",
              "    ' with',\n",
              "    ' the',\n",
              "    ' integer',\n",
              "    ' factor',\n",
              "    'ization',\n",
              "    ' problem',\n",
              "    ' is',\n",
              "    ' the',\n",
              "    ' general'],\n",
              "   'generated_probs': [0.992426535904648,\n",
              "    0.6885379586113798,\n",
              "    0.99693635815776,\n",
              "    0.9982823600348809,\n",
              "    0.9999200566396408,\n",
              "    0.9966858373013318,\n",
              "    0.510519287757528,\n",
              "    0.9999653580450464,\n",
              "    0.992259284545503,\n",
              "    0.9968853954756017,\n",
              "    0.9998708239039504,\n",
              "    0.9999926553342722,\n",
              "    0.9999193433229246,\n",
              "    0.9993060102623496,\n",
              "    0.9732200744742574,\n",
              "    0.990705712395792],\n",
              "   'generated_text': ' The most well-known algorithm associated with the integer factorization problem is the general',\n",
              "   'generated_tokens': [' The',\n",
              "    ' most',\n",
              "    ' well',\n",
              "    '-',\n",
              "    'known',\n",
              "    ' algorithm',\n",
              "    ' associated',\n",
              "    ' with',\n",
              "    ' the',\n",
              "    ' integer',\n",
              "    ' factor',\n",
              "    'ization',\n",
              "    ' problem',\n",
              "    ' is',\n",
              "    ' the',\n",
              "    ' general'],\n",
              "   'id': '56e1ec83cd28a01900c67c0e',\n",
              "   'prediction': ' The most well-known algorithm associated with the integer factorization problem is the general',\n",
              "   'prompt': 'Title: Computational complexity theory\\n\\nBackground: integer. Phrased as a decision problem, it is the problem of deciding whether the input has a prime factor less than \"k\". No efficient integer factorization algorithm is known, and this fact forms the basis of several modern cryptographic systems, such as the RSA algorithm. The integer factorization problem is in NP and in co-NP (and even in UP and co-UP). If the problem is NP-complete, the polynomial time hierarchy will collapse to its first level (i.e., NP will equal co-NP). The best known algorithm for integer factorization is the general number field sieve, which takes time formula_4 to factor\\n\\nQ: What is the most well-known algorithm associated with the integer factorization problem?\\n\\nA:',\n",
              "   'question': 'What is the most well-known algorithm associated with the integer factorization problem?'},\n",
              "  {'answers': ['a finite value', 'finite', 'finite', 'finite'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' If there were only finitely many primes, thenbytes: \\\\xcebytes:\\\\xb6(1)',\n",
              "   'generated_answer_probs': [0.7267072680243277,\n",
              "    0.9955466039080726,\n",
              "    0.9966025675786019,\n",
              "    0.685367752374471,\n",
              "    0.8694279694195127,\n",
              "    0.999997903306798,\n",
              "    0.9995955713033419,\n",
              "    0.7762705675863412,\n",
              "    0.9999993338092819,\n",
              "    0.7998768825260352,\n",
              "    0.7102374487489298,\n",
              "    0.5934935100728719,\n",
              "    0.9999987377612967,\n",
              "    0.9990865453039771,\n",
              "    0.9998600956275296,\n",
              "    0.9999886013379652],\n",
              "   'generated_answer_tokens': [' If',\n",
              "    ' there',\n",
              "    ' were',\n",
              "    ' only',\n",
              "    ' fin',\n",
              "    'itely',\n",
              "    ' many',\n",
              "    ' pr',\n",
              "    'imes',\n",
              "    ',',\n",
              "    ' then',\n",
              "    'bytes: \\\\xce',\n",
              "    'bytes:\\\\xb6',\n",
              "    '(',\n",
              "    '1',\n",
              "    ')'],\n",
              "   'generated_probs': [0.7267072680243277,\n",
              "    0.9955466039080726,\n",
              "    0.9966025675786019,\n",
              "    0.685367752374471,\n",
              "    0.8694279694195127,\n",
              "    0.999997903306798,\n",
              "    0.9995955713033419,\n",
              "    0.7762705675863412,\n",
              "    0.9999993338092819,\n",
              "    0.7998768825260352,\n",
              "    0.7102374487489298,\n",
              "    0.5934935100728719,\n",
              "    0.9999987377612967,\n",
              "    0.9990865453039771,\n",
              "    0.9998600956275296,\n",
              "    0.9999886013379652],\n",
              "   'generated_text': ' If there were only finitely many primes, then ζ(1)',\n",
              "   'generated_tokens': [' If',\n",
              "    ' there',\n",
              "    ' were',\n",
              "    ' only',\n",
              "    ' fin',\n",
              "    'itely',\n",
              "    ' many',\n",
              "    ' pr',\n",
              "    'imes',\n",
              "    ',',\n",
              "    ' then',\n",
              "    'bytes: \\\\xce',\n",
              "    'bytes:\\\\xb6',\n",
              "    '(',\n",
              "    '1',\n",
              "    ')'],\n",
              "   'id': '572989846aef051400154fc1',\n",
              "   'prediction': ' If there were only finitely many primes, thenbytes: \\\\xcebytes:\\\\xb6(1)',\n",
              "   'prompt': 'Title: Prime number\\n\\nBackground: are infinitely many primes can also be seen using the zeta function: if there were only finitely many primes then ζ(1) would have a finite value. However, the harmonic series diverges (i.e., exceeds any given number), so there must be infinitely many primes. Another example of the richness of the zeta function and a glimpse of modern algebraic number theory is the following identity (Basel problem), due to Euler, The reciprocal of ζ(2), 6/π, is the probability that two numbers selected at random are relatively prime. The unproven \"Riemann hypothesis\", dating from 1859, states that except for all zeroes of\\n\\nQ: What type of value would the zeta function have if there were finite primes?\\n\\nA:',\n",
              "   'question': 'What type of value would the zeta function have if there were finite primes?'},\n",
              "  {'answers': [\"the product of the host's cell membrane infolding to form a vesicle to surround the ancestral cyanobacterium\",\n",
              "    \"is the product of the host's cell membrane\",\n",
              "    \"is the product of the host's cell membrane infolding to form a vesicle to surround the ancestral cyanobacterium\"],\n",
              "   'em': 0,\n",
              "   'f1': 0.7200000000000001,\n",
              "   'generated_answer': \" That it is the product of the host's cell membrane infolding to form a\",\n",
              "   'generated_answer_probs': [0.4194870766939752,\n",
              "    0.8405854715407404,\n",
              "    0.9928800642997759,\n",
              "    0.9792960027556596,\n",
              "    0.9442263783610702,\n",
              "    0.9999384181762384,\n",
              "    0.9558793498316369,\n",
              "    0.9384853435182515,\n",
              "    0.7084470202456599,\n",
              "    0.999564875294225,\n",
              "    0.9999417539413675,\n",
              "    0.9764402504428029,\n",
              "    0.9998903727395073,\n",
              "    0.9995612996371572,\n",
              "    0.9999132613820114,\n",
              "    0.9999363898832093],\n",
              "   'generated_answer_tokens': [' That',\n",
              "    ' it',\n",
              "    ' is',\n",
              "    ' the',\n",
              "    ' product',\n",
              "    ' of',\n",
              "    ' the',\n",
              "    ' host',\n",
              "    \"'s\",\n",
              "    ' cell',\n",
              "    ' membrane',\n",
              "    ' inf',\n",
              "    'olding',\n",
              "    ' to',\n",
              "    ' form',\n",
              "    ' a'],\n",
              "   'generated_probs': [0.4194870766939752,\n",
              "    0.8405854715407404,\n",
              "    0.9928800642997759,\n",
              "    0.9792960027556596,\n",
              "    0.9442263783610702,\n",
              "    0.9999384181762384,\n",
              "    0.9558793498316369,\n",
              "    0.9384853435182515,\n",
              "    0.7084470202456599,\n",
              "    0.999564875294225,\n",
              "    0.9999417539413675,\n",
              "    0.9764402504428029,\n",
              "    0.9998903727395073,\n",
              "    0.9995612996371572,\n",
              "    0.9999132613820114,\n",
              "    0.9999363898832093],\n",
              "   'generated_text': \" That it is the product of the host's cell membrane infolding to form a\",\n",
              "   'generated_tokens': [' That',\n",
              "    ' it',\n",
              "    ' is',\n",
              "    ' the',\n",
              "    ' product',\n",
              "    ' of',\n",
              "    ' the',\n",
              "    ' host',\n",
              "    \"'s\",\n",
              "    ' cell',\n",
              "    ' membrane',\n",
              "    ' inf',\n",
              "    'olding',\n",
              "    ' to',\n",
              "    ' form',\n",
              "    ' a'],\n",
              "   'id': '57296d1b1d0469140077940e',\n",
              "   'prediction': \" That it is the product of the host's cell membrane infolding to form a\",\n",
              "   'prompt': \"Title: Chloroplast\\n\\nBackground: membranes surrounding these three. Inside the outer and inner chloroplast membranes is the chloroplast stroma, a semi-gel-like fluid that makes up much of a chloroplast's volume, and in which the thylakoid system floats. There are some common misconceptions about the outer and inner chloroplast membranes. The fact that chloroplasts are surrounded by a double membrane is often cited as evidence that they are the descendants of endosymbiotic cyanobacteria. This is often interpreted as meaning the outer chloroplast membrane is the product of the host's cell membrane infolding to form a vesicle to surround the ancestral cyanobacterium—which is not true—both chloroplast\\n\\nQ: What is incorrectly thought about the outer chloroplast membrane?\\n\\nA:\",\n",
              "   'question': 'What is incorrectly thought about the outer chloroplast membrane?'},\n",
              "  {'answers': ['1784', '1784', '1784'],\n",
              "   'em': 1,\n",
              "   'f1': 1.0,\n",
              "   'generated_answer': ' 1784',\n",
              "   'generated_answer_probs': [0.9274821128717389, 0.9047645272696421],\n",
              "   'generated_answer_tokens': [' 17', '84'],\n",
              "   'generated_probs': [0.9274821128717389, 0.9047645272696421],\n",
              "   'generated_text': ' 1784',\n",
              "   'generated_tokens': [' 17', '84'],\n",
              "   'id': '57309cd6069b5314008321c5',\n",
              "   'prediction': ' 1784',\n",
              "   'prompt': \"Title: United Methodist Church\\n\\nBackground: use in the United States, beginning in 1769. The congregation was founded in 1767, meeting initially in a sail loft on Dock Street, and in 1769 it purchased the shell of a building which had been erected in 1763 by a German Reformed congregation. At this time, Methodists had not yet broken away from the Anglican Church and the Methodist Episcopal Church was not founded until 1784. Richard Allen and Absalom Jones became the first African Americans ordained by the Methodist Church. They were licensed by St. George's Church in 1784. Three years later, protesting racial segregation in the worship\\n\\nQ: Richard Allen and Absalom Jones were licensed by St. George's Church in what year?\\n\\nA:\",\n",
              "   'question': \"Richard Allen and Absalom Jones were licensed by St. George's Church in what year?\"},\n",
              "  {'answers': ['Old Rhine Bridge at Constance',\n",
              "    'Old Rhine Bridge at Constance',\n",
              "    'the Old Rhine Bridge at Constance',\n",
              "    'Old Rhine Bridge at Constance',\n",
              "    'Old Rhine Bridge'],\n",
              "   'em': 0,\n",
              "   'f1': 0.2,\n",
              "   'generated_answer': \" The Rhine river's measurement begins in Konstanz, Germany.\",\n",
              "   'generated_answer_probs': [0.45538449633143746,\n",
              "    0.7160512044382324,\n",
              "    0.9998274309817463,\n",
              "    0.4606170847057589,\n",
              "    0.899580558861793,\n",
              "    0.9918313978372783,\n",
              "    0.972196965156811,\n",
              "    0.5973711900044688,\n",
              "    0.9809731576730947,\n",
              "    0.9999953989891847,\n",
              "    0.9999961161145423,\n",
              "    0.9643822192078024,\n",
              "    0.6103366187517002,\n",
              "    0.9376120765152166],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' Rh',\n",
              "    'ine',\n",
              "    ' river',\n",
              "    \"'s\",\n",
              "    ' measurement',\n",
              "    ' begins',\n",
              "    ' in',\n",
              "    ' Kon',\n",
              "    'stan',\n",
              "    'z',\n",
              "    ',',\n",
              "    ' Germany',\n",
              "    '.'],\n",
              "   'generated_probs': [0.45538449633143746,\n",
              "    0.7160512044382324,\n",
              "    0.9998274309817463,\n",
              "    0.4606170847057589,\n",
              "    0.899580558861793,\n",
              "    0.9918313978372783,\n",
              "    0.972196965156811,\n",
              "    0.5973711900044688,\n",
              "    0.9809731576730947,\n",
              "    0.9999953989891847,\n",
              "    0.9999961161145423,\n",
              "    0.9643822192078024,\n",
              "    0.6103366187517002,\n",
              "    0.9376120765152166],\n",
              "   'generated_text': \" The Rhine river's measurement begins in Konstanz, Germany.\",\n",
              "   'generated_tokens': [' The',\n",
              "    ' Rh',\n",
              "    'ine',\n",
              "    ' river',\n",
              "    \"'s\",\n",
              "    ' measurement',\n",
              "    ' begins',\n",
              "    ' in',\n",
              "    ' Kon',\n",
              "    'stan',\n",
              "    'z',\n",
              "    ',',\n",
              "    ' Germany',\n",
              "    '.'],\n",
              "   'id': '572f567cb2c2fd1400568041',\n",
              "   'prediction': \" The Rhine river's measurement begins in Konstanz, Germany.\",\n",
              "   'prompt': 'Title: Upper Rhine\\n\\nBackground: Upper Rhine The Upper Rhine () is the section of the Rhine in the Upper Rhine Plain between Basle in Switzerland and Bingen in Germany. The river is marked by Rhine-kilometres 170 to 529 (the scale beginning in Konstanz and ending in Rotterdam). The \"Upper Rhine\" is one of four sections of the river (the others being the High Rhine, Middle Rhine and Lower Rhine) between Lake Constance and the North Sea. The countries and states along the Upper Rhine are Switzerland, France (Alsace) and the German states of Baden-Württemberg, Rhineland-Palatinate and Hesse. The largest cities along the river are\\n\\nQ: Where does the Rhine river\\'s measurement begin?\\n\\nA:',\n",
              "   'question': \"Where does the Rhine river's measurement begin?\"},\n",
              "  {'answers': ['detention', 'detention', 'detention'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' Caning is a common punishment in Singapore.',\n",
              "   'generated_answer_probs': [0.2895232136106948,\n",
              "    0.9999560591954254,\n",
              "    0.8222222527481234,\n",
              "    0.7329560265200525,\n",
              "    0.9874062247446125,\n",
              "    0.9988827592786612,\n",
              "    0.9986488698992949,\n",
              "    0.9999583221935439,\n",
              "    0.9955179940022075],\n",
              "   'generated_answer_tokens': [' Can',\n",
              "    'ing',\n",
              "    ' is',\n",
              "    ' a',\n",
              "    ' common',\n",
              "    ' punishment',\n",
              "    ' in',\n",
              "    ' Singapore',\n",
              "    '.'],\n",
              "   'generated_probs': [0.2895232136106948,\n",
              "    0.9999560591954254,\n",
              "    0.8222222527481234,\n",
              "    0.7329560265200525,\n",
              "    0.9874062247446125,\n",
              "    0.9988827592786612,\n",
              "    0.9986488698992949,\n",
              "    0.9999583221935439,\n",
              "    0.9955179940022075],\n",
              "   'generated_text': ' Caning is a common punishment in Singapore.',\n",
              "   'generated_tokens': [' Can',\n",
              "    'ing',\n",
              "    ' is',\n",
              "    ' a',\n",
              "    ' common',\n",
              "    ' punishment',\n",
              "    ' in',\n",
              "    ' Singapore',\n",
              "    '.'],\n",
              "   'id': '56e75a9037bdd419002c3ec7',\n",
              "   'prediction': ' Caning is a common punishment in Singapore.',\n",
              "   'prompt': 'Title: Law of Singapore\\n\\nBackground: possession of pornography, the sale of chewing gum, and sexual activity such as oral and anal sex between men. Nonetheless, Singapore is one of the countries with the least crime in the world, with a low incidence of violent crimes. Singapore retains both corporal punishment (in the form of caning) and capital punishment (by hanging) as punishments for serious offences. For some offences, most notably trafficking in drugs above a certain specified quantity, the imposition of these penalties is mandatory.           Law of Singapore The legal system of Singapore is based\\n\\nQ: What is a common punishment in Singapore?\\n\\nA:',\n",
              "   'question': 'What is a common punishment in Singapore?'},\n",
              "  {'answers': ['river systems', 'river systems', 'river systems'],\n",
              "   'em': 0,\n",
              "   'f1': 0.14285714285714285,\n",
              "   'generated_answer': ' Victoria has a number of different topological systems, including a number of small freight',\n",
              "   'generated_answer_probs': [0.6307689552438217,\n",
              "    0.6041958733459559,\n",
              "    0.8260890686327642,\n",
              "    0.3396969779796012,\n",
              "    0.999804305950579,\n",
              "    0.4018195547162305,\n",
              "    0.7850535947212541,\n",
              "    0.9992691146868865,\n",
              "    0.9991369717233083,\n",
              "    0.5724331951825357,\n",
              "    0.9778331302220505,\n",
              "    0.5293815714774864,\n",
              "    0.7342445437376001,\n",
              "    0.999997903306798,\n",
              "    0.4426566348974111,\n",
              "    0.9999701243662856],\n",
              "   'generated_answer_tokens': [' Victoria',\n",
              "    ' has',\n",
              "    ' a',\n",
              "    ' number',\n",
              "    ' of',\n",
              "    ' different',\n",
              "    ' top',\n",
              "    'ological',\n",
              "    ' systems',\n",
              "    ',',\n",
              "    ' including',\n",
              "    ' a',\n",
              "    ' number',\n",
              "    ' of',\n",
              "    ' small',\n",
              "    ' freight'],\n",
              "   'generated_probs': [0.6307689552438217,\n",
              "    0.6041958733459559,\n",
              "    0.8260890686327642,\n",
              "    0.3396969779796012,\n",
              "    0.999804305950579,\n",
              "    0.4018195547162305,\n",
              "    0.7850535947212541,\n",
              "    0.9992691146868865,\n",
              "    0.9991369717233083,\n",
              "    0.5724331951825357,\n",
              "    0.9778331302220505,\n",
              "    0.5293815714774864,\n",
              "    0.7342445437376001,\n",
              "    0.999997903306798,\n",
              "    0.4426566348974111,\n",
              "    0.9999701243662856],\n",
              "   'generated_text': ' Victoria has a number of different topological systems, including a number of small freight',\n",
              "   'generated_tokens': [' Victoria',\n",
              "    ' has',\n",
              "    ' a',\n",
              "    ' number',\n",
              "    ' of',\n",
              "    ' different',\n",
              "    ' top',\n",
              "    'ological',\n",
              "    ' systems',\n",
              "    ',',\n",
              "    ' including',\n",
              "    ' a',\n",
              "    ' number',\n",
              "    ' of',\n",
              "    ' small',\n",
              "    ' freight'],\n",
              "   'id': '570d35b7b3d812140066d550',\n",
              "   'prediction': ' Victoria has a number of different topological systems, including a number of small freight',\n",
              "   'prompt': \"Title: Victoria (Australia)\\n\\nBackground: are also several smaller freight operators and numerous tourist railways operating over lines which were once parts of a state-owned system. Victorian lines mainly use the broad gauge. However, the interstate trunk routes, as well as a number of branch lines in the west of the state have been converted to standard gauge. Two tourist railways operate over narrow gauge lines, which are the remnants of five formerly government-owned lines which were built in mountainous areas. Melbourne has the world's largest tram network, currently operated by Yarra Trams. As well as being a popular form of public transport, over the\\n\\nQ: What type of topological systems are found in numbers in Victoria?\\n\\nA:\",\n",
              "   'question': 'What type of topological systems are found in numbers in Victoria?'},\n",
              "  {'answers': ['28,000', '28,000', '28,000'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' There were 88 private schools in New Zealand in April 2014, catering for around 28',\n",
              "   'generated_answer_probs': [0.48306802342377775,\n",
              "    0.6327530052892677,\n",
              "    0.9983955483110314,\n",
              "    0.9998959777606884,\n",
              "    0.9979716379123494,\n",
              "    0.994638639271201,\n",
              "    0.9981646402364028,\n",
              "    0.9999897952890684,\n",
              "    0.4733352820766833,\n",
              "    0.953877067404531,\n",
              "    0.9995998620365567,\n",
              "    0.6630257705127612,\n",
              "    0.9988964089050497,\n",
              "    0.9999260184967664,\n",
              "    0.9993424305536123,\n",
              "    0.9987138993372358],\n",
              "   'generated_answer_tokens': [' There',\n",
              "    ' were',\n",
              "    ' 88',\n",
              "    ' private',\n",
              "    ' schools',\n",
              "    ' in',\n",
              "    ' New',\n",
              "    ' Zealand',\n",
              "    ' in',\n",
              "    ' April',\n",
              "    ' 2014',\n",
              "    ',',\n",
              "    ' catering',\n",
              "    ' for',\n",
              "    ' around',\n",
              "    ' 28'],\n",
              "   'generated_probs': [0.48306802342377775,\n",
              "    0.6327530052892677,\n",
              "    0.9983955483110314,\n",
              "    0.9998959777606884,\n",
              "    0.9979716379123494,\n",
              "    0.994638639271201,\n",
              "    0.9981646402364028,\n",
              "    0.9999897952890684,\n",
              "    0.4733352820766833,\n",
              "    0.953877067404531,\n",
              "    0.9995998620365567,\n",
              "    0.6630257705127612,\n",
              "    0.9988964089050497,\n",
              "    0.9999260184967664,\n",
              "    0.9993424305536123,\n",
              "    0.9987138993372358],\n",
              "   'generated_text': ' There were 88 private schools in New Zealand in April 2014, catering for around 28',\n",
              "   'generated_tokens': [' There',\n",
              "    ' were',\n",
              "    ' 88',\n",
              "    ' private',\n",
              "    ' schools',\n",
              "    ' in',\n",
              "    ' New',\n",
              "    ' Zealand',\n",
              "    ' in',\n",
              "    ' April',\n",
              "    ' 2014',\n",
              "    ',',\n",
              "    ' catering',\n",
              "    ' for',\n",
              "    ' around',\n",
              "    ' 28'],\n",
              "   'id': '57274eca5951b619008f8800',\n",
              "   'prediction': ' There were 88 private schools in New Zealand in April 2014, catering for around 28',\n",
              "   'prompt': 'Title: Private school\\n\\nBackground: linked to faith groups. The Programme for International Student Assessment, coordinated by the OECD, ranks the education in the Netherlands as the 9th best in the world as of 2008, being significantly higher than the OECD average. As of April 2014, there are 88 private schools in New Zealand, catering for around 28,000 students or 3.7% of the entire student population. Private school numbers have been in decline since the mid-1970s as a result of many private schools opting to become state-integrated schools, mostly due of financial difficulties stemming from changes in student numbers and/or the economy. State-integrated schools keep\\n\\nQ: In April 2014, how many New Zealand students attended private schools?\\n\\nA:',\n",
              "   'question': 'In April 2014, how many New Zealand students attended private schools?'},\n",
              "  {'answers': ['deflate', 'deflate', 'deflate'],\n",
              "   'em': 0,\n",
              "   'f1': 0.2222222222222222,\n",
              "   'generated_answer': \" A teacher would try to deflate the cocky student's ego.\",\n",
              "   'generated_answer_probs': [0.22988157361274197,\n",
              "    0.9925284577856105,\n",
              "    0.7034675218626064,\n",
              "    0.15213677914098492,\n",
              "    0.9930563145641883,\n",
              "    0.3978132519579962,\n",
              "    0.9998522261796268,\n",
              "    0.9209419905483583,\n",
              "    0.9772509179402226,\n",
              "    0.9982194763163872,\n",
              "    0.5307026212124696,\n",
              "    0.9536973605409292,\n",
              "    0.8809756433701834,\n",
              "    0.7387973629741363],\n",
              "   'generated_answer_tokens': [' A',\n",
              "    ' teacher',\n",
              "    ' would',\n",
              "    ' try',\n",
              "    ' to',\n",
              "    ' def',\n",
              "    'late',\n",
              "    ' the',\n",
              "    ' cock',\n",
              "    'y',\n",
              "    ' student',\n",
              "    \"'s\",\n",
              "    ' ego',\n",
              "    '.'],\n",
              "   'generated_probs': [0.22988157361274197,\n",
              "    0.9925284577856105,\n",
              "    0.7034675218626064,\n",
              "    0.15213677914098492,\n",
              "    0.9930563145641883,\n",
              "    0.3978132519579962,\n",
              "    0.9998522261796268,\n",
              "    0.9209419905483583,\n",
              "    0.9772509179402226,\n",
              "    0.9982194763163872,\n",
              "    0.5307026212124696,\n",
              "    0.9536973605409292,\n",
              "    0.8809756433701834,\n",
              "    0.7387973629741363],\n",
              "   'generated_text': \" A teacher would try to deflate the cocky student's ego.\",\n",
              "   'generated_tokens': [' A',\n",
              "    ' teacher',\n",
              "    ' would',\n",
              "    ' try',\n",
              "    ' to',\n",
              "    ' def',\n",
              "    'late',\n",
              "    ' the',\n",
              "    ' cock',\n",
              "    'y',\n",
              "    ' student',\n",
              "    \"'s\",\n",
              "    ' ego',\n",
              "    '.'],\n",
              "   'id': '56e7542f00c9c71400d76fbf',\n",
              "   'prediction': \" A teacher would try to deflate the cocky student's ego.\",\n",
              "   'prompt': 'Title: Teacher\\n\\nBackground: described the place of a teacher in learning as follows: \"The real bulk of learning takes place in self-study and problem solving with a lot of feedback around that loop. The function of the teacher is to pressure the lazy, inspire the bored, deflate the cocky, encourage the timid, detect and correct individual flaws, and broaden the viewpoint of all. This function looks like that of a coach using the whole gamut of psychology to get each new class of rookies off the bench and into the game.\" Perhaps the most significant difference between primary school and secondary school teaching\\n\\nQ: What would a teacher do for someone who is cocky?\\n\\nA:',\n",
              "   'question': 'What would a teacher do for someone who is cocky?'},\n",
              "  {'answers': ['Rhine', 'Rhine', 'The Rhine'],\n",
              "   'em': 0,\n",
              "   'f1': 0.2857142857142857,\n",
              "   'generated_answer': ' The Rhine is the longest river in Germany.',\n",
              "   'generated_answer_probs': [0.9967873446566483,\n",
              "    0.979274723864001,\n",
              "    0.9999847857717375,\n",
              "    0.9207935696842194,\n",
              "    0.9994080538193105,\n",
              "    0.9997516762074582,\n",
              "    0.9967529532955557,\n",
              "    0.9999561755903175,\n",
              "    0.9997609722116948,\n",
              "    0.9667472752138707],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' Rh',\n",
              "    'ine',\n",
              "    ' is',\n",
              "    ' the',\n",
              "    ' longest',\n",
              "    ' river',\n",
              "    ' in',\n",
              "    ' Germany',\n",
              "    '.'],\n",
              "   'generated_probs': [0.9967873446566483,\n",
              "    0.979274723864001,\n",
              "    0.9999847857717375,\n",
              "    0.9207935696842194,\n",
              "    0.9994080538193105,\n",
              "    0.9997516762074582,\n",
              "    0.9967529532955557,\n",
              "    0.9999561755903175,\n",
              "    0.9997609722116948,\n",
              "    0.9667472752138707],\n",
              "   'generated_text': ' The Rhine is the longest river in Germany.',\n",
              "   'generated_tokens': [' The',\n",
              "    ' Rh',\n",
              "    'ine',\n",
              "    ' is',\n",
              "    ' the',\n",
              "    ' longest',\n",
              "    ' river',\n",
              "    ' in',\n",
              "    ' Germany',\n",
              "    '.'],\n",
              "   'id': '572f65e9b2c2fd14005680cb',\n",
              "   'prediction': ' The Rhine is the longest river in Germany.',\n",
              "   'prompt': 'Title: Rhine\\n\\nBackground: river islands occur, locally known as \"Rheinauen\". The Rhine is the longest river in Germany. It is here that the Rhine encounters some more of its main tributaries, such as the Neckar, the Main and, later, the Moselle, which contributes an average discharge of more than . Northeastern France drains to the Rhine via the Moselle; smaller rivers drain the Vosges and Jura Mountains uplands. Most of Luxembourg and a very small part of Belgium also drain to the Rhine via the Moselle. As it approaches the Dutch border, the Rhine has an annual mean discharge of and an average\\n\\nQ: What is the longest river in Germany?\\n\\nA:',\n",
              "   'question': 'What is the longest river in Germany?'},\n",
              "  {'answers': ['villes de sûreté', '\"villes de sûreté\"', 'villes de sûreté'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' The towns granted to the Huguenots in 1598 collectively called were the',\n",
              "   'generated_answer_probs': [0.810552414951854,\n",
              "    0.886640630857653,\n",
              "    0.690767244912386,\n",
              "    0.9984585517536205,\n",
              "    0.9999689351265232,\n",
              "    0.9999701243662856,\n",
              "    0.999995041369894,\n",
              "    0.9999998115819777,\n",
              "    0.9998908504622442,\n",
              "    0.7433409697816464,\n",
              "    0.9998496039806154,\n",
              "    0.9999983792026135,\n",
              "    0.8409497677369543,\n",
              "    0.8840085539299177,\n",
              "    0.5668412481974903,\n",
              "    0.4656693854197429],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' towns',\n",
              "    ' granted',\n",
              "    ' to',\n",
              "    ' the',\n",
              "    ' Hug',\n",
              "    'u',\n",
              "    'en',\n",
              "    'ots',\n",
              "    ' in',\n",
              "    ' 15',\n",
              "    '98',\n",
              "    ' collectively',\n",
              "    ' called',\n",
              "    ' were',\n",
              "    ' the'],\n",
              "   'generated_probs': [0.810552414951854,\n",
              "    0.886640630857653,\n",
              "    0.690767244912386,\n",
              "    0.9984585517536205,\n",
              "    0.9999689351265232,\n",
              "    0.9999701243662856,\n",
              "    0.999995041369894,\n",
              "    0.9999998115819777,\n",
              "    0.9998908504622442,\n",
              "    0.7433409697816464,\n",
              "    0.9998496039806154,\n",
              "    0.9999983792026135,\n",
              "    0.8409497677369543,\n",
              "    0.8840085539299177,\n",
              "    0.5668412481974903,\n",
              "    0.4656693854197429],\n",
              "   'generated_text': ' The towns granted to the Huguenots in 1598 collectively called were the',\n",
              "   'generated_tokens': [' The',\n",
              "    ' towns',\n",
              "    ' granted',\n",
              "    ' to',\n",
              "    ' the',\n",
              "    ' Hug',\n",
              "    'u',\n",
              "    'en',\n",
              "    'ots',\n",
              "    ' in',\n",
              "    ' 15',\n",
              "    '98',\n",
              "    ' collectively',\n",
              "    ' called',\n",
              "    ' were',\n",
              "    ' the'],\n",
              "   'id': '57106d2fb654c5140001f8ef',\n",
              "   'prediction': ' The towns granted to the Huguenots in 1598 collectively called were the',\n",
              "   'prompt': 'Title: Huguenot\\n\\nBackground: \"villes de sûreté\" that the Edict of 1598 granted to the Huguenots. The city\\'s political institutions and the university were all handed over to the Huguenots. Tension with Paris led to a siege by the royal army in 1622. Peace terms called for the dismantling of the city\\'s fortifications. A royal citadel was built and the university and consulate were taken over by the Catholic party. Even before the Edict of Alès (1629), Protestant rule was dead and the ville de sûreté was no more. By 1620 the Huguenots were on the defensive, and the government increasingly applied pressure. A\\n\\nQ: What were the towns granted to the Huguenots in 1598 collectively called?\\n\\nA:',\n",
              "   'question': 'What were the towns granted to the Huguenots in 1598 collectively called?'},\n",
              "  {'answers': ['A steep and steady decline',\n",
              "    'A steep and steady decline',\n",
              "    'steep and steady decline'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' The Six-Day War was a pivotal event in the Arab Muslim world. The',\n",
              "   'generated_answer_probs': [0.7562394501116337,\n",
              "    0.4489940378762923,\n",
              "    0.9910459920414858,\n",
              "    0.9993533980971676,\n",
              "    0.9999504538374516,\n",
              "    0.4068554159579368,\n",
              "    0.9764074054980807,\n",
              "    0.8315413102364672,\n",
              "    0.999580966289159,\n",
              "    0.9647068270185472,\n",
              "    0.9994540102566762,\n",
              "    0.9992576725614422,\n",
              "    0.9972640660079035,\n",
              "    0.9998041867639148,\n",
              "    0.4451187092638423,\n",
              "    0.9936522442682182],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' Six',\n",
              "    '-',\n",
              "    'Day',\n",
              "    ' War',\n",
              "    ' was',\n",
              "    ' a',\n",
              "    ' pivotal',\n",
              "    ' event',\n",
              "    ' in',\n",
              "    ' the',\n",
              "    ' Arab',\n",
              "    ' Muslim',\n",
              "    ' world',\n",
              "    '.',\n",
              "    ' The'],\n",
              "   'generated_probs': [0.7562394501116337,\n",
              "    0.4489940378762923,\n",
              "    0.9910459920414858,\n",
              "    0.9993533980971676,\n",
              "    0.9999504538374516,\n",
              "    0.4068554159579368,\n",
              "    0.9764074054980807,\n",
              "    0.8315413102364672,\n",
              "    0.999580966289159,\n",
              "    0.9647068270185472,\n",
              "    0.9994540102566762,\n",
              "    0.9992576725614422,\n",
              "    0.9972640660079035,\n",
              "    0.9998041867639148,\n",
              "    0.4451187092638423,\n",
              "    0.9936522442682182],\n",
              "   'generated_text': ' The Six-Day War was a pivotal event in the Arab Muslim world. The',\n",
              "   'generated_tokens': [' The',\n",
              "    ' Six',\n",
              "    '-',\n",
              "    'Day',\n",
              "    ' War',\n",
              "    ' was',\n",
              "    ' a',\n",
              "    ' pivotal',\n",
              "    ' event',\n",
              "    ' in',\n",
              "    ' the',\n",
              "    ' Arab',\n",
              "    ' Muslim',\n",
              "    ' world',\n",
              "    '.',\n",
              "    ' The'],\n",
              "   'id': '573005b9947a6a140053cf6d',\n",
              "   'prediction': ' The Six-Day War was a pivotal event in the Arab Muslim world. The',\n",
              "   'prompt': \"Title: Islamism\\n\\nBackground: and armed jihad, something for which they have been denounced by radical Islamists. The quick and decisive defeat of the Arab troops during the Six-Day War by Israeli troops constituted a pivotal event in the Arab Muslim world. The defeat along with economic stagnation in the defeated countries, was blamed on the secular Arab nationalism of the ruling regimes. A steep and steady decline in the popularity and credibility of secular, socialist and nationalist politics ensued. Ba'athism, Arab socialism, and Arab nationalism suffered, and different democratic and anti-democratic Islamist movements inspired by Maududi and Sayyid Qutb gained ground. The first\\n\\nQ: What happened to the credibility of secular politics as a result of the Six-Day War?\\n\\nA:\",\n",
              "   'question': 'What happened to the credibility of secular politics as a result of the Six-Day War?'},\n",
              "  {'answers': ['rapid combustion',\n",
              "    'rapid combustion',\n",
              "    'rapid combustion',\n",
              "    'rapid combustion',\n",
              "    'rapid combustion'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' Oxygen can produce fire or explosion.',\n",
              "   'generated_answer_probs': [0.5273058174407147,\n",
              "    0.9999976639519286,\n",
              "    0.8311796933647004,\n",
              "    0.928702266216667,\n",
              "    0.4633361789155574,\n",
              "    0.7185708644525982,\n",
              "    0.9371776971063902,\n",
              "    0.835129830992039],\n",
              "   'generated_answer_tokens': [' Oxy',\n",
              "    'gen',\n",
              "    ' can',\n",
              "    ' produce',\n",
              "    ' fire',\n",
              "    ' or',\n",
              "    ' explosion',\n",
              "    '.'],\n",
              "   'generated_probs': [0.5273058174407147,\n",
              "    0.9999976639519286,\n",
              "    0.8311796933647004,\n",
              "    0.928702266216667,\n",
              "    0.4633361789155574,\n",
              "    0.7185708644525982,\n",
              "    0.9371776971063902,\n",
              "    0.835129830992039],\n",
              "   'generated_text': ' Oxygen can produce fire or explosion.',\n",
              "   'generated_tokens': [' Oxy',\n",
              "    'gen',\n",
              "    ' can',\n",
              "    ' produce',\n",
              "    ' fire',\n",
              "    ' or',\n",
              "    ' explosion',\n",
              "    '.'],\n",
              "   'id': '571cebc05efbb31900334e48',\n",
              "   'prediction': ' Oxygen can produce fire or explosion.',\n",
              "   'prompt': 'Title: Oxygen therapy\\n\\nBackground: as peroxides, chlorates, nitrates, perchlorates, and dichromates because they can donate oxygen to a fire. Concentrated will allow combustion to proceed rapidly and energetically. Steel pipes and storage vessels used to store and transmit both gaseous and liquid oxygen will act as a fuel; and therefore the design and manufacture of systems requires special training to ensure that ignition sources are minimized. Highly concentrated oxygen in a high-pressure environment can spontaneously ignite hydrocarbons such as oil and grease, resulting in fire or explosion. The heat caused by rapid pressurization serves as the ignition source. For this reason, storage vessels, regulators,\\n\\nQ: What can concentrated oxygen produce?\\n\\nA:',\n",
              "   'question': 'What can concentrated oxygen produce?'},\n",
              "  {'answers': ['programmes to avoid similar disasters in the future',\n",
              "    'programmes',\n",
              "    'programmes'],\n",
              "   'em': 0,\n",
              "   'f1': 0.5555555555555556,\n",
              "   'generated_answer': ' The government and civil society organisations started programmes to avoid similar disasters.',\n",
              "   'generated_answer_probs': [0.48675610131798286,\n",
              "    0.9614403513068936,\n",
              "    0.9691394560056518,\n",
              "    0.9994337447830334,\n",
              "    0.9996614917468517,\n",
              "    0.9816513395971972,\n",
              "    0.9909754786546633,\n",
              "    0.9957546865287005,\n",
              "    0.9911608520080392,\n",
              "    0.9821329449187215,\n",
              "    0.999418128053179,\n",
              "    0.9991475806559624,\n",
              "    0.6305693295418469],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' government',\n",
              "    ' and',\n",
              "    ' civil',\n",
              "    ' society',\n",
              "    ' organisations',\n",
              "    ' started',\n",
              "    ' programmes',\n",
              "    ' to',\n",
              "    ' avoid',\n",
              "    ' similar',\n",
              "    ' disasters',\n",
              "    '.'],\n",
              "   'generated_probs': [0.48675610131798286,\n",
              "    0.9614403513068936,\n",
              "    0.9691394560056518,\n",
              "    0.9994337447830334,\n",
              "    0.9996614917468517,\n",
              "    0.9816513395971972,\n",
              "    0.9909754786546633,\n",
              "    0.9957546865287005,\n",
              "    0.9911608520080392,\n",
              "    0.9821329449187215,\n",
              "    0.999418128053179,\n",
              "    0.9991475806559624,\n",
              "    0.6305693295418469],\n",
              "   'generated_text': ' The government and civil society organisations started programmes to avoid similar disasters.',\n",
              "   'generated_tokens': [' The',\n",
              "    ' government',\n",
              "    ' and',\n",
              "    ' civil',\n",
              "    ' society',\n",
              "    ' organisations',\n",
              "    ' started',\n",
              "    ' programmes',\n",
              "    ' to',\n",
              "    ' avoid',\n",
              "    ' similar',\n",
              "    ' disasters',\n",
              "    '.'],\n",
              "   'id': '57290e153f37b31900477fd9',\n",
              "   'prediction': ' The government and civil society organisations started programmes to avoid similar disasters.',\n",
              "   'prompt': 'Title: Kenya\\n\\nBackground: almost 1,000 people were killed and nearly 600,000 displaced. The dispute caused underlying tensions over land and its distribution to re-erupt, as it had in the 1992 and 1997 elections. Hundreds of thousands were forced off their land to relatives elsewhere in the country and some claim weapons are being bought in the region, perhaps in anticipation of the 2013 elections. A group of eminent persons of Africa, led by former United Nations secretary-general Kofi Annan, brokered a peaceful solution to the political stalemate. Since the election riots, the government and civil society organisations started programmes to avoid similar disasters\\n\\nQ: What did the government and civil society organisations start after the riots?\\n\\nA:',\n",
              "   'question': 'What did the government and civil society organisations start after the riots?'},\n",
              "  {'answers': ['blazer', 'blazer', 'blazer'],\n",
              "   'em': 0,\n",
              "   'f1': 0.15384615384615385,\n",
              "   'generated_answer': ' A compulsory blazer is an example of an article of uniform clothing typically present in',\n",
              "   'generated_answer_probs': [0.6193487228904239,\n",
              "    0.6789772684270289,\n",
              "    0.9995763181585107,\n",
              "    0.9999948020155096,\n",
              "    0.6885736671158269,\n",
              "    0.7337584145757243,\n",
              "    0.996019571291033,\n",
              "    0.9995421053357746,\n",
              "    0.9811514363132137,\n",
              "    0.9998037090675865,\n",
              "    0.9999188665274982,\n",
              "    0.8186703166045273,\n",
              "    0.9978777605413581,\n",
              "    0.9808562728566766,\n",
              "    0.9997598986389464,\n",
              "    0.9999716740381877],\n",
              "   'generated_answer_tokens': [' A',\n",
              "    ' compulsory',\n",
              "    ' bl',\n",
              "    'azer',\n",
              "    ' is',\n",
              "    ' an',\n",
              "    ' example',\n",
              "    ' of',\n",
              "    ' an',\n",
              "    ' article',\n",
              "    ' of',\n",
              "    ' uniform',\n",
              "    ' clothing',\n",
              "    ' typically',\n",
              "    ' present',\n",
              "    ' in'],\n",
              "   'generated_probs': [0.6193487228904239,\n",
              "    0.6789772684270289,\n",
              "    0.9995763181585107,\n",
              "    0.9999948020155096,\n",
              "    0.6885736671158269,\n",
              "    0.7337584145757243,\n",
              "    0.996019571291033,\n",
              "    0.9995421053357746,\n",
              "    0.9811514363132137,\n",
              "    0.9998037090675865,\n",
              "    0.9999188665274982,\n",
              "    0.8186703166045273,\n",
              "    0.9978777605413581,\n",
              "    0.9808562728566766,\n",
              "    0.9997598986389464,\n",
              "    0.9999716740381877],\n",
              "   'generated_text': ' A compulsory blazer is an example of an article of uniform clothing typically present in',\n",
              "   'generated_tokens': [' A',\n",
              "    ' compulsory',\n",
              "    ' bl',\n",
              "    'azer',\n",
              "    ' is',\n",
              "    ' an',\n",
              "    ' example',\n",
              "    ' of',\n",
              "    ' an',\n",
              "    ' article',\n",
              "    ' of',\n",
              "    ' uniform',\n",
              "    ' clothing',\n",
              "    ' typically',\n",
              "    ' present',\n",
              "    ' in'],\n",
              "   'id': '5727490bdd62a815002e9a83',\n",
              "   'prediction': ' A compulsory blazer is an example of an article of uniform clothing typically present in',\n",
              "   'prompt': 'Title: Private school\\n\\nBackground: facilities; or stricter discipline based on their power of expulsion, a tool not readily available to government schools. Student uniforms for Australian private schools are generally stricter and more formal than in government schools - for example, a compulsory blazer. Private schools in Australia are always more expensive than their public counterparts. There are two main categories of private schools in Australia: Catholic schools and Independent schools. Catholic schools form the second largest sector after government schools, with around 21% of secondary enrollments. Most Australian Catholic schools belong to a system, like government schools, are typically co-educational and attempt to\\n\\nQ: What is an example of an article of uniform clothing typically present in Australian private schools?\\n\\nA:',\n",
              "   'question': 'What is an example of an article of uniform clothing typically present in Australian private schools?'},\n",
              "  {'answers': ['unpaired electrons',\n",
              "    'its unpaired electrons',\n",
              "    'its unpaired electrons',\n",
              "    'Because of its unpaired electrons',\n",
              "    'unpaired electrons'],\n",
              "   'em': 0,\n",
              "   'f1': 0.33333333333333337,\n",
              "   'generated_answer': ' Triplet oxygen reacts slowly because it has unpaired electrons, which makes it difficult',\n",
              "   'generated_answer_probs': [0.8702736992235754,\n",
              "    0.9998951405781336,\n",
              "    0.9995369789073664,\n",
              "    0.4801144816884686,\n",
              "    0.9973797590397175,\n",
              "    0.9795168951470004,\n",
              "    0.6314094728757563,\n",
              "    0.9756818471418033,\n",
              "    0.970815395194373,\n",
              "    0.9999944443861325,\n",
              "    0.9992042068514564,\n",
              "    0.4817800966756161,\n",
              "    0.9523677945379716,\n",
              "    0.85307884770531,\n",
              "    0.9889409340943338,\n",
              "    0.33324487462886043],\n",
              "   'generated_answer_tokens': [' Triple',\n",
              "    't',\n",
              "    ' oxygen',\n",
              "    ' reacts',\n",
              "    ' slowly',\n",
              "    ' because',\n",
              "    ' it',\n",
              "    ' has',\n",
              "    ' unp',\n",
              "    'aired',\n",
              "    ' electrons',\n",
              "    ',',\n",
              "    ' which',\n",
              "    ' makes',\n",
              "    ' it',\n",
              "    ' difficult'],\n",
              "   'generated_probs': [0.8702736992235754,\n",
              "    0.9998951405781336,\n",
              "    0.9995369789073664,\n",
              "    0.4801144816884686,\n",
              "    0.9973797590397175,\n",
              "    0.9795168951470004,\n",
              "    0.6314094728757563,\n",
              "    0.9756818471418033,\n",
              "    0.970815395194373,\n",
              "    0.9999944443861325,\n",
              "    0.9992042068514564,\n",
              "    0.4817800966756161,\n",
              "    0.9523677945379716,\n",
              "    0.85307884770531,\n",
              "    0.9889409340943338,\n",
              "    0.33324487462886043],\n",
              "   'generated_text': ' Triplet oxygen reacts slowly because it has unpaired electrons, which makes it difficult',\n",
              "   'generated_tokens': [' Triple',\n",
              "    't',\n",
              "    ' oxygen',\n",
              "    ' reacts',\n",
              "    ' slowly',\n",
              "    ' because',\n",
              "    ' it',\n",
              "    ' has',\n",
              "    ' unp',\n",
              "    'aired',\n",
              "    ' electrons',\n",
              "    ',',\n",
              "    ' which',\n",
              "    ' makes',\n",
              "    ' it',\n",
              "    ' difficult'],\n",
              "   'id': '571c879bdd7acb1400e4c0ee',\n",
              "   'prediction': ' Triplet oxygen reacts slowly because it has unpaired electrons, which makes it difficult',\n",
              "   'prompt': \"Title: Oxygen\\n\\nBackground: combination of cancellations and σ and overlaps results in dioxygen's double bond character and reactivity, and a triplet electronic ground state. An electron configuration with two unpaired electrons, as is found in dioxygen orbitals (see the filled * orbitals in the diagram) that are of equal energy—i.e., degenerate—is a configuration termed a spin triplet state. Hence, the ground state of the molecule is referred to as triplet oxygen. The highest energy, partially filled orbitals are antibonding, and so their filling weakens the bond order from three to two. Because of its unpaired electrons, triplet oxygen reacts only slowly with most\\n\\nQ: What causes triplet oxygen to react slowly?\\n\\nA:\",\n",
              "   'question': 'What causes triplet oxygen to react slowly?'},\n",
              "  {'answers': ['1975', '1975', '1975'],\n",
              "   'em': 0,\n",
              "   'f1': 0.18181818181818182,\n",
              "   'generated_answer': \" The gentlemen's agreement between Sadat and the Islamists broke down in 1975.\",\n",
              "   'generated_answer_probs': [0.8019381770976892,\n",
              "    0.667038055480945,\n",
              "    0.9981014577157306,\n",
              "    0.999908256938652,\n",
              "    0.9770019529657011,\n",
              "    0.9976717059910473,\n",
              "    0.9999986176197555,\n",
              "    0.9999946837406314,\n",
              "    0.9848559865967716,\n",
              "    0.9688621822371569,\n",
              "    0.9990797510190463,\n",
              "    0.999977042039538,\n",
              "    0.9740783763940216,\n",
              "    0.9992899180675839,\n",
              "    0.9891372093919967],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' gentlemen',\n",
              "    \"'s\",\n",
              "    ' agreement',\n",
              "    ' between',\n",
              "    ' Sad',\n",
              "    'at',\n",
              "    ' and',\n",
              "    ' the',\n",
              "    ' Islamists',\n",
              "    ' broke',\n",
              "    ' down',\n",
              "    ' in',\n",
              "    ' 1975',\n",
              "    '.'],\n",
              "   'generated_probs': [0.8019381770976892,\n",
              "    0.667038055480945,\n",
              "    0.9981014577157306,\n",
              "    0.999908256938652,\n",
              "    0.9770019529657011,\n",
              "    0.9976717059910473,\n",
              "    0.9999986176197555,\n",
              "    0.9999946837406314,\n",
              "    0.9848559865967716,\n",
              "    0.9688621822371569,\n",
              "    0.9990797510190463,\n",
              "    0.999977042039538,\n",
              "    0.9740783763940216,\n",
              "    0.9992899180675839,\n",
              "    0.9891372093919967],\n",
              "   'generated_text': \" The gentlemen's agreement between Sadat and the Islamists broke down in 1975.\",\n",
              "   'generated_tokens': [' The',\n",
              "    ' gentlemen',\n",
              "    \"'s\",\n",
              "    ' agreement',\n",
              "    ' between',\n",
              "    ' Sad',\n",
              "    'at',\n",
              "    ' and',\n",
              "    ' the',\n",
              "    ' Islamists',\n",
              "    ' broke',\n",
              "    ' down',\n",
              "    ' in',\n",
              "    ' 1975',\n",
              "    '.'],\n",
              "   'id': '572ffc99947a6a140053cef9',\n",
              "   'prediction': \" The gentlemen's agreement between Sadat and the Islamists broke down in 1975.\",\n",
              "   'prompt': 'Title: Islamism\\n\\nBackground: Islamist movement\" was said to have been \"imitated by many other Muslim leaders in the years that followed.\" This \"gentlemen\\'s agreement\" between Sadat and Islamists broke down in 1975 but not before Islamists came to completely dominate university student unions. Sadat was later assassinated and a formidable insurgency was formed in Egypt in the 1990s. The French government has also been reported to have promoted Islamist preachers \"in the hope of channeling Muslim energies into zones of piety and charity.\" The resurgence of Islamic devotion and the attraction to things Islamic can be traced to several events. Starting in the\\n\\nQ: When did the so called gentlemen\\'s agreement between Sadat and the Islamists break down?\\n\\nA:',\n",
              "   'question': \"When did the so called gentlemen's agreement between Sadat and the Islamists break down?\"},\n",
              "  {'answers': ['citizenship', '\"citizenship\"', '\"citizenship\"'],\n",
              "   'em': 0,\n",
              "   'f1': 0.14285714285714288,\n",
              "   'generated_answer': ' \"citizenship\", so that people had rights to empower them to become economically and',\n",
              "   'generated_answer_probs': [0.8524605726371248,\n",
              "    0.5193394829097638,\n",
              "    0.9999999317236823,\n",
              "    0.9734875190018893,\n",
              "    0.9996082061212747,\n",
              "    0.9996659037725784,\n",
              "    0.9999431834281226,\n",
              "    0.999943421830605,\n",
              "    0.9998970477199497,\n",
              "    0.9999533165847045,\n",
              "    0.9850754477922775,\n",
              "    0.9989242452394593,\n",
              "    0.9999162413379526,\n",
              "    0.9999640449263991,\n",
              "    0.9998782129866405,\n",
              "    0.9999845520483208],\n",
              "   'generated_answer_tokens': [' \"',\n",
              "    'citizens',\n",
              "    'hip',\n",
              "    '\",',\n",
              "    ' so',\n",
              "    ' that',\n",
              "    ' people',\n",
              "    ' had',\n",
              "    ' rights',\n",
              "    ' to',\n",
              "    ' empower',\n",
              "    ' them',\n",
              "    ' to',\n",
              "    ' become',\n",
              "    ' economically',\n",
              "    ' and'],\n",
              "   'generated_probs': [0.8524605726371248,\n",
              "    0.5193394829097638,\n",
              "    0.9999999317236823,\n",
              "    0.9734875190018893,\n",
              "    0.9996082061212747,\n",
              "    0.9996659037725784,\n",
              "    0.9999431834281226,\n",
              "    0.999943421830605,\n",
              "    0.9998970477199497,\n",
              "    0.9999533165847045,\n",
              "    0.9850754477922775,\n",
              "    0.9989242452394593,\n",
              "    0.9999162413379526,\n",
              "    0.9999640449263991,\n",
              "    0.9998782129866405,\n",
              "    0.9999845520483208],\n",
              "   'generated_text': ' \"citizenship\", so that people had rights to empower them to become economically and',\n",
              "   'generated_tokens': [' \"',\n",
              "    'citizens',\n",
              "    'hip',\n",
              "    '\",',\n",
              "    ' so',\n",
              "    ' that',\n",
              "    ' people',\n",
              "    ' had',\n",
              "    ' rights',\n",
              "    ' to',\n",
              "    ' empower',\n",
              "    ' them',\n",
              "    ' to',\n",
              "    ' become',\n",
              "    ' economically',\n",
              "    ' and'],\n",
              "   'id': '5726baf2dd62a815002e8e76',\n",
              "   'prediction': ' \"citizenship\", so that people had rights to empower them to become economically and',\n",
              "   'prompt': 'Title: European Union law\\n\\nBackground: consumers access to goods from around the continent. Since its foundation, the Treaties sought to enable people to pursue their life goals in any country through free movement. Reflecting the economic nature of the project, the European Community originally focused upon free movement of workers: as a \"factor of production\". However, from the 1970s, this focus shifted towards developing a more \"social\" Europe.<ref name=\"Case 43/75\">\"Defrenne v Sabena\" (1976) Case 43/75, [10]</ref> Free movement was increasingly based on \"citizenship\", so that people had rights to empower them to become economically and socially active, rather than economic activity being a precondition for\\n\\nQ: What was free movement increasingly based on?\\n\\nA:',\n",
              "   'question': 'What was free movement increasingly based on?'},\n",
              "  {'answers': ['£21,000', '£21,000', '£21,000'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' The upper range of annual fees for non-boarding students in British public schools is',\n",
              "   'generated_answer_probs': [0.6833211123797749,\n",
              "    0.7533401174197627,\n",
              "    0.9756794606269239,\n",
              "    0.8514830373347623,\n",
              "    0.9917128443733788,\n",
              "    0.9919900668534181,\n",
              "    0.9983438718961521,\n",
              "    0.9994318367059266,\n",
              "    0.996413382333839,\n",
              "    0.9881562964087897,\n",
              "    0.9998103853491307,\n",
              "    0.9957010405947634,\n",
              "    0.9992300745448246,\n",
              "    0.9997502441941754,\n",
              "    0.9998943071358843,\n",
              "    0.8657744973485169],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' upper',\n",
              "    ' range',\n",
              "    ' of',\n",
              "    ' annual',\n",
              "    ' fees',\n",
              "    ' for',\n",
              "    ' non',\n",
              "    '-',\n",
              "    'boarding',\n",
              "    ' students',\n",
              "    ' in',\n",
              "    ' British',\n",
              "    ' public',\n",
              "    ' schools',\n",
              "    ' is'],\n",
              "   'generated_probs': [0.6833211123797749,\n",
              "    0.7533401174197627,\n",
              "    0.9756794606269239,\n",
              "    0.8514830373347623,\n",
              "    0.9917128443733788,\n",
              "    0.9919900668534181,\n",
              "    0.9983438718961521,\n",
              "    0.9994318367059266,\n",
              "    0.996413382333839,\n",
              "    0.9881562964087897,\n",
              "    0.9998103853491307,\n",
              "    0.9957010405947634,\n",
              "    0.9992300745448246,\n",
              "    0.9997502441941754,\n",
              "    0.9998943071358843,\n",
              "    0.8657744973485169],\n",
              "   'generated_text': ' The upper range of annual fees for non-boarding students in British public schools is',\n",
              "   'generated_tokens': [' The',\n",
              "    ' upper',\n",
              "    ' range',\n",
              "    ' of',\n",
              "    ' annual',\n",
              "    ' fees',\n",
              "    ' for',\n",
              "    ' non',\n",
              "    '-',\n",
              "    'boarding',\n",
              "    ' students',\n",
              "    ' in',\n",
              "    ' British',\n",
              "    ' public',\n",
              "    ' schools',\n",
              "    ' is'],\n",
              "   'id': '572756265951b619008f8871',\n",
              "   'prediction': ' The upper range of annual fees for non-boarding students in British public schools is',\n",
              "   'prompt': 'Title: Independent school (United Kingdom)\\n\\nBackground: parents can afford school fees averaging over £23,000 per annum for boarding pupils and £11,000 for day pupils, with additional costs for uniform, equipment and extra-curricular facilities. Scholarships and means-tested bursaries to assist the education of the less well-off are usually awarded by a process which combines academic and other criteria. Independent schools are generally academically selective, using the competitive Common Entrance Examination at ages 11–13. Schools often offer scholarships to attract abler pupils (which improves their average results); the standard sometimes approaches the General Certificate of Secondary Education (GCSE) intended for age 16. Poorly-performing pupils may be required to\\n\\nQ: What is the upper range of annual fees for non-boarding students in British public schools?\\n\\nA:',\n",
              "   'question': 'What is the upper range of annual fees for non-boarding students in British public schools?'},\n",
              "  {'answers': ['ten', 'ten', 'ten'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' 8-10% of undergraduates are members of fraternities or soror',\n",
              "   'generated_answer_probs': [0.5153719015516597,\n",
              "    0.9614624041171432,\n",
              "    0.9998541341794535,\n",
              "    0.9608428365091695,\n",
              "    0.8434735457210673,\n",
              "    0.6881938857959891,\n",
              "    0.9999758481046617,\n",
              "    0.9381970381896297,\n",
              "    0.9752038820985883,\n",
              "    0.9983121600067282,\n",
              "    0.987852129434202,\n",
              "    0.9999633297003718,\n",
              "    0.9999688149902626,\n",
              "    0.9582313619518593,\n",
              "    0.9994819634273038,\n",
              "    0.9999708405331456],\n",
              "   'generated_answer_tokens': [' 8',\n",
              "    '-',\n",
              "    '10',\n",
              "    '%',\n",
              "    ' of',\n",
              "    ' undergrad',\n",
              "    'uates',\n",
              "    ' are',\n",
              "    ' members',\n",
              "    ' of',\n",
              "    ' fr',\n",
              "    'atern',\n",
              "    'ities',\n",
              "    ' or',\n",
              "    ' sor',\n",
              "    'or'],\n",
              "   'generated_probs': [0.5153719015516597,\n",
              "    0.9614624041171432,\n",
              "    0.9998541341794535,\n",
              "    0.9608428365091695,\n",
              "    0.8434735457210673,\n",
              "    0.6881938857959891,\n",
              "    0.9999758481046617,\n",
              "    0.9381970381896297,\n",
              "    0.9752038820985883,\n",
              "    0.9983121600067282,\n",
              "    0.987852129434202,\n",
              "    0.9999633297003718,\n",
              "    0.9999688149902626,\n",
              "    0.9582313619518593,\n",
              "    0.9994819634273038,\n",
              "    0.9999708405331456],\n",
              "   'generated_text': ' 8-10% of undergraduates are members of fraternities or soror',\n",
              "   'generated_tokens': [' 8',\n",
              "    '-',\n",
              "    '10',\n",
              "    '%',\n",
              "    ' of',\n",
              "    ' undergrad',\n",
              "    'uates',\n",
              "    ' are',\n",
              "    ' members',\n",
              "    ' of',\n",
              "    ' fr',\n",
              "    'atern',\n",
              "    'ities',\n",
              "    ' or',\n",
              "    ' sor',\n",
              "    'or'],\n",
              "   'id': '572867543acd2414000df9a5',\n",
              "   'prediction': ' 8-10% of undergraduates are members of fraternities or soror',\n",
              "   'prompt': 'Title: University of Chicago\\n\\nBackground: of the fraternities form the University of Chicago Interfraternity Council. In 2002, the Associate Director of Student Activities estimated that 8–10 percent of undergraduates were members of fraternities or sororities. The student activities office has used similar figures, stating that one in ten undergraduates participate in Greek life. On-campus undergraduate students at the University of Chicago participate in a house system in which each student is assigned to one of the university\\'s 7 residence hall buildings and to a smaller community within their residence hall called a \"House\". There are 38 houses, with an average of 70 students in each\\n\\nQ: How many fraternities form the University of Chicago Interfraternity Council?\\n\\nA:',\n",
              "   'question': 'How many fraternities form the University of Chicago Interfraternity Council?'},\n",
              "  {'answers': ['the mesoglea', 'mesoglea', 'mesoglea'],\n",
              "   'em': 0,\n",
              "   'f1': 0.19999999999999998,\n",
              "   'generated_answer': ' The ciliary rosettes pump water into the mesoglea to increase its',\n",
              "   'generated_answer_probs': [0.433867691350489,\n",
              "    0.9928967546546501,\n",
              "    0.9997045865631448,\n",
              "    0.9999663107444957,\n",
              "    0.999984312696047,\n",
              "    0.9994146102075013,\n",
              "    0.8316856118038612,\n",
              "    0.999843642585095,\n",
              "    0.9994641422230885,\n",
              "    0.9998404253833838,\n",
              "    0.9998583086791635,\n",
              "    0.9990939379922928,\n",
              "    0.9999903931971457,\n",
              "    0.9952163333536665,\n",
              "    0.7047781546116035,\n",
              "    0.9995679752495796],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' c',\n",
              "    'iliary',\n",
              "    ' ro',\n",
              "    'set',\n",
              "    'tes',\n",
              "    ' pump',\n",
              "    ' water',\n",
              "    ' into',\n",
              "    ' the',\n",
              "    ' mes',\n",
              "    'ogle',\n",
              "    'a',\n",
              "    ' to',\n",
              "    ' increase',\n",
              "    ' its'],\n",
              "   'generated_probs': [0.433867691350489,\n",
              "    0.9928967546546501,\n",
              "    0.9997045865631448,\n",
              "    0.9999663107444957,\n",
              "    0.999984312696047,\n",
              "    0.9994146102075013,\n",
              "    0.8316856118038612,\n",
              "    0.999843642585095,\n",
              "    0.9994641422230885,\n",
              "    0.9998404253833838,\n",
              "    0.9998583086791635,\n",
              "    0.9990939379922928,\n",
              "    0.9999903931971457,\n",
              "    0.9952163333536665,\n",
              "    0.7047781546116035,\n",
              "    0.9995679752495796],\n",
              "   'generated_text': ' The ciliary rosettes pump water into the mesoglea to increase its',\n",
              "   'generated_tokens': [' The',\n",
              "    ' c',\n",
              "    'iliary',\n",
              "    ' ro',\n",
              "    'set',\n",
              "    'tes',\n",
              "    ' pump',\n",
              "    ' water',\n",
              "    ' into',\n",
              "    ' the',\n",
              "    ' mes',\n",
              "    'ogle',\n",
              "    'a',\n",
              "    ' to',\n",
              "    ' increase',\n",
              "    ' its'],\n",
              "   'id': '57264e66dd62a815002e811b',\n",
              "   'prediction': ' The ciliary rosettes pump water into the mesoglea to increase its',\n",
              "   'prompt': 'Title: Ctenophora\\n\\nBackground: as part of their escape behavior, by reversing the power stroke of the comb plate cilia. It is uncertain how ctenophores control their buoyancy, but experiments have shown that some species rely on osmotic pressure to adapt to water of different densities. Their body fluids are normally as concentrated as seawater. If they enter less dense brackish water, the ciliary rosettes in the body cavity may pump this into the mesoglea to increase its bulk and decrease its density, to avoid sinking. Conversely if they move from brackish to full-strength seawater, the rosettes may pump water out of the mesoglea\\n\\nQ: Ciliary rosettes pump water into what to control buoyancy?\\n\\nA:',\n",
              "   'question': 'Ciliary rosettes pump water into what to control buoyancy?'},\n",
              "  {'answers': ['drama series', 'drama series', 'drama series'],\n",
              "   'em': 0,\n",
              "   'f1': 0.3636363636363636,\n",
              "   'generated_answer': ' NBC Red tested new programs, drama series, and movies.',\n",
              "   'generated_answer_probs': [0.2790361878545355,\n",
              "    0.990826351039963,\n",
              "    0.8895058457031305,\n",
              "    0.4735716300370387,\n",
              "    0.5238298820230161,\n",
              "    0.8949647651766067,\n",
              "    0.4472548824730072,\n",
              "    0.9989016511271592,\n",
              "    0.6115367546118133,\n",
              "    0.9569942030179854,\n",
              "    0.23377805421098907,\n",
              "    0.9990283709375002],\n",
              "   'generated_answer_tokens': [' NBC',\n",
              "    ' Red',\n",
              "    ' tested',\n",
              "    ' new',\n",
              "    ' programs',\n",
              "    ',',\n",
              "    ' drama',\n",
              "    ' series',\n",
              "    ',',\n",
              "    ' and',\n",
              "    ' movies',\n",
              "    '.'],\n",
              "   'generated_probs': [0.2790361878545355,\n",
              "    0.990826351039963,\n",
              "    0.8895058457031305,\n",
              "    0.4735716300370387,\n",
              "    0.5238298820230161,\n",
              "    0.8949647651766067,\n",
              "    0.4472548824730072,\n",
              "    0.9989016511271592,\n",
              "    0.6115367546118133,\n",
              "    0.9569942030179854,\n",
              "    0.23377805421098907,\n",
              "    0.9990283709375002],\n",
              "   'generated_text': ' NBC Red tested new programs, drama series, and movies.',\n",
              "   'generated_tokens': [' NBC',\n",
              "    ' Red',\n",
              "    ' tested',\n",
              "    ' new',\n",
              "    ' programs',\n",
              "    ',',\n",
              "    ' drama',\n",
              "    ' series',\n",
              "    ',',\n",
              "    ' and',\n",
              "    ' movies',\n",
              "    '.'],\n",
              "   'id': '5726808bdd62a815002e8779',\n",
              "   'prediction': ' NBC Red tested new programs, drama series, and movies.',\n",
              "   'prompt': 'Title: American Broadcasting Company\\n\\nBackground: properties in 2007. In the 1930s, radio in the United States was dominated by three companies: the Columbia Broadcasting System (CBS), the Mutual Broadcasting System and the National Broadcasting Company (NBC). The last was owned by electronics manufacturer Radio Corporation of America (RCA), which owned two radio networks that each ran different varieties of programming, NBC Blue and NBC Red. The NBC Blue Network was created in 1927 for the primary purpose of testing new programs on markets of lesser importance than those served by NBC Red, which served the major cities, and to test drama series. In 1934, Mutual\\n\\nQ: What kind of programs did NBC Red test?\\n\\nA:',\n",
              "   'question': 'What kind of programs did NBC Red test?'},\n",
              "  {'answers': ['natural specificity of the immune system',\n",
              "    'natural specificity',\n",
              "    'the natural specificity'],\n",
              "   'em': 0,\n",
              "   'f1': 0.8333333333333333,\n",
              "   'generated_answer': ' Vaccination exploits the natural specificity of the immune system.',\n",
              "   'generated_answer_probs': [0.5546417051589415,\n",
              "    0.9937021297446593,\n",
              "    0.9988559948733648,\n",
              "    0.9983489968077383,\n",
              "    0.9773475366736531,\n",
              "    0.9998414990326058,\n",
              "    0.9988627904134708,\n",
              "    0.9996725190935817,\n",
              "    0.9125856581372058,\n",
              "    0.9998853684157022,\n",
              "    0.44374519341145907],\n",
              "   'generated_answer_tokens': [' Vacc',\n",
              "    'ination',\n",
              "    ' exploits',\n",
              "    ' the',\n",
              "    ' natural',\n",
              "    ' specificity',\n",
              "    ' of',\n",
              "    ' the',\n",
              "    ' immune',\n",
              "    ' system',\n",
              "    '.'],\n",
              "   'generated_probs': [0.5546417051589415,\n",
              "    0.9937021297446593,\n",
              "    0.9988559948733648,\n",
              "    0.9983489968077383,\n",
              "    0.9773475366736531,\n",
              "    0.9998414990326058,\n",
              "    0.9988627904134708,\n",
              "    0.9996725190935817,\n",
              "    0.9125856581372058,\n",
              "    0.9998853684157022,\n",
              "    0.44374519341145907],\n",
              "   'generated_text': ' Vaccination exploits the natural specificity of the immune system.',\n",
              "   'generated_tokens': [' Vacc',\n",
              "    'ination',\n",
              "    ' exploits',\n",
              "    ' the',\n",
              "    ' natural',\n",
              "    ' specificity',\n",
              "    ' of',\n",
              "    ' the',\n",
              "    ' immune',\n",
              "    ' system',\n",
              "    '.'],\n",
              "   'id': '5729ffda1d046914007796b2',\n",
              "   'prediction': ' Vaccination exploits the natural specificity of the immune system.',\n",
              "   'prompt': 'Title: Immune system\\n\\nBackground: be transferred artificially from one individual to another via antibody-rich serum. Long-term \"active\" memory is acquired following infection by activation of B and T cells. Active immunity can also be generated artificially, through vaccination. The principle behind vaccination (also called immunization) is to introduce an antigen from a pathogen in order to stimulate the immune system and develop specific immunity against that particular pathogen without causing disease associated with that organism. This deliberate induction of an immune response is successful because it exploits the natural specificity of the immune system, as well as its inducibility. With infectious disease remaining one\\n\\nQ: Vaccination exploits what feature of the human immune system in order to be successful?\\n\\nA:',\n",
              "   'question': 'Vaccination exploits what feature of the human immune system in order to be successful?'},\n",
              "  {'answers': ['the Queen', 'the Queen', 'the Queen'],\n",
              "   'em': 1,\n",
              "   'f1': 1.0,\n",
              "   'generated_answer': ' The Queen',\n",
              "   'generated_answer_probs': [0.6863556330928111, 0.8600656976810241],\n",
              "   'generated_answer_tokens': [' The', ' Queen'],\n",
              "   'generated_probs': [0.6863556330928111, 0.8600656976810241],\n",
              "   'generated_text': ' The Queen',\n",
              "   'generated_tokens': [' The', ' Queen'],\n",
              "   'id': '572fbf21a23a5019007fc93a',\n",
              "   'prediction': ' The Queen',\n",
              "   'prompt': \"Title: Scottish Parliament\\n\\nBackground: to make laws. Presented to the Scottish Parliament by the Queen upon Parliament's official opening in July 1999, the mace is displayed in a glass case, suspended from the lid. At the beginning of each sitting in the chamber, the lid of the case is rotated so that the mace is above the glass, to symbolise that a full meeting of the Parliament is taking place. Parliament typically sits Tuesdays, Wednesdays and Thursdays from early January to late June and from early September to mid December, with two-week recesses in April and October. Plenary meetings in the debating chamber usually\\n\\nQ: Who presented the mac to the Scottish Parliament when it was initially opened?\\n\\nA:\",\n",
              "   'question': 'Who presented the mac to the Scottish Parliament when it was initially opened?'},\n",
              "  {'answers': ['greater than 1',\n",
              "    '1',\n",
              "    '1',\n",
              "    'is greater than 1 and less than or equal to the square root of n',\n",
              "    '1'],\n",
              "   'em': 0,\n",
              "   'f1': 0.8275862068965518,\n",
              "   'generated_answer': ' m must be greater than 1 and less than or equal to the square root of',\n",
              "   'generated_answer_probs': [0.3182232495208934,\n",
              "    0.282441112910125,\n",
              "    0.9927242582972311,\n",
              "    0.9548682845029103,\n",
              "    0.9903513008046472,\n",
              "    0.7088582513586758,\n",
              "    0.86691636645282,\n",
              "    0.99937515252854,\n",
              "    0.9947939718813166,\n",
              "    0.7938210507701295,\n",
              "    0.9997892840037347,\n",
              "    0.9998810755280757,\n",
              "    0.986089973034983,\n",
              "    0.995585587289673,\n",
              "    0.9993703852905766,\n",
              "    0.9988735792886221],\n",
              "   'generated_answer_tokens': [' m',\n",
              "    ' must',\n",
              "    ' be',\n",
              "    ' greater',\n",
              "    ' than',\n",
              "    ' 1',\n",
              "    ' and',\n",
              "    ' less',\n",
              "    ' than',\n",
              "    ' or',\n",
              "    ' equal',\n",
              "    ' to',\n",
              "    ' the',\n",
              "    ' square',\n",
              "    ' root',\n",
              "    ' of'],\n",
              "   'generated_probs': [0.3182232495208934,\n",
              "    0.282441112910125,\n",
              "    0.9927242582972311,\n",
              "    0.9548682845029103,\n",
              "    0.9903513008046472,\n",
              "    0.7088582513586758,\n",
              "    0.86691636645282,\n",
              "    0.99937515252854,\n",
              "    0.9947939718813166,\n",
              "    0.7938210507701295,\n",
              "    0.9997892840037347,\n",
              "    0.9998810755280757,\n",
              "    0.986089973034983,\n",
              "    0.995585587289673,\n",
              "    0.9993703852905766,\n",
              "    0.9988735792886221],\n",
              "   'generated_text': ' m must be greater than 1 and less than or equal to the square root of',\n",
              "   'generated_tokens': [' m',\n",
              "    ' must',\n",
              "    ' be',\n",
              "    ' greater',\n",
              "    ' than',\n",
              "    ' 1',\n",
              "    ' and',\n",
              "    ' less',\n",
              "    ' than',\n",
              "    ' or',\n",
              "    ' equal',\n",
              "    ' to',\n",
              "    ' the',\n",
              "    ' square',\n",
              "    ' root',\n",
              "    ' of'],\n",
              "   'id': '57297bc9af94a219006aa4c9',\n",
              "   'prediction': ' m must be greater than 1 and less than or equal to the square root of',\n",
              "   'prompt': 'Title: Prime number\\n\\nBackground: particular numbers. Most such methods only tell whether \"n\" is prime or not. Routines also yielding one (or all) prime factors of \"n\" are called factorization algorithms. The most basic method of checking the primality of a given integer \"n\" is called \"trial division\". This routine consists of dividing \"n\" by each integer \"m\" that is greater than 1 and less than or equal to the square root of \"n\". If the result of any of these divisions is an integer, then \"n\" is not a prime, otherwise it is a prime. Indeed, if formula_6 is composite (with \"a\" and\\n\\nQ: Trial division involves dividing n by every integer m greater than what?\\n\\nA:',\n",
              "   'question': 'Trial division involves dividing n by every integer m greater than what?'},\n",
              "  {'answers': ['The Day of the Doctor',\n",
              "    'The Day of the Doctor',\n",
              "    'The Day of the Doctor'],\n",
              "   'em': 0,\n",
              "   'f1': 0.3333333333333333,\n",
              "   'generated_answer': ' The Name of the Doctor was the name of the 50th Anniversary episode.',\n",
              "   'generated_answer_probs': [0.6662739744396022,\n",
              "    0.4819653960192132,\n",
              "    0.9983072714837121,\n",
              "    0.9963708228401325,\n",
              "    0.9985691769048336,\n",
              "    0.4694364951869625,\n",
              "    0.7546651787123736,\n",
              "    0.42988334405347495,\n",
              "    0.9827418065330903,\n",
              "    0.9995298269260179,\n",
              "    0.8230175451520861,\n",
              "    0.9999828803405431,\n",
              "    0.5005581015256982,\n",
              "    0.994764585802988,\n",
              "    0.9378134221959846],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' Name',\n",
              "    ' of',\n",
              "    ' the',\n",
              "    ' Doctor',\n",
              "    ' was',\n",
              "    ' the',\n",
              "    ' name',\n",
              "    ' of',\n",
              "    ' the',\n",
              "    ' 50',\n",
              "    'th',\n",
              "    ' Anniversary',\n",
              "    ' episode',\n",
              "    '.'],\n",
              "   'generated_probs': [0.6662739744396022,\n",
              "    0.4819653960192132,\n",
              "    0.9983072714837121,\n",
              "    0.9963708228401325,\n",
              "    0.9985691769048336,\n",
              "    0.4694364951869625,\n",
              "    0.7546651787123736,\n",
              "    0.42988334405347495,\n",
              "    0.9827418065330903,\n",
              "    0.9995298269260179,\n",
              "    0.8230175451520861,\n",
              "    0.9999828803405431,\n",
              "    0.5005581015256982,\n",
              "    0.994764585802988,\n",
              "    0.9378134221959846],\n",
              "   'generated_text': ' The Name of the Doctor was the name of the 50th Anniversary episode.',\n",
              "   'generated_tokens': [' The',\n",
              "    ' Name',\n",
              "    ' of',\n",
              "    ' the',\n",
              "    ' Doctor',\n",
              "    ' was',\n",
              "    ' the',\n",
              "    ' name',\n",
              "    ' of',\n",
              "    ' the',\n",
              "    ' 50',\n",
              "    'th',\n",
              "    ' Anniversary',\n",
              "    ' episode',\n",
              "    '.'],\n",
              "   'id': '57280b2b2ca10214002d9c69',\n",
              "   'prediction': ' The Name of the Doctor was the name of the 50th Anniversary episode.',\n",
              "   'prompt': 'Title: The Doctor (Doctor Who)\\n\\nBackground: the 50th anniversary special, featured Paul McGann reprising his role as the Eighth Doctor and was set during the Time War, albeit much earlier than during \"The End of Time\". The mini-episode presented him as a conscientious objector to the war who regenerated under controlled circumstances into the War Doctor (John Hurt), a previously unseen incarnation created retroactively by Davies\\' successor as head writer, Steven Moffat, for the 50th anniversary special \"The Day of the Doctor\". He was a numberless \"mayfly\" Doctor so as not to disrupt the accepted numbering of the Ninth, Tenth and Eleventh Doctors. \"The Day of\\n\\nQ: What was the name of the 50th Anniversary episode?\\n\\nA:',\n",
              "   'question': 'What was the name of the 50th Anniversary episode?'},\n",
              "  {'answers': ['oceanic',\n",
              "    'oceanic',\n",
              "    'significantly milder than some other locations'],\n",
              "   'em': 0,\n",
              "   'f1': 0.2222222222222222,\n",
              "   'generated_answer': ' The climate in Newcastle is a cold oceanic (Köppen \"C',\n",
              "   'generated_answer_probs': [0.63043593410053,\n",
              "    0.969027162508234,\n",
              "    0.903555213623199,\n",
              "    0.9999796626968057,\n",
              "    0.9973999659588532,\n",
              "    0.899965541151734,\n",
              "    0.929402358198664,\n",
              "    0.9990250335888986,\n",
              "    0.9999858605059636,\n",
              "    0.5370398063174402,\n",
              "    0.9995925894842121,\n",
              "    0.9999928937497495,\n",
              "    0.9999992145956385,\n",
              "    0.9999958767602006,\n",
              "    0.9912958523532557,\n",
              "    0.9999969487016552],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' climate',\n",
              "    ' in',\n",
              "    ' Newcastle',\n",
              "    ' is',\n",
              "    ' a',\n",
              "    ' cold',\n",
              "    ' ocean',\n",
              "    'ic',\n",
              "    ' (',\n",
              "    'K',\n",
              "    'ö',\n",
              "    'pp',\n",
              "    'en',\n",
              "    ' \"',\n",
              "    'C'],\n",
              "   'generated_probs': [0.63043593410053,\n",
              "    0.969027162508234,\n",
              "    0.903555213623199,\n",
              "    0.9999796626968057,\n",
              "    0.9973999659588532,\n",
              "    0.899965541151734,\n",
              "    0.929402358198664,\n",
              "    0.9990250335888986,\n",
              "    0.9999858605059636,\n",
              "    0.5370398063174402,\n",
              "    0.9995925894842121,\n",
              "    0.9999928937497495,\n",
              "    0.9999992145956385,\n",
              "    0.9999958767602006,\n",
              "    0.9912958523532557,\n",
              "    0.9999969487016552],\n",
              "   'generated_text': ' The climate in Newcastle is a cold oceanic (Köppen \"C',\n",
              "   'generated_tokens': [' The',\n",
              "    ' climate',\n",
              "    ' in',\n",
              "    ' Newcastle',\n",
              "    ' is',\n",
              "    ' a',\n",
              "    ' cold',\n",
              "    ' ocean',\n",
              "    'ic',\n",
              "    ' (',\n",
              "    'K',\n",
              "    'ö',\n",
              "    'pp',\n",
              "    'en',\n",
              "    ' \"',\n",
              "    'C'],\n",
              "   'id': '57267383dd62a815002e8552',\n",
              "   'prediction': ' The climate in Newcastle is a cold oceanic (Köppen \"C',\n",
              "   'prompt': 'Title: Newcastle upon Tyne\\n\\nBackground: Newcastle City Council. A corruption scandal was uncovered involving Smith and John Poulson, a property developer from Pontefract, West Yorkshire, and both were imprisoned. Echoes of the scandal were revisited in the late 1990s in the BBC TV mini-series, \"Our Friends in the North\". Situated in the coldest region of England, the climate in Newcastle is a cold oceanic (Köppen \"Cfb\") one. Being in the rain shadow of the North Pennines, it is also among the driest cities in the UK. Temperature extremes recorded at Newcastle Weather Centre include during August 1990 down to during January 1982. In contrast to\\n\\nQ: What\\'s the climate like in Newcastle?\\n\\nA:',\n",
              "   'question': \"What's the climate like in Newcastle?\"},\n",
              "  {'answers': ['New England Patriots',\n",
              "    'the New England Patriots',\n",
              "    'New England Patriots'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' The Denver Broncos beat the Carolina Panthers 24-10 in the AFC Championship game.',\n",
              "   'generated_answer_probs': [0.9155156871056597,\n",
              "    0.7504257251210503,\n",
              "    0.9993253828565383,\n",
              "    0.80241196574635,\n",
              "    0.9994292146599653,\n",
              "    0.8054118640842586,\n",
              "    0.9996813423621335,\n",
              "    0.9384243721061609,\n",
              "    0.965459396860936,\n",
              "    0.9999855028895841,\n",
              "    0.9770759216524926,\n",
              "    0.8231641293989092,\n",
              "    0.6116504376291328,\n",
              "    0.994776149411649,\n",
              "    0.8596330300887403,\n",
              "    0.994436998121504],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' Denver',\n",
              "    ' Broncos',\n",
              "    ' beat',\n",
              "    ' the',\n",
              "    ' Carolina',\n",
              "    ' Panthers',\n",
              "    ' 24',\n",
              "    '-',\n",
              "    '10',\n",
              "    ' in',\n",
              "    ' the',\n",
              "    ' AFC',\n",
              "    ' Championship',\n",
              "    ' game',\n",
              "    '.'],\n",
              "   'generated_probs': [0.9155156871056597,\n",
              "    0.7504257251210503,\n",
              "    0.9993253828565383,\n",
              "    0.80241196574635,\n",
              "    0.9994292146599653,\n",
              "    0.8054118640842586,\n",
              "    0.9996813423621335,\n",
              "    0.9384243721061609,\n",
              "    0.965459396860936,\n",
              "    0.9999855028895841,\n",
              "    0.9770759216524926,\n",
              "    0.8231641293989092,\n",
              "    0.6116504376291328,\n",
              "    0.994776149411649,\n",
              "    0.8596330300887403,\n",
              "    0.994436998121504],\n",
              "   'generated_text': ' The Denver Broncos beat the Carolina Panthers 24-10 in the AFC Championship game.',\n",
              "   'generated_tokens': [' The',\n",
              "    ' Denver',\n",
              "    ' Broncos',\n",
              "    ' beat',\n",
              "    ' the',\n",
              "    ' Carolina',\n",
              "    ' Panthers',\n",
              "    ' 24',\n",
              "    '-',\n",
              "    '10',\n",
              "    ' in',\n",
              "    ' the',\n",
              "    ' AFC',\n",
              "    ' Championship',\n",
              "    ' game',\n",
              "    '.'],\n",
              "   'id': '56d6017d1c85041400946ec1',\n",
              "   'prediction': ' The Denver Broncos beat the Carolina Panthers 24-10 in the AFC Championship game.',\n",
              "   'prompt': \"Title: 2015 Denver Broncos season\\n\\nBackground: the Pittsburgh Steelers 23–16 in the Divisional round and the defending Super Bowl champions New England Patriots 20–18 in the AFC Championship Game. The Broncos then defeated the Carolina Panthers 24–10 in Super Bowl 50 — the franchise's third Super Bowl championship, and the first since winning back-to-back Super Bowls in 1997 and 1998. On January 12, 2015, one day after the Broncos' loss to the Indianapolis Colts in the Divisional round of the 2014 playoffs, the Broncos and head coach John Fox decided to mutually part ways. Fox compiled a 49–22 record in four seasons (including the playoffs), led\\n\\nQ: Who did Denver beat in the 2015 AFC Championship game?\\n\\nA:\",\n",
              "   'question': 'Who did Denver beat in the 2015 AFC Championship game?'},\n",
              "  {'answers': ['evening', 'evening', 'evening'],\n",
              "   'em': 0,\n",
              "   'f1': 0.18181818181818182,\n",
              "   'generated_answer': ' The couple was married on the evening of the same day, the Bugenhagen wedding',\n",
              "   'generated_answer_probs': [0.5483666754541724,\n",
              "    0.9887926347318201,\n",
              "    0.7810196261068468,\n",
              "    0.999845074732159,\n",
              "    0.46360883978494427,\n",
              "    0.9844454315663145,\n",
              "    0.9968695405382244,\n",
              "    0.9999608282812318,\n",
              "    0.9905923435118057,\n",
              "    0.9991085404863379,\n",
              "    0.9999934907225855,\n",
              "    0.802902333063384,\n",
              "    0.3913212911205631,\n",
              "    0.30068580398369427,\n",
              "    0.9999520062817353,\n",
              "    0.3724628528603911],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' couple',\n",
              "    ' was',\n",
              "    ' married',\n",
              "    ' on',\n",
              "    ' the',\n",
              "    ' evening',\n",
              "    ' of',\n",
              "    ' the',\n",
              "    ' same',\n",
              "    ' day',\n",
              "    ',',\n",
              "    ' the',\n",
              "    ' Bug',\n",
              "    'enhagen',\n",
              "    ' wedding'],\n",
              "   'generated_probs': [0.5483666754541724,\n",
              "    0.9887926347318201,\n",
              "    0.7810196261068468,\n",
              "    0.999845074732159,\n",
              "    0.46360883978494427,\n",
              "    0.9844454315663145,\n",
              "    0.9968695405382244,\n",
              "    0.9999608282812318,\n",
              "    0.9905923435118057,\n",
              "    0.9991085404863379,\n",
              "    0.9999934907225855,\n",
              "    0.802902333063384,\n",
              "    0.3913212911205631,\n",
              "    0.30068580398369427,\n",
              "    0.9999520062817353,\n",
              "    0.3724628528603911],\n",
              "   'generated_text': ' The couple was married on the evening of the same day, the Bugenhagen wedding',\n",
              "   'generated_tokens': [' The',\n",
              "    ' couple',\n",
              "    ' was',\n",
              "    ' married',\n",
              "    ' on',\n",
              "    ' the',\n",
              "    ' evening',\n",
              "    ' of',\n",
              "    ' the',\n",
              "    ' same',\n",
              "    ' day',\n",
              "    ',',\n",
              "    ' the',\n",
              "    ' Bug',\n",
              "    'enhagen',\n",
              "    ' wedding'],\n",
              "   'id': '56f8541da6d7ea1400e17578',\n",
              "   'prediction': ' The couple was married on the evening of the same day, the Bugenhagen wedding',\n",
              "   'prompt': 'Title: Martin Luther\\n\\nBackground: On the evening of the same day, the couple was married by Bugenhagen. The ceremonial walk to the church and the wedding banquet were left out, and were made up two weeks later on 27 June. Some priests and former religious had already married, including Andreas Karlstadt and Justus Jonas, but Luther\\'s wedding set the seal of approval on clerical marriage. He had long condemned vows of celibacy on Biblical grounds, but his decision to marry surprised many, not least Melanchthon, who called it reckless. Luther had written to George Spalatin on 30 November 1524, \"I shall never take a\\n\\nQ: At what point in the day was the couple married?\\n\\nA:',\n",
              "   'question': 'At what point in the day was the couple married?'},\n",
              "  {'answers': [\"Carlo Crivelli's Virgin and Child\",\n",
              "    \"Carlo Crivelli's Virgin and Child)\",\n",
              "    \"Carlo Crivelli's Virgin and Child\"],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' One example of a non-French painting was included in the Jones bequest of',\n",
              "   'generated_answer_probs': [0.5899218550041754,\n",
              "    0.9897718806410458,\n",
              "    0.9884963369929805,\n",
              "    0.9998196837889225,\n",
              "    0.9792439672864778,\n",
              "    0.9997998942138341,\n",
              "    0.9995449659793965,\n",
              "    0.9999349604091659,\n",
              "    0.9624426105504429,\n",
              "    0.9995067612822303,\n",
              "    0.9999282832977656,\n",
              "    0.999998499344226,\n",
              "    0.9999592767592137,\n",
              "    0.9999906297369012,\n",
              "    0.9999992145956385,\n",
              "    0.9999987377612967],\n",
              "   'generated_answer_tokens': [' One',\n",
              "    ' example',\n",
              "    ' of',\n",
              "    ' a',\n",
              "    ' non',\n",
              "    '-',\n",
              "    'French',\n",
              "    ' painting',\n",
              "    ' was',\n",
              "    ' included',\n",
              "    ' in',\n",
              "    ' the',\n",
              "    ' Jones',\n",
              "    ' be',\n",
              "    'quest',\n",
              "    ' of'],\n",
              "   'generated_probs': [0.5899218550041754,\n",
              "    0.9897718806410458,\n",
              "    0.9884963369929805,\n",
              "    0.9998196837889225,\n",
              "    0.9792439672864778,\n",
              "    0.9997998942138341,\n",
              "    0.9995449659793965,\n",
              "    0.9999349604091659,\n",
              "    0.9624426105504429,\n",
              "    0.9995067612822303,\n",
              "    0.9999282832977656,\n",
              "    0.999998499344226,\n",
              "    0.9999592767592137,\n",
              "    0.9999906297369012,\n",
              "    0.9999992145956385,\n",
              "    0.9999987377612967],\n",
              "   'generated_text': ' One example of a non-French painting was included in the Jones bequest of',\n",
              "   'generated_tokens': [' One',\n",
              "    ' example',\n",
              "    ' of',\n",
              "    ' a',\n",
              "    ' non',\n",
              "    '-',\n",
              "    'French',\n",
              "    ' painting',\n",
              "    ' was',\n",
              "    ' included',\n",
              "    ' in',\n",
              "    ' the',\n",
              "    ' Jones',\n",
              "    ' be',\n",
              "    'quest',\n",
              "    ' of'],\n",
              "   'id': '5726f755708984140094d739',\n",
              "   'prediction': ' One example of a non-French painting was included in the Jones bequest of',\n",
              "   'prompt': 'Title: Victoria and Albert Museum\\n\\nBackground: Danby, Richard Parkes Bonington and Alphonse Legros. Richard Ellison\\'s collection of 100 British watercolours was given by his widow in 1860 and 1873 \\'to promote the foundation of the National Collection of Water Colour Paintings\\'. Over 500 British and European oil paintings, watercolours and miniatures and 3000 drawings and prints were bequeathed in 1868-9 by the clergymen Chauncey Hare Townshend and Alexander Dyce. Several French paintings entered the collection as part of the 260 paintings and miniatures (not all the works were French, for example Carlo Crivelli\\'s \"Virgin and Child\") that formed part of the Jones bequest of 1882 and\\n\\nQ: What was one example of a non-French painting was included in the Jones bequest of 1882?\\n\\nA:',\n",
              "   'question': 'What was one example of a non-French painting was included in the Jones bequest of 1882?'},\n",
              "  {'answers': ['Citizenship of the EU',\n",
              "    'Citizenship of the EU',\n",
              "    'Citizenship of the EU'],\n",
              "   'em': 0,\n",
              "   'f1': 0.23529411764705882,\n",
              "   'generated_answer': ' The Court of Justice has increasingly been viewing citizenship as a fundamental status of member state',\n",
              "   'generated_answer_probs': [0.6263550663726843,\n",
              "    0.901749579963585,\n",
              "    0.9314196326602096,\n",
              "    0.9994535336671451,\n",
              "    0.872135209785328,\n",
              "    0.7339083367338491,\n",
              "    0.5357680789897251,\n",
              "    0.8587693095934816,\n",
              "    0.9119310817680646,\n",
              "    0.969193279629041,\n",
              "    0.9818386182505537,\n",
              "    0.9994224189641813,\n",
              "    0.9995664243610951,\n",
              "    0.9304390895094794,\n",
              "    0.6227453199516005,\n",
              "    0.9996161937724614],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' Court',\n",
              "    ' of',\n",
              "    ' Justice',\n",
              "    ' has',\n",
              "    ' increasingly',\n",
              "    ' been',\n",
              "    ' viewing',\n",
              "    ' citizenship',\n",
              "    ' as',\n",
              "    ' a',\n",
              "    ' fundamental',\n",
              "    ' status',\n",
              "    ' of',\n",
              "    ' member',\n",
              "    ' state'],\n",
              "   'generated_probs': [0.6263550663726843,\n",
              "    0.901749579963585,\n",
              "    0.9314196326602096,\n",
              "    0.9994535336671451,\n",
              "    0.872135209785328,\n",
              "    0.7339083367338491,\n",
              "    0.5357680789897251,\n",
              "    0.8587693095934816,\n",
              "    0.9119310817680646,\n",
              "    0.969193279629041,\n",
              "    0.9818386182505537,\n",
              "    0.9994224189641813,\n",
              "    0.9995664243610951,\n",
              "    0.9304390895094794,\n",
              "    0.6227453199516005,\n",
              "    0.9996161937724614],\n",
              "   'generated_text': ' The Court of Justice has increasingly been viewing citizenship as a fundamental status of member state',\n",
              "   'generated_tokens': [' The',\n",
              "    ' Court',\n",
              "    ' of',\n",
              "    ' Justice',\n",
              "    ' has',\n",
              "    ' increasingly',\n",
              "    ' been',\n",
              "    ' viewing',\n",
              "    ' citizenship',\n",
              "    ' as',\n",
              "    ' a',\n",
              "    ' fundamental',\n",
              "    ' status',\n",
              "    ' of',\n",
              "    ' member',\n",
              "    ' state'],\n",
              "   'id': '5726bcde708984140094cfbf',\n",
              "   'prediction': ' The Court of Justice has increasingly been viewing citizenship as a fundamental status of member state',\n",
              "   'prompt': \"Title: European Union law\\n\\nBackground: increasingly sought to guarantee rights of citizens, and rights simply be being a human being. But although the Court of Justice stated that 'Citizenship is destined to be the fundamental status of nationals of the Member States', political debate remains on who should have access to public services and welfare systems funded by taxation. In 2008, just 8 million people from 500\\xa0million EU citizens (1.7 per cent) had in fact exercised rights of free movement, the vast majority workers. According to TFEU article 20, citizenship of the EU derives from nationality of a member state. Article 21 confers general rights\\n\\nQ: What has lately been being viewed as a fundamental status of member state nationals by the Court of Justice?\\n\\nA:\",\n",
              "   'question': 'What has lately been being viewed as a fundamental status of member state nationals by the Court of Justice?'},\n",
              "  {'answers': ['the capacity of the Tyne Tunnel',\n",
              "    'capacity of the Tyne Tunnel',\n",
              "    'the capacity of the Tyne Tunnel'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' The Euro Plus Monitor 2011 report increased the standard VAT from 19.6% to',\n",
              "   'generated_answer_probs': [0.6944581345709884,\n",
              "    0.8339498919692524,\n",
              "    0.9954373492610473,\n",
              "    0.9990675917629567,\n",
              "    0.9807434386989929,\n",
              "    0.39832054834689234,\n",
              "    0.5398836638222412,\n",
              "    0.9077610734262928,\n",
              "    0.16621374473671655,\n",
              "    0.9558633839121964,\n",
              "    0.9727917543586302,\n",
              "    0.99915330245083,\n",
              "    0.9955616238329883,\n",
              "    0.999904084080226,\n",
              "    0.9927278943550308,\n",
              "    0.999615716215935],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' Euro',\n",
              "    ' Plus',\n",
              "    ' Monitor',\n",
              "    ' 2011',\n",
              "    ' report',\n",
              "    ' increased',\n",
              "    ' the',\n",
              "    ' standard',\n",
              "    ' VAT',\n",
              "    ' from',\n",
              "    ' 19',\n",
              "    '.',\n",
              "    '6',\n",
              "    '%',\n",
              "    ' to'],\n",
              "   'generated_probs': [0.6944581345709884,\n",
              "    0.8339498919692524,\n",
              "    0.9954373492610473,\n",
              "    0.9990675917629567,\n",
              "    0.9807434386989929,\n",
              "    0.39832054834689234,\n",
              "    0.5398836638222412,\n",
              "    0.9077610734262928,\n",
              "    0.16621374473671655,\n",
              "    0.9558633839121964,\n",
              "    0.9727917543586302,\n",
              "    0.99915330245083,\n",
              "    0.9955616238329883,\n",
              "    0.999904084080226,\n",
              "    0.9927278943550308,\n",
              "    0.999615716215935],\n",
              "   'generated_text': ' The Euro Plus Monitor 2011 report increased the standard VAT from 19.6% to',\n",
              "   'generated_tokens': [' The',\n",
              "    ' Euro',\n",
              "    ' Plus',\n",
              "    ' Monitor',\n",
              "    ' 2011',\n",
              "    ' report',\n",
              "    ' increased',\n",
              "    ' the',\n",
              "    ' standard',\n",
              "    ' VAT',\n",
              "    ' from',\n",
              "    ' 19',\n",
              "    '.',\n",
              "    '6',\n",
              "    '%',\n",
              "    ' to'],\n",
              "   'id': '57268d1b708984140094c9d1',\n",
              "   'prediction': ' The Euro Plus Monitor 2011 report increased the standard VAT from 19.6% to',\n",
              "   'prompt': \"Title: Economic reforms and recovery proposals regarding the Eurozone crisis\\n\\nBackground: to follow this suit. In November 2012 French president François Hollande announced plans to reduce tax burden of the corporate sector by within three years, while increasing the standard VAT from 19.6% to 20% and introducing additional eco-taxes in 2016. To minimize negative effects of such policies on purchasing power and economic activity the French government will partly offset the tax hikes by decreasing employees' social security contributions by and by reducing the lower VAT for convenience goods (necessities) from 5.5% to 5%. On 15 November 2011, the Lisbon Council published the Euro Plus Monitor 2011. According to the report\\n\\nQ: What was increased in November 2011?\\n\\nA:\",\n",
              "   'question': 'What was increased in November 2011?'},\n",
              "  {'answers': ['2011', '2011', '2011'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' Harvard was on top of the World Reputation Rankings from 2004-2009.',\n",
              "   'generated_answer_probs': [0.9607894900741648,\n",
              "    0.6793089619178857,\n",
              "    0.9184603991080255,\n",
              "    0.9989420051715986,\n",
              "    0.9981549825411478,\n",
              "    0.921047366154367,\n",
              "    0.9236604529854072,\n",
              "    0.9997919079341581,\n",
              "    0.9999722719354299,\n",
              "    0.9993419540072945,\n",
              "    0.6361475281761813,\n",
              "    0.8642376241845233,\n",
              "    0.8012074393291454,\n",
              "    0.9983062003005845,\n",
              "    0.9913183837727412],\n",
              "   'generated_answer_tokens': [' Harvard',\n",
              "    ' was',\n",
              "    ' on',\n",
              "    ' top',\n",
              "    ' of',\n",
              "    ' the',\n",
              "    ' World',\n",
              "    ' Rep',\n",
              "    'utation',\n",
              "    ' Rankings',\n",
              "    ' from',\n",
              "    ' 2004',\n",
              "    '-',\n",
              "    '2009',\n",
              "    '.'],\n",
              "   'generated_probs': [0.9607894900741648,\n",
              "    0.6793089619178857,\n",
              "    0.9184603991080255,\n",
              "    0.9989420051715986,\n",
              "    0.9981549825411478,\n",
              "    0.921047366154367,\n",
              "    0.9236604529854072,\n",
              "    0.9997919079341581,\n",
              "    0.9999722719354299,\n",
              "    0.9993419540072945,\n",
              "    0.6361475281761813,\n",
              "    0.8642376241845233,\n",
              "    0.8012074393291454,\n",
              "    0.9983062003005845,\n",
              "    0.9913183837727412],\n",
              "   'generated_text': ' Harvard was on top of the World Reputation Rankings from 2004-2009.',\n",
              "   'generated_tokens': [' Harvard',\n",
              "    ' was',\n",
              "    ' on',\n",
              "    ' top',\n",
              "    ' of',\n",
              "    ' the',\n",
              "    ' World',\n",
              "    ' Rep',\n",
              "    'utation',\n",
              "    ' Rankings',\n",
              "    ' from',\n",
              "    ' 2004',\n",
              "    '-',\n",
              "    '2009',\n",
              "    '.'],\n",
              "   'id': '5727d9c43acd2414000dee18',\n",
              "   'prediction': ' Harvard was on top of the World Reputation Rankings from 2004-2009.',\n",
              "   'prompt': 'Title: Harvard University\\n\\nBackground: housing the film archive, the Peabody Museum of Archaeology and Ethnology, specializing in the cultural history and civilizations of the Western Hemisphere, and the Semitic Museum featuring artifacts from excavations in the Middle East. Among overall rankings, both \"Academic Ranking of World Universities\" (\"ARWU\") and \"THE World Reputation Rankings\" have consecutively ranked Harvard the best since the time when they were first released. When QS and \"THE\" were published in partnership as the \"THE-QS World University Rankings\" during 2004-2009, Harvard had also held the top spot every year. Regarding rankings of specific indicators, Harvard topped both \"University Ranking by Academic\\n\\nQ: Beginning in what year was Harvard on top of the World Reputation Rankings?\\n\\nA:',\n",
              "   'question': 'Beginning in what year was Harvard on top of the World Reputation Rankings?'},\n",
              "  {'answers': ['49.6%', '49.6%', '49.6%'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' The percentage of whit people in Fresno in 2010 was 98.2%.',\n",
              "   'generated_answer_probs': [0.38684841700788347,\n",
              "    0.591280278200561,\n",
              "    0.9999264962315344,\n",
              "    0.5822275664664304,\n",
              "    0.9999560591954254,\n",
              "    0.9986920233480903,\n",
              "    0.9999917035484157,\n",
              "    0.7310718017849545,\n",
              "    0.9999685756437554,\n",
              "    0.9994031662761449,\n",
              "    0.7851857460638626,\n",
              "    0.9992902754337083,\n",
              "    0.999990987363614,\n",
              "    0.971340927145121],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' percentage',\n",
              "    ' of',\n",
              "    ' whit',\n",
              "    ' people',\n",
              "    ' in',\n",
              "    ' Fresno',\n",
              "    ' in',\n",
              "    ' 2010',\n",
              "    ' was',\n",
              "    ' 98',\n",
              "    '.',\n",
              "    '2',\n",
              "    '%.'],\n",
              "   'generated_probs': [0.38684841700788347,\n",
              "    0.591280278200561,\n",
              "    0.9999264962315344,\n",
              "    0.5822275664664304,\n",
              "    0.9999560591954254,\n",
              "    0.9986920233480903,\n",
              "    0.9999917035484157,\n",
              "    0.7310718017849545,\n",
              "    0.9999685756437554,\n",
              "    0.9994031662761449,\n",
              "    0.7851857460638626,\n",
              "    0.9992902754337083,\n",
              "    0.999990987363614,\n",
              "    0.971340927145121],\n",
              "   'generated_text': ' The percentage of whit people in Fresno in 2010 was 98.2%.',\n",
              "   'generated_tokens': [' The',\n",
              "    ' percentage',\n",
              "    ' of',\n",
              "    ' whit',\n",
              "    ' people',\n",
              "    ' in',\n",
              "    ' Fresno',\n",
              "    ' in',\n",
              "    ' 2010',\n",
              "    ' was',\n",
              "    ' 98',\n",
              "    '.',\n",
              "    '2',\n",
              "    '%.'],\n",
              "   'id': '5725f7cd38643c19005acf24',\n",
              "   'prediction': ' The percentage of whit people in Fresno in 2010 was 98.2%.',\n",
              "   'prompt': 'Title: Fresno, California\\n\\nBackground: 0.4% Puerto Rican. Non-Hispanic Whites were 30.0% of the population in 2010, down from 72.6% in 1970. The Census reported that 485,798 people (98.2% of the population) lived in households, 4,315 (0.9%) lived in non-institutionalized group quarters, and 4,552 (0.9%) were institutionalized. There were 158,349 households, of which 68,511 (43.3%) had children under the age of 18 living in them, 69,284 (43.8%) were opposite-sex married couples living together, 30,547 (19.3%) had a female householder with no husband present, 11,698 (7.4%) had a male householder with no wife present. There were 12,843 (8.1%) unmarried opposite-sex partnerships, and 1,388 (0.9%) same-sex married\\n\\nQ: What was the percentage of whit people in Fresno in 2010?\\n\\nA:',\n",
              "   'question': 'What was the percentage of whit people in Fresno in 2010?'},\n",
              "  {'answers': ['Beyoncé', 'Beyoncé', 'Beyoncé'],\n",
              "   'em': 0,\n",
              "   'f1': 0.4,\n",
              "   'generated_answer': ' Beyoncé and Bruno Mars',\n",
              "   'generated_answer_probs': [0.5317105056832674,\n",
              "    0.9995028274712408,\n",
              "    0.45330204938994934,\n",
              "    0.999957130154938,\n",
              "    0.9998617643254315],\n",
              "   'generated_answer_tokens': [' Beyon', 'cé', ' and', ' Bruno', ' Mars'],\n",
              "   'generated_probs': [0.5317105056832674,\n",
              "    0.9995028274712408,\n",
              "    0.45330204938994934,\n",
              "    0.999957130154938,\n",
              "    0.9998617643254315],\n",
              "   'generated_text': ' Beyoncé and Bruno Mars',\n",
              "   'generated_tokens': [' Beyon', 'cé', ' and', ' Bruno', ' Mars'],\n",
              "   'id': '56d9c551dc89441400fdb7d1',\n",
              "   'prediction': ' Beyoncé and Bruno Mars',\n",
              "   'prompt': 'Title: Super Bowl 50 halftime show\\n\\nBackground: that multiple acts would perform during the halftime show. Coldplay was confirmed as the lead half time performer for Super Bowl 50 on December 3, 2015, one day before the release of their seventh studio album \"A Head Full of Dreams\". It was confirmed that Beyoncé and Bruno Mars would join Coldplay as special guests. Chris Martin called Mars to ask him to perform with Coldplay, however Mars declined the offer. Nevertheless, the singer of the Coldplay invited Mars to his studio in Malibu where he was working. There, Martin revealed to Mars that he wanted for him to perform\\n\\nQ: On January 7, 2016, it was confirmed that which start would join Coldplay for the halftime show?\\n\\nA:',\n",
              "   'question': 'On January 7, 2016, it was confirmed that which start would join Coldplay for the halftime show?'},\n",
              "  {'answers': ['5,000 to 30,000', '5,000 to 30,000', '5,000 to 30,000'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' It is not known exactly how many Huguenots were killed during the St',\n",
              "   'generated_answer_probs': [0.25974048007793576,\n",
              "    0.9915432135082778,\n",
              "    0.48485771607658,\n",
              "    0.8865811392672877,\n",
              "    0.4195082864967522,\n",
              "    0.997811358576029,\n",
              "    0.99994127619731,\n",
              "    0.9863093186283065,\n",
              "    0.9999790647951444,\n",
              "    0.9999967093467143,\n",
              "    0.9976460761341372,\n",
              "    0.9979505388194277,\n",
              "    0.997081971744846,\n",
              "    0.9012824008650674,\n",
              "    0.5263500464687082,\n",
              "    0.9654045043311038],\n",
              "   'generated_answer_tokens': [' It',\n",
              "    ' is',\n",
              "    ' not',\n",
              "    ' known',\n",
              "    ' exactly',\n",
              "    ' how',\n",
              "    ' many',\n",
              "    ' Hug',\n",
              "    'u',\n",
              "    'en',\n",
              "    'ots',\n",
              "    ' were',\n",
              "    ' killed',\n",
              "    ' during',\n",
              "    ' the',\n",
              "    ' St'],\n",
              "   'generated_probs': [0.25974048007793576,\n",
              "    0.9915432135082778,\n",
              "    0.48485771607658,\n",
              "    0.8865811392672877,\n",
              "    0.4195082864967522,\n",
              "    0.997811358576029,\n",
              "    0.99994127619731,\n",
              "    0.9863093186283065,\n",
              "    0.9999790647951444,\n",
              "    0.9999967093467143,\n",
              "    0.9976460761341372,\n",
              "    0.9979505388194277,\n",
              "    0.997081971744846,\n",
              "    0.9012824008650674,\n",
              "    0.5263500464687082,\n",
              "    0.9654045043311038],\n",
              "   'generated_text': ' It is not known exactly how many Huguenots were killed during the St',\n",
              "   'generated_tokens': [' It',\n",
              "    ' is',\n",
              "    ' not',\n",
              "    ' known',\n",
              "    ' exactly',\n",
              "    ' how',\n",
              "    ' many',\n",
              "    ' Hug',\n",
              "    'u',\n",
              "    'en',\n",
              "    'ots',\n",
              "    ' were',\n",
              "    ' killed',\n",
              "    ' during',\n",
              "    ' the',\n",
              "    ' St'],\n",
              "   'id': '57107e6ca58dae1900cd69f4',\n",
              "   'prediction': ' It is not known exactly how many Huguenots were killed during the St',\n",
              "   'prompt': \"Title: Huguenot\\n\\nBackground: St. Bartholomew's Day Massacre of 24 August – 3 October 1572, Catholics killed thousands of Huguenots in Paris. Similar massacres took place in other towns in the weeks following. The main provincial towns and cities experiencing the Massacre were Aix, Bordeaux, Bourges, Lyons, Meaux, Orleans, Rouen, Toulouse, and Troyes. Nearly 3,000 Protestants were slaughtered in Toulouse alone. The exact number of fatalities throughout the country is not known. On 23–24 August, between about 2,000 and 3,000 Protestants were killed in Paris and between 3,000 and 7,000 more in the French provinces. By 17 September, almost 25,000 Protestants had been massacred\\n\\nQ: How many Huguenots were killed during this purge?\\n\\nA:\",\n",
              "   'question': 'How many Huguenots were killed during this purge?'},\n",
              "  {'answers': ['£76 million', '£76 million', '£76 million'],\n",
              "   'em': 0,\n",
              "   'f1': 0.3636363636363636,\n",
              "   'generated_answer': ' The estimated cost of the V&A branded gallery is £76 million.',\n",
              "   'generated_answer_probs': [0.5130078663055416,\n",
              "    0.6953834075425384,\n",
              "    0.9966179465704615,\n",
              "    0.9560461911456585,\n",
              "    0.9995819204696132,\n",
              "    0.9930883222780805,\n",
              "    0.9999883657376786,\n",
              "    0.999990869089687,\n",
              "    0.7231425439731696,\n",
              "    0.9911471423659503,\n",
              "    0.9817192290246919,\n",
              "    0.9989316357079341,\n",
              "    0.9849496222912224,\n",
              "    0.6437585149402615,\n",
              "    0.9724385394457631],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' estimated',\n",
              "    ' cost',\n",
              "    ' of',\n",
              "    ' the',\n",
              "    ' V',\n",
              "    '&',\n",
              "    'A',\n",
              "    ' branded',\n",
              "    ' gallery',\n",
              "    ' is',\n",
              "    ' £',\n",
              "    '76',\n",
              "    ' million',\n",
              "    '.'],\n",
              "   'generated_probs': [0.5130078663055416,\n",
              "    0.6953834075425384,\n",
              "    0.9966179465704615,\n",
              "    0.9560461911456585,\n",
              "    0.9995819204696132,\n",
              "    0.9930883222780805,\n",
              "    0.9999883657376786,\n",
              "    0.999990869089687,\n",
              "    0.7231425439731696,\n",
              "    0.9911471423659503,\n",
              "    0.9817192290246919,\n",
              "    0.9989316357079341,\n",
              "    0.9849496222912224,\n",
              "    0.6437585149402615,\n",
              "    0.9724385394457631],\n",
              "   'generated_text': ' The estimated cost of the V&A branded gallery is £76 million.',\n",
              "   'generated_tokens': [' The',\n",
              "    ' estimated',\n",
              "    ' cost',\n",
              "    ' of',\n",
              "    ' the',\n",
              "    ' V',\n",
              "    '&',\n",
              "    'A',\n",
              "    ' branded',\n",
              "    ' gallery',\n",
              "    ' is',\n",
              "    ' £',\n",
              "    '76',\n",
              "    ' million',\n",
              "    '.'],\n",
              "   'id': '57269656708984140094cafe',\n",
              "   'prediction': ' The estimated cost of the V&A branded gallery is £76 million.',\n",
              "   'prompt': \"Title: Victoria and Albert Museum\\n\\nBackground: Scottish Government with a view to opening a new £43\\xa0million gallery in Dundee that would use the V&A brand although it would be funded through and operated independently. As of 2015, with costs estimated at £76\\xa0million, it is the most expensive gallery project ever undertaken in Scotland. The V&A Dundee will be on the city's waterfront and is intended to focus on fashion, architecture, product design, graphic arts and photography. It is planned that it could open within five years. Dundee City Council is expected to pay a major part of the running costs. The V&A is not contributing financially,\\n\\nQ: What is the estimated cost of the V&A branded gallery?\\n\\nA:\",\n",
              "   'question': 'What is the estimated cost of the V&A branded gallery?'},\n",
              "  {'answers': ['Gender',\n",
              "    'ranges from 53% in Botswana to -40% in Bahrain',\n",
              "    'Gender'],\n",
              "   'em': 0,\n",
              "   'f1': 0.1904761904761905,\n",
              "   'generated_answer': ' There is a gender pay gap in favor of males in the labor market.',\n",
              "   'generated_answer_probs': [0.34042671641747424,\n",
              "    0.9823373902924744,\n",
              "    0.9085862981035144,\n",
              "    0.8075809994496121,\n",
              "    0.9992720955510724,\n",
              "    0.9996289508557669,\n",
              "    0.9973951972015361,\n",
              "    0.9974492585834391,\n",
              "    0.9999878879703512,\n",
              "    0.9996259698867098,\n",
              "    0.999824928036885,\n",
              "    0.9995998620365567,\n",
              "    0.9995353098219404,\n",
              "    0.9999387757842788,\n",
              "    0.9945881560768314],\n",
              "   'generated_answer_tokens': [' There',\n",
              "    ' is',\n",
              "    ' a',\n",
              "    ' gender',\n",
              "    ' pay',\n",
              "    ' gap',\n",
              "    ' in',\n",
              "    ' favor',\n",
              "    ' of',\n",
              "    ' males',\n",
              "    ' in',\n",
              "    ' the',\n",
              "    ' labor',\n",
              "    ' market',\n",
              "    '.'],\n",
              "   'generated_probs': [0.34042671641747424,\n",
              "    0.9823373902924744,\n",
              "    0.9085862981035144,\n",
              "    0.8075809994496121,\n",
              "    0.9992720955510724,\n",
              "    0.9996289508557669,\n",
              "    0.9973951972015361,\n",
              "    0.9974492585834391,\n",
              "    0.9999878879703512,\n",
              "    0.9996259698867098,\n",
              "    0.999824928036885,\n",
              "    0.9995998620365567,\n",
              "    0.9995353098219404,\n",
              "    0.9999387757842788,\n",
              "    0.9945881560768314],\n",
              "   'generated_text': ' There is a gender pay gap in favor of males in the labor market.',\n",
              "   'generated_tokens': [' There',\n",
              "    ' is',\n",
              "    ' a',\n",
              "    ' gender',\n",
              "    ' pay',\n",
              "    ' gap',\n",
              "    ' in',\n",
              "    ' favor',\n",
              "    ' of',\n",
              "    ' males',\n",
              "    ' in',\n",
              "    ' the',\n",
              "    ' labor',\n",
              "    ' market',\n",
              "    '.'],\n",
              "   'id': '5729f1c13f37b319004785e7',\n",
              "   'prediction': ' There is a gender pay gap in favor of males in the labor market.',\n",
              "   'prompt': 'Title: Economic inequality\\n\\nBackground: globally, including 30 million Americans (i.e., the top 12% of Americans by income were in the global top 1% in 2008). In many countries, there is a Gender pay gap in favor of males in the labor market. Several factors other than discrimination may contribute to this gap. On average, women are more likely than men to consider factors other than pay when looking for work, and may be less willing to travel or relocate. Thomas Sowell, in his book Knowledge and Decisions, claims that this difference is due to women not taking jobs due to marriage or pregnancy, but\\n\\nQ: In many countries, what kind of pay gap is there?\\n\\nA:',\n",
              "   'question': 'In many countries, what kind of pay gap is there?'},\n",
              "  {'answers': ['three, later four', 'four', 'three'],\n",
              "   'em': 0,\n",
              "   'f1': 0.18181818181818182,\n",
              "   'generated_answer': ' There were three societal class divisions in the plan Kublai rejected.',\n",
              "   'generated_answer_probs': [0.6712279384955687,\n",
              "    0.9853872961792289,\n",
              "    0.8960453889320584,\n",
              "    0.5566131135894437,\n",
              "    0.986080081616074,\n",
              "    0.9991825705776083,\n",
              "    0.959974151887433,\n",
              "    0.9855854232837539,\n",
              "    0.7864784395650373,\n",
              "    0.9362527471026304,\n",
              "    0.9998012061821101,\n",
              "    0.999995638343512,\n",
              "    0.9996862311857337,\n",
              "    0.9760857820369196],\n",
              "   'generated_answer_tokens': [' There',\n",
              "    ' were',\n",
              "    ' three',\n",
              "    ' societal',\n",
              "    ' class',\n",
              "    ' divisions',\n",
              "    ' in',\n",
              "    ' the',\n",
              "    ' plan',\n",
              "    ' Kub',\n",
              "    'l',\n",
              "    'ai',\n",
              "    ' rejected',\n",
              "    '.'],\n",
              "   'generated_probs': [0.6712279384955687,\n",
              "    0.9853872961792289,\n",
              "    0.8960453889320584,\n",
              "    0.5566131135894437,\n",
              "    0.986080081616074,\n",
              "    0.9991825705776083,\n",
              "    0.959974151887433,\n",
              "    0.9855854232837539,\n",
              "    0.7864784395650373,\n",
              "    0.9362527471026304,\n",
              "    0.9998012061821101,\n",
              "    0.999995638343512,\n",
              "    0.9996862311857337,\n",
              "    0.9760857820369196],\n",
              "   'generated_text': ' There were three societal class divisions in the plan Kublai rejected.',\n",
              "   'generated_tokens': [' There',\n",
              "    ' were',\n",
              "    ' three',\n",
              "    ' societal',\n",
              "    ' class',\n",
              "    ' divisions',\n",
              "    ' in',\n",
              "    ' the',\n",
              "    ' plan',\n",
              "    ' Kub',\n",
              "    'l',\n",
              "    'ai',\n",
              "    ' rejected',\n",
              "    '.'],\n",
              "   'id': '572869b84b864d19001649b1',\n",
              "   'prediction': ' There were three societal class divisions in the plan Kublai rejected.',\n",
              "   'prompt': \"Title: Yuan dynasty\\n\\nBackground: plans to revive the Confucian imperial examinations and divided Yuan society into three, later four, classes with the Han Chinese occupying the lowest rank. Kublai's Chinese advisers still wielded significant power in the government, but their official rank was nebulous. Kublai readied the move of the Mongol capital from Karakorum in Mongolia to Khanbaliq in 1264, constructing a new city near the former Jurchen capital Zhongdu, now modern Beijing, in 1266. In 1271, Kublai formally claimed the Mandate of Heaven and declared that 1272 was the first year of the Great Yuan () in the style of a traditional Chinese\\n\\nQ: How many societal class divisions were in the plan Kublai rejected?\\n\\nA:\",\n",
              "   'question': 'How many societal class divisions were in the plan Kublai rejected?'},\n",
              "  {'answers': ['their disciples', 'lives of their disciples', 'disciples'],\n",
              "   'em': 0,\n",
              "   'f1': 0.375,\n",
              "   'generated_answer': ' In general, gurus control their disciples by exerting a great deal of spiritual',\n",
              "   'generated_answer_probs': [0.26255397474782705,\n",
              "    0.5986424922692426,\n",
              "    0.9818582856568941,\n",
              "    0.8403724353415523,\n",
              "    0.9999936099356166,\n",
              "    0.8373634360598073,\n",
              "    0.8828831147648295,\n",
              "    0.9750923056538088,\n",
              "    0.655471490157741,\n",
              "    0.17727471277787307,\n",
              "    0.9999931331039772,\n",
              "    0.42779521822113786,\n",
              "    0.6384060730301158,\n",
              "    0.9684738209611539,\n",
              "    0.9999886013379652,\n",
              "    0.4254634515319468],\n",
              "   'generated_answer_tokens': [' In',\n",
              "    ' general',\n",
              "    ',',\n",
              "    ' g',\n",
              "    'urus',\n",
              "    ' control',\n",
              "    ' their',\n",
              "    ' disciples',\n",
              "    ' by',\n",
              "    ' exert',\n",
              "    'ing',\n",
              "    ' a',\n",
              "    ' great',\n",
              "    ' deal',\n",
              "    ' of',\n",
              "    ' spiritual'],\n",
              "   'generated_probs': [0.26255397474782705,\n",
              "    0.5986424922692426,\n",
              "    0.9818582856568941,\n",
              "    0.8403724353415523,\n",
              "    0.9999936099356166,\n",
              "    0.8373634360598073,\n",
              "    0.8828831147648295,\n",
              "    0.9750923056538088,\n",
              "    0.655471490157741,\n",
              "    0.17727471277787307,\n",
              "    0.9999931331039772,\n",
              "    0.42779521822113786,\n",
              "    0.6384060730301158,\n",
              "    0.9684738209611539,\n",
              "    0.9999886013379652,\n",
              "    0.4254634515319468],\n",
              "   'generated_text': ' In general, gurus control their disciples by exerting a great deal of spiritual',\n",
              "   'generated_tokens': [' In',\n",
              "    ' general',\n",
              "    ',',\n",
              "    ' g',\n",
              "    'urus',\n",
              "    ' control',\n",
              "    ' their',\n",
              "    ' disciples',\n",
              "    ' by',\n",
              "    ' exert',\n",
              "    'ing',\n",
              "    ' a',\n",
              "    ' great',\n",
              "    ' deal',\n",
              "    ' of',\n",
              "    ' spiritual'],\n",
              "   'id': '56e77cee00c9c71400d771aa',\n",
              "   'prediction': ' In general, gurus control their disciples by exerting a great deal of spiritual',\n",
              "   'prompt': 'Title: Teacher\\n\\nBackground: to prophesy, to its holders. This guidance is generally offered during a ceremony called the patriarchal blessing. In Hinduism the spiritual teacher is known as a guru, and, in many traditions of Hinduism - especially those common in the West - the emphasis on spiritual mentorship is extremely high, with gurus often exercising a great deal of control over the lives of their disciples. In Tibetan Buddhism the teachers of Dharma in Tibet are most commonly called a Lama. A Lama who has through phowa and siddhi consciously determined to be reborn, often many times, in order to continue their\\n\\nQ: Who do gurus control?\\n\\nA:',\n",
              "   'question': 'Who do gurus control?'},\n",
              "  {'answers': ['Duisburg', 'Duisburg', 'Duisburg'],\n",
              "   'em': 0,\n",
              "   'f1': 0.6666666666666666,\n",
              "   'generated_answer': ' Duisburg, Germany',\n",
              "   'generated_answer_probs': [0.7526746396622166,\n",
              "    0.9999330522551003,\n",
              "    0.9999148128286331,\n",
              "    0.41251001281957417,\n",
              "    0.991352595751825],\n",
              "   'generated_answer_tokens': [' Du', 'is', 'burg', ',', ' Germany'],\n",
              "   'generated_probs': [0.7526746396622166,\n",
              "    0.9999330522551003,\n",
              "    0.9999148128286331,\n",
              "    0.41251001281957417,\n",
              "    0.991352595751825],\n",
              "   'generated_text': ' Duisburg, Germany',\n",
              "   'generated_tokens': [' Du', 'is', 'burg', ',', ' Germany'],\n",
              "   'id': '572ff293947a6a140053ce55',\n",
              "   'prediction': ' Duisburg, Germany',\n",
              "   'prompt': \"Title: Rhine\\n\\nBackground: villages. Until the early 1980s, industry was a major source of water pollution. Although many plants and factories can be found along the Rhine up into Switzerland, it is along the Lower Rhine that the bulk of them are concentrated, as the river passes the major cities of Cologne, Düsseldorf and Duisburg. Duisburg is the home of Europe's largest inland port and functions as a hub to the sea ports of Rotterdam, Antwerp and Amsterdam. The Ruhr, which joins the Rhine in Duisburg, is nowadays a clean river, thanks to a combination of stricter environmental controls, a transition from heavy\\n\\nQ: What city has the largest inland port in Europe?\\n\\nA:\",\n",
              "   'question': 'What city has the largest inland port in Europe?'},\n",
              "  {'answers': ['1985', '1985', '1985', '1985'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' Greenland signed a Treaty granting them special status in 1979.',\n",
              "   'generated_answer_probs': [0.7029485824719796,\n",
              "    0.9833648519495611,\n",
              "    0.9695910764894707,\n",
              "    0.8230583842958874,\n",
              "    0.9808752859589441,\n",
              "    0.9025309461500785,\n",
              "    0.998687373648592,\n",
              "    0.9994861364231348,\n",
              "    0.8387136080109932,\n",
              "    0.19530801549121427,\n",
              "    0.9840548879977882],\n",
              "   'generated_answer_tokens': [' Greenland',\n",
              "    ' signed',\n",
              "    ' a',\n",
              "    ' Treaty',\n",
              "    ' granting',\n",
              "    ' them',\n",
              "    ' special',\n",
              "    ' status',\n",
              "    ' in',\n",
              "    ' 1979',\n",
              "    '.'],\n",
              "   'generated_probs': [0.7029485824719796,\n",
              "    0.9833648519495611,\n",
              "    0.9695910764894707,\n",
              "    0.8230583842958874,\n",
              "    0.9808752859589441,\n",
              "    0.9025309461500785,\n",
              "    0.998687373648592,\n",
              "    0.9994861364231348,\n",
              "    0.8387136080109932,\n",
              "    0.19530801549121427,\n",
              "    0.9840548879977882],\n",
              "   'generated_text': ' Greenland signed a Treaty granting them special status in 1979.',\n",
              "   'generated_tokens': [' Greenland',\n",
              "    ' signed',\n",
              "    ' a',\n",
              "    ' Treaty',\n",
              "    ' granting',\n",
              "    ' them',\n",
              "    ' special',\n",
              "    ' status',\n",
              "    ' in',\n",
              "    ' 1979',\n",
              "    '.'],\n",
              "   'id': '57268e2bf1498d1400e8e3b4',\n",
              "   'prediction': ' Greenland signed a Treaty granting them special status in 1979.',\n",
              "   'prompt': \"Title: History of Greenland\\n\\nBackground: 1986. Following a successful referendum on self-government in 2008, the local parliament's powers were expanded and Danish was removed as an official language in 2009. International relations are now largely, but not entirely, also left to the discretion of the home rule government. After leaving the EEC, Greenland signed a special treaty with it, granting it special access to the market as a constituent country of Denmark, which remains a member. Greenland is also a member of several small organizations along with Iceland, the Faroes, and the Inuit populations of Canada and Russia. It was one of the founders of\\n\\nQ: When did Greenland sign a Treaty granting them special status?\\n\\nA:\",\n",
              "   'question': 'When did Greenland sign a Treaty granting them special status?'},\n",
              "  {'answers': ['Ed Lee', 'Ed Lee', 'Lee'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' The current mayor of San Francisco is London Breed.',\n",
              "   'generated_answer_probs': [0.8820089020491789,\n",
              "    0.6180743940794824,\n",
              "    0.9495058781161366,\n",
              "    0.8187815568973825,\n",
              "    0.9990528697113028,\n",
              "    0.9999388959169305,\n",
              "    0.9993497003365392,\n",
              "    0.7444044472182166,\n",
              "    0.999943541039867,\n",
              "    0.6717841603546258],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' current',\n",
              "    ' mayor',\n",
              "    ' of',\n",
              "    ' San',\n",
              "    ' Francisco',\n",
              "    ' is',\n",
              "    ' London',\n",
              "    ' Breed',\n",
              "    '.'],\n",
              "   'generated_probs': [0.8820089020491789,\n",
              "    0.6180743940794824,\n",
              "    0.9495058781161366,\n",
              "    0.8187815568973825,\n",
              "    0.9990528697113028,\n",
              "    0.9999388959169305,\n",
              "    0.9993497003365392,\n",
              "    0.7444044472182166,\n",
              "    0.999943541039867,\n",
              "    0.6717841603546258],\n",
              "   'generated_text': ' The current mayor of San Francisco is London Breed.',\n",
              "   'generated_tokens': [' The',\n",
              "    ' current',\n",
              "    ' mayor',\n",
              "    ' of',\n",
              "    ' San',\n",
              "    ' Francisco',\n",
              "    ' is',\n",
              "    ' London',\n",
              "    ' Breed',\n",
              "    '.'],\n",
              "   'id': '56d7145c0d65d2140019834f',\n",
              "   'prediction': ' The current mayor of San Francisco is London Breed.',\n",
              "   'prompt': \"Title: Mayor of San Francisco\\n\\nBackground: combined set of governing bodies since 1856. There have been 45 individuals sworn into office. John W. Geary, elected in 1850, was the first mayor of the city. Charles James Brenham, who served as mayor during the 1850s, is the only person who has served two non-consecutive terms. The current mayor is former District 5 Supervisor and President of the Board of Supervisors London Breed, who won a special election following the death of Mayor Ed Lee on December 12, 2017. Breed will serve out the remainder of Lee's uncompleted term (until January 8, 2020), after which she is eligible\\n\\nQ: Who is the mayor of San Francisco?\\n\\nA:\",\n",
              "   'question': 'Who is the mayor of San Francisco?'},\n",
              "  {'answers': ['Prime Minister', 'second Prime Minister', 'Prime Minister'],\n",
              "   'em': 0,\n",
              "   'f1': 0.4444444444444445,\n",
              "   'generated_answer': ' Odinga would be the Prime Minister of Kenya.',\n",
              "   'generated_answer_probs': [0.5949432239037389,\n",
              "    0.999998499344226,\n",
              "    0.9999992145956385,\n",
              "    0.9064996634956877,\n",
              "    0.40320701260609343,\n",
              "    0.5297472886583563,\n",
              "    0.9572682057516494,\n",
              "    0.9994249237197864,\n",
              "    0.8992411077261747,\n",
              "    0.9115590350846857,\n",
              "    0.606684556061929],\n",
              "   'generated_answer_tokens': [' Od',\n",
              "    'ing',\n",
              "    'a',\n",
              "    ' would',\n",
              "    ' be',\n",
              "    ' the',\n",
              "    ' Prime',\n",
              "    ' Minister',\n",
              "    ' of',\n",
              "    ' Kenya',\n",
              "    '.'],\n",
              "   'generated_probs': [0.5949432239037389,\n",
              "    0.999998499344226,\n",
              "    0.9999992145956385,\n",
              "    0.9064996634956877,\n",
              "    0.40320701260609343,\n",
              "    0.5297472886583563,\n",
              "    0.9572682057516494,\n",
              "    0.9994249237197864,\n",
              "    0.8992411077261747,\n",
              "    0.9115590350846857,\n",
              "    0.606684556061929],\n",
              "   'generated_text': ' Odinga would be the Prime Minister of Kenya.',\n",
              "   'generated_tokens': [' Od',\n",
              "    'ing',\n",
              "    'a',\n",
              "    ' would',\n",
              "    ' be',\n",
              "    ' the',\n",
              "    ' Prime',\n",
              "    ' Minister',\n",
              "    ' of',\n",
              "    ' Kenya',\n",
              "    '.'],\n",
              "   'id': '57290ee2af94a219006aa000',\n",
              "   'prediction': ' Odinga would be the Prime Minister of Kenya.',\n",
              "   'prompt': \"Title: Raila Odinga\\n\\nBackground: was heavy-handed as it deployed police and paramilitary units to counter public protests.  Following two months of unrest, which led to the death of about 1000 people and displacement of about 250, 000, a deal between Odinga and Kibaki, which provided for power-sharing and the creation of the post of Prime Minister, was signed in February 2008; it was brokered by former UN Secretary General Kofi Annan. Odinga was sworn in as Prime Minister, along with the power-sharing Cabinet, on 17 April 2008. The post of Prime Minister was last held by Jomo Kenyatta between 1963 and 1964 following\\n\\nQ: What would be Odinga's role in the government?\\n\\nA:\",\n",
              "   'question': \"What would be Odinga's role in the government?\"},\n",
              "  {'answers': ['nearly a million and a half',\n",
              "    'nearly a million and a half visitors',\n",
              "    'nearly a million and a half'],\n",
              "   'em': 0,\n",
              "   'f1': 0.625,\n",
              "   'generated_answer': ' The Britain Can Make It exhibition attracted nearly a million and a half visitors.',\n",
              "   'generated_answer_probs': [0.4330952752346018,\n",
              "    0.4925420900456695,\n",
              "    0.9998722542301858,\n",
              "    0.9998267158654303,\n",
              "    0.9989203099851467,\n",
              "    0.9965749718362528,\n",
              "    0.998267457387734,\n",
              "    0.9610240108963376,\n",
              "    0.992461642026381,\n",
              "    0.9998572340920223,\n",
              "    0.9999671451857313,\n",
              "    0.9999400832450804,\n",
              "    0.9998265966560981,\n",
              "    0.9998376840246636,\n",
              "    0.9957273896821799],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' Britain',\n",
              "    ' Can',\n",
              "    ' Make',\n",
              "    ' It',\n",
              "    ' exhibition',\n",
              "    ' attracted',\n",
              "    ' nearly',\n",
              "    ' a',\n",
              "    ' million',\n",
              "    ' and',\n",
              "    ' a',\n",
              "    ' half',\n",
              "    ' visitors',\n",
              "    '.'],\n",
              "   'generated_probs': [0.4330952752346018,\n",
              "    0.4925420900456695,\n",
              "    0.9998722542301858,\n",
              "    0.9998267158654303,\n",
              "    0.9989203099851467,\n",
              "    0.9965749718362528,\n",
              "    0.998267457387734,\n",
              "    0.9610240108963376,\n",
              "    0.992461642026381,\n",
              "    0.9998572340920223,\n",
              "    0.9999671451857313,\n",
              "    0.9999400832450804,\n",
              "    0.9998265966560981,\n",
              "    0.9998376840246636,\n",
              "    0.9957273896821799],\n",
              "   'generated_text': ' The Britain Can Make It exhibition attracted nearly a million and a half visitors.',\n",
              "   'generated_tokens': [' The',\n",
              "    ' Britain',\n",
              "    ' Can',\n",
              "    ' Make',\n",
              "    ' It',\n",
              "    ' exhibition',\n",
              "    ' attracted',\n",
              "    ' nearly',\n",
              "    ' a',\n",
              "    ' million',\n",
              "    ' and',\n",
              "    ' a',\n",
              "    ' half',\n",
              "    ' visitors',\n",
              "    '.'],\n",
              "   'id': '57268f2c708984140094ca26',\n",
              "   'prediction': ' The Britain Can Make It exhibition attracted nearly a million and a half visitors.',\n",
              "   'prompt': 'Title: Victoria and Albert Museum\\n\\nBackground: the Royal Air Force and later for Bomb Damage Repair Squads. Before the return of the collections after the war, the \"Britain Can Make It\" exhibition was held between September and November 1946, attracting nearly a million and a half visitors. This was organised by the Council of Industrial Design established by the British government in 1944 \"to promote by all practicable means the improvement of design in the products of British industry\". The success of this exhibition led to the planning of the Festival of Britain (1951). By 1948 most of the collections had been returned to the museum.\\n\\nQ: How many visitors did the Britain Can Make It exhibition attract?\\n\\nA:',\n",
              "   'question': 'How many visitors did the Britain Can Make It exhibition attract?'},\n",
              "  {'answers': ['Saudi Arabia',\n",
              "    'Saudi Arabia',\n",
              "    'Saudi Arabia',\n",
              "    'Saudi Arabia',\n",
              "    'Saudi Arabia'],\n",
              "   'em': 0,\n",
              "   'f1': 0.14285714285714285,\n",
              "   'generated_answer': \" Saudi Arabia's arms purchase from the US became 5 times more than Israel's.\",\n",
              "   'generated_answer_probs': [0.9241797330208091,\n",
              "    0.9981736385315605,\n",
              "    0.9201569966180217,\n",
              "    0.92122850332296,\n",
              "    0.9927141246197247,\n",
              "    0.998541161341155,\n",
              "    0.9994403003902956,\n",
              "    0.9988112911747284,\n",
              "    0.9024474478496316,\n",
              "    0.9651131554343981,\n",
              "    0.9999286408961819,\n",
              "    0.9999938483514215,\n",
              "    0.999988126385492,\n",
              "    0.9998593795379841,\n",
              "    0.9983593078094232,\n",
              "    0.9267388484392067],\n",
              "   'generated_answer_tokens': [' Saudi',\n",
              "    ' Arabia',\n",
              "    \"'s\",\n",
              "    ' arms',\n",
              "    ' purchase',\n",
              "    ' from',\n",
              "    ' the',\n",
              "    ' US',\n",
              "    ' became',\n",
              "    ' 5',\n",
              "    ' times',\n",
              "    ' more',\n",
              "    ' than',\n",
              "    ' Israel',\n",
              "    \"'s\",\n",
              "    '.'],\n",
              "   'generated_probs': [0.9241797330208091,\n",
              "    0.9981736385315605,\n",
              "    0.9201569966180217,\n",
              "    0.92122850332296,\n",
              "    0.9927141246197247,\n",
              "    0.998541161341155,\n",
              "    0.9994403003902956,\n",
              "    0.9988112911747284,\n",
              "    0.9024474478496316,\n",
              "    0.9651131554343981,\n",
              "    0.9999286408961819,\n",
              "    0.9999938483514215,\n",
              "    0.999988126385492,\n",
              "    0.9998593795379841,\n",
              "    0.9983593078094232,\n",
              "    0.9267388484392067],\n",
              "   'generated_text': \" Saudi Arabia's arms purchase from the US became 5 times more than Israel's.\",\n",
              "   'generated_tokens': [' Saudi',\n",
              "    ' Arabia',\n",
              "    \"'s\",\n",
              "    ' arms',\n",
              "    ' purchase',\n",
              "    ' from',\n",
              "    ' the',\n",
              "    ' US',\n",
              "    ' became',\n",
              "    ' 5',\n",
              "    ' times',\n",
              "    ' more',\n",
              "    ' than',\n",
              "    ' Israel',\n",
              "    \"'s\",\n",
              "    '.'],\n",
              "   'id': '57265526708984140094c2bf',\n",
              "   'prediction': \" Saudi Arabia's arms purchase from the US became 5 times more than Israel's.\",\n",
              "   'prompt': \"Title: 1973 oil crisis\\n\\nBackground: Gulf and using increased revenues to fund expanded militaries. By 1979, Saudi arms purchases from the US exceeded five times Israel's. Another motive for the large scale purchase of arms from the US by Saudi Arabia was the failure of the Shah during January 1979 to maintain control of Iran, a non-Arabic but largely Shiite Muslim nation, which fell to a theocratic Islamist government under the Ayatollah Ruhollah Khomeini in the wake of the 1979 Iranian Revolution. Saudi Arabia, on the other hand, is an Arab, largely Sunni Muslim nation headed by a near absolutist monarchy. In the wake of\\n\\nQ: Which country's arms purchase from the US became 5 times more than Israel?\\n\\nA:\",\n",
              "   'question': \"Which country's arms purchase from the US became 5 times more than Israel?\"},\n",
              "  {'answers': ['twice the figure for the average profession',\n",
              "    'twice',\n",
              "    'twice'],\n",
              "   'em': 0,\n",
              "   'f1': 0.7692307692307693,\n",
              "   'generated_answer': ' The 42% figure was twice the figure for the average profession.',\n",
              "   'generated_answer_probs': [0.5294266237661669,\n",
              "    0.47295291069599943,\n",
              "    0.9999179129393272,\n",
              "    0.6687584335068985,\n",
              "    0.6533151025991417,\n",
              "    0.6343596843119264,\n",
              "    0.7964422953723009,\n",
              "    0.6810466997001645,\n",
              "    0.9934269350242195,\n",
              "    0.9901577664494657,\n",
              "    0.9999520062817353,\n",
              "    0.9984570006494652,\n",
              "    0.996213646382717],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' 42',\n",
              "    '%',\n",
              "    ' figure',\n",
              "    ' was',\n",
              "    ' twice',\n",
              "    ' the',\n",
              "    ' figure',\n",
              "    ' for',\n",
              "    ' the',\n",
              "    ' average',\n",
              "    ' profession',\n",
              "    '.'],\n",
              "   'generated_probs': [0.5294266237661669,\n",
              "    0.47295291069599943,\n",
              "    0.9999179129393272,\n",
              "    0.6687584335068985,\n",
              "    0.6533151025991417,\n",
              "    0.6343596843119264,\n",
              "    0.7964422953723009,\n",
              "    0.6810466997001645,\n",
              "    0.9934269350242195,\n",
              "    0.9901577664494657,\n",
              "    0.9999520062817353,\n",
              "    0.9984570006494652,\n",
              "    0.996213646382717],\n",
              "   'generated_text': ' The 42% figure was twice the figure for the average profession.',\n",
              "   'generated_tokens': [' The',\n",
              "    ' 42',\n",
              "    '%',\n",
              "    ' figure',\n",
              "    ' was',\n",
              "    ' twice',\n",
              "    ' the',\n",
              "    ' figure',\n",
              "    ' for',\n",
              "    ' the',\n",
              "    ' average',\n",
              "    ' profession',\n",
              "    '.'],\n",
              "   'id': '56e76b8337bdd419002c3f81',\n",
              "   'prediction': ' The 42% figure was twice the figure for the average profession.',\n",
              "   'prompt': \"Title: Teacher\\n\\nBackground: Teachers face several occupational hazards in their line of work, including occupational stress, which can negatively impact teachers' mental and physical health, productivity, and students' performance. Stress can be caused by organizational change, relationships with students, fellow teachers, and administrative personnel, working environment, expectations to substitute, long hours with a heavy workload, and inspections. Teachers are also at high risk for occupational burnout. A 2000 study found that 42% of UK teachers experienced occupational stress, twice the figure for the average profession. A 2012 study found that teachers experienced double the rate of anxiety, depression, and stress than average workers.\\n\\nQ: How much higher was the 42% occupation stress figure, compared to other jobs?\\n\\nA:\",\n",
              "   'question': 'How much higher was the 42% occupation stress figure, compared to other jobs?'},\n",
              "  {'answers': ['the Eleventh Doctor', 'the Eleventh Doctor', 'the Eleventh'],\n",
              "   'em': 0,\n",
              "   'f1': 0.2,\n",
              "   'generated_answer': ' The Doctor during the 50th Anniversary special was Paul McGann.',\n",
              "   'generated_answer_probs': [0.749925245564567,\n",
              "    0.26494749624582,\n",
              "    0.44828457328547416,\n",
              "    0.997945411961499,\n",
              "    0.9990725985627757,\n",
              "    0.9999759673147897,\n",
              "    0.5854349814607788,\n",
              "    0.9746127854448471,\n",
              "    0.9576334062081466,\n",
              "    0.8549665188943608,\n",
              "    0.9999806172858472,\n",
              "    0.9999924159807588,\n",
              "    0.3852839245983212],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' Doctor',\n",
              "    ' during',\n",
              "    ' the',\n",
              "    ' 50',\n",
              "    'th',\n",
              "    ' Anniversary',\n",
              "    ' special',\n",
              "    ' was',\n",
              "    ' Paul',\n",
              "    ' McG',\n",
              "    'ann',\n",
              "    '.'],\n",
              "   'generated_probs': [0.749925245564567,\n",
              "    0.26494749624582,\n",
              "    0.44828457328547416,\n",
              "    0.997945411961499,\n",
              "    0.9990725985627757,\n",
              "    0.9999759673147897,\n",
              "    0.5854349814607788,\n",
              "    0.9746127854448471,\n",
              "    0.9576334062081466,\n",
              "    0.8549665188943608,\n",
              "    0.9999806172858472,\n",
              "    0.9999924159807588,\n",
              "    0.3852839245983212],\n",
              "   'generated_text': ' The Doctor during the 50th Anniversary special was Paul McGann.',\n",
              "   'generated_tokens': [' The',\n",
              "    ' Doctor',\n",
              "    ' during',\n",
              "    ' the',\n",
              "    ' 50',\n",
              "    'th',\n",
              "    ' Anniversary',\n",
              "    ' special',\n",
              "    ' was',\n",
              "    ' Paul',\n",
              "    ' McG',\n",
              "    'ann',\n",
              "    '.'],\n",
              "   'id': '57281f203acd2414000df4f9',\n",
              "   'prediction': ' The Doctor during the 50th Anniversary special was Paul McGann.',\n",
              "   'prompt': 'Title: The Doctor (Doctor Who)\\n\\nBackground: the 50th anniversary special, featured Paul McGann reprising his role as the Eighth Doctor and was set during the Time War, albeit much earlier than during \"The End of Time\". The mini-episode presented him as a conscientious objector to the war who regenerated under controlled circumstances into the War Doctor (John Hurt), a previously unseen incarnation created retroactively by Davies\\' successor as head writer, Steven Moffat, for the 50th anniversary special \"The Day of the Doctor\". He was a numberless \"mayfly\" Doctor so as not to disrupt the accepted numbering of the Ninth, Tenth and Eleventh Doctors. \"The Day of\\n\\nQ: Which Doctor was the current Doctor during the 50th Anniversary special?\\n\\nA:',\n",
              "   'question': 'Which Doctor was the current Doctor during the 50th Anniversary special?'},\n",
              "  {'answers': ['Brest', 'Brest, France', 'offshore of Brest,'],\n",
              "   'em': 0,\n",
              "   'f1': 0.5,\n",
              "   'generated_answer': ' The mouth of the Rhine was located offshore of Brest, France.',\n",
              "   'generated_answer_probs': [0.9050787070027396,\n",
              "    0.9074451095652415,\n",
              "    0.9985726336577364,\n",
              "    0.9997637133600863,\n",
              "    0.9955038082705198,\n",
              "    0.9999900337026638,\n",
              "    0.998434887567919,\n",
              "    0.9996599434823288,\n",
              "    0.9773875315305105,\n",
              "    0.9999409167204857,\n",
              "    0.998764322778599,\n",
              "    0.9999989771165232,\n",
              "    0.998787150796838,\n",
              "    0.9992986188828077,\n",
              "    0.8213636435540005],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' mouth',\n",
              "    ' of',\n",
              "    ' the',\n",
              "    ' Rh',\n",
              "    'ine',\n",
              "    ' was',\n",
              "    ' located',\n",
              "    ' offshore',\n",
              "    ' of',\n",
              "    ' B',\n",
              "    'rest',\n",
              "    ',',\n",
              "    ' France',\n",
              "    '.'],\n",
              "   'generated_probs': [0.9050787070027396,\n",
              "    0.9074451095652415,\n",
              "    0.9985726336577364,\n",
              "    0.9997637133600863,\n",
              "    0.9955038082705198,\n",
              "    0.9999900337026638,\n",
              "    0.998434887567919,\n",
              "    0.9996599434823288,\n",
              "    0.9773875315305105,\n",
              "    0.9999409167204857,\n",
              "    0.998764322778599,\n",
              "    0.9999989771165232,\n",
              "    0.998787150796838,\n",
              "    0.9992986188828077,\n",
              "    0.8213636435540005],\n",
              "   'generated_text': ' The mouth of the Rhine was located offshore of Brest, France.',\n",
              "   'generated_tokens': [' The',\n",
              "    ' mouth',\n",
              "    ' of',\n",
              "    ' the',\n",
              "    ' Rh',\n",
              "    'ine',\n",
              "    ' was',\n",
              "    ' located',\n",
              "    ' offshore',\n",
              "    ' of',\n",
              "    ' B',\n",
              "    'rest',\n",
              "    ',',\n",
              "    ' France',\n",
              "    '.'],\n",
              "   'id': '572ffce5a23a5019007fcc19',\n",
              "   'prediction': ' The mouth of the Rhine was located offshore of Brest, France.',\n",
              "   'prompt': \"Title: Rhine\\n\\nBackground: Ages have occurred, in which sea level dropped and much of the continental margins became exposed. In the Early Pleistocene, the Rhine followed a course to the northwest, through the present North Sea. During the so-called Anglian glaciation (~450,000\\xa0yr\\xa0BP, marine oxygen isotope stage\\xa012), the northern part of the present North Sea was blocked by the ice and a large lake developed, that overflowed through the English Channel. This caused the Rhine's course to be diverted through the English Channel. Since then, during glacial times, the river mouth was located offshore of Brest, France and rivers, like the Thames and the\\n\\nQ: During glacial times, where was the mouth of the Rhine located?\\n\\nA:\",\n",
              "   'question': 'During glacial times, where was the mouth of the Rhine located?'},\n",
              "  {'answers': ['high', 'high wages', 'high'],\n",
              "   'em': 0,\n",
              "   'f1': 0.2666666666666667,\n",
              "   'generated_answer': ' High wages will result from jobs that have a high demand for the position, as',\n",
              "   'generated_answer_probs': [0.3165686681345112,\n",
              "    0.9843897617668202,\n",
              "    0.3177621284034328,\n",
              "    0.9139674599198372,\n",
              "    0.680879618580276,\n",
              "    0.971281918033594,\n",
              "    0.5270498198969996,\n",
              "    0.7071623975199498,\n",
              "    0.950209407244463,\n",
              "    0.7168435521710345,\n",
              "    0.9927053034012061,\n",
              "    0.2772350712523375,\n",
              "    0.7090637507930089,\n",
              "    0.5716111251170077,\n",
              "    0.6698716179216141,\n",
              "    0.3844953668169255],\n",
              "   'generated_answer_tokens': [' High',\n",
              "    ' wages',\n",
              "    ' will',\n",
              "    ' result',\n",
              "    ' from',\n",
              "    ' jobs',\n",
              "    ' that',\n",
              "    ' have',\n",
              "    ' a',\n",
              "    ' high',\n",
              "    ' demand',\n",
              "    ' for',\n",
              "    ' the',\n",
              "    ' position',\n",
              "    ',',\n",
              "    ' as'],\n",
              "   'generated_probs': [0.3165686681345112,\n",
              "    0.9843897617668202,\n",
              "    0.3177621284034328,\n",
              "    0.9139674599198372,\n",
              "    0.680879618580276,\n",
              "    0.971281918033594,\n",
              "    0.5270498198969996,\n",
              "    0.7071623975199498,\n",
              "    0.950209407244463,\n",
              "    0.7168435521710345,\n",
              "    0.9927053034012061,\n",
              "    0.2772350712523375,\n",
              "    0.7090637507930089,\n",
              "    0.5716111251170077,\n",
              "    0.6698716179216141,\n",
              "    0.3844953668169255],\n",
              "   'generated_text': ' High wages will result from jobs that have a high demand for the position, as',\n",
              "   'generated_tokens': [' High',\n",
              "    ' wages',\n",
              "    ' will',\n",
              "    ' result',\n",
              "    ' from',\n",
              "    ' jobs',\n",
              "    ' that',\n",
              "    ' have',\n",
              "    ' a',\n",
              "    ' high',\n",
              "    ' demand',\n",
              "    ' for',\n",
              "    ' the',\n",
              "    ' position',\n",
              "    ',',\n",
              "    ' as'],\n",
              "   'id': '5729da0faf94a219006aa678',\n",
              "   'prediction': ' High wages will result from jobs that have a high demand for the position, as',\n",
              "   'prompt': 'Title: Economic inequality\\n\\nBackground: amongst workers tends to drive down wages due to the expendable nature of the worker in relation to his or her particular job. A job where there are few able or willing workers (low supply), but a large need for the positions (high demand), will result in high wages for that job. This is because competition between employers \"for employees\" will drive up the wage. Examples of this would include jobs that require highly developed skills, rare abilities, or a high level of risk. Competition amongst employers tends to drive up wages due to the nature of the job, since\\n\\nQ: What type of wages result from jobs where there is low supply but high demand?\\n\\nA:',\n",
              "   'question': 'What type of wages result from jobs where there is low supply but high demand?'},\n",
              "  {'answers': ['Liberal Party', 'Liberal Party of Australia', 'Liberals'],\n",
              "   'em': 0,\n",
              "   'f1': 0.4,\n",
              "   'generated_answer': \" The Liberal Party is strongest in Melbourne's affluent areas.\",\n",
              "   'generated_answer_probs': [0.99332995973152,\n",
              "    0.9659266416250233,\n",
              "    0.964127405232608,\n",
              "    0.7325932224831267,\n",
              "    0.9911438646477702,\n",
              "    0.9999406801934893,\n",
              "    0.9995919927276145,\n",
              "    0.9998273136720007,\n",
              "    0.8251695323506852,\n",
              "    0.9999133815115979,\n",
              "    0.9973520436376334],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' Liberal',\n",
              "    ' Party',\n",
              "    ' is',\n",
              "    ' strongest',\n",
              "    ' in',\n",
              "    ' Melbourne',\n",
              "    \"'s\",\n",
              "    ' affluent',\n",
              "    ' areas',\n",
              "    '.'],\n",
              "   'generated_probs': [0.99332995973152,\n",
              "    0.9659266416250233,\n",
              "    0.964127405232608,\n",
              "    0.7325932224831267,\n",
              "    0.9911438646477702,\n",
              "    0.9999406801934893,\n",
              "    0.9995919927276145,\n",
              "    0.9998273136720007,\n",
              "    0.8251695323506852,\n",
              "    0.9999133815115979,\n",
              "    0.9973520436376334],\n",
              "   'generated_text': \" The Liberal Party is strongest in Melbourne's affluent areas.\",\n",
              "   'generated_tokens': [' The',\n",
              "    ' Liberal',\n",
              "    ' Party',\n",
              "    ' is',\n",
              "    ' strongest',\n",
              "    ' in',\n",
              "    ' Melbourne',\n",
              "    \"'s\",\n",
              "    ' affluent',\n",
              "    ' areas',\n",
              "    '.'],\n",
              "   'id': '570d28bdb3d812140066d4a4',\n",
              "   'prediction': \" The Liberal Party is strongest in Melbourne's affluent areas.\",\n",
              "   'prompt': 'Title: Victoria (Australia)\\n\\nBackground: are also said to be \"generally socially progressive, supportive of multiculturalism, wary of extremes of any kind.\" Premier Daniel Andrews leads the Australian Labor Party that won the November 2014 Victorian state election. The centre-left Australian Labor Party (ALP), the centre-right Liberal Party of Australia, the rural-based National Party of Australia, and the environmentalist Australian Greens are Victoria\\'s main political parties. Traditionally, Labor is strongest in Melbourne\\'s working class western and northern suburbs, and the regional cities of Ballarat, Bendigo and Geelong. The Liberals\\' main support lies in Melbourne\\'s more affluent eastern and outer suburbs, and some rural and regional\\n\\nQ: What party is strongest in Melbourne\\'s affluent areas?\\n\\nA:',\n",
              "   'question': \"What party is strongest in Melbourne's affluent areas?\"},\n",
              "  {'answers': ['environmental determinism',\n",
              "    'environmental determinism',\n",
              "    'environmental determinism',\n",
              "    'environmental determinism',\n",
              "    'environmental determinism'],\n",
              "   'em': 0,\n",
              "   'f1': 0.2857142857142857,\n",
              "   'generated_answer': ' Geographical theories such as environmental determinism suggested that tropical environments created uncivilized',\n",
              "   'generated_answer_probs': [0.7353667975240952,\n",
              "    0.9996400341532572,\n",
              "    0.9946027587273367,\n",
              "    0.586270612456048,\n",
              "    0.9999326946511067,\n",
              "    0.9979562004084842,\n",
              "    0.9998449564704905,\n",
              "    0.999995041369894,\n",
              "    0.8159329389944876,\n",
              "    0.9344272259236359,\n",
              "    0.9540075380930746,\n",
              "    0.9997212775303267,\n",
              "    0.9990653880220932,\n",
              "    0.9990464310361161,\n",
              "    0.9999980234482534,\n",
              "    0.999998499344226],\n",
              "   'generated_answer_tokens': [' Ge',\n",
              "    'ographical',\n",
              "    ' theories',\n",
              "    ' such',\n",
              "    ' as',\n",
              "    ' environmental',\n",
              "    ' determin',\n",
              "    'ism',\n",
              "    ' suggested',\n",
              "    ' that',\n",
              "    ' tropical',\n",
              "    ' environments',\n",
              "    ' created',\n",
              "    ' unc',\n",
              "    'ivil',\n",
              "    'ized'],\n",
              "   'generated_probs': [0.7353667975240952,\n",
              "    0.9996400341532572,\n",
              "    0.9946027587273367,\n",
              "    0.586270612456048,\n",
              "    0.9999326946511067,\n",
              "    0.9979562004084842,\n",
              "    0.9998449564704905,\n",
              "    0.999995041369894,\n",
              "    0.8159329389944876,\n",
              "    0.9344272259236359,\n",
              "    0.9540075380930746,\n",
              "    0.9997212775303267,\n",
              "    0.9990653880220932,\n",
              "    0.9990464310361161,\n",
              "    0.9999980234482534,\n",
              "    0.999998499344226],\n",
              "   'generated_text': ' Geographical theories such as environmental determinism suggested that tropical environments created uncivilized',\n",
              "   'generated_tokens': [' Ge',\n",
              "    'ographical',\n",
              "    ' theories',\n",
              "    ' such',\n",
              "    ' as',\n",
              "    ' environmental',\n",
              "    ' determin',\n",
              "    'ism',\n",
              "    ' suggested',\n",
              "    ' that',\n",
              "    ' tropical',\n",
              "    ' environments',\n",
              "    ' created',\n",
              "    ' unc',\n",
              "    'ivil',\n",
              "    'ized'],\n",
              "   'id': '57308cf88ab72b1400f9c576',\n",
              "   'prediction': ' Geographical theories such as environmental determinism suggested that tropical environments created uncivilized',\n",
              "   'prompt': 'Title: Imperialism\\n\\nBackground: supported Britain\\'s imperial expansion; these two arguments dominated the discipline for decades. Geographical theories such as environmental determinism also suggested that tropical environments created uncivilized people in need of European guidance. For instance, American geographer Ellen Churchill Semple argued that even though human beings originated in the tropics they were only able to become fully human in the temperate zone. Tropicality can be paralleled with Edward Said\\'s Orientalism as the west\\'s construction of the east as the \"other\". According to Said, orientalism allowed Europe to establish itself as the superior and the norm, which justified its dominance over the essentialized\\n\\nQ: Which theory suggested people in the tropics were uncivilized?\\n\\nA:',\n",
              "   'question': 'Which theory suggested people in the tropics were uncivilized?'},\n",
              "  {'answers': ['a theta intermediary form',\n",
              "    'theta intermediary form',\n",
              "    'a theta intermediary form'],\n",
              "   'em': 0,\n",
              "   'f1': 0.15384615384615383,\n",
              "   'generated_answer': ' A Cairns replication intermediate is a form of chloroplast DNA that is',\n",
              "   'generated_answer_probs': [0.7647735209753254,\n",
              "    0.9987055532199243,\n",
              "    0.9999975456765119,\n",
              "    0.999918029329779,\n",
              "    0.9999187463962529,\n",
              "    0.9953564065731703,\n",
              "    0.9978099892804412,\n",
              "    0.9566636951656764,\n",
              "    0.2248639559204428,\n",
              "    0.734018335818851,\n",
              "    0.5075387075196488,\n",
              "    0.9992316239521795,\n",
              "    0.9999919419639661,\n",
              "    0.9978093936878363,\n",
              "    0.9353015110173087,\n",
              "    0.977614083959205],\n",
              "   'generated_answer_tokens': [' A',\n",
              "    ' C',\n",
              "    'air',\n",
              "    'ns',\n",
              "    ' replication',\n",
              "    ' intermediate',\n",
              "    ' is',\n",
              "    ' a',\n",
              "    ' form',\n",
              "    ' of',\n",
              "    ' chlor',\n",
              "    'op',\n",
              "    'last',\n",
              "    ' DNA',\n",
              "    ' that',\n",
              "    ' is'],\n",
              "   'generated_probs': [0.7647735209753254,\n",
              "    0.9987055532199243,\n",
              "    0.9999975456765119,\n",
              "    0.999918029329779,\n",
              "    0.9999187463962529,\n",
              "    0.9953564065731703,\n",
              "    0.9978099892804412,\n",
              "    0.9566636951656764,\n",
              "    0.2248639559204428,\n",
              "    0.734018335818851,\n",
              "    0.5075387075196488,\n",
              "    0.9992316239521795,\n",
              "    0.9999919419639661,\n",
              "    0.9978093936878363,\n",
              "    0.9353015110173087,\n",
              "    0.977614083959205],\n",
              "   'generated_text': ' A Cairns replication intermediate is a form of chloroplast DNA that is',\n",
              "   'generated_tokens': [' A',\n",
              "    ' C',\n",
              "    'air',\n",
              "    'ns',\n",
              "    ' replication',\n",
              "    ' intermediate',\n",
              "    ' is',\n",
              "    ' a',\n",
              "    ' form',\n",
              "    ' of',\n",
              "    ' chlor',\n",
              "    'op',\n",
              "    'last',\n",
              "    ' DNA',\n",
              "    ' that',\n",
              "    ' is'],\n",
              "   'id': '572969f51d046914007793e0',\n",
              "   'prediction': ' A Cairns replication intermediate is a form of chloroplast DNA that is',\n",
              "   'prompt': 'Title: Chloroplast\\n\\nBackground: that tightly pack each chloroplast DNA ring into a nucleoid have been found. The mechanism for chloroplast DNA (cpDNA) replication has not been conclusively determined, but two main models have been proposed. Scientists have attempted to observe chloroplast replication via electron microscopy since the 1970s. The results of the microscopy experiments led to the idea that chloroplast DNA replicates using a double displacement loop (D-loop). As the D-loop moves through the circular DNA, it adopts a theta intermediary form, also known as a Cairns replication intermediate, and completes replication with a rolling circle mechanism. Transcription starts at specific points of\\n\\nQ: What is a Cairns replication intermediate?\\n\\nA:',\n",
              "   'question': 'What is a Cairns replication intermediate?'},\n",
              "  {'answers': ['double coronation', 'double', 'double'],\n",
              "   'em': 0,\n",
              "   'f1': 0.14285714285714285,\n",
              "   'generated_answer': ' The coronation of the British monarch is an elaborate and formal ceremony that is performed',\n",
              "   'generated_answer_probs': [0.6185897429121384,\n",
              "    0.7280687852612,\n",
              "    0.9999473555057701,\n",
              "    0.9966909033686493,\n",
              "    0.6151911047587496,\n",
              "    0.9892496277617199,\n",
              "    0.977583983684956,\n",
              "    0.4112473996343971,\n",
              "    0.9761265530154251,\n",
              "    0.999490905092811,\n",
              "    0.3925319554164277,\n",
              "    0.2283269924649769,\n",
              "    0.9473386355663972,\n",
              "    0.4696998055203737,\n",
              "    0.8214916301938429,\n",
              "    0.8645564916115954],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' coron',\n",
              "    'ation',\n",
              "    ' of',\n",
              "    ' the',\n",
              "    ' British',\n",
              "    ' monarch',\n",
              "    ' is',\n",
              "    ' an',\n",
              "    ' elaborate',\n",
              "    ' and',\n",
              "    ' formal',\n",
              "    ' ceremony',\n",
              "    ' that',\n",
              "    ' is',\n",
              "    ' performed'],\n",
              "   'generated_probs': [0.6185897429121384,\n",
              "    0.7280687852612,\n",
              "    0.9999473555057701,\n",
              "    0.9966909033686493,\n",
              "    0.6151911047587496,\n",
              "    0.9892496277617199,\n",
              "    0.977583983684956,\n",
              "    0.4112473996343971,\n",
              "    0.9761265530154251,\n",
              "    0.999490905092811,\n",
              "    0.3925319554164277,\n",
              "    0.2283269924649769,\n",
              "    0.9473386355663972,\n",
              "    0.4696998055203737,\n",
              "    0.8214916301938429,\n",
              "    0.8645564916115954],\n",
              "   'generated_text': ' The coronation of the British monarch is an elaborate and formal ceremony that is performed',\n",
              "   'generated_tokens': [' The',\n",
              "    ' coron',\n",
              "    'ation',\n",
              "    ' of',\n",
              "    ' the',\n",
              "    ' British',\n",
              "    ' monarch',\n",
              "    ' is',\n",
              "    ' an',\n",
              "    ' elaborate',\n",
              "    ' and',\n",
              "    ' formal',\n",
              "    ' ceremony',\n",
              "    ' that',\n",
              "    ' is',\n",
              "    ' performed'],\n",
              "   'id': '56de41504396321400ee2716',\n",
              "   'prediction': ' The coronation of the British monarch is an elaborate and formal ceremony that is performed',\n",
              "   'prompt': 'Title: Coronation of the British monarch\\n\\nBackground: elaborate arrangements required. For example, Queen Elizabeth\\xa0II was crowned on 2\\xa0June 1953, having ascended the throne on 6\\xa0February 1952; the date of her coronation was announced almost a year in advance, and preparations inside the abbey took five months. The ceremony is performed by the Archbishop of Canterbury, the most senior cleric in the Church of England, of which the monarch is head. Other clergy and members of the nobility also have roles; most participants in the ceremony are required to wear ceremonial uniforms or robes and coronets. Many other government officials and guests attend, including representatives of other countries.\\n\\nQ: What kind of coronation happened?\\n\\nA:',\n",
              "   'question': 'What kind of coronation happened?'},\n",
              "  {'answers': ['Stewart', 'Stewart', 'Stewart'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' Cam Newton.',\n",
              "   'generated_answer_probs': [0.9927228277826056,\n",
              "    0.9991906766789297,\n",
              "    0.4659332012912085],\n",
              "   'generated_answer_tokens': [' Cam', ' Newton', '.'],\n",
              "   'generated_probs': [0.9927228277826056,\n",
              "    0.9991906766789297,\n",
              "    0.4659332012912085,\n",
              "    0.8506307549878986,\n",
              "    0.999971318293328,\n",
              "    0.1845284365012335,\n",
              "    0.8810532607433594,\n",
              "    0.9724362153204312,\n",
              "    0.9999527215016635],\n",
              "   'generated_text': ' Cam Newton.\\n\\nA: Cam Newton',\n",
              "   'generated_tokens': [' Cam',\n",
              "    ' Newton',\n",
              "    '.',\n",
              "    '\\n',\n",
              "    '\\n',\n",
              "    'A',\n",
              "    ':',\n",
              "    ' Cam',\n",
              "    ' Newton'],\n",
              "   'id': '56bec9e83aeaaa14008c9462',\n",
              "   'prediction': ' Cam Newton.',\n",
              "   'prompt': \"Title: Cam Newton\\n\\nBackground: ball on their own 24-yard line with a chance to mount a game-winning drive, but Von Miller again stripped the ball away from Newton, with the Broncos recovering. Newton would later earn criticism for awkwardly trying to fall on the loose ball as he approached it, when film angles appeared to show he initially had a clear path to dive on it. Newton finished the game going 18 of 41 for 265 yards, and was the team's leading rusher with 45 yards on six carries. In the Super Bowl 50 post-game interview, occurring within twenty minutes after the game, and\\n\\nQ: Who had a 12-yard rush on this drive?\\n\\nA:\",\n",
              "   'question': 'Who had a 12-yard rush on this drive?'},\n",
              "  {'answers': ['Carolina Panthers', 'the Panthers', 'Carolina'],\n",
              "   'em': 0,\n",
              "   'f1': 0.4444444444444445,\n",
              "   'generated_answer': ' The Carolina Panthers had the best record in the NFC.',\n",
              "   'generated_answer_probs': [0.9765002721168043,\n",
              "    0.9739105308522275,\n",
              "    0.9998273136720007,\n",
              "    0.7553624565738221,\n",
              "    0.9894034047177885,\n",
              "    0.9983529299111935,\n",
              "    0.9980470366195355,\n",
              "    0.9997498885130942,\n",
              "    0.9992540961546842,\n",
              "    0.9996034368919436,\n",
              "    0.4851595369351144],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' Carolina',\n",
              "    ' Panthers',\n",
              "    ' had',\n",
              "    ' the',\n",
              "    ' best',\n",
              "    ' record',\n",
              "    ' in',\n",
              "    ' the',\n",
              "    ' NFC',\n",
              "    '.'],\n",
              "   'generated_probs': [0.9765002721168043,\n",
              "    0.9739105308522275,\n",
              "    0.9998273136720007,\n",
              "    0.7553624565738221,\n",
              "    0.9894034047177885,\n",
              "    0.9983529299111935,\n",
              "    0.9980470366195355,\n",
              "    0.9997498885130942,\n",
              "    0.9992540961546842,\n",
              "    0.9996034368919436,\n",
              "    0.4851595369351144],\n",
              "   'generated_text': ' The Carolina Panthers had the best record in the NFC.',\n",
              "   'generated_tokens': [' The',\n",
              "    ' Carolina',\n",
              "    ' Panthers',\n",
              "    ' had',\n",
              "    ' the',\n",
              "    ' best',\n",
              "    ' record',\n",
              "    ' in',\n",
              "    ' the',\n",
              "    ' NFC',\n",
              "    '.'],\n",
              "   'id': '56beb3083aeaaa14008c923e',\n",
              "   'prediction': ' The Carolina Panthers had the best record in the NFC.',\n",
              "   'prompt': \"Title: Super Bowl 50\\n\\nBackground: the best start and the longest single-season winning streak, but also posting the best start to a season by an NFC team in NFL history, breaking the 13–0 record previously shared with the 2009 New Orleans Saints and the 2011 Green Bay Packers. With their NFC-best 15–1 regular season record, the Panthers clinched home-field advantage throughout the NFC playoffs for the first time in franchise history. Ten players were selected to the Pro Bowl (the most in franchise history) along with eight All-Pro selections. The Panthers' offense, which led the NFL in scoring (500 points), was loaded with talent, boasting\\n\\nQ: Who had the best record in the NFC?\\n\\nA:\",\n",
              "   'question': 'Who had the best record in the NFC?'},\n",
              "  {'answers': ['the mid-sixties', 'the mid-sixties', '1965'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' The first Doctor Who books were available in 1966.',\n",
              "   'generated_answer_probs': [0.7768181089765784,\n",
              "    0.4995826445625243,\n",
              "    0.9629963407841553,\n",
              "    0.9997988206092882,\n",
              "    0.5938605033764321,\n",
              "    0.9696119364962805,\n",
              "    0.9247388274872801,\n",
              "    0.9772852522998535,\n",
              "    0.9852801283287888,\n",
              "    0.9658862870188563],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' first',\n",
              "    ' Doctor',\n",
              "    ' Who',\n",
              "    ' books',\n",
              "    ' were',\n",
              "    ' available',\n",
              "    ' in',\n",
              "    ' 1966',\n",
              "    '.'],\n",
              "   'generated_probs': [0.7768181089765784,\n",
              "    0.4995826445625243,\n",
              "    0.9629963407841553,\n",
              "    0.9997988206092882,\n",
              "    0.5938605033764321,\n",
              "    0.9696119364962805,\n",
              "    0.9247388274872801,\n",
              "    0.9772852522998535,\n",
              "    0.9852801283287888,\n",
              "    0.9658862870188563],\n",
              "   'generated_text': ' The first Doctor Who books were available in 1966.',\n",
              "   'generated_tokens': [' The',\n",
              "    ' first',\n",
              "    ' Doctor',\n",
              "    ' Who',\n",
              "    ' books',\n",
              "    ' were',\n",
              "    ' available',\n",
              "    ' in',\n",
              "    ' 1966',\n",
              "    '.'],\n",
              "   'id': '572836732ca10214002da0dd',\n",
              "   'prediction': ' The first Doctor Who books were available in 1966.',\n",
              "   'prompt': 'Title: Doctor Who\\n\\nBackground: the First Doctor television story \"The Chase\" released in 1966. Ten years later, the first original Doctor Who audio was released on LP record; \"Doctor Who and the Pescatons\" featuring the Fourth Doctor. The first commercially available audiobook was an abridged reading of the Fourth Doctor story \"State of Decay\" in 1981. In 1988, during a hiatus in the television show, \"Slipback\", the first radio drama, was transmitted. Since 1999, Big Finish Productions has released several different series of Doctor Who audios on CD. The earliest of these featured the Fifth, Sixth and Seventh Doctors, with Paul McGann\\'s Eight Doctor\\n\\nQ: When were the earliest Doctor Who books available?\\n\\nA:',\n",
              "   'question': 'When were the earliest Doctor Who books available?'},\n",
              "  {'answers': ['late 1920s', 'the late 1920s', 'the late 1920s'],\n",
              "   'em': 0,\n",
              "   'f1': 0.4,\n",
              "   'generated_answer': ' Tesla became friends with Viereck in the late 1920s.',\n",
              "   'generated_answer_probs': [0.7953078393258846,\n",
              "    0.861773262035975,\n",
              "    0.9992239939985144,\n",
              "    0.9999874111422403,\n",
              "    0.9960402565414755,\n",
              "    0.9999032478307931,\n",
              "    0.7398130202866584,\n",
              "    0.9816952655507868,\n",
              "    0.9130471196733596,\n",
              "    0.9954136864038087,\n",
              "    0.9996426567423162,\n",
              "    0.9946501437260906],\n",
              "   'generated_answer_tokens': [' Tesla',\n",
              "    ' became',\n",
              "    ' friends',\n",
              "    ' with',\n",
              "    ' Vie',\n",
              "    'reck',\n",
              "    ' in',\n",
              "    ' the',\n",
              "    ' late',\n",
              "    ' 1920',\n",
              "    's',\n",
              "    '.'],\n",
              "   'generated_probs': [0.7953078393258846,\n",
              "    0.861773262035975,\n",
              "    0.9992239939985144,\n",
              "    0.9999874111422403,\n",
              "    0.9960402565414755,\n",
              "    0.9999032478307931,\n",
              "    0.7398130202866584,\n",
              "    0.9816952655507868,\n",
              "    0.9130471196733596,\n",
              "    0.9954136864038087,\n",
              "    0.9996426567423162,\n",
              "    0.9946501437260906],\n",
              "   'generated_text': ' Tesla became friends with Viereck in the late 1920s.',\n",
              "   'generated_tokens': [' Tesla',\n",
              "    ' became',\n",
              "    ' friends',\n",
              "    ' with',\n",
              "    ' Vie',\n",
              "    'reck',\n",
              "    ' in',\n",
              "    ' the',\n",
              "    ' late',\n",
              "    ' 1920',\n",
              "    's',\n",
              "    '.'],\n",
              "   'id': '56e11f83cd28a01900c67613',\n",
              "   'prediction': ' Tesla became friends with Viereck in the late 1920s.',\n",
              "   'prompt': 'Title: Nikola Tesla\\n\\nBackground: most valuable patent since the telephone.\" In the late 1920s, Tesla befriended George Sylvester Viereck, a poet, writer, mystic, and later, a Nazi propagandist. Tesla occasionally attended dinner parties held by Viereck and his wife. Tesla could be harsh at times and openly expressed disgust for overweight people, such as when he fired a secretary because of her weight. He was quick to criticize clothing; on several occasions, Tesla directed a subordinate to go home and change her dress. When Thomas Edison died, in 1931, Tesla contributed the only negative opinion to \"The New York Times\", buried in an extensive\\n\\nQ: When did Tesla become friends with Viereck?\\n\\nA:',\n",
              "   'question': 'When did Tesla become friends with Viereck?'},\n",
              "  {'answers': ['Atlanta Falcons', 'the Atlanta Falcons', 'Falcons'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' The Green Bay Packers',\n",
              "   'generated_answer_probs': [0.9648112563961557,\n",
              "    0.7876846496669027,\n",
              "    0.9990632413825534,\n",
              "    0.9998722542301858],\n",
              "   'generated_answer_tokens': [' The', ' Green', ' Bay', ' Packers'],\n",
              "   'generated_probs': [0.9648112563961557,\n",
              "    0.7876846496669027,\n",
              "    0.9990632413825534,\n",
              "    0.9998722542301858],\n",
              "   'generated_text': ' The Green Bay Packers',\n",
              "   'generated_tokens': [' The', ' Green', ' Bay', ' Packers'],\n",
              "   'id': '56bebad93aeaaa14008c92fb',\n",
              "   'prediction': ' The Green Bay Packers',\n",
              "   'prompt': \"Title: Super Bowl XXXII\\n\\nBackground: in the same year. This was Denver's first league championship after suffering four previous Super Bowl losses, and snapped a 13-game losing streak for AFC teams in the Super Bowl (the previous being the Los Angeles Raiders' win in Super Bowl XVIII after the 1983 season). The Broncos, who entered the game after posting a 12–4 regular season record in 1997, became just the second wild card team to win a Super Bowl and the first since the Raiders in Super Bowl XV. The Packers, who entered the game as the defending Super Bowl XXXI champions after posting a 13–3\\n\\nQ: What team lost Super Bowl XXXIII?\\n\\nA:\",\n",
              "   'question': 'What team lost Super Bowl XXXIII?'},\n",
              "  {'answers': ['Lek', 'Lek', 'the Lek'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' The Nederrijn changes its name to Angeren, and second near',\n",
              "   'generated_answer_probs': [0.7559156976994342,\n",
              "    0.9532137964855399,\n",
              "    0.9999883657376786,\n",
              "    0.9999846721884721,\n",
              "    0.9999952788481447,\n",
              "    0.9999993338092819,\n",
              "    0.9885904532439285,\n",
              "    0.5586740112867363,\n",
              "    0.9999282832977656,\n",
              "    0.9999309066470556,\n",
              "    0.48722918541425053,\n",
              "    0.9999952788481447,\n",
              "    0.9287652027868951,\n",
              "    0.9770197159996823,\n",
              "    0.6577060171109611,\n",
              "    0.9991587880173496],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' N',\n",
              "    'eder',\n",
              "    'ri',\n",
              "    'j',\n",
              "    'n',\n",
              "    ' changes',\n",
              "    ' its',\n",
              "    ' name',\n",
              "    ' to',\n",
              "    ' Ange',\n",
              "    'ren',\n",
              "    ',',\n",
              "    ' and',\n",
              "    ' second',\n",
              "    ' near'],\n",
              "   'generated_probs': [0.7559156976994342,\n",
              "    0.9532137964855399,\n",
              "    0.9999883657376786,\n",
              "    0.9999846721884721,\n",
              "    0.9999952788481447,\n",
              "    0.9999993338092819,\n",
              "    0.9885904532439285,\n",
              "    0.5586740112867363,\n",
              "    0.9999282832977656,\n",
              "    0.9999309066470556,\n",
              "    0.48722918541425053,\n",
              "    0.9999952788481447,\n",
              "    0.9287652027868951,\n",
              "    0.9770197159996823,\n",
              "    0.6577060171109611,\n",
              "    0.9991587880173496],\n",
              "   'generated_text': ' The Nederrijn changes its name to Angeren, and second near',\n",
              "   'generated_tokens': [' The',\n",
              "    ' N',\n",
              "    'eder',\n",
              "    'ri',\n",
              "    'j',\n",
              "    'n',\n",
              "    ' changes',\n",
              "    ' its',\n",
              "    ' name',\n",
              "    ' to',\n",
              "    ' Ange',\n",
              "    'ren',\n",
              "    ',',\n",
              "    ' and',\n",
              "    ' second',\n",
              "    ' near'],\n",
              "   'id': '572ff56304bcaa1900d76f30',\n",
              "   'prediction': ' The Nederrijn changes its name to Angeren, and second near',\n",
              "   'prompt': 'Title: Rhine\\n\\nBackground: changes its name to Nederrijn at Angeren, and second near Arnhem, the IJssel branches off from the Nederrijn. This creates three main flows, two of which change names rather often. The largest and southern main branch begins as Waal and continues as Boven Merwede (\"Upper Merwede\"), Beneden Merwede (\"Lower Merwede\"), Noord River (\"North River\"), Nieuwe Maas (\"New Meuse\"), Het Scheur (\"the Rip\") and Nieuwe Waterweg (\"New Waterway\"). The middle flow begins as Nederrijn, then changes into Lek, then joins the Noord, thereby forming Nieuwe Maas. The northern flow keeps the name IJssel until it flows into Lake IJsselmeer. Three more\\n\\nQ: What does the Nederrijn change it\\'s name to?\\n\\nA:',\n",
              "   'question': \"What does the Nederrijn change it's name to?\"},\n",
              "  {'answers': ['Milutin Tesla', 'Milutin Tesla', 'Milutin Tesla'],\n",
              "   'em': 0,\n",
              "   'f1': 0.4444444444444445,\n",
              "   'generated_answer': \" Nikola Tesla's father's name was Milutin Tesla.\",\n",
              "   'generated_answer_probs': [0.35867976789763384,\n",
              "    0.7189232301854889,\n",
              "    0.9937314551221753,\n",
              "    0.9991575950224689,\n",
              "    0.9672335234249514,\n",
              "    0.9996093987045565,\n",
              "    0.99881600128024,\n",
              "    0.8595107817724849,\n",
              "    0.9999992145956385,\n",
              "    0.9999999317236823,\n",
              "    0.8899134928722733,\n",
              "    0.9937478460627197],\n",
              "   'generated_answer_tokens': [' Nikola',\n",
              "    ' Tesla',\n",
              "    \"'s\",\n",
              "    ' father',\n",
              "    \"'s\",\n",
              "    ' name',\n",
              "    ' was',\n",
              "    ' Mil',\n",
              "    'ut',\n",
              "    'in',\n",
              "    ' Tesla',\n",
              "    '.'],\n",
              "   'generated_probs': [0.35867976789763384,\n",
              "    0.7189232301854889,\n",
              "    0.9937314551221753,\n",
              "    0.9991575950224689,\n",
              "    0.9672335234249514,\n",
              "    0.9996093987045565,\n",
              "    0.99881600128024,\n",
              "    0.8595107817724849,\n",
              "    0.9999992145956385,\n",
              "    0.9999999317236823,\n",
              "    0.8899134928722733,\n",
              "    0.9937478460627197],\n",
              "   'generated_text': \" Nikola Tesla's father's name was Milutin Tesla.\",\n",
              "   'generated_tokens': [' Nikola',\n",
              "    ' Tesla',\n",
              "    \"'s\",\n",
              "    ' father',\n",
              "    \"'s\",\n",
              "    ' name',\n",
              "    ' was',\n",
              "    ' Mil',\n",
              "    'ut',\n",
              "    'in',\n",
              "    ' Tesla',\n",
              "    '.'],\n",
              "   'id': '56e0bcc0231d4119001ac36c',\n",
              "   'prediction': \" Nikola Tesla's father's name was Milutin Tesla.\",\n",
              "   'prompt': \"Title: Nikola Tesla\\n\\nBackground: on 7 January 1943 in New York City. His work fell into relative obscurity after his death, but in 1960, the General Conference on Weights and Measures named the SI unit of magnetic flux density the tesla in his honor. There has been a resurgence in popular interest in Tesla since the 1990s. Tesla was born on 1856 into a Serb family in the village of Smiljan, Austrian Empire (modern-day Croatia). His father, Milutin Tesla (1819–1879), was an Orthodox priest. Tesla's mother, Đuka Tesla (née Mandić; 1822–1892), whose father was also an Orthodox priest, had a talent for making home\\n\\nQ: What was Tesla's father's name?\\n\\nA:\",\n",
              "   'question': \"What was Tesla's father's name?\"},\n",
              "  {'answers': ['core curriculum of seven classes', 'seven', 'seven'],\n",
              "   'em': 0,\n",
              "   'f1': 0.4210526315789473,\n",
              "   'generated_answer': ' Between 1978 and 2008, entering students were required to complete a core curriculum of seven',\n",
              "   'generated_answer_probs': [0.8101372752967763,\n",
              "    0.999485778956982,\n",
              "    0.9086049025070256,\n",
              "    0.9992963544747029,\n",
              "    0.6588575359633866,\n",
              "    0.6421659433202882,\n",
              "    0.9978258429108371,\n",
              "    0.9998685592390938,\n",
              "    0.9987491834239843,\n",
              "    0.9998369670113223,\n",
              "    0.9987275474551532,\n",
              "    0.9924427467290529,\n",
              "    0.9991018642655546,\n",
              "    0.9998215907768186,\n",
              "    0.9987942451072864,\n",
              "    0.9911137610923392],\n",
              "   'generated_answer_tokens': [' Between',\n",
              "    ' 1978',\n",
              "    ' and',\n",
              "    ' 2008',\n",
              "    ',',\n",
              "    ' entering',\n",
              "    ' students',\n",
              "    ' were',\n",
              "    ' required',\n",
              "    ' to',\n",
              "    ' complete',\n",
              "    ' a',\n",
              "    ' core',\n",
              "    ' curriculum',\n",
              "    ' of',\n",
              "    ' seven'],\n",
              "   'generated_probs': [0.8101372752967763,\n",
              "    0.999485778956982,\n",
              "    0.9086049025070256,\n",
              "    0.9992963544747029,\n",
              "    0.6588575359633866,\n",
              "    0.6421659433202882,\n",
              "    0.9978258429108371,\n",
              "    0.9998685592390938,\n",
              "    0.9987491834239843,\n",
              "    0.9998369670113223,\n",
              "    0.9987275474551532,\n",
              "    0.9924427467290529,\n",
              "    0.9991018642655546,\n",
              "    0.9998215907768186,\n",
              "    0.9987942451072864,\n",
              "    0.9911137610923392],\n",
              "   'generated_text': ' Between 1978 and 2008, entering students were required to complete a core curriculum of seven',\n",
              "   'generated_tokens': [' Between',\n",
              "    ' 1978',\n",
              "    ' and',\n",
              "    ' 2008',\n",
              "    ',',\n",
              "    ' entering',\n",
              "    ' students',\n",
              "    ' were',\n",
              "    ' required',\n",
              "    ' to',\n",
              "    ' complete',\n",
              "    ' a',\n",
              "    ' core',\n",
              "    ' curriculum',\n",
              "    ' of',\n",
              "    ' seven'],\n",
              "   'id': '5727d3843acd2414000ded69',\n",
              "   'prediction': ' Between 1978 and 2008, entering students were required to complete a core curriculum of seven',\n",
              "   'prompt': 'Title: Harvard University\\n\\nBackground: concept of meritocratic admissions. Harvard is a large, highly residential research university. The university has been accredited by the New England Association of Schools and Colleges since 1929. The university offers 46 undergraduate concentrations (majors), 134 graduate degrees, and 32 professional degrees. For the 2008–2009 academic year, Harvard granted 1,664 baccalaureate degrees, 400 master\\'s degrees, 512 doctoral degrees, and 4,460 professional degrees. The four-year, full-time undergraduate program comprises a minority of enrollments at the university and emphasizes instruction with an \"arts and sciences focus\". Between 1978 and 2008, entering students were required to complete a core curriculum of seven classes\\n\\nQ: Between 1978 an d2008 four year full time undergraduate students were required to complete how many classes outside of their concentration?\\n\\nA:',\n",
              "   'question': 'Between 1978 an d2008 four year full time undergraduate students were required to complete how many classes outside of their concentration?'},\n",
              "  {'answers': ['Jessé de Forest', 'Jessé de Forest', 'Jessé de Forest'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' Jean Ribault',\n",
              "   'generated_answer_probs': [0.9441379840253314,\n",
              "    0.9999627346113719,\n",
              "    0.9996133320153413],\n",
              "   'generated_answer_tokens': [' Jean', ' Rib', 'ault'],\n",
              "   'generated_probs': [0.9441379840253314,\n",
              "    0.9999627346113719,\n",
              "    0.9996133320153413],\n",
              "   'generated_text': ' Jean Ribault',\n",
              "   'generated_tokens': [' Jean', ' Rib', 'ault'],\n",
              "   'id': '57107932a58dae1900cd69cb',\n",
              "   'prediction': ' Jean Ribault',\n",
              "   'prompt': 'Title: France–Americas relations\\n\\nBackground: resistance. The first French expedition to Florida occurred in 1562, composed of Protestants, and was led by Jean Ribault and permitted the short-lived establishment of Fort Caroline, named after the French king Charles IX. These first attempts at Huguenot colonization would be taken over by Catholics, following the Huguenot repression in the French wars of religion. Towards the end of his reign Henry IV of France started to look at the possibility of ventures abroad, with both America and the Levant being among the possibilities. In 1604, the French explorer Samuel Champlain initiated the first important French involvement in Northern\\n\\nQ: Who led the North American Huguenot colonial expedition?\\n\\nA:',\n",
              "   'question': 'Who led the North American Huguenot colonial expedition?'},\n",
              "  {'answers': ['fourth', 'fourth', 'fourth'],\n",
              "   'em': 0,\n",
              "   'f1': 0.13333333333333333,\n",
              "   'generated_answer': ' Victoria ranks second in Australia, although Victoria is ranked fourth in terms of GSP',\n",
              "   'generated_answer_probs': [0.9872451129423281,\n",
              "    0.5322498590647684,\n",
              "    0.5206701745403038,\n",
              "    0.9942404799967722,\n",
              "    0.9948083370089468,\n",
              "    0.6380688156076364,\n",
              "    0.9120495128279053,\n",
              "    0.99934588532634,\n",
              "    0.9999809720970328,\n",
              "    0.9993395695802368,\n",
              "    0.9997593036920054,\n",
              "    0.9999601111855799,\n",
              "    0.9999800193836151,\n",
              "    0.9999957566187032,\n",
              "    0.9599943595560151,\n",
              "    0.9999977840931551],\n",
              "   'generated_answer_tokens': [' Victoria',\n",
              "    ' ranks',\n",
              "    ' second',\n",
              "    ' in',\n",
              "    ' Australia',\n",
              "    ',',\n",
              "    ' although',\n",
              "    ' Victoria',\n",
              "    ' is',\n",
              "    ' ranked',\n",
              "    ' fourth',\n",
              "    ' in',\n",
              "    ' terms',\n",
              "    ' of',\n",
              "    ' G',\n",
              "    'SP'],\n",
              "   'generated_probs': [0.9872451129423281,\n",
              "    0.5322498590647684,\n",
              "    0.5206701745403038,\n",
              "    0.9942404799967722,\n",
              "    0.9948083370089468,\n",
              "    0.6380688156076364,\n",
              "    0.9120495128279053,\n",
              "    0.99934588532634,\n",
              "    0.9999809720970328,\n",
              "    0.9993395695802368,\n",
              "    0.9997593036920054,\n",
              "    0.9999601111855799,\n",
              "    0.9999800193836151,\n",
              "    0.9999957566187032,\n",
              "    0.9599943595560151,\n",
              "    0.9999977840931551],\n",
              "   'generated_text': ' Victoria ranks second in Australia, although Victoria is ranked fourth in terms of GSP',\n",
              "   'generated_tokens': [' Victoria',\n",
              "    ' ranks',\n",
              "    ' second',\n",
              "    ' in',\n",
              "    ' Australia',\n",
              "    ',',\n",
              "    ' although',\n",
              "    ' Victoria',\n",
              "    ' is',\n",
              "    ' ranked',\n",
              "    ' fourth',\n",
              "    ' in',\n",
              "    ' terms',\n",
              "    ' of',\n",
              "    ' G',\n",
              "    'SP'],\n",
              "   'id': '570d2417fed7b91900d45c3f',\n",
              "   'prediction': ' Victoria ranks second in Australia, although Victoria is ranked fourth in terms of GSP',\n",
              "   'prompt': 'Title: Victoria (Australia)\\n\\nBackground: is ranked second in Australia, although Victoria is ranked fourth in terms of GSP per capita because of its limited mining activity. Culturally, Melbourne is home to a number of museums, art galleries and theatres and is also described as the \"sporting capital of Australia\". The Melbourne Cricket Ground is the largest stadium in Australia, and the host of the 1956 Summer Olympics and the 2006 Commonwealth Games. The ground is also considered the \"spiritual home\" of Australian cricket and Australian rules football, and hosts the grand final of the Australian Football League (AFL) each year, drawing crowds of approximately\\n\\nQ: At what rank does GPS per capita set Victoria?\\n\\nA:',\n",
              "   'question': 'At what rank does GPS per capita set Victoria?'},\n",
              "  {'answers': ['theatre', 'theatre', 'theatre.'],\n",
              "   'em': 0,\n",
              "   'f1': 0.16666666666666669,\n",
              "   'generated_answer': ' Theatre. The Kemble family successfully managed the original Theatre Royal, Newcastle for fifteen',\n",
              "   'generated_answer_probs': [0.8952361506823674,\n",
              "    0.6219193854676087,\n",
              "    0.6306833530903097,\n",
              "    0.5862603528101021,\n",
              "    0.9684485479980851,\n",
              "    0.9992855067419562,\n",
              "    0.8051116866557299,\n",
              "    0.9992225636603519,\n",
              "    0.9996123787145496,\n",
              "    0.9992192265623284,\n",
              "    0.9997910736381527,\n",
              "    0.9999824044518034,\n",
              "    0.998572991745947,\n",
              "    0.9999989771165232,\n",
              "    0.999990869089687,\n",
              "    0.9975489205128913],\n",
              "   'generated_answer_tokens': [' Theatre',\n",
              "    '.',\n",
              "    ' The',\n",
              "    ' Kem',\n",
              "    'ble',\n",
              "    ' family',\n",
              "    ' successfully',\n",
              "    ' managed',\n",
              "    ' the',\n",
              "    ' original',\n",
              "    ' Theatre',\n",
              "    ' Royal',\n",
              "    ',',\n",
              "    ' Newcastle',\n",
              "    ' for',\n",
              "    ' fifteen'],\n",
              "   'generated_probs': [0.8952361506823674,\n",
              "    0.6219193854676087,\n",
              "    0.6306833530903097,\n",
              "    0.5862603528101021,\n",
              "    0.9684485479980851,\n",
              "    0.9992855067419562,\n",
              "    0.8051116866557299,\n",
              "    0.9992225636603519,\n",
              "    0.9996123787145496,\n",
              "    0.9992192265623284,\n",
              "    0.9997910736381527,\n",
              "    0.9999824044518034,\n",
              "    0.998572991745947,\n",
              "    0.9999989771165232,\n",
              "    0.999990869089687,\n",
              "    0.9975489205128913],\n",
              "   'generated_text': ' Theatre. The Kemble family successfully managed the original Theatre Royal, Newcastle for fifteen',\n",
              "   'generated_tokens': [' Theatre',\n",
              "    '.',\n",
              "    ' The',\n",
              "    ' Kem',\n",
              "    'ble',\n",
              "    ' family',\n",
              "    ' successfully',\n",
              "    ' managed',\n",
              "    ' the',\n",
              "    ' original',\n",
              "    ' Theatre',\n",
              "    ' Royal',\n",
              "    ',',\n",
              "    ' Newcastle',\n",
              "    ' for',\n",
              "    ' fifteen'],\n",
              "   'id': '57267f695951b619008f74bd',\n",
              "   'prediction': ' Theatre. The Kemble family successfully managed the original Theatre Royal, Newcastle for fifteen',\n",
              "   'prompt': 'Title: Newcastle upon Tyne\\n\\nBackground: American, Polish, Malaysian, French, Mongolian, Moroccan, Thai, Vietnamese and Lebanese. Newcastle is one of 7 cities in the UK that has a Chinese village with many Chinese restaurants on Stowell Street. There has also been a growth in premium restaurants in recent years with top chefs. The city has a proud history of theatre. Stephen Kemble of the famous Kemble family successfully managed the original Theatre Royal, Newcastle for fifteen years (1791–1806). He brought members of his famous acting family such as Sarah Siddons and John Kemble out of London to Newcastle. Stephen Kemble guided the theatre through many celebrated\\n\\nQ: What does Newcastle have a proud history of?\\n\\nA:',\n",
              "   'question': 'What does Newcastle have a proud history of?'},\n",
              "  {'answers': ['body and blood of Christ',\n",
              "    'Real Presence',\n",
              "    'Real Presence of the body and blood of Christ in the consecrated bread and wine'],\n",
              "   'em': 0,\n",
              "   'f1': 0.6153846153846154,\n",
              "   'generated_answer': ' Luther insisted that the bread and wine were actually the body and blood of Christ.',\n",
              "   'generated_answer_probs': [0.9896645348146227,\n",
              "    0.9865229418367153,\n",
              "    0.9731550421888836,\n",
              "    0.7319626067503691,\n",
              "    0.6244532325818486,\n",
              "    0.9999717941767917,\n",
              "    0.9999368676279321,\n",
              "    0.8966472675419281,\n",
              "    0.7321573273798607,\n",
              "    0.8291468901311927,\n",
              "    0.9853054020735075,\n",
              "    0.9991123555895837,\n",
              "    0.9992987388486141,\n",
              "    0.9999299521034685,\n",
              "    0.854966279503769,\n",
              "    0.6162005501556643],\n",
              "   'generated_answer_tokens': [' Luther',\n",
              "    ' insisted',\n",
              "    ' that',\n",
              "    ' the',\n",
              "    ' bread',\n",
              "    ' and',\n",
              "    ' wine',\n",
              "    ' were',\n",
              "    ' actually',\n",
              "    ' the',\n",
              "    ' body',\n",
              "    ' and',\n",
              "    ' blood',\n",
              "    ' of',\n",
              "    ' Christ',\n",
              "    '.'],\n",
              "   'generated_probs': [0.9896645348146227,\n",
              "    0.9865229418367153,\n",
              "    0.9731550421888836,\n",
              "    0.7319626067503691,\n",
              "    0.6244532325818486,\n",
              "    0.9999717941767917,\n",
              "    0.9999368676279321,\n",
              "    0.8966472675419281,\n",
              "    0.7321573273798607,\n",
              "    0.8291468901311927,\n",
              "    0.9853054020735075,\n",
              "    0.9991123555895837,\n",
              "    0.9992987388486141,\n",
              "    0.9999299521034685,\n",
              "    0.854966279503769,\n",
              "    0.6162005501556643],\n",
              "   'generated_text': ' Luther insisted that the bread and wine were actually the body and blood of Christ.',\n",
              "   'generated_tokens': [' Luther',\n",
              "    ' insisted',\n",
              "    ' that',\n",
              "    ' the',\n",
              "    ' bread',\n",
              "    ' and',\n",
              "    ' wine',\n",
              "    ' were',\n",
              "    ' actually',\n",
              "    ' the',\n",
              "    ' body',\n",
              "    ' and',\n",
              "    ' blood',\n",
              "    ' of',\n",
              "    ' Christ',\n",
              "    '.'],\n",
              "   'id': '56f88eafaef2371900626195',\n",
              "   'prediction': ' Luther insisted that the bread and wine were actually the body and blood of Christ.',\n",
              "   'prompt': 'Title: Martin Luther\\n\\nBackground: of the Lord\\'s Supper—an issue crucial to Luther. The theologians, including Zwingli, Melanchthon, Martin Bucer, and Johannes Oecolampadius, differed on the significance of the words spoken by Jesus at the Last Supper: \"This is my body which is for you\" and \"This cup is the new covenant in my blood\" (1 Corinthians 11:23–26). Luther insisted on the Real Presence of the body and blood of Christ in the consecrated bread and wine, which he called the sacramental union, while his opponents believed God to be only spiritually or symbolically present. Zwingli, for example, denied Jesus\\' ability to be in more\\n\\nQ: What did Luther insist was present in the bread and wine?\\n\\nA:',\n",
              "   'question': 'What did Luther insist was present in the bread and wine?'},\n",
              "  {'answers': ['Emmanuel Sanders', 'Emmanuel Sanders', 'Sanders'],\n",
              "   'em': 1,\n",
              "   'f1': 1.0,\n",
              "   'generated_answer': ' Emmanuel Sanders',\n",
              "   'generated_answer_probs': [0.917677791155272, 0.9998915656394303],\n",
              "   'generated_answer_tokens': [' Emmanuel', ' Sanders'],\n",
              "   'generated_probs': [0.917677791155272, 0.9998915656394303],\n",
              "   'generated_text': ' Emmanuel Sanders',\n",
              "   'generated_tokens': [' Emmanuel', ' Sanders'],\n",
              "   'id': '56d9c92bdc89441400fdb811',\n",
              "   'prediction': ' Emmanuel Sanders',\n",
              "   'prompt': \"Title: Super Bowl 50\\n\\nBackground: miss, Manning completed a pair of passes to Emmanuel Sanders for gains of 25 and 22 yards, setting up McManus' 33-yard field goal that gave the Broncos a 16–7 lead. Carolina got off to another strong start after the kickoff, with Newton completing a 42-yard pass to Corey Brown. But once again they came up empty, this time as a result of a Newton pass that bounced off the hands of Ginn and was intercepted by safety T. J. Ward. Ward fumbled the ball deep in Denver territory during the return, but Trevathan was able to recover the ball enabling\\n\\nQ: Who caught two passes from Manning after the failed Carolina field goal attempt?\\n\\nA:\",\n",
              "   'question': 'Who caught two passes from Manning after the failed Carolina field goal attempt?'},\n",
              "  {'answers': ['Confucian',\n",
              "    'Confucian governmental practices and examinations',\n",
              "    'Confucian'],\n",
              "   'em': 0,\n",
              "   'f1': 0.3333333333333333,\n",
              "   'generated_answer': ' The Yuan dynasty reintroduced Confucian practices into government.',\n",
              "   'generated_answer_probs': [0.8074640055896517,\n",
              "    0.9995041362810702,\n",
              "    0.9148277982976448,\n",
              "    0.7618465283083314,\n",
              "    0.9997275938792867,\n",
              "    0.6745830855308591,\n",
              "    0.9999628519460061,\n",
              "    0.9999996923682474,\n",
              "    0.7844750115696822,\n",
              "    0.7016979417231752,\n",
              "    0.8322666472695912,\n",
              "    0.90764722463355],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' Yuan',\n",
              "    ' dynasty',\n",
              "    ' reintrodu',\n",
              "    'ced',\n",
              "    ' Conf',\n",
              "    'uc',\n",
              "    'ian',\n",
              "    ' practices',\n",
              "    ' into',\n",
              "    ' government',\n",
              "    '.'],\n",
              "   'generated_probs': [0.8074640055896517,\n",
              "    0.9995041362810702,\n",
              "    0.9148277982976448,\n",
              "    0.7618465283083314,\n",
              "    0.9997275938792867,\n",
              "    0.6745830855308591,\n",
              "    0.9999628519460061,\n",
              "    0.9999996923682474,\n",
              "    0.7844750115696822,\n",
              "    0.7016979417231752,\n",
              "    0.8322666472695912,\n",
              "    0.90764722463355],\n",
              "   'generated_text': ' The Yuan dynasty reintroduced Confucian practices into government.',\n",
              "   'generated_tokens': [' The',\n",
              "    ' Yuan',\n",
              "    ' dynasty',\n",
              "    ' reintrodu',\n",
              "    'ced',\n",
              "    ' Conf',\n",
              "    'uc',\n",
              "    'ian',\n",
              "    ' practices',\n",
              "    ' into',\n",
              "    ' government',\n",
              "    '.'],\n",
              "   'id': '572879574b864d1900164a17',\n",
              "   'prediction': ' The Yuan dynasty reintroduced Confucian practices into government.',\n",
              "   'prompt': 'Title: Yuan dynasty\\n\\nBackground: to reform the government based on the Confucian principles, with the help of his newly appointed grand chancellor Baiju. During his reign, the Da Yuan Tong Zhi (Chinese: 大元通制, \"the comprehensive institutions of the Great Yuan\"), a huge collection of codes and regulations of the Yuan dynasty begun by his father, was formally promulgated. Gegeen was assassinated in a coup involving five princes from a rival faction, perhaps steppe elite opposed to Confucian reforms. They placed Yesün Temür (or Taidingdi) on the throne, and, after an unsuccessful attempt to calm the princes, he also succumbed to regicide. Before Yesün Temür\\'s\\n\\nQ: What type of practices did the Yuan reintroduce in government?\\n\\nA:',\n",
              "   'question': 'What type of practices did the Yuan reintroduce in government?'},\n",
              "  {'answers': ['Mohandas Gandhi',\n",
              "    'Mohandas Gandhi',\n",
              "    'Mohandas Gandhi',\n",
              "    'Mohandas Gandhi',\n",
              "    'Gan'],\n",
              "   'em': 0,\n",
              "   'f1': 0.3076923076923077,\n",
              "   'generated_answer': ' Mohandas Gandhi, who pleaded guilty to a charge of disobedience in 1922.',\n",
              "   'generated_answer_probs': [0.9935327933834378,\n",
              "    0.9999955182025433,\n",
              "    0.9999700042268822,\n",
              "    0.9501716153172628,\n",
              "    0.31928907350512264,\n",
              "    0.31358554039601033,\n",
              "    0.6064351992997262,\n",
              "    0.99758152104406,\n",
              "    0.8915914330761873,\n",
              "    0.13843825015922256,\n",
              "    0.5982478775286187,\n",
              "    0.9947850906988182,\n",
              "    0.18422780803947414,\n",
              "    0.5200694804929161,\n",
              "    0.2828331871017401,\n",
              "    0.6119673668695889],\n",
              "   'generated_answer_tokens': [' Moh',\n",
              "    'and',\n",
              "    'as',\n",
              "    ' Gandhi',\n",
              "    ',',\n",
              "    ' who',\n",
              "    ' pleaded',\n",
              "    ' guilty',\n",
              "    ' to',\n",
              "    ' a',\n",
              "    ' charge',\n",
              "    ' of',\n",
              "    ' disobedience',\n",
              "    ' in',\n",
              "    ' 1922',\n",
              "    '.'],\n",
              "   'generated_probs': [0.9935327933834378,\n",
              "    0.9999955182025433,\n",
              "    0.9999700042268822,\n",
              "    0.9501716153172628,\n",
              "    0.31928907350512264,\n",
              "    0.31358554039601033,\n",
              "    0.6064351992997262,\n",
              "    0.99758152104406,\n",
              "    0.8915914330761873,\n",
              "    0.13843825015922256,\n",
              "    0.5982478775286187,\n",
              "    0.9947850906988182,\n",
              "    0.18422780803947414,\n",
              "    0.5200694804929161,\n",
              "    0.2828331871017401,\n",
              "    0.6119673668695889],\n",
              "   'generated_text': ' Mohandas Gandhi, who pleaded guilty to a charge of disobedience in 1922.',\n",
              "   'generated_tokens': [' Moh',\n",
              "    'and',\n",
              "    'as',\n",
              "    ' Gandhi',\n",
              "    ',',\n",
              "    ' who',\n",
              "    ' pleaded',\n",
              "    ' guilty',\n",
              "    ' to',\n",
              "    ' a',\n",
              "    ' charge',\n",
              "    ' of',\n",
              "    ' disobedience',\n",
              "    ' in',\n",
              "    ' 1922',\n",
              "    '.'],\n",
              "   'id': '5728eef92ca10214002daab4',\n",
              "   'prediction': ' Mohandas Gandhi, who pleaded guilty to a charge of disobedience in 1922.',\n",
              "   'prompt': 'Title: Civil disobedience\\n\\nBackground: mass arrest situations, the activists decide to use solidarity tactics to secure the same plea bargain for everyone. But some activists have opted to enter a blind plea, pleading guilty without any plea agreement in place. Mohandas Gandhi pleaded guilty and told the court, \"I am here to . . . submit cheerfully to the highest penalty that can be inflicted upon me for what in law is a deliberate crime and what appears to me to be the highest duty of a citizen.\" Some civil disobedience defendants choose to make a defiant speech, or a speech explaining their actions,\\n\\nQ: Which famous Indian took a plea and put himself at the mercy of the courts?\\n\\nA:',\n",
              "   'question': 'Which famous Indian took a plea and put himself at the mercy of the courts?'},\n",
              "  {'answers': ['Ming-Tan', 'Ming-Tan', 'Ming-Tan'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' Wu Xi was the Jin dynasty defector who betrayed the location of the Jin army',\n",
              "   'generated_answer_probs': [0.9988820447780791,\n",
              "    0.9991196273555928,\n",
              "    0.4392776744628962,\n",
              "    0.9619277404643886,\n",
              "    0.724933929503152,\n",
              "    0.9994739768986877,\n",
              "    0.9985032546422821,\n",
              "    0.999995041369894,\n",
              "    0.999589965127285,\n",
              "    0.9995968811442488,\n",
              "    0.9999746560471634,\n",
              "    0.9998347033529964,\n",
              "    0.9999962315756006,\n",
              "    0.9999933705813747,\n",
              "    0.9999764441394436,\n",
              "    0.9999322178473139],\n",
              "   'generated_answer_tokens': [' Wu',\n",
              "    ' Xi',\n",
              "    ' was',\n",
              "    ' the',\n",
              "    ' Jin',\n",
              "    ' dynasty',\n",
              "    ' def',\n",
              "    'ector',\n",
              "    ' who',\n",
              "    ' betrayed',\n",
              "    ' the',\n",
              "    ' location',\n",
              "    ' of',\n",
              "    ' the',\n",
              "    ' Jin',\n",
              "    ' army'],\n",
              "   'generated_probs': [0.9988820447780791,\n",
              "    0.9991196273555928,\n",
              "    0.4392776744628962,\n",
              "    0.9619277404643886,\n",
              "    0.724933929503152,\n",
              "    0.9994739768986877,\n",
              "    0.9985032546422821,\n",
              "    0.999995041369894,\n",
              "    0.999589965127285,\n",
              "    0.9995968811442488,\n",
              "    0.9999746560471634,\n",
              "    0.9998347033529964,\n",
              "    0.9999962315756006,\n",
              "    0.9999933705813747,\n",
              "    0.9999764441394436,\n",
              "    0.9999322178473139],\n",
              "   'generated_text': ' Wu Xi was the Jin dynasty defector who betrayed the location of the Jin army',\n",
              "   'generated_tokens': [' Wu',\n",
              "    ' Xi',\n",
              "    ' was',\n",
              "    ' the',\n",
              "    ' Jin',\n",
              "    ' dynasty',\n",
              "    ' def',\n",
              "    'ector',\n",
              "    ' who',\n",
              "    ' betrayed',\n",
              "    ' the',\n",
              "    ' location',\n",
              "    ' of',\n",
              "    ' the',\n",
              "    ' Jin',\n",
              "    ' army'],\n",
              "   'id': '5726bb645951b619008f7c3c',\n",
              "   'prediction': ' Wu Xi was the Jin dynasty defector who betrayed the location of the Jin army',\n",
              "   'prompt': \"Title: Jin–Song Wars\\n\\nBackground: Soldier morale sank as weather conditions worsened, supplies ran out, and hunger spread, forcing many to desert. The massive defections of Han Chinese in northern China that the Song had expected never materialized. A notable betrayal did occur on the Song side, however: Wu Xi (; d. 1207), the governor-general of Sichuan, defected to the Jin in December 1206. The Song had depended on Wu's success in the west to divert Jin soldiers away from the eastern front. He had attacked Jin positions earlier in 1206, but his army of about 50,000 men had been repelled. Wu's defection could have\\n\\nQ: Who was the Jin dynasty defector who betrayed the location of the Jin army?\\n\\nA:\",\n",
              "   'question': 'Who was the Jin dynasty defector who betrayed the location of the Jin army?'},\n",
              "  {'answers': ['Battle of Fort Bull',\n",
              "    'Battle of Fort Bull',\n",
              "    'Battle of Fort Bull',\n",
              "    'Battle of Fort Bull',\n",
              "    'March Battle of Fort Bull'],\n",
              "   'em': 0,\n",
              "   'f1': 0.14285714285714288,\n",
              "   'generated_answer': ' The attack on the British weakness was the bombing of British sea communications.',\n",
              "   'generated_answer_probs': [0.9126717336252228,\n",
              "    0.4741804374488904,\n",
              "    0.9841233727285208,\n",
              "    0.9506569281975479,\n",
              "    0.998999108226648,\n",
              "    0.9634549421356478,\n",
              "    0.9994572290134938,\n",
              "    0.8721210987517922,\n",
              "    0.868442657704981,\n",
              "    0.9907326510410605,\n",
              "    0.6609254428303638,\n",
              "    0.9904120978611959,\n",
              "    0.9903346100596482,\n",
              "    0.9239919125779718],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' attack',\n",
              "    ' on',\n",
              "    ' the',\n",
              "    ' British',\n",
              "    ' weakness',\n",
              "    ' was',\n",
              "    ' the',\n",
              "    ' bombing',\n",
              "    ' of',\n",
              "    ' British',\n",
              "    ' sea',\n",
              "    ' communications',\n",
              "    '.'],\n",
              "   'generated_probs': [0.9126717336252228,\n",
              "    0.4741804374488904,\n",
              "    0.9841233727285208,\n",
              "    0.9506569281975479,\n",
              "    0.998999108226648,\n",
              "    0.9634549421356478,\n",
              "    0.9994572290134938,\n",
              "    0.8721210987517922,\n",
              "    0.868442657704981,\n",
              "    0.9907326510410605,\n",
              "    0.6609254428303638,\n",
              "    0.9904120978611959,\n",
              "    0.9903346100596482,\n",
              "    0.9239919125779718],\n",
              "   'generated_text': ' The attack on the British weakness was the bombing of British sea communications.',\n",
              "   'generated_tokens': [' The',\n",
              "    ' attack',\n",
              "    ' on',\n",
              "    ' the',\n",
              "    ' British',\n",
              "    ' weakness',\n",
              "    ' was',\n",
              "    ' the',\n",
              "    ' bombing',\n",
              "    ' of',\n",
              "    ' British',\n",
              "    ' sea',\n",
              "    ' communications',\n",
              "    '.'],\n",
              "   'id': '5733fc6ed058e614000b6710',\n",
              "   'prediction': ' The attack on the British weakness was the bombing of British sea communications.',\n",
              "   'prompt': \"Title: The Blitz\\n\\nBackground: The air offensive against the RAF and British industry failed to have the desired effect. More might have been achieved had the OKL exploited their enemy's weak spot, the vulnerability of British sea communications. The Allies did so later when Bomber Command attacked rail communications and the United States Army Air Forces targeted oil, but that would have required an economic-industrial analysis of which the Luftwaffe was incapable. The OKL instead sought clusters of targets that suited the latest policy (which changed frequently), and disputes within the leadership were about tactics rather than strategy. Though militarily ineffective, the Blitz caused\\n\\nQ: What was the attack on the British weakness?\\n\\nA:\",\n",
              "   'question': 'What was the attack on the British weakness?'},\n",
              "  {'answers': ['October 16, 1973,',\n",
              "    'October 16, 1973',\n",
              "    'October 16, 1973',\n",
              "    'October 16, 1973',\n",
              "    'October 16, 1973'],\n",
              "   'em': 0,\n",
              "   'f1': 0.42857142857142855,\n",
              "   'generated_answer': ' On October 16, 1973, OPEC raised the price of oil by 70%.',\n",
              "   'generated_answer_probs': [0.48752924529249714,\n",
              "    0.9983571618383974,\n",
              "    0.999886917004364,\n",
              "    0.9518864181258061,\n",
              "    0.9976358809416854,\n",
              "    0.5522914571310902,\n",
              "    0.9478651876118576,\n",
              "    0.9973865547098569,\n",
              "    0.9999441379803408,\n",
              "    0.519132359703501,\n",
              "    0.999986933375369,\n",
              "    0.9999742965583391,\n",
              "    0.9729254455600848,\n",
              "    0.9980255818329969,\n",
              "    0.7989227909401517],\n",
              "   'generated_answer_tokens': [' On',\n",
              "    ' October',\n",
              "    ' 16',\n",
              "    ',',\n",
              "    ' 1973',\n",
              "    ',',\n",
              "    ' OPEC',\n",
              "    ' raised',\n",
              "    ' the',\n",
              "    ' price',\n",
              "    ' of',\n",
              "    ' oil',\n",
              "    ' by',\n",
              "    ' 70',\n",
              "    '%.'],\n",
              "   'generated_probs': [0.48752924529249714,\n",
              "    0.9983571618383974,\n",
              "    0.999886917004364,\n",
              "    0.9518864181258061,\n",
              "    0.9976358809416854,\n",
              "    0.5522914571310902,\n",
              "    0.9478651876118576,\n",
              "    0.9973865547098569,\n",
              "    0.9999441379803408,\n",
              "    0.519132359703501,\n",
              "    0.999986933375369,\n",
              "    0.9999742965583391,\n",
              "    0.9729254455600848,\n",
              "    0.9980255818329969,\n",
              "    0.7989227909401517],\n",
              "   'generated_text': ' On October 16, 1973, OPEC raised the price of oil by 70%.',\n",
              "   'generated_tokens': [' On',\n",
              "    ' October',\n",
              "    ' 16',\n",
              "    ',',\n",
              "    ' 1973',\n",
              "    ',',\n",
              "    ' OPEC',\n",
              "    ' raised',\n",
              "    ' the',\n",
              "    ' price',\n",
              "    ' of',\n",
              "    ' oil',\n",
              "    ' by',\n",
              "    ' 70',\n",
              "    '%.'],\n",
              "   'id': '5725bcb6271a42140099d0ec',\n",
              "   'prediction': ' On October 16, 1973, OPEC raised the price of oil by 70%.',\n",
              "   'prompt': \"Title: 1973 oil crisis\\n\\nBackground: president Richard Nixon authorized Operation Nickel Grass, a strategic airlift to deliver weapons and supplies to Israel, after the Soviet Union began sending arms to Syria and Egypt. In response to American aid to Israel, on October 16, 1973, OPEC raised the posted price of oil by 70%, to $5.11 a barrel. The following day, oil ministers agreed to the embargo, a cut in production by five percent from September's output and to continue to cut production in five percent monthly increments until their economic and political objectives were met. On October 19, Nixon requested Congress to appropriate $2.2\\xa0billion in\\n\\nQ: When did they raise the price of oil to $5.11?\\n\\nA:\",\n",
              "   'question': 'When did they raise the price of oil to $5.11?'},\n",
              "  {'answers': ['5 million people', '5 million', 'Some 5 million'],\n",
              "   'em': 0,\n",
              "   'f1': 0.35294117647058826,\n",
              "   'generated_answer': ' 5 million people were believed to have lived in the Amazon region in AD 1500.',\n",
              "   'generated_answer_probs': [0.7745683906918528,\n",
              "    0.9988016365116877,\n",
              "    0.6568854557931006,\n",
              "    0.8231535682708787,\n",
              "    0.9753788201077667,\n",
              "    0.9999938483514215,\n",
              "    0.9996512395510694,\n",
              "    0.9988729828613859,\n",
              "    0.9999847857717375,\n",
              "    0.9999442562517404,\n",
              "    0.9998490089602946,\n",
              "    0.9999436611730913,\n",
              "    0.9972011219829938,\n",
              "    0.9232297581959671,\n",
              "    0.9993731272668643,\n",
              "    0.9811546564575119],\n",
              "   'generated_answer_tokens': [' 5',\n",
              "    ' million',\n",
              "    ' people',\n",
              "    ' were',\n",
              "    ' believed',\n",
              "    ' to',\n",
              "    ' have',\n",
              "    ' lived',\n",
              "    ' in',\n",
              "    ' the',\n",
              "    ' Amazon',\n",
              "    ' region',\n",
              "    ' in',\n",
              "    ' AD',\n",
              "    ' 1500',\n",
              "    '.'],\n",
              "   'generated_probs': [0.7745683906918528,\n",
              "    0.9988016365116877,\n",
              "    0.6568854557931006,\n",
              "    0.8231535682708787,\n",
              "    0.9753788201077667,\n",
              "    0.9999938483514215,\n",
              "    0.9996512395510694,\n",
              "    0.9988729828613859,\n",
              "    0.9999847857717375,\n",
              "    0.9999442562517404,\n",
              "    0.9998490089602946,\n",
              "    0.9999436611730913,\n",
              "    0.9972011219829938,\n",
              "    0.9232297581959671,\n",
              "    0.9993731272668643,\n",
              "    0.9811546564575119],\n",
              "   'generated_text': ' 5 million people were believed to have lived in the Amazon region in AD 1500.',\n",
              "   'generated_tokens': [' 5',\n",
              "    ' million',\n",
              "    ' people',\n",
              "    ' were',\n",
              "    ' believed',\n",
              "    ' to',\n",
              "    ' have',\n",
              "    ' lived',\n",
              "    ' in',\n",
              "    ' the',\n",
              "    ' Amazon',\n",
              "    ' region',\n",
              "    ' in',\n",
              "    ' AD',\n",
              "    ' 1500',\n",
              "    '.'],\n",
              "   'id': '5729eb34af94a219006aa6cc',\n",
              "   'prediction': ' 5 million people were believed to have lived in the Amazon region in AD 1500.',\n",
              "   'prompt': \"Title: Amazon rainforest\\n\\nBackground: density of is the maximum that can be sustained in the rainforest through hunting, with agriculture needed to host a larger population. However, recent anthropological findings have suggested that the region was actually densely populated. Some 5 million people may have lived in the Amazon region in AD 1500, divided between dense coastal settlements, such as that at Marajó, and inland dwellers. By 1900 the population had fallen to 1 million and by the early 1980s it was less than 200,000. The first European to travel the length of the Amazon River was Francisco de Orellana in 1542. The BBC's\\n\\nQ: In 1500 AD how many people were believed to have lived in the Amazon region?\\n\\nA:\",\n",
              "   'question': 'In 1500 AD how many people were believed to have lived in the Amazon region?'},\n",
              "  {'answers': ['San Fernando Valley',\n",
              "    'the San Fernando Valley',\n",
              "    'San Fernando Valley'],\n",
              "   'em': 0,\n",
              "   'f1': 0.42857142857142855,\n",
              "   'generated_answer': ' The Warner Center is located in the San Fernando Valley in Los Angeles.',\n",
              "   'generated_answer_probs': [0.5627408661887773,\n",
              "    0.9942519242676817,\n",
              "    0.9995004416808291,\n",
              "    0.9947428912187056,\n",
              "    0.985025260461796,\n",
              "    0.9988250627798706,\n",
              "    0.9844494845364993,\n",
              "    0.9917980807965582,\n",
              "    0.999990273057307,\n",
              "    0.9997349847027595,\n",
              "    0.38190963345377976,\n",
              "    0.513281408310874,\n",
              "    0.9999292378437595,\n",
              "    0.47486119438506375],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' Warner',\n",
              "    ' Center',\n",
              "    ' is',\n",
              "    ' located',\n",
              "    ' in',\n",
              "    ' the',\n",
              "    ' San',\n",
              "    ' Fernando',\n",
              "    ' Valley',\n",
              "    ' in',\n",
              "    ' Los',\n",
              "    ' Angeles',\n",
              "    '.'],\n",
              "   'generated_probs': [0.5627408661887773,\n",
              "    0.9942519242676817,\n",
              "    0.9995004416808291,\n",
              "    0.9947428912187056,\n",
              "    0.985025260461796,\n",
              "    0.9988250627798706,\n",
              "    0.9844494845364993,\n",
              "    0.9917980807965582,\n",
              "    0.999990273057307,\n",
              "    0.9997349847027595,\n",
              "    0.38190963345377976,\n",
              "    0.513281408310874,\n",
              "    0.9999292378437595,\n",
              "    0.47486119438506375],\n",
              "   'generated_text': ' The Warner Center is located in the San Fernando Valley in Los Angeles.',\n",
              "   'generated_tokens': [' The',\n",
              "    ' Warner',\n",
              "    ' Center',\n",
              "    ' is',\n",
              "    ' located',\n",
              "    ' in',\n",
              "    ' the',\n",
              "    ' San',\n",
              "    ' Fernando',\n",
              "    ' Valley',\n",
              "    ' in',\n",
              "    ' Los',\n",
              "    ' Angeles',\n",
              "    '.'],\n",
              "   'id': '57060cc352bb891400689810',\n",
              "   'prediction': ' The Warner Center is located in the San Fernando Valley in Los Angeles.',\n",
              "   'prompt': 'Title: Southern California\\n\\nBackground: many business districts, such as Downtown Los Angeles and those lining the Wilshire Boulevard Miracle Mile, including Century City, Westwood, and Warner Center in the San Fernando Valley. The area of Santa Monica and Venice (and perhaps some of Culver City) is informally referred to as \"Silicon Beach\" because of the concentration of financial and marketing technology-centric firms located in the region. The San Bernardino-Riverside area maintains the business districts of Downtown San Bernardino, Hospitality Business/Financial Centre, University Town which are in San Bernardino and Downtown Riverside. Orange County is a rapidly developing business center that includes Downtown Santa Ana,\\n\\nQ: Warner Center is located in which area?\\n\\nA:',\n",
              "   'question': 'Warner Center is located in which area?'},\n",
              "  {'answers': ['public', 'public', 'public'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' Preparatory schools prepare British children to attend independent schools.',\n",
              "   'generated_answer_probs': [0.6994806135398328,\n",
              "    0.999919581723723,\n",
              "    0.9852203453149372,\n",
              "    0.3732593696491796,\n",
              "    0.9041960831240636,\n",
              "    0.9993730071722029,\n",
              "    0.9405975793419156,\n",
              "    0.9985784760237352,\n",
              "    0.40307192057210356,\n",
              "    0.9721538093192033,\n",
              "    0.687712215487259],\n",
              "   'generated_answer_tokens': [' Prepar',\n",
              "    'atory',\n",
              "    ' schools',\n",
              "    ' prepare',\n",
              "    ' British',\n",
              "    ' children',\n",
              "    ' to',\n",
              "    ' attend',\n",
              "    ' independent',\n",
              "    ' schools',\n",
              "    '.'],\n",
              "   'generated_probs': [0.6994806135398328,\n",
              "    0.999919581723723,\n",
              "    0.9852203453149372,\n",
              "    0.3732593696491796,\n",
              "    0.9041960831240636,\n",
              "    0.9993730071722029,\n",
              "    0.9405975793419156,\n",
              "    0.9985784760237352,\n",
              "    0.40307192057210356,\n",
              "    0.9721538093192033,\n",
              "    0.687712215487259],\n",
              "   'generated_text': ' Preparatory schools prepare British children to attend independent schools.',\n",
              "   'generated_tokens': [' Prepar',\n",
              "    'atory',\n",
              "    ' schools',\n",
              "    ' prepare',\n",
              "    ' British',\n",
              "    ' children',\n",
              "    ' to',\n",
              "    ' attend',\n",
              "    ' independent',\n",
              "    ' schools',\n",
              "    '.'],\n",
              "   'id': '572756265951b619008f886e',\n",
              "   'prediction': ' Preparatory schools prepare British children to attend independent schools.',\n",
              "   'prompt': 'Title: Preparatory school (United Kingdom)\\n\\nBackground: is less clear. There are 130,000 pupils in over 500 prep schools of all types and sizes. Prep schools may be for boys or girls only, or may be co-educational. They may be day schools, boarding schools, weekly boarding, flexi-boarding, or a combination. They fall into the following general categories: The Independent Association of Preparatory Schools (IAPS) is a prep schools heads association; one of seven affiliated associations of the Independent Schools Council. Originally developed in England and Wales in the early 19th century as boarding schools to prepare boys for leading public schools, such as Eton and Winchester, the\\n\\nQ: What schools do preparatory schools prepare British children to attend?\\n\\nA:',\n",
              "   'question': 'What schools do preparatory schools prepare British children to attend?'},\n",
              "  {'answers': ['1521', '1521', '1521'],\n",
              "   'em': 0,\n",
              "   'f1': 0.25,\n",
              "   'generated_answer': ' Luther started preaching prophetic faith in 1521.',\n",
              "   'generated_answer_probs': [0.7217674091368722,\n",
              "    0.5366468155576513,\n",
              "    0.9991388793174012,\n",
              "    0.6294266961591883,\n",
              "    0.9988844282133696,\n",
              "    0.6195786306367789,\n",
              "    0.9576015750027619,\n",
              "    0.9734248138229515,\n",
              "    0.9025105672313932],\n",
              "   'generated_answer_tokens': [' Luther',\n",
              "    ' started',\n",
              "    ' preaching',\n",
              "    ' prophetic',\n",
              "    ' faith',\n",
              "    ' in',\n",
              "    ' 15',\n",
              "    '21',\n",
              "    '.'],\n",
              "   'generated_probs': [0.7217674091368722,\n",
              "    0.5366468155576513,\n",
              "    0.9991388793174012,\n",
              "    0.6294266961591883,\n",
              "    0.9988844282133696,\n",
              "    0.6195786306367789,\n",
              "    0.9576015750027619,\n",
              "    0.9734248138229515,\n",
              "    0.9025105672313932],\n",
              "   'generated_text': ' Luther started preaching prophetic faith in 1521.',\n",
              "   'generated_tokens': [' Luther',\n",
              "    ' started',\n",
              "    ' preaching',\n",
              "    ' prophetic',\n",
              "    ' faith',\n",
              "    ' in',\n",
              "    ' 15',\n",
              "    '21',\n",
              "    '.'],\n",
              "   'id': '56f845dba6d7ea1400e1751a',\n",
              "   'prediction': ' Luther started preaching prophetic faith in 1521.',\n",
              "   'prompt': 'Title: Martin Luther\\n\\nBackground: In 1521 Luther dealt largely with prophecy, in which he broadened the foundations of the Reformation placing them on prophetic faith. His main interest was centered on the prophecy of the Little Horn in Daniel 8:9–12, 23–25. The antichrist of 2 Thessalonians 2 was identified as the power of the Papacy. So too was the Little Horn of Daniel 7, coming up among the divisions of Rome, explicitly applied. Luther made his pronouncements from Wartburg in the context of rapid developments at Wittenberg, of which he was kept fully informed. Andreas Karlstadt, supported by the ex-Augustinian Gabriel Zwilling, embarked on\\n\\nQ: When did Luther start preaching Prophetic faith?\\n\\nA:',\n",
              "   'question': 'When did Luther start preaching Prophetic faith?'},\n",
              "  {'answers': ['since at least the mid-14th century',\n",
              "    'mid-14th century',\n",
              "    'at least the mid-14th century'],\n",
              "   'em': 0,\n",
              "   'f1': 0.35294117647058826,\n",
              "   'generated_answer': ' The imagery of the mermaid has been used by Warsaw since at least the mid',\n",
              "   'generated_answer_probs': [0.7780727890421432,\n",
              "    0.8936911297093852,\n",
              "    0.9994472153417675,\n",
              "    0.9971152913909745,\n",
              "    0.9834481759834397,\n",
              "    0.9999995722265915,\n",
              "    0.9955461273400273,\n",
              "    0.9997932189521486,\n",
              "    0.9331349944649003,\n",
              "    0.9937749066818774,\n",
              "    0.9997070910861945,\n",
              "    0.7016588933192502,\n",
              "    0.9310996192617915,\n",
              "    0.9999882465250727,\n",
              "    0.9999852635375828,\n",
              "    0.9866867951996925],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' imagery',\n",
              "    ' of',\n",
              "    ' the',\n",
              "    ' mer',\n",
              "    'maid',\n",
              "    ' has',\n",
              "    ' been',\n",
              "    ' used',\n",
              "    ' by',\n",
              "    ' Warsaw',\n",
              "    ' since',\n",
              "    ' at',\n",
              "    ' least',\n",
              "    ' the',\n",
              "    ' mid'],\n",
              "   'generated_probs': [0.7780727890421432,\n",
              "    0.8936911297093852,\n",
              "    0.9994472153417675,\n",
              "    0.9971152913909745,\n",
              "    0.9834481759834397,\n",
              "    0.9999995722265915,\n",
              "    0.9955461273400273,\n",
              "    0.9997932189521486,\n",
              "    0.9331349944649003,\n",
              "    0.9937749066818774,\n",
              "    0.9997070910861945,\n",
              "    0.7016588933192502,\n",
              "    0.9310996192617915,\n",
              "    0.9999882465250727,\n",
              "    0.9999852635375828,\n",
              "    0.9866867951996925],\n",
              "   'generated_text': ' The imagery of the mermaid has been used by Warsaw since at least the mid',\n",
              "   'generated_tokens': [' The',\n",
              "    ' imagery',\n",
              "    ' of',\n",
              "    ' the',\n",
              "    ' mer',\n",
              "    'maid',\n",
              "    ' has',\n",
              "    ' been',\n",
              "    ' used',\n",
              "    ' by',\n",
              "    ' Warsaw',\n",
              "    ' since',\n",
              "    ' at',\n",
              "    ' least',\n",
              "    ' the',\n",
              "    ' mid'],\n",
              "   'id': '5733a45d4776f41900660f25',\n",
              "   'prediction': ' The imagery of the mermaid has been used by Warsaw since at least the mid',\n",
              "   'prompt': 'Title: Warsaw\\n\\nBackground: Konwiktorska Street, a ten-minute walk north from the Old Town. Polonia was relegated from the country\\'s top flight in 2013 because of their disastrous financial situation. They are now playing in the second league (3th tier in Poland). The mermaid (\"syrenka\") is Warsaw\\'s symbol and can be found on statues throughout the city and on the city\\'s coat of arms. This imagery has been in use since at least the mid-14th century. The oldest existing armed seal of Warsaw is from the year 1390, consisting of a round seal bordered with the Latin inscription \"Sigilium Civitatis Varsoviensis\" (Seal of the\\n\\nQ: How long has the imagery of the mermaid been used by Warsaw?\\n\\nA:',\n",
              "   'question': 'How long has the imagery of the mermaid been used by Warsaw?'},\n",
              "  {'answers': ['three-dimensional objects',\n",
              "    'three-dimensional objects',\n",
              "    'three-dimensional objects'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': \" Newton's mechanics didn't affect the behavior of subatomic particles.\",\n",
              "   'generated_answer_probs': [0.3572349108546729,\n",
              "    0.957563669094673,\n",
              "    0.689692936504582,\n",
              "    0.4782273413682735,\n",
              "    0.9999635690436234,\n",
              "    0.5788532429180357,\n",
              "    0.673401058757459,\n",
              "    0.28793543730548876,\n",
              "    0.999279544912486,\n",
              "    0.25286048121791566,\n",
              "    0.9995282760667369,\n",
              "    0.9955825492648886,\n",
              "    0.615818673489333],\n",
              "   'generated_answer_tokens': [' Newton',\n",
              "    \"'s\",\n",
              "    ' mechanics',\n",
              "    ' didn',\n",
              "    \"'t\",\n",
              "    ' affect',\n",
              "    ' the',\n",
              "    ' behavior',\n",
              "    ' of',\n",
              "    ' sub',\n",
              "    'atomic',\n",
              "    ' particles',\n",
              "    '.'],\n",
              "   'generated_probs': [0.3572349108546729,\n",
              "    0.957563669094673,\n",
              "    0.689692936504582,\n",
              "    0.4782273413682735,\n",
              "    0.9999635690436234,\n",
              "    0.5788532429180357,\n",
              "    0.673401058757459,\n",
              "    0.28793543730548876,\n",
              "    0.999279544912486,\n",
              "    0.25286048121791566,\n",
              "    0.9995282760667369,\n",
              "    0.9955825492648886,\n",
              "    0.615818673489333],\n",
              "   'generated_text': \" Newton's mechanics didn't affect the behavior of subatomic particles.\",\n",
              "   'generated_tokens': [' Newton',\n",
              "    \"'s\",\n",
              "    ' mechanics',\n",
              "    ' didn',\n",
              "    \"'t\",\n",
              "    ' affect',\n",
              "    ' the',\n",
              "    ' behavior',\n",
              "    ' of',\n",
              "    ' sub',\n",
              "    'atomic',\n",
              "    ' particles',\n",
              "    '.'],\n",
              "   'id': '5737a0acc3c5551400e51f48',\n",
              "   'prediction': \" Newton's mechanics didn't affect the behavior of subatomic particles.\",\n",
              "   'prompt': \"Title: Mechanics\\n\\nBackground: (air resistance) is discounted. The English mathematician and physicist Isaac Newton improved this analysis by defining force and mass and relating these to acceleration. For objects traveling at speeds close to the speed of light, Newton’s laws were superseded by Albert Einstein’s theory of relativity. For atomic and subatomic particles, Newton’s laws were superseded by quantum theory. For everyday phenomena, however, Newton’s three laws of motion remain the cornerstone of dynamics, which is the study of what causes motion. In analogy to the distinction between quantum and classical mechanics, Einstein's general and special theories of relativity have expanded the scope\\n\\nQ: What didn't Newton's mechanics affext?\\n\\nA:\",\n",
              "   'question': \"What didn't Newton's mechanics affext?\"},\n",
              "  {'answers': ['Cultural imperialism',\n",
              "    'Cultural imperialism',\n",
              "    'Cultural imperialism',\n",
              "    'Cultural imperialism',\n",
              "    'Cultural imperialism'],\n",
              "   'em': 0,\n",
              "   'f1': 0.28571428571428575,\n",
              "   'generated_answer': ' It is called cultural hegemony.',\n",
              "   'generated_answer_probs': [0.3541760758849543,\n",
              "    0.9531007615639528,\n",
              "    0.9238951110163293,\n",
              "    0.8946058936293536,\n",
              "    0.9831785878384035,\n",
              "    0.9789049931024053],\n",
              "   'generated_answer_tokens': [' It',\n",
              "    ' is',\n",
              "    ' called',\n",
              "    ' cultural',\n",
              "    ' hegemony',\n",
              "    '.'],\n",
              "   'generated_probs': [0.3541760758849543,\n",
              "    0.9531007615639528,\n",
              "    0.9238951110163293,\n",
              "    0.8946058936293536,\n",
              "    0.9831785878384035,\n",
              "    0.9789049931024053],\n",
              "   'generated_text': ' It is called cultural hegemony.',\n",
              "   'generated_tokens': [' It',\n",
              "    ' is',\n",
              "    ' called',\n",
              "    ' cultural',\n",
              "    ' hegemony',\n",
              "    '.'],\n",
              "   'id': '573093598ab72b1400f9c5ae',\n",
              "   'prediction': ' It is called cultural hegemony.',\n",
              "   'prompt': 'Title: Hegemony\\n\\nBackground: then leads to a definition of imperialism (direct foreign rule). In the early 20th century, in the field of international relations, the Italian Marxist philosopher Antonio Gramsci developed the theory of cultural domination (an analysis of economic class) to include social class; hence, the philosophic and sociologic theory of cultural hegemony analysed the social norms that established the social structures (social and economic classes) with which the ruling class establish and exert cultural dominance to impose their \"Weltanschauung\" (world view)—justifying the social, political, and economic \"status quo\"—as natural, inevitable, and beneficial to every social class, rather than as artificial social\\n\\nQ: When imperialism impacts social norms of a state, what is it called?\\n\\nA:',\n",
              "   'question': 'When imperialism impacts social norms of a state, what is it called?'},\n",
              "  {'answers': ['pharynx', 'pharynx', 'pharynx'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' The throat is called the anterior part of the neck.',\n",
              "   'generated_answer_probs': [0.8041121093772619,\n",
              "    0.9280434000446487,\n",
              "    0.9913500945723811,\n",
              "    0.7782757368887742,\n",
              "    0.9930282409610851,\n",
              "    0.5497488177898809,\n",
              "    0.998427139044354,\n",
              "    0.9998758328593775,\n",
              "    0.999264945415079,\n",
              "    0.9992589856268569,\n",
              "    0.8456719758217649],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' throat',\n",
              "    ' is',\n",
              "    ' called',\n",
              "    ' the',\n",
              "    ' anterior',\n",
              "    ' part',\n",
              "    ' of',\n",
              "    ' the',\n",
              "    ' neck',\n",
              "    '.'],\n",
              "   'generated_probs': [0.8041121093772619,\n",
              "    0.9280434000446487,\n",
              "    0.9913500945723811,\n",
              "    0.7782757368887742,\n",
              "    0.9930282409610851,\n",
              "    0.5497488177898809,\n",
              "    0.998427139044354,\n",
              "    0.9998758328593775,\n",
              "    0.999264945415079,\n",
              "    0.9992589856268569,\n",
              "    0.8456719758217649],\n",
              "   'generated_text': ' The throat is called the anterior part of the neck.',\n",
              "   'generated_tokens': [' The',\n",
              "    ' throat',\n",
              "    ' is',\n",
              "    ' called',\n",
              "    ' the',\n",
              "    ' anterior',\n",
              "    ' part',\n",
              "    ' of',\n",
              "    ' the',\n",
              "    ' neck',\n",
              "    '.'],\n",
              "   'id': '57264b1ddd62a815002e80a2',\n",
              "   'prediction': ' The throat is called the anterior part of the neck.',\n",
              "   'prompt': 'Title: Throat\\n\\nBackground: Throat In vertebrate anatomy, the throat () is the anterior part of the neck, positioned in front of the vertebra. It contains the pharynx and larynx. An important section of it is the epiglottis, which is a flap separating the esophagus from the trachea (windpipe) preventing food and drink being inhaled into the lungs. The throat contains various blood vessels, pharyngeal muscles, the nasopharyngeal tonsil, the tonsils, the palatine uvula, the trachea, the esophagus, and the vocal cords. Mammal throats consist of two bones, the hyoid bone and the clavicle. The \"throat\" is sometimes thought to be synonymous for the\\n\\nQ: What is the throat called?\\n\\nA:',\n",
              "   'question': 'What is the throat called?'},\n",
              "  {'answers': ['articles 1 to 7', 'articles 1 to 7', 'articles 1 to 7'],\n",
              "   'em': 0,\n",
              "   'f1': 0.75,\n",
              "   'generated_answer': ' Articles 1 to 4.',\n",
              "   'generated_answer_probs': [0.9540646428772896,\n",
              "    0.9999334089132849,\n",
              "    0.8002643087036851,\n",
              "    0.974618211129326,\n",
              "    0.6251822448439672],\n",
              "   'generated_answer_tokens': [' Articles', ' 1', ' to', ' 4', '.'],\n",
              "   'generated_probs': [0.9540646428772896,\n",
              "    0.9999334089132849,\n",
              "    0.8002643087036851,\n",
              "    0.974618211129326,\n",
              "    0.6251822448439672],\n",
              "   'generated_text': ' Articles 1 to 4.',\n",
              "   'generated_tokens': [' Articles', ' 1', ' to', ' 4', '.'],\n",
              "   'id': '5726bc1add62a815002e8ea6',\n",
              "   'prediction': ' Articles 1 to 4.',\n",
              "   'prompt': 'Title: European Union law\\n\\nBackground: claim social security. In practice, free movement has become politically contentious as nationalist political parties have manipulated fears about immigrants taking away people\\'s jobs and benefits (paradoxically at the same time). Nevertheless, practically \"all available research finds little impact\" of \"labour mobility on wages and employment of local workers\". The Free Movement of Workers Regulation articles 1 to 7 set out the main provisions on equal treatment of workers. First, articles 1 to 4 generally require that workers can take up employment, conclude contracts, and not suffer discrimination compared to nationals of the member state. In a famous case, the\\n\\nQ: Which articles of the Free Movement of Workers Regulation set out the primary provisions on equal treatment of workers?\\n\\nA:',\n",
              "   'question': 'Which articles of the Free Movement of Workers Regulation set out the primary provisions on equal treatment of workers?'},\n",
              "  {'answers': ['Gottfried Fritschel', 'Gottfried Fritschel', 'Fritschel'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' The passage under dispute refers to a living man.',\n",
              "   'generated_answer_probs': [0.41937945011917566,\n",
              "    0.7879608524423658,\n",
              "    0.8663230179713319,\n",
              "    0.9941125692452909,\n",
              "    0.2744296596138067,\n",
              "    0.9994038829883884,\n",
              "    0.6728171231954772,\n",
              "    0.9177310088334127,\n",
              "    0.9897870232768811,\n",
              "    0.9197344609524902],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' passage',\n",
              "    ' under',\n",
              "    ' dispute',\n",
              "    ' refers',\n",
              "    ' to',\n",
              "    ' a',\n",
              "    ' living',\n",
              "    ' man',\n",
              "    '.'],\n",
              "   'generated_probs': [0.41937945011917566,\n",
              "    0.7879608524423658,\n",
              "    0.8663230179713319,\n",
              "    0.9941125692452909,\n",
              "    0.2744296596138067,\n",
              "    0.9994038829883884,\n",
              "    0.6728171231954772,\n",
              "    0.9177310088334127,\n",
              "    0.9897870232768811,\n",
              "    0.9197344609524902],\n",
              "   'generated_text': ' The passage under dispute refers to a living man.',\n",
              "   'generated_tokens': [' The',\n",
              "    ' passage',\n",
              "    ' under',\n",
              "    ' dispute',\n",
              "    ' refers',\n",
              "    ' to',\n",
              "    ' a',\n",
              "    ' living',\n",
              "    ' man',\n",
              "    '.'],\n",
              "   'id': '56f88690a6d7ea1400e17726',\n",
              "   'prediction': ' The passage under dispute refers to a living man.',\n",
              "   'prompt': \"Title: Humanism\\n\\nBackground: philosophy. Nasadiya Sukta, a passage in the Rig Veda, contains one of the first recorded assertion of agnosticism. In the 6th-century BCE, Gautama Buddha expressed, in Pali literature, a skeptical attitude toward the supernatural: Since neither soul, nor aught belonging to soul, can really and truly exist, the view which holds that this I who am 'world', who am 'soul', shall hereafter live permanent, persisting, unchanging, yea abide eternally: is not this utterly and entirely a foolish doctrine? Another instance of ancient humanism as an organised system of thought is found in the Gathas of Zarathustra, composed between 1,000BCE600BCE in\\n\\nQ: Who pointed out that the passage under dispute actually refers to a living man?\\n\\nA:\",\n",
              "   'question': 'Who pointed out that the passage under dispute actually refers to a living man?'},\n",
              "  {'answers': ['4', 'four', 'four'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' Eight teams have played in the Super Bowl eight times.',\n",
              "   'generated_answer_probs': [0.5568117318783957,\n",
              "    0.8245455441499068,\n",
              "    0.6093898916190009,\n",
              "    0.9309002409725192,\n",
              "    0.9998051411674489,\n",
              "    0.9756376809756114,\n",
              "    0.9996245380434885,\n",
              "    0.9999431834281226,\n",
              "    0.9710666892988192,\n",
              "    0.9998294581239193,\n",
              "    0.8402093096749845],\n",
              "   'generated_answer_tokens': [' Eight',\n",
              "    ' teams',\n",
              "    ' have',\n",
              "    ' played',\n",
              "    ' in',\n",
              "    ' the',\n",
              "    ' Super',\n",
              "    ' Bowl',\n",
              "    ' eight',\n",
              "    ' times',\n",
              "    '.'],\n",
              "   'generated_probs': [0.5568117318783957,\n",
              "    0.8245455441499068,\n",
              "    0.6093898916190009,\n",
              "    0.9309002409725192,\n",
              "    0.9998051411674489,\n",
              "    0.9756376809756114,\n",
              "    0.9996245380434885,\n",
              "    0.9999431834281226,\n",
              "    0.9710666892988192,\n",
              "    0.9998294581239193,\n",
              "    0.8402093096749845],\n",
              "   'generated_text': ' Eight teams have played in the Super Bowl eight times.',\n",
              "   'generated_tokens': [' Eight',\n",
              "    ' teams',\n",
              "    ' have',\n",
              "    ' played',\n",
              "    ' in',\n",
              "    ' the',\n",
              "    ' Super',\n",
              "    ' Bowl',\n",
              "    ' eight',\n",
              "    ' times',\n",
              "    '.'],\n",
              "   'id': '56bf159b3aeaaa14008c950a',\n",
              "   'prediction': ' Eight teams have played in the Super Bowl eight times.',\n",
              "   'prompt': \"Title: Super Bowl\\n\\nBackground: have four Super Bowl championships. Thirteen other NFL franchises have won at least one Super Bowl. Nine teams have appeared in Super Bowl games without a win. The Minnesota Vikings were the first team to have appeared a record four times without a win. The Buffalo Bills played in a record four Super Bowls in a row, and lost every one. Four teams (the Cleveland Browns, Detroit Lions, Jacksonville Jaguars, and Houston Texans) have never appeared in a Super Bowl. The Browns and Lions both won NFL Championships prior to the Super Bowl's creation, while the Jaguars (1995) and Texans\\n\\nQ: How many teams have played in the Super Bowl eight times?\\n\\nA:\",\n",
              "   'question': 'How many teams have played in the Super Bowl eight times?'},\n",
              "  {'answers': ['epithelium', 'epithelium', 'epithelium'],\n",
              "   'em': 0,\n",
              "   'f1': 0.25,\n",
              "   'generated_answer': ' The inside of a ctenophore is lined with an epithelium,',\n",
              "   'generated_answer_probs': [0.7902445377211135,\n",
              "    0.9686438098127297,\n",
              "    0.9992870562252714,\n",
              "    0.9973076984619874,\n",
              "    0.9999809720970328,\n",
              "    0.9999995722265915,\n",
              "    0.9999953989891847,\n",
              "    0.9999660723375562,\n",
              "    0.9986072042415731,\n",
              "    0.9985449168615251,\n",
              "    0.9999663107444957,\n",
              "    0.9837721270002951,\n",
              "    0.9995306610240112,\n",
              "    0.9974465762464996,\n",
              "    0.9999932532447594,\n",
              "    0.9574702010791287],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' inside',\n",
              "    ' of',\n",
              "    ' a',\n",
              "    ' c',\n",
              "    'ten',\n",
              "    'oph',\n",
              "    'ore',\n",
              "    ' is',\n",
              "    ' lined',\n",
              "    ' with',\n",
              "    ' an',\n",
              "    ' epit',\n",
              "    'hel',\n",
              "    'ium',\n",
              "    ','],\n",
              "   'generated_probs': [0.7902445377211135,\n",
              "    0.9686438098127297,\n",
              "    0.9992870562252714,\n",
              "    0.9973076984619874,\n",
              "    0.9999809720970328,\n",
              "    0.9999995722265915,\n",
              "    0.9999953989891847,\n",
              "    0.9999660723375562,\n",
              "    0.9986072042415731,\n",
              "    0.9985449168615251,\n",
              "    0.9999663107444957,\n",
              "    0.9837721270002951,\n",
              "    0.9995306610240112,\n",
              "    0.9974465762464996,\n",
              "    0.9999932532447594,\n",
              "    0.9574702010791287],\n",
              "   'generated_text': ' The inside of a ctenophore is lined with an epithelium,',\n",
              "   'generated_tokens': [' The',\n",
              "    ' inside',\n",
              "    ' of',\n",
              "    ' a',\n",
              "    ' c',\n",
              "    'ten',\n",
              "    'oph',\n",
              "    'ore',\n",
              "    ' is',\n",
              "    ' lined',\n",
              "    ' with',\n",
              "    ' an',\n",
              "    ' epit',\n",
              "    'hel',\n",
              "    'ium',\n",
              "    ','],\n",
              "   'id': '57264b1ddd62a815002e80a0',\n",
              "   'prediction': ' The inside of a ctenophore is lined with an epithelium,',\n",
              "   'prompt': 'Title: Ctenophora\\n\\nBackground: can usually be closed by muscles; a pharynx (\"throat\"); a wider area in the center that acts as a stomach; and a system of internal canals. These branch through the mesoglea to the most active parts of the animal: the mouth and pharynx; the roots of the tentacles, if present; all along the underside of each comb row; and four branches round the sensory complex at the far end from the mouth – two of these four branches terminate in anal pores. The inner surface of the cavity is lined with an epithelium, the gastrodermis. The mouth and pharynx have\\n\\nQ: The inside of a ctenophore is lined with what?\\n\\nA:',\n",
              "   'question': 'The inside of a ctenophore is lined with what?'},\n",
              "  {'answers': ['6.7', '6.7+', '6.7+'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' Southern California is divided culturally, politically, and economically into distinct regions, each containing',\n",
              "   'generated_answer_probs': [0.4448344893702234,\n",
              "    0.9992810953758452,\n",
              "    0.8525241003660116,\n",
              "    0.8801205431840012,\n",
              "    0.9986992340303988,\n",
              "    0.999998499344226,\n",
              "    0.9995378130113279,\n",
              "    0.999995041369894,\n",
              "    0.9999993338092819,\n",
              "    0.999421345784964,\n",
              "    0.99999813984753,\n",
              "    0.9998898959618946,\n",
              "    0.9999098055637627,\n",
              "    0.9999889608319321,\n",
              "    0.9999940877054777,\n",
              "    0.9999212505149035],\n",
              "   'generated_answer_tokens': [' Southern',\n",
              "    ' California',\n",
              "    ' is',\n",
              "    ' divided',\n",
              "    ' culturally',\n",
              "    ',',\n",
              "    ' politically',\n",
              "    ',',\n",
              "    ' and',\n",
              "    ' economically',\n",
              "    ' into',\n",
              "    ' distinct',\n",
              "    ' regions',\n",
              "    ',',\n",
              "    ' each',\n",
              "    ' containing'],\n",
              "   'generated_probs': [0.4448344893702234,\n",
              "    0.9992810953758452,\n",
              "    0.8525241003660116,\n",
              "    0.8801205431840012,\n",
              "    0.9986992340303988,\n",
              "    0.999998499344226,\n",
              "    0.9995378130113279,\n",
              "    0.999995041369894,\n",
              "    0.9999993338092819,\n",
              "    0.999421345784964,\n",
              "    0.99999813984753,\n",
              "    0.9998898959618946,\n",
              "    0.9999098055637627,\n",
              "    0.9999889608319321,\n",
              "    0.9999940877054777,\n",
              "    0.9999212505149035],\n",
              "   'generated_text': ' Southern California is divided culturally, politically, and economically into distinct regions, each containing',\n",
              "   'generated_tokens': [' Southern',\n",
              "    ' California',\n",
              "    ' is',\n",
              "    ' divided',\n",
              "    ' culturally',\n",
              "    ',',\n",
              "    ' politically',\n",
              "    ',',\n",
              "    ' and',\n",
              "    ' economically',\n",
              "    ' into',\n",
              "    ' distinct',\n",
              "    ' regions',\n",
              "    ',',\n",
              "    ' each',\n",
              "    ' containing'],\n",
              "   'id': '5705ffde52bb891400689785',\n",
              "   'prediction': ' Southern California is divided culturally, politically, and economically into distinct regions, each containing',\n",
              "   'prompt': 'Title: Southern California\\n\\nBackground: the most property damage of any earthquake in U.S. history at an estimated $20 billion. Many faults are able to produce a magnitude greater than 6.7 earthquake, such as the San Andreas Fault, which can produce a magnitude 8.0 event. Other faults include the San Jacinto Fault, the Puente Hills Fault, and the Elsinore Fault Zone. The United States Geological Survey (USGS) has released a California earthquake forecast, which models earthquake occurrence in California. Southern California is divided culturally, politically, and economically into distinct regions, each containing its own culture and atmosphere, anchored usually by a city with both national\\n\\nQ: What magnitude of earthquake can many faults produce?\\n\\nA:',\n",
              "   'question': 'What magnitude of earthquake can many faults produce?'},\n",
              "  {'answers': ['$100,000', '$100,000', '$100,000'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' Astor provided Tesla with $6,000.',\n",
              "   'generated_answer_probs': [0.5261027200731238,\n",
              "    0.9999765642766208,\n",
              "    0.9790035248484881,\n",
              "    0.9923260410343672,\n",
              "    0.9986984006162358,\n",
              "    0.9804695553061605,\n",
              "    0.9995847812571718,\n",
              "    0.9999886013379652,\n",
              "    0.999990273057307,\n",
              "    0.7823392570266855],\n",
              "   'generated_answer_tokens': [' Ast',\n",
              "    'or',\n",
              "    ' provided',\n",
              "    ' Tesla',\n",
              "    ' with',\n",
              "    ' $',\n",
              "    '6',\n",
              "    ',',\n",
              "    '000',\n",
              "    '.'],\n",
              "   'generated_probs': [0.5261027200731238,\n",
              "    0.9999765642766208,\n",
              "    0.9790035248484881,\n",
              "    0.9923260410343672,\n",
              "    0.9986984006162358,\n",
              "    0.9804695553061605,\n",
              "    0.9995847812571718,\n",
              "    0.9999886013379652,\n",
              "    0.999990273057307,\n",
              "    0.7823392570266855],\n",
              "   'generated_text': ' Astor provided Tesla with $6,000.',\n",
              "   'generated_tokens': [' Ast',\n",
              "    'or',\n",
              "    ' provided',\n",
              "    ' Tesla',\n",
              "    ' with',\n",
              "    ' $',\n",
              "    '6',\n",
              "    ',',\n",
              "    '000',\n",
              "    '.'],\n",
              "   'id': '56e100b6cd28a01900c67403',\n",
              "   'prediction': ' Astor provided Tesla with $6,000.',\n",
              "   'prompt': 'Title: Wardenclyffe Tower\\n\\nBackground: for similar equipment. Tesla asked Westinghouse to “…meet me on some fair terms in furnishing me the machinery, retaining the ownership of the same and interesting yourself to a certain extent”. While Westinghouse declined to buy into the project, he did agree to lend Tesla $6,000\". Westinghouse suggested Tesla pursue some of the rich venture capitalists. Tesla talked to John Jacob Astor, Thomas Fortune Ryan, and even sent a cabochon sapphire ring as a gift to Henry O. Havemeyer. No investment was forthcoming from Havemeyer and Ryan but Astor did buy 500 shares in Tesla\\'s company. Tesla gained the attention\\n\\nQ: How much money did John Jacob Astor IV provide Tesla with?\\n\\nA:',\n",
              "   'question': 'How much money did John Jacob Astor IV provide Tesla with?'},\n",
              "  {'answers': ['John Madejski Garden',\n",
              "    'the John Madejski Garden',\n",
              "    'John Madejski Garden'],\n",
              "   'em': 1,\n",
              "   'f1': 1.0,\n",
              "   'generated_answer': ' The John Madejski Garden.',\n",
              "   'generated_answer_probs': [0.9109236356396959,\n",
              "    0.9547049109685704,\n",
              "    0.9996203673287254,\n",
              "    0.99995140840061,\n",
              "    0.9999669067745929,\n",
              "    0.9983677718356774,\n",
              "    0.8321408846367196],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' John',\n",
              "    ' Made',\n",
              "    'js',\n",
              "    'ki',\n",
              "    ' Garden',\n",
              "    '.'],\n",
              "   'generated_probs': [0.9109236356396959,\n",
              "    0.9547049109685704,\n",
              "    0.9996203673287254,\n",
              "    0.99995140840061,\n",
              "    0.9999669067745929,\n",
              "    0.9983677718356774,\n",
              "    0.8321408846367196],\n",
              "   'generated_text': ' The John Madejski Garden.',\n",
              "   'generated_tokens': [' The', ' John', ' Made', 'js', 'ki', ' Garden', '.'],\n",
              "   'id': '5726b12f5951b619008f7ab0',\n",
              "   'prediction': ' The John Madejski Garden.',\n",
              "   'prompt': 'Title: Victoria and Albert Museum\\n\\nBackground: gallery beneath a new entrance courtyard on Exhibition Road. Planning for the scheme was granted in 2012. The central garden was redesigned by Kim Wilkie and opened as the John Madejski Garden, on 5 July 2005. The design is a subtle blend of the traditional and modern, the layout is formal; there is an elliptical water feature lined in stone with steps around the edge which may be drained to use the area for receptions, gatherings or exhibition purposes. This is in front of the bronze doors leading to the refreshment rooms, a central path flanked by lawns leads to\\n\\nQ: The redesigned central garden opened in 2005 with what new moniker?\\n\\nA:',\n",
              "   'question': 'The redesigned central garden opened in 2005 with what new moniker?'},\n",
              "  {'answers': ['Justin Tucker', 'Justin Tucker', 'Tucker'],\n",
              "   'em': 1,\n",
              "   'f1': 1.0,\n",
              "   'generated_answer': ' Justin Tucker',\n",
              "   'generated_answer_probs': [0.753762912557186, 0.9999943242451071],\n",
              "   'generated_answer_tokens': [' Justin', ' Tucker'],\n",
              "   'generated_probs': [0.753762912557186, 0.9999943242451071],\n",
              "   'generated_text': ' Justin Tucker',\n",
              "   'generated_tokens': [' Justin', ' Tucker'],\n",
              "   'id': '56d70adc0d65d21400198311',\n",
              "   'prediction': ' Justin Tucker',\n",
              "   'prompt': 'Title: Super Bowl 50\\n\\nBackground: the field had to be re-sodded multiple times due to various issues, and earlier in the 2015 season, a portion of the turf collapsed under Baltimore Ravens kicker Justin Tucker, causing him to slip and miss a field goal, although the field has not had any major issues since. As is customary for Super Bowl games played at natural grass stadiums, the NFL re-sodded the hybrid Bermuda 419 turf playing surface prior to the game; NFL and Atlanta Braves field director Ed Mangan stated that the field was in \"great shape\" for the game. However, the turf showed problems throughout\\n\\nQ: Which kicker had a portion of the turf collapse, causing him to miss a field goal?\\n\\nA:',\n",
              "   'question': 'Which kicker had a portion of the turf collapse, causing him to miss a field goal?'},\n",
              "  {'answers': [\"salvation by God's grace\",\n",
              "    'plain, old, Bible Christianity\"',\n",
              "    \"salvation by God's grace\"],\n",
              "   'em': 0,\n",
              "   'f1': 0.5,\n",
              "   'generated_answer': ' Salvation by grace through faith in Jesus Christ.',\n",
              "   'generated_answer_probs': [0.4163690260893412,\n",
              "    0.9677179259329943,\n",
              "    0.8235109768047748,\n",
              "    0.9888846056229779,\n",
              "    0.9980549647374645,\n",
              "    0.9997550141539345,\n",
              "    0.9601299625756673,\n",
              "    0.9977645119335834,\n",
              "    0.9353558723208533],\n",
              "   'generated_answer_tokens': [' Salvation',\n",
              "    ' by',\n",
              "    ' grace',\n",
              "    ' through',\n",
              "    ' faith',\n",
              "    ' in',\n",
              "    ' Jesus',\n",
              "    ' Christ',\n",
              "    '.'],\n",
              "   'generated_probs': [0.4163690260893412,\n",
              "    0.9677179259329943,\n",
              "    0.8235109768047748,\n",
              "    0.9888846056229779,\n",
              "    0.9980549647374645,\n",
              "    0.9997550141539345,\n",
              "    0.9601299625756673,\n",
              "    0.9977645119335834,\n",
              "    0.9353558723208533],\n",
              "   'generated_text': ' Salvation by grace through faith in Jesus Christ.',\n",
              "   'generated_tokens': [' Salvation',\n",
              "    ' by',\n",
              "    ' grace',\n",
              "    ' through',\n",
              "    ' faith',\n",
              "    ' in',\n",
              "    ' Jesus',\n",
              "    ' Christ',\n",
              "    '.'],\n",
              "   'id': '573099f42461fd1900a9cefa',\n",
              "   'prediction': ' Salvation by grace through faith in Jesus Christ.',\n",
              "   'prompt': 'Title: United Methodist Church\\n\\nBackground: grace for salvation. For the first time in his life, he felt complete peace and the assurance of salvation. In less than two years, the \"Holy Club\" disbanded. John Wesley met with a group of clergy. He said \"they appeared to be of one heart, as well as of one judgment, resolved to be Bible-Christians at all events; and, wherever they were, to preach with all their might plain, old, Bible Christianity\". The ministers retained their membership in the Church of England. Though not always emphasized or appreciated in the Anglican churches of their day, their teaching emphasized salvation by\\n\\nQ: What did \"The Holy Club\\'s\" teachings emphasize?\\n\\nA:',\n",
              "   'question': 'What did \"The Holy Club\\'s\" teachings emphasize?'},\n",
              "  {'answers': ['public-key cryptography',\n",
              "    'public-key cryptography',\n",
              "    'public-key cryptography',\n",
              "    'cryptography',\n",
              "    'public-key cryptography'],\n",
              "   'em': 0,\n",
              "   'f1': 0.2857142857142857,\n",
              "   'generated_answer': ' In information technology, prime numbers are used in public-key cryptography. This is',\n",
              "   'generated_answer_probs': [0.2095865077560643,\n",
              "    0.7373222476159181,\n",
              "    0.9993025536788313,\n",
              "    0.997031726660232,\n",
              "    0.9607202263742008,\n",
              "    0.9989912399408579,\n",
              "    0.9834191489554603,\n",
              "    0.9812776774154965,\n",
              "    0.8647124803187853,\n",
              "    0.6403258446030331,\n",
              "    0.9767591258637469,\n",
              "    0.9998977647723771,\n",
              "    0.9989356891809495,\n",
              "    0.5105176132570103,\n",
              "    0.8252417295912928,\n",
              "    0.5426870556266403],\n",
              "   'generated_answer_tokens': [' In',\n",
              "    ' information',\n",
              "    ' technology',\n",
              "    ',',\n",
              "    ' prime',\n",
              "    ' numbers',\n",
              "    ' are',\n",
              "    ' used',\n",
              "    ' in',\n",
              "    ' public',\n",
              "    '-',\n",
              "    'key',\n",
              "    ' cryptography',\n",
              "    '.',\n",
              "    ' This',\n",
              "    ' is'],\n",
              "   'generated_probs': [0.2095865077560643,\n",
              "    0.7373222476159181,\n",
              "    0.9993025536788313,\n",
              "    0.997031726660232,\n",
              "    0.9607202263742008,\n",
              "    0.9989912399408579,\n",
              "    0.9834191489554603,\n",
              "    0.9812776774154965,\n",
              "    0.8647124803187853,\n",
              "    0.6403258446030331,\n",
              "    0.9767591258637469,\n",
              "    0.9998977647723771,\n",
              "    0.9989356891809495,\n",
              "    0.5105176132570103,\n",
              "    0.8252417295912928,\n",
              "    0.5426870556266403],\n",
              "   'generated_text': ' In information technology, prime numbers are used in public-key cryptography. This is',\n",
              "   'generated_tokens': [' In',\n",
              "    ' information',\n",
              "    ' technology',\n",
              "    ',',\n",
              "    ' prime',\n",
              "    ' numbers',\n",
              "    ' are',\n",
              "    ' used',\n",
              "    ' in',\n",
              "    ' public',\n",
              "    '-',\n",
              "    'key',\n",
              "    ' cryptography',\n",
              "    '.',\n",
              "    ' This',\n",
              "    ' is'],\n",
              "   'id': '5729727baf94a219006aa43a',\n",
              "   'prediction': ' In information technology, prime numbers are used in public-key cryptography. This is',\n",
              "   'prompt': 'Title: Prime number\\n\\nBackground: of primes whose difference is 2). Such questions spurred the development of various branches of number theory, focusing on analytic or algebraic aspects of numbers. Primes are used in several routines in information technology, such as public-key cryptography, which makes use of properties such as the difficulty of factoring large numbers into their prime factors. Prime numbers give rise to various generalizations in other mathematical domains, mainly algebra, such as prime elements and prime ideals. A natural number (i.e. 1, 2, 3, 4, 5, 6, etc.) is called a prime number (or a prime) if it has exactly two positive\\n\\nQ: What is the application of prime numbers used in information technology which utilizes the fact that factoring very large prime numbers is very challenging?\\n\\nA:',\n",
              "   'question': 'What is the application of prime numbers used in information technology which utilizes the fact that factoring very large prime numbers is very challenging?'},\n",
              "  {'answers': ['January 30', 'January 30', 'January 30'],\n",
              "   'em': 0,\n",
              "   'f1': 0.16666666666666669,\n",
              "   'generated_answer': ' The opening of \"Super Bowl City\" was on January 30th, 2016.',\n",
              "   'generated_answer_probs': [0.5331234170135832,\n",
              "    0.9646223088971442,\n",
              "    0.9843177986150439,\n",
              "    0.8439579819878908,\n",
              "    0.9998362518881858,\n",
              "    0.9998662955092422,\n",
              "    0.9998689168221506,\n",
              "    0.9999859797182851,\n",
              "    0.9275272359741407,\n",
              "    0.8024129366654159,\n",
              "    0.9978131484516494,\n",
              "    0.9999235162450315,\n",
              "    0.5117895876661689,\n",
              "    0.6012789554314583,\n",
              "    0.8566206132998384,\n",
              "    0.9870391783100809],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' opening',\n",
              "    ' of',\n",
              "    ' \"',\n",
              "    'Super',\n",
              "    ' Bowl',\n",
              "    ' City',\n",
              "    '\"',\n",
              "    ' was',\n",
              "    ' on',\n",
              "    ' January',\n",
              "    ' 30',\n",
              "    'th',\n",
              "    ',',\n",
              "    ' 2016',\n",
              "    '.'],\n",
              "   'generated_probs': [0.5331234170135832,\n",
              "    0.9646223088971442,\n",
              "    0.9843177986150439,\n",
              "    0.8439579819878908,\n",
              "    0.9998362518881858,\n",
              "    0.9998662955092422,\n",
              "    0.9998689168221506,\n",
              "    0.9999859797182851,\n",
              "    0.9275272359741407,\n",
              "    0.8024129366654159,\n",
              "    0.9978131484516494,\n",
              "    0.9999235162450315,\n",
              "    0.5117895876661689,\n",
              "    0.6012789554314583,\n",
              "    0.8566206132998384,\n",
              "    0.9870391783100809],\n",
              "   'generated_text': ' The opening of \"Super Bowl City\" was on January 30th, 2016.',\n",
              "   'generated_tokens': [' The',\n",
              "    ' opening',\n",
              "    ' of',\n",
              "    ' \"',\n",
              "    'Super',\n",
              "    ' Bowl',\n",
              "    ' City',\n",
              "    '\"',\n",
              "    ' was',\n",
              "    ' on',\n",
              "    ' January',\n",
              "    ' 30',\n",
              "    'th',\n",
              "    ',',\n",
              "    ' 2016',\n",
              "    '.'],\n",
              "   'id': '56bebcbe3aeaaa14008c9329',\n",
              "   'prediction': ' The opening of \"Super Bowl City\" was on January 30th, 2016.',\n",
              "   'prompt': 'Title: Super Bowl 50\\n\\nBackground: towards the game by residents of the city, the statues notably became the target of vandals, with the \"SUPER BOWL 50\" lettering on their bases re-arranged to form other phrases such as \"SUPERB OWL\", \"SUP BRO 50\", and after the Alamo Square statue was toppled, \"OOPS\". The annual NFL Experience was held at the Moscone Center in San Francisco. In addition, \"Super Bowl City\" opened on January 30 at Justin Herman Plaza on The Embarcadero, featuring games and activities that will highlight the Bay Area\\'s technology, culinary creations, and cultural diversity. More than a million people are expected to attend\\n\\nQ: When was the opening of \"Super Bowl City\"?\\n\\nA:',\n",
              "   'question': 'When was the opening of \"Super Bowl City\"?'},\n",
              "  {'answers': ['black-and-white television',\n",
              "    'automated scientific instruments',\n",
              "    'black-and-white television',\n",
              "    'black-and-white television',\n",
              "    'black-and-white television'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' The astronauts on the moon sent back limited radio bandwidth signals that needed to be multiple',\n",
              "   'generated_answer_probs': [0.27154918385804977,\n",
              "    0.2905140032189884,\n",
              "    0.7563337514877653,\n",
              "    0.9939785166373734,\n",
              "    0.9966810688686871,\n",
              "    0.7782642807542446,\n",
              "    0.9966785655079903,\n",
              "    0.36760172349686276,\n",
              "    0.5469058565807823,\n",
              "    0.9559873578733737,\n",
              "    0.9308299736890606,\n",
              "    0.21335428183838984,\n",
              "    0.9618792249384418,\n",
              "    0.9994777923978773,\n",
              "    0.9994794613672676,\n",
              "    0.9956981200087545],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' astronauts',\n",
              "    ' on',\n",
              "    ' the',\n",
              "    ' moon',\n",
              "    ' sent',\n",
              "    ' back',\n",
              "    ' limited',\n",
              "    ' radio',\n",
              "    ' bandwidth',\n",
              "    ' signals',\n",
              "    ' that',\n",
              "    ' needed',\n",
              "    ' to',\n",
              "    ' be',\n",
              "    ' multiple'],\n",
              "   'generated_probs': [0.27154918385804977,\n",
              "    0.2905140032189884,\n",
              "    0.7563337514877653,\n",
              "    0.9939785166373734,\n",
              "    0.9966810688686871,\n",
              "    0.7782642807542446,\n",
              "    0.9966785655079903,\n",
              "    0.36760172349686276,\n",
              "    0.5469058565807823,\n",
              "    0.9559873578733737,\n",
              "    0.9308299736890606,\n",
              "    0.21335428183838984,\n",
              "    0.9618792249384418,\n",
              "    0.9994777923978773,\n",
              "    0.9994794613672676,\n",
              "    0.9956981200087545],\n",
              "   'generated_text': ' The astronauts on the moon sent back limited radio bandwidth signals that needed to be multiple',\n",
              "   'generated_tokens': [' The',\n",
              "    ' astronauts',\n",
              "    ' on',\n",
              "    ' the',\n",
              "    ' moon',\n",
              "    ' sent',\n",
              "    ' back',\n",
              "    ' limited',\n",
              "    ' radio',\n",
              "    ' bandwidth',\n",
              "    ' signals',\n",
              "    ' that',\n",
              "    ' needed',\n",
              "    ' to',\n",
              "    ' be',\n",
              "    ' multiple'],\n",
              "   'id': '5725e36f89a1e219009ac03a',\n",
              "   'prediction': ' The astronauts on the moon sent back limited radio bandwidth signals that needed to be multiple',\n",
              "   'prompt': \"Title: Apollo 11 missing tapes\\n\\nBackground: the tapes' disappearance. They also partially released newly enhanced footage obtained during the search. Lowry Digital completed the full moonwalk restoration project in late 2009. Apollo 11 was the spaceflight that landed the first two people on the Moon. Neil Armstrong became the first person to step onto the lunar surface on July 21, 1969, at 02:56 UTC; Buzz Aldrin joined him about 20 minutes later. Only limited radio bandwidth was available to transmit the video signal from the lunar landings, which needed to be multiplexed with other communication and telemetry channels beamed from the Lunar Module, back to Earth.\\n\\nQ: What did the astronauts on the moon send back to Earth live via signals?\\n\\nA:\",\n",
              "   'question': 'What did the astronauts on the moon send back to Earth live via signals?'},\n",
              "  {'answers': ['through phowa and siddhi',\n",
              "    'phowa and siddhi',\n",
              "    'phowa and siddhi'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' The Lama may have determined to be reborn because they have a strong desire to help',\n",
              "   'generated_answer_probs': [0.24552379789739368,\n",
              "    0.5356305114114737,\n",
              "    0.4513992392104951,\n",
              "    0.9174180333430492,\n",
              "    0.3821070400774938,\n",
              "    0.9764056762820968,\n",
              "    0.9759600771159245,\n",
              "    0.9998014455045535,\n",
              "    0.24647968566270964,\n",
              "    0.7286083384431452,\n",
              "    0.3887307750341141,\n",
              "    0.49324850253444324,\n",
              "    0.39094950912802867,\n",
              "    0.41241027995666346,\n",
              "    0.9920397152146742,\n",
              "    0.9725911289679668],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' Lama',\n",
              "    ' may',\n",
              "    ' have',\n",
              "    ' determined',\n",
              "    ' to',\n",
              "    ' be',\n",
              "    ' reborn',\n",
              "    ' because',\n",
              "    ' they',\n",
              "    ' have',\n",
              "    ' a',\n",
              "    ' strong',\n",
              "    ' desire',\n",
              "    ' to',\n",
              "    ' help'],\n",
              "   'generated_probs': [0.24552379789739368,\n",
              "    0.5356305114114737,\n",
              "    0.4513992392104951,\n",
              "    0.9174180333430492,\n",
              "    0.3821070400774938,\n",
              "    0.9764056762820968,\n",
              "    0.9759600771159245,\n",
              "    0.9998014455045535,\n",
              "    0.24647968566270964,\n",
              "    0.7286083384431452,\n",
              "    0.3887307750341141,\n",
              "    0.49324850253444324,\n",
              "    0.39094950912802867,\n",
              "    0.41241027995666346,\n",
              "    0.9920397152146742,\n",
              "    0.9725911289679668],\n",
              "   'generated_text': ' The Lama may have determined to be reborn because they have a strong desire to help',\n",
              "   'generated_tokens': [' The',\n",
              "    ' Lama',\n",
              "    ' may',\n",
              "    ' have',\n",
              "    ' determined',\n",
              "    ' to',\n",
              "    ' be',\n",
              "    ' reborn',\n",
              "    ' because',\n",
              "    ' they',\n",
              "    ' have',\n",
              "    ' a',\n",
              "    ' strong',\n",
              "    ' desire',\n",
              "    ' to',\n",
              "    ' help'],\n",
              "   'id': '56e77da237bdd419002c403f',\n",
              "   'prediction': ' The Lama may have determined to be reborn because they have a strong desire to help',\n",
              "   'prompt': 'Title: Teacher\\n\\nBackground: to prophesy, to its holders. This guidance is generally offered during a ceremony called the patriarchal blessing. In Hinduism the spiritual teacher is known as a guru, and, in many traditions of Hinduism - especially those common in the West - the emphasis on spiritual mentorship is extremely high, with gurus often exercising a great deal of control over the lives of their disciples. In Tibetan Buddhism the teachers of Dharma in Tibet are most commonly called a Lama. A Lama who has through phowa and siddhi consciously determined to be reborn, often many times, in order to continue their\\n\\nQ: What helped the Lama determine to be reborn?\\n\\nA:',\n",
              "   'question': 'What helped the Lama determine to be reborn?'},\n",
              "  {'answers': ['about 300', '300', '300'],\n",
              "   'em': 0,\n",
              "   'f1': 0.1818181818181818,\n",
              "   'generated_answer': ' Warsaw is located about 200 kilometers from the Carpathian Mountains.',\n",
              "   'generated_answer_probs': [0.3059717504751655,\n",
              "    0.9983349890712355,\n",
              "    0.4478992545915028,\n",
              "    0.5137075213981918,\n",
              "    0.3179352923765702,\n",
              "    0.9978788341586182,\n",
              "    0.9234017774629109,\n",
              "    0.9997041107838511,\n",
              "    0.9987277866504295,\n",
              "    0.9999471161663992,\n",
              "    0.9935218274251021,\n",
              "    0.9858748602660132,\n",
              "    0.9895444304771294],\n",
              "   'generated_answer_tokens': [' Warsaw',\n",
              "    ' is',\n",
              "    ' located',\n",
              "    ' about',\n",
              "    ' 200',\n",
              "    ' kilometers',\n",
              "    ' from',\n",
              "    ' the',\n",
              "    ' Car',\n",
              "    'path',\n",
              "    'ian',\n",
              "    ' Mountains',\n",
              "    '.'],\n",
              "   'generated_probs': [0.3059717504751655,\n",
              "    0.9983349890712355,\n",
              "    0.4478992545915028,\n",
              "    0.5137075213981918,\n",
              "    0.3179352923765702,\n",
              "    0.9978788341586182,\n",
              "    0.9234017774629109,\n",
              "    0.9997041107838511,\n",
              "    0.9987277866504295,\n",
              "    0.9999471161663992,\n",
              "    0.9935218274251021,\n",
              "    0.9858748602660132,\n",
              "    0.9895444304771294],\n",
              "   'generated_text': ' Warsaw is located about 200 kilometers from the Carpathian Mountains.',\n",
              "   'generated_tokens': [' Warsaw',\n",
              "    ' is',\n",
              "    ' located',\n",
              "    ' about',\n",
              "    ' 200',\n",
              "    ' kilometers',\n",
              "    ' from',\n",
              "    ' the',\n",
              "    ' Car',\n",
              "    'path',\n",
              "    'ian',\n",
              "    ' Mountains',\n",
              "    '.'],\n",
              "   'id': '5733314e4776f4190066076a',\n",
              "   'prediction': ' Warsaw is located about 200 kilometers from the Carpathian Mountains.',\n",
              "   'prompt': \"Title: Geography of Poland\\n\\nBackground: to 200 kilometers, formed by the gently sloping foothills of the Sudeten and Carpathian mountain ranges and the uplands that connect the ranges in southcentral Poland. The topography of this region is divided transversely into higher and lower elevations, reflecting its underlying geological structure. In the western section, the Silesia-Kraków Upthrust contains rich coal deposits. The third topographic area is located on either side of Poland's southern border and is formed by the Sudeten and Carpathian ranges. Within Poland, neither of these ranges is forbidding enough to prevent substantial habitation; the Carpathians are especially densely populated. The rugged form of\\n\\nQ: How many kilometers is Warsaw from the Carpathian Mountains?\\n\\nA:\",\n",
              "   'question': 'How many kilometers is Warsaw from the Carpathian Mountains?'},\n",
              "  {'answers': ['for fear of their lives',\n",
              "    'fear of their lives',\n",
              "    'fear of their lives'],\n",
              "   'em': 0,\n",
              "   'f1': 0.10526315789473685,\n",
              "   'generated_answer': ' People may be afraid to go to work if they are afraid of being attacked.',\n",
              "   'generated_answer_probs': [0.24293584083235353,\n",
              "    0.6218691985982688,\n",
              "    0.8145385356722326,\n",
              "    0.7333599745733949,\n",
              "    0.9621088221269605,\n",
              "    0.9910025415735388,\n",
              "    0.9987722511011374,\n",
              "    0.9987537142599321,\n",
              "    0.5049963638650131,\n",
              "    0.8568733793643327,\n",
              "    0.7471815160454675,\n",
              "    0.6866450273027205,\n",
              "    0.7330907928735456,\n",
              "    0.587805657600652,\n",
              "    0.6300930828216719,\n",
              "    0.6802223016810244],\n",
              "   'generated_answer_tokens': [' People',\n",
              "    ' may',\n",
              "    ' be',\n",
              "    ' afraid',\n",
              "    ' to',\n",
              "    ' go',\n",
              "    ' to',\n",
              "    ' work',\n",
              "    ' if',\n",
              "    ' they',\n",
              "    ' are',\n",
              "    ' afraid',\n",
              "    ' of',\n",
              "    ' being',\n",
              "    ' attacked',\n",
              "    '.'],\n",
              "   'generated_probs': [0.24293584083235353,\n",
              "    0.6218691985982688,\n",
              "    0.8145385356722326,\n",
              "    0.7333599745733949,\n",
              "    0.9621088221269605,\n",
              "    0.9910025415735388,\n",
              "    0.9987722511011374,\n",
              "    0.9987537142599321,\n",
              "    0.5049963638650131,\n",
              "    0.8568733793643327,\n",
              "    0.7471815160454675,\n",
              "    0.6866450273027205,\n",
              "    0.7330907928735456,\n",
              "    0.587805657600652,\n",
              "    0.6300930828216719,\n",
              "    0.6802223016810244],\n",
              "   'generated_text': ' People may be afraid to go to work if they are afraid of being attacked.',\n",
              "   'generated_tokens': [' People',\n",
              "    ' may',\n",
              "    ' be',\n",
              "    ' afraid',\n",
              "    ' to',\n",
              "    ' go',\n",
              "    ' to',\n",
              "    ' work',\n",
              "    ' if',\n",
              "    ' they',\n",
              "    ' are',\n",
              "    ' afraid',\n",
              "    ' of',\n",
              "    ' being',\n",
              "    ' attacked',\n",
              "    '.'],\n",
              "   'id': '572a2224af94a219006aa826',\n",
              "   'prediction': ' People may be afraid to go to work if they are afraid of being attacked.',\n",
              "   'prompt': 'Title: Economic inequality\\n\\nBackground: capabilities are lowered, they are in some way deprived of earning as much income as they would otherwise. An old, ill man cannot earn as much as a healthy young man; gender roles and customs may prevent a woman from receiving an education or working outside the home. There may be an epidemic that causes widespread panic, or there could be rampant violence in the area that prevents people from going to work for fear of their lives. As a result, income and economic inequality increases, and it becomes more difficult to reduce the gap without additional aid. To prevent\\n\\nQ: Why would rampant violence prevent people from going to work?\\n\\nA:',\n",
              "   'question': 'Why would rampant violence prevent people from going to work?'},\n",
              "  {'answers': ['less civilized',\n",
              "    'less civilized',\n",
              "    'less civilized',\n",
              "    'less civilized',\n",
              "    'less civilized'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' Uncivilized.',\n",
              "   'generated_answer_probs': [0.49637494516581493,\n",
              "    0.9610635338214704,\n",
              "    0.9998187302913394,\n",
              "    0.5332203423293218],\n",
              "   'generated_answer_tokens': [' Un', 'civil', 'ized', '.'],\n",
              "   'generated_probs': [0.49637494516581493,\n",
              "    0.9610635338214704,\n",
              "    0.9998187302913394,\n",
              "    0.5332203423293218],\n",
              "   'generated_text': ' Uncivilized.',\n",
              "   'generated_tokens': [' Un', 'civil', 'ized', '.'],\n",
              "   'id': '5730a0778ab72b1400f9c60c',\n",
              "   'prediction': ' Uncivilized.',\n",
              "   'prompt': 'Title: Imperialism\\n\\nBackground: supported Britain\\'s imperial expansion; these two arguments dominated the discipline for decades. Geographical theories such as environmental determinism also suggested that tropical environments created uncivilized people in need of European guidance. For instance, American geographer Ellen Churchill Semple argued that even though human beings originated in the tropics they were only able to become fully human in the temperate zone. Tropicality can be paralleled with Edward Said\\'s Orientalism as the west\\'s construction of the east as the \"other\". According to Said, orientalism allowed Europe to establish itself as the superior and the norm, which justified its dominance over the essentialized\\n\\nQ: Humans in tropical environments were considered what?\\n\\nA:',\n",
              "   'question': 'Humans in tropical environments were considered what?'},\n",
              "  {'answers': ['reduced moist tropical vegetation cover in the basin',\n",
              "    'reduced moist tropical vegetation cover in the basin',\n",
              "    'reduced moist tropical vegetation cover'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' There is debate over how extensive this reduction was. Some scientists argue that the rain',\n",
              "   'generated_answer_probs': [0.6558668520992603,\n",
              "    0.9970832829085009,\n",
              "    0.9058594023733283,\n",
              "    0.6843239242467133,\n",
              "    0.9756195586739987,\n",
              "    0.9993179322140562,\n",
              "    0.9695821339922106,\n",
              "    0.9992557647805149,\n",
              "    0.9999486667295974,\n",
              "    0.8873091579955321,\n",
              "    0.9869368385105686,\n",
              "    0.9994591353200629,\n",
              "    0.9998100278070027,\n",
              "    0.9999824044518034,\n",
              "    0.9999709588057036,\n",
              "    0.9999671451857313],\n",
              "   'generated_answer_tokens': [' There',\n",
              "    ' is',\n",
              "    ' debate',\n",
              "    ' over',\n",
              "    ' how',\n",
              "    ' extensive',\n",
              "    ' this',\n",
              "    ' reduction',\n",
              "    ' was',\n",
              "    '.',\n",
              "    ' Some',\n",
              "    ' scientists',\n",
              "    ' argue',\n",
              "    ' that',\n",
              "    ' the',\n",
              "    ' rain'],\n",
              "   'generated_probs': [0.6558668520992603,\n",
              "    0.9970832829085009,\n",
              "    0.9058594023733283,\n",
              "    0.6843239242467133,\n",
              "    0.9756195586739987,\n",
              "    0.9993179322140562,\n",
              "    0.9695821339922106,\n",
              "    0.9992557647805149,\n",
              "    0.9999486667295974,\n",
              "    0.8873091579955321,\n",
              "    0.9869368385105686,\n",
              "    0.9994591353200629,\n",
              "    0.9998100278070027,\n",
              "    0.9999824044518034,\n",
              "    0.9999709588057036,\n",
              "    0.9999671451857313],\n",
              "   'generated_text': ' There is debate over how extensive this reduction was. Some scientists argue that the rain',\n",
              "   'generated_tokens': [' There',\n",
              "    ' is',\n",
              "    ' debate',\n",
              "    ' over',\n",
              "    ' how',\n",
              "    ' extensive',\n",
              "    ' this',\n",
              "    ' reduction',\n",
              "    ' was',\n",
              "    '.',\n",
              "    ' Some',\n",
              "    ' scientists',\n",
              "    ' argue',\n",
              "    ' that',\n",
              "    ' the',\n",
              "    ' rain'],\n",
              "   'id': '572841772ca10214002da1a9',\n",
              "   'prediction': ' There is debate over how extensive this reduction was. Some scientists argue that the rain',\n",
              "   'prompt': 'Title: Amazon rainforest\\n\\nBackground: in the basin during the LGM was lower than for the present, and this was almost certainly associated with reduced moist tropical vegetation cover in the basin. There is debate, however, over how extensive this reduction was. Some scientists argue that the rainforest was reduced to small, isolated refugia separated by open forest and grassland; other scientists argue that the rainforest remained largely intact but extended less far to the north, south, and east than is seen today. This debate has proved difficult to resolve because the practical limitations of working in the rainforest mean that data sampling is biased\\n\\nQ: What has the lower rainfall in the Amazon during the LGM been attributed to?\\n\\nA:',\n",
              "   'question': 'What has the lower rainfall in the Amazon during the LGM been attributed to?'},\n",
              "  {'answers': ['weak force', 'weak force', 'weak force', 'weak force'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' The W and Z bosons exchange create the Ws and Zs bosons',\n",
              "   'generated_answer_probs': [0.6860799725429481,\n",
              "    0.9601169077773194,\n",
              "    0.9958805119658866,\n",
              "    0.9997746226512914,\n",
              "    0.9925054502501004,\n",
              "    0.8978427880436597,\n",
              "    0.8977105949149616,\n",
              "    0.6007334221513486,\n",
              "    0.522078875512482,\n",
              "    0.7520368000446859,\n",
              "    0.723767088007931,\n",
              "    0.9972733050041865,\n",
              "    0.9995497349997242,\n",
              "    0.9998078815171197,\n",
              "    0.44109440771285524,\n",
              "    0.9954626216457316],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' W',\n",
              "    ' and',\n",
              "    ' Z',\n",
              "    ' bos',\n",
              "    'ons',\n",
              "    ' exchange',\n",
              "    ' create',\n",
              "    ' the',\n",
              "    ' W',\n",
              "    's',\n",
              "    ' and',\n",
              "    ' Z',\n",
              "    's',\n",
              "    ' bos',\n",
              "    'ons'],\n",
              "   'generated_probs': [0.6860799725429481,\n",
              "    0.9601169077773194,\n",
              "    0.9958805119658866,\n",
              "    0.9997746226512914,\n",
              "    0.9925054502501004,\n",
              "    0.8978427880436597,\n",
              "    0.8977105949149616,\n",
              "    0.6007334221513486,\n",
              "    0.522078875512482,\n",
              "    0.7520368000446859,\n",
              "    0.723767088007931,\n",
              "    0.9972733050041865,\n",
              "    0.9995497349997242,\n",
              "    0.9998078815171197,\n",
              "    0.44109440771285524,\n",
              "    0.9954626216457316],\n",
              "   'generated_text': ' The W and Z bosons exchange create the Ws and Zs bosons',\n",
              "   'generated_tokens': [' The',\n",
              "    ' W',\n",
              "    ' and',\n",
              "    ' Z',\n",
              "    ' bos',\n",
              "    'ons',\n",
              "    ' exchange',\n",
              "    ' create',\n",
              "    ' the',\n",
              "    ' W',\n",
              "    's',\n",
              "    ' and',\n",
              "    ' Z',\n",
              "    's',\n",
              "    ' bos',\n",
              "    'ons'],\n",
              "   'id': '57379829c3c5551400e51f3d',\n",
              "   'prediction': ' The W and Z bosons exchange create the Ws and Zs bosons',\n",
              "   'prompt': 'Title: Theory of everything\\n\\nBackground: two were combined in 1967–68 by Sheldon Glashow, Steven Weinberg, and Abdus Salam into the \"electroweak\" force. Electroweak unification is a broken symmetry: the electromagnetic and weak forces appear distinct at low energies because the particles carrying the weak force, the W and Z bosons, have non-zero masses of and , whereas the photon, which carries the electromagnetic force, is massless. At higher energies Ws and Zs can be created easily and the unified nature of the force becomes apparent. While the strong and electroweak forces peacefully coexist in the Standard Model of particle physics, they remain distinct. So far,\\n\\nQ: What does the W and Z boson exchange create?\\n\\nA:',\n",
              "   'question': 'What does the W and Z boson exchange create?'},\n",
              "  {'answers': ['874.3 square miles',\n",
              "    '874.3 square miles',\n",
              "    '874.3 square miles'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' The land area of Jacksonville is 86.66% of the total area of the',\n",
              "   'generated_answer_probs': [0.4006712954171445,\n",
              "    0.7980561424976302,\n",
              "    0.999843642585095,\n",
              "    0.9947650632901037,\n",
              "    0.999543655276942,\n",
              "    0.9891932985239594,\n",
              "    0.8442996937780878,\n",
              "    0.998751806342534,\n",
              "    0.9913626699280897,\n",
              "    0.7524767574091837,\n",
              "    0.8292205050598168,\n",
              "    0.9509796321154622,\n",
              "    0.6844450808348816,\n",
              "    0.7003235054882324,\n",
              "    0.6302573379893341,\n",
              "    0.8779996710547455],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' land',\n",
              "    ' area',\n",
              "    ' of',\n",
              "    ' Jacksonville',\n",
              "    ' is',\n",
              "    ' 86',\n",
              "    '.',\n",
              "    '66',\n",
              "    '%',\n",
              "    ' of',\n",
              "    ' the',\n",
              "    ' total',\n",
              "    ' area',\n",
              "    ' of',\n",
              "    ' the'],\n",
              "   'generated_probs': [0.4006712954171445,\n",
              "    0.7980561424976302,\n",
              "    0.999843642585095,\n",
              "    0.9947650632901037,\n",
              "    0.999543655276942,\n",
              "    0.9891932985239594,\n",
              "    0.8442996937780878,\n",
              "    0.998751806342534,\n",
              "    0.9913626699280897,\n",
              "    0.7524767574091837,\n",
              "    0.8292205050598168,\n",
              "    0.9509796321154622,\n",
              "    0.6844450808348816,\n",
              "    0.7003235054882324,\n",
              "    0.6302573379893341,\n",
              "    0.8779996710547455],\n",
              "   'generated_text': ' The land area of Jacksonville is 86.66% of the total area of the',\n",
              "   'generated_tokens': [' The',\n",
              "    ' land',\n",
              "    ' area',\n",
              "    ' of',\n",
              "    ' Jacksonville',\n",
              "    ' is',\n",
              "    ' 86',\n",
              "    '.',\n",
              "    '66',\n",
              "    '%',\n",
              "    ' of',\n",
              "    ' the',\n",
              "    ' total',\n",
              "    ' area',\n",
              "    ' of',\n",
              "    ' the'],\n",
              "   'id': '572820512ca10214002d9e72',\n",
              "   'prediction': ' The land area of Jacksonville is 86.66% of the total area of the',\n",
              "   'prompt': 'Title: Jacksonville, Florida\\n\\nBackground: the area since 2004. According to the United States Census Bureau, the city has a total area of , making Jacksonville the largest city in land area in the contiguous United States; of this, 86.66% () is land and ; 13.34% () is water. Jacksonville surrounds the town of Baldwin. Nassau County lies to the north, Baker County lies to the west, and Clay and St. Johns County lie to the south; the Atlantic Ocean lies to the east, along with the Jacksonville Beaches. The St. Johns River divides the city. The Trout River, a major tributary of the St.\\n\\nQ: What is the land area of Jacksonville?\\n\\nA:',\n",
              "   'question': 'What is the land area of Jacksonville?'},\n",
              "  {'answers': ['energy', 'energy', 'energy'],\n",
              "   'em': 0,\n",
              "   'f1': 0.18181818181818182,\n",
              "   'generated_answer': ' NADPH stores energy in a cell to power most cellular activities.',\n",
              "   'generated_answer_probs': [0.9607156389460725,\n",
              "    0.9974930698111473,\n",
              "    0.955309415202505,\n",
              "    0.7862488449740349,\n",
              "    0.9765226801256459,\n",
              "    0.6410329816198792,\n",
              "    0.7574790263263144,\n",
              "    0.40937767838261585,\n",
              "    0.8564628297497625,\n",
              "    0.7123655403119238,\n",
              "    0.94553203491815,\n",
              "    0.9994292146599653,\n",
              "    0.9432227000402231],\n",
              "   'generated_answer_tokens': [' NAD',\n",
              "    'PH',\n",
              "    ' stores',\n",
              "    ' energy',\n",
              "    ' in',\n",
              "    ' a',\n",
              "    ' cell',\n",
              "    ' to',\n",
              "    ' power',\n",
              "    ' most',\n",
              "    ' cellular',\n",
              "    ' activities',\n",
              "    '.'],\n",
              "   'generated_probs': [0.9607156389460725,\n",
              "    0.9974930698111473,\n",
              "    0.955309415202505,\n",
              "    0.7862488449740349,\n",
              "    0.9765226801256459,\n",
              "    0.6410329816198792,\n",
              "    0.7574790263263144,\n",
              "    0.40937767838261585,\n",
              "    0.8564628297497625,\n",
              "    0.7123655403119238,\n",
              "    0.94553203491815,\n",
              "    0.9994292146599653,\n",
              "    0.9432227000402231],\n",
              "   'generated_text': ' NADPH stores energy in a cell to power most cellular activities.',\n",
              "   'generated_tokens': [' NAD',\n",
              "    'PH',\n",
              "    ' stores',\n",
              "    ' energy',\n",
              "    ' in',\n",
              "    ' a',\n",
              "    ' cell',\n",
              "    ' to',\n",
              "    ' power',\n",
              "    ' most',\n",
              "    ' cellular',\n",
              "    ' activities',\n",
              "    '.'],\n",
              "   'id': '572953013f37b3190047824f',\n",
              "   'prediction': ' NADPH stores energy in a cell to power most cellular activities.',\n",
              "   'prompt': 'Title: Chloroplast\\n\\nBackground: place on the thylakoid membranes. They take light energy and store it in NADPH, a form of NADP, and ATP to fuel the dark reactions. ATP is the phosphorylated version of adenosine diphosphate (ADP), which stores energy in a cell and powers most cellular activities. ATP is the energized form, while ADP is the (partially) depleted form. NADP is an electron carrier which ferries high energy electrons. In the light reactions, it gets reduced, meaning it picks up electrons, becoming NADPH. Like mitochondria, chloroplasts use the potential energy stored in an H, or hydrogen ion gradient to generate ATP energy.\\n\\nQ: What does NADPH store?\\n\\nA:',\n",
              "   'question': 'What does NADPH store?'},\n",
              "  {'answers': ['result of its colouring', 'its colouring', 'its colouring,'],\n",
              "   'em': 0,\n",
              "   'f1': 0.11764705882352941,\n",
              "   'generated_answer': ' The building is coloured pink because it used to be the headquarters of the BBC North',\n",
              "   'generated_answer_probs': [0.7605189574348391,\n",
              "    0.9790284966098723,\n",
              "    0.41276927429909366,\n",
              "    0.6554226724591476,\n",
              "    0.9959785033623326,\n",
              "    0.44660863713819615,\n",
              "    0.8974964949280279,\n",
              "    0.7854220204414345,\n",
              "    0.9999920621045053,\n",
              "    0.9885988577813922,\n",
              "    0.8421591570311632,\n",
              "    0.3920584120347013,\n",
              "    0.9927725376373115,\n",
              "    0.8830691401746767,\n",
              "    0.32003612465917175,\n",
              "    0.9307018221173762],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' building',\n",
              "    ' is',\n",
              "    ' coloured',\n",
              "    ' pink',\n",
              "    ' because',\n",
              "    ' it',\n",
              "    ' used',\n",
              "    ' to',\n",
              "    ' be',\n",
              "    ' the',\n",
              "    ' headquarters',\n",
              "    ' of',\n",
              "    ' the',\n",
              "    ' BBC',\n",
              "    ' North'],\n",
              "   'generated_probs': [0.7605189574348391,\n",
              "    0.9790284966098723,\n",
              "    0.41276927429909366,\n",
              "    0.6554226724591476,\n",
              "    0.9959785033623326,\n",
              "    0.44660863713819615,\n",
              "    0.8974964949280279,\n",
              "    0.7854220204414345,\n",
              "    0.9999920621045053,\n",
              "    0.9885988577813922,\n",
              "    0.8421591570311632,\n",
              "    0.3920584120347013,\n",
              "    0.9927725376373115,\n",
              "    0.8830691401746767,\n",
              "    0.32003612465917175,\n",
              "    0.9307018221173762],\n",
              "   'generated_text': ' The building is coloured pink because it used to be the headquarters of the BBC North',\n",
              "   'generated_tokens': [' The',\n",
              "    ' building',\n",
              "    ' is',\n",
              "    ' coloured',\n",
              "    ' pink',\n",
              "    ' because',\n",
              "    ' it',\n",
              "    ' used',\n",
              "    ' to',\n",
              "    ' be',\n",
              "    ' the',\n",
              "    ' headquarters',\n",
              "    ' of',\n",
              "    ' the',\n",
              "    ' BBC',\n",
              "    ' North'],\n",
              "   'id': '57269c26f1498d1400e8e4cd',\n",
              "   'prediction': ' The building is coloured pink because it used to be the headquarters of the BBC North',\n",
              "   'prompt': 'Title: Newcastle upon Tyne\\n\\nBackground: January 1959. In 2005 it moved to a new facility on The Watermark business park next to the MetroCentre in Gateshead. The entrance to studio 5 at the City Road complex gave its name to the 1980s music television programme, \"The Tube\". BBC North East and Cumbria is located to the north of the city on Barrack Road, Spital Tongues, in a building known, as the result of its colouring, as the Pink Palace. It is from here that the Corporation broadcasts the \"Look North\" television regional news programme and local radio station BBC Radio Newcastle. Independent local radio stations\\n\\nQ: Why is the building on Spital Tongues known as the Pink Palace?\\n\\nA:',\n",
              "   'question': 'Why is the building on Spital Tongues known as the Pink Palace?'},\n",
              "  {'answers': ['ivory', 'ivory', 'ivory'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' The combs in the V&A collection of South East Asian art are made',\n",
              "   'generated_answer_probs': [0.45751207553631346,\n",
              "    0.968230224264334,\n",
              "    0.9999998115819777,\n",
              "    0.9279181690379649,\n",
              "    0.9918446304441436,\n",
              "    0.9818430276976897,\n",
              "    0.9998730914035773,\n",
              "    0.9999982599891138,\n",
              "    0.9740181149512258,\n",
              "    0.9958620333752485,\n",
              "    0.9969314705895514,\n",
              "    0.9943527173898694,\n",
              "    0.9999173150685874,\n",
              "    0.9998986000813193,\n",
              "    0.9460328863036336,\n",
              "    0.9403857401798917],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' com',\n",
              "    'bs',\n",
              "    ' in',\n",
              "    ' the',\n",
              "    ' V',\n",
              "    '&',\n",
              "    'A',\n",
              "    ' collection',\n",
              "    ' of',\n",
              "    ' South',\n",
              "    ' East',\n",
              "    ' Asian',\n",
              "    ' art',\n",
              "    ' are',\n",
              "    ' made'],\n",
              "   'generated_probs': [0.45751207553631346,\n",
              "    0.968230224264334,\n",
              "    0.9999998115819777,\n",
              "    0.9279181690379649,\n",
              "    0.9918446304441436,\n",
              "    0.9818430276976897,\n",
              "    0.9998730914035773,\n",
              "    0.9999982599891138,\n",
              "    0.9740181149512258,\n",
              "    0.9958620333752485,\n",
              "    0.9969314705895514,\n",
              "    0.9943527173898694,\n",
              "    0.9999173150685874,\n",
              "    0.9998986000813193,\n",
              "    0.9460328863036336,\n",
              "    0.9403857401798917],\n",
              "   'generated_text': ' The combs in the V&A collection of South East Asian art are made',\n",
              "   'generated_tokens': [' The',\n",
              "    ' com',\n",
              "    'bs',\n",
              "    ' in',\n",
              "    ' the',\n",
              "    ' V',\n",
              "    '&',\n",
              "    'A',\n",
              "    ' collection',\n",
              "    ' of',\n",
              "    ' South',\n",
              "    ' East',\n",
              "    ' Asian',\n",
              "    ' art',\n",
              "    ' are',\n",
              "    ' made'],\n",
              "   'id': '5726c80c5951b619008f7deb',\n",
              "   'prediction': ' The combs in the V&A collection of South East Asian art are made',\n",
              "   'prompt': \"Title: Victoria and Albert Museum\\n\\nBackground: mosques and metalwork are on display. The collection of Middle Eastern and Persian rugs and carpets is amongst the finest in the world, many were part of the Salting Bequest of 1909. Examples of tile work from various buildings including a fireplace dated 1731 from Istanbul made of intricately decorated blue and white tiles and turquoise tiles from the exterior of buildings from Samarkand are also displayed. The Museum's collections of South and South-East Asian art are the most comprehensive and important in the West comprising nearly 60,000 objects, including about 10,000 textiles and 6000 paintings, the range of the\\n\\nQ: Some of the combs in the V&A collection of South East Asian art is made of what material?\\n\\nA:\",\n",
              "   'question': 'Some of the combs in the V&A collection of South East Asian art is made of what material?'},\n",
              "  {'answers': ['algebraic number theory',\n",
              "    'algebraic',\n",
              "    'algebraic',\n",
              "    'algebraic'],\n",
              "   'em': 0,\n",
              "   'f1': 0.6666666666666666,\n",
              "   'generated_answer': ' Algebraic number theory and algebraic geometry.',\n",
              "   'generated_answer_probs': [0.9404995864068003,\n",
              "    0.9998972870553358,\n",
              "    0.9893933910166038,\n",
              "    0.9884959801458673,\n",
              "    0.9997814169727517,\n",
              "    0.6040159102021273,\n",
              "    0.9932682087113918,\n",
              "    0.9999994539509491,\n",
              "    0.9997449993781868,\n",
              "    0.44699646172675384],\n",
              "   'generated_answer_tokens': [' Al',\n",
              "    'gebra',\n",
              "    'ic',\n",
              "    ' number',\n",
              "    ' theory',\n",
              "    ' and',\n",
              "    ' algebra',\n",
              "    'ic',\n",
              "    ' geometry',\n",
              "    '.'],\n",
              "   'generated_probs': [0.9404995864068003,\n",
              "    0.9998972870553358,\n",
              "    0.9893933910166038,\n",
              "    0.9884959801458673,\n",
              "    0.9997814169727517,\n",
              "    0.6040159102021273,\n",
              "    0.9932682087113918,\n",
              "    0.9999994539509491,\n",
              "    0.9997449993781868,\n",
              "    0.44699646172675384],\n",
              "   'generated_text': ' Algebraic number theory and algebraic geometry.',\n",
              "   'generated_tokens': [' Al',\n",
              "    'gebra',\n",
              "    'ic',\n",
              "    ' number',\n",
              "    ' theory',\n",
              "    ' and',\n",
              "    ' algebra',\n",
              "    'ic',\n",
              "    ' geometry',\n",
              "    '.'],\n",
              "   'id': '57299ec43f37b3190047850f',\n",
              "   'prediction': ' Algebraic number theory and algebraic geometry.',\n",
              "   'prompt': 'Title: Prime number\\n\\nBackground: by a prime element is a prime ideal, are an important tool and object of study in commutative algebra, algebraic number theory and algebraic geometry. The prime ideals of the ring of integers are the ideals (0), (2), (3), (5), (7), (11), … The fundamental theorem of arithmetic generalizes to the Lasker–Noether theorem, which expresses every ideal in a Noetherian commutative ring as an intersection of primary ideals, which are the appropriate generalizations of prime powers. Prime ideals are the points of algebro-geometric objects, via the notion of the spectrum of a ring. Arithmetic geometry also benefits from this notion,\\n\\nQ: What type of number theory utilizes and studies prime ideals?\\n\\nA:',\n",
              "   'question': 'What type of number theory utilizes and studies prime ideals?'},\n",
              "  {'answers': ['high density', 'high density', 'high density'],\n",
              "   'em': 0,\n",
              "   'f1': 0.5714285714285715,\n",
              "   'generated_answer': ' High density without building high.',\n",
              "   'generated_answer_probs': [0.16396729365163198,\n",
              "    0.9721292539962564,\n",
              "    0.7428147443575975,\n",
              "    0.5871727555396248,\n",
              "    0.9948013639243475,\n",
              "    0.5394991499018595],\n",
              "   'generated_answer_tokens': [' High',\n",
              "    ' density',\n",
              "    ' without',\n",
              "    ' building',\n",
              "    ' high',\n",
              "    '.'],\n",
              "   'generated_probs': [0.16396729365163198,\n",
              "    0.9721292539962564,\n",
              "    0.7428147443575975,\n",
              "    0.5871727555396248,\n",
              "    0.9948013639243475,\n",
              "    0.5394991499018595],\n",
              "   'generated_text': ' High density without building high.',\n",
              "   'generated_tokens': [' High',\n",
              "    ' density',\n",
              "    ' without',\n",
              "    ' building',\n",
              "    ' high',\n",
              "    '.'],\n",
              "   'id': '5726778df1498d1400e8e0b0',\n",
              "   'prediction': ' High density without building high.',\n",
              "   'prompt': 'Title: Newcastle upon Tyne\\n\\nBackground: streetscape on both sides of the Tyne. Tyneside flats were built as terraces, one of each pair of doors led to an upstairs flat while the other led into the ground-floor flat, each of two or three rooms. A new development in the Ouseburn valley has recreated them; Architects Cany Ash and Robert Sakula were attracted by the possibilities of high density without building high and getting rid of common areas. In terms of housing stock, the authority is one of few authorities to see the proportion of detached homes rise in the 2010 Census (to 7.8%), in this instance\\n\\nQ: What can be achieved without building high or getting rid of common areas?\\n\\nA:',\n",
              "   'question': 'What can be achieved without building high or getting rid of common areas?'},\n",
              "  {'answers': ['Jamukha, and his protector, Toghrul Khan of the Keraite tribe',\n",
              "    'Jamukha, and his protector, Toghrul Khan',\n",
              "    'Jamukha, and his protector, Toghrul Khan'],\n",
              "   'em': 0,\n",
              "   'f1': 0.8,\n",
              "   'generated_answer': ' Jamukha and Toghrul Khan.',\n",
              "   'generated_answer_probs': [0.4361274333554095,\n",
              "    0.9993187671445374,\n",
              "    0.9999957566187032,\n",
              "    0.7915697181220663,\n",
              "    0.9982486805527604,\n",
              "    0.9999905095960342,\n",
              "    0.9995484233514406,\n",
              "    0.9996482603648951,\n",
              "    0.977007197526261,\n",
              "    0.7367487897891662],\n",
              "   'generated_answer_tokens': [' Jam',\n",
              "    'uk',\n",
              "    'ha',\n",
              "    ' and',\n",
              "    ' To',\n",
              "    'gh',\n",
              "    'r',\n",
              "    'ul',\n",
              "    ' Khan',\n",
              "    '.'],\n",
              "   'generated_probs': [0.4361274333554095,\n",
              "    0.9993187671445374,\n",
              "    0.9999957566187032,\n",
              "    0.7915697181220663,\n",
              "    0.9982486805527604,\n",
              "    0.9999905095960342,\n",
              "    0.9995484233514406,\n",
              "    0.9996482603648951,\n",
              "    0.977007197526261,\n",
              "    0.7367487897891662],\n",
              "   'generated_text': ' Jamukha and Toghrul Khan.',\n",
              "   'generated_tokens': [' Jam',\n",
              "    'uk',\n",
              "    'ha',\n",
              "    ' and',\n",
              "    ' To',\n",
              "    'gh',\n",
              "    'r',\n",
              "    'ul',\n",
              "    ' Khan',\n",
              "    '.'],\n",
              "   'id': '5726a8d4dd62a815002e8c36',\n",
              "   'prediction': ' Jamukha and Toghrul Khan.',\n",
              "   'prompt': \"Title: Genghis Khan\\n\\nBackground: ensure stability in Mongolia. As previously arranged by his father, Temüjin married Börte of the Onggirat tribe when he was around 16 in order to cement alliances between their two tribes. Soon after the marriage, Börte was kidnapped by the Merkits and reportedly given away as a wife. Temüjin rescued her with the help of his friend and future rival, Jamukha, and his protector, Toghrul Khan of the Keraite tribe. She gave birth to a son, Jochi (1185–1226), nine months later, clouding the issue of his parentage. Despite speculation over Jochi, Börte would be Temüjin's only empress, though he did\\n\\nQ: Who helped Temüjin rescue his wife from the Merkits?\\n\\nA:\",\n",
              "   'question': 'Who helped Temüjin rescue his wife from the Merkits?'},\n",
              "  {'answers': ['Battle of Olustee', 'Battle of Olustee', 'Battle of Olustee'],\n",
              "   'em': 1,\n",
              "   'f1': 1.0,\n",
              "   'generated_answer': ' The Battle of Olustee.',\n",
              "   'generated_answer_probs': [0.9678684255138614,\n",
              "    0.9682383864795283,\n",
              "    0.999993013890903,\n",
              "    0.9987918600893562,\n",
              "    0.9999988569748532,\n",
              "    0.9999995722265915,\n",
              "    0.3979964871471871],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' Battle',\n",
              "    ' of',\n",
              "    ' Ol',\n",
              "    'ust',\n",
              "    'ee',\n",
              "    '.'],\n",
              "   'generated_probs': [0.9678684255138614,\n",
              "    0.9682383864795283,\n",
              "    0.999993013890903,\n",
              "    0.9987918600893562,\n",
              "    0.9999988569748532,\n",
              "    0.9999995722265915,\n",
              "    0.3979964871471871],\n",
              "   'generated_text': ' The Battle of Olustee.',\n",
              "   'generated_tokens': [' The', ' Battle', ' of', ' Ol', 'ust', 'ee', '.'],\n",
              "   'id': '5728128cff5b5019007d9c78',\n",
              "   'prediction': ' The Battle of Olustee.',\n",
              "   'prompt': 'Title: Jacksonville, Florida\\n\\nBackground: the nearby Fort Clinch. Though no battles were fought in Jacksonville proper, the city changed hands several times between Union and Confederate forces. The Skirmish of the Brick Church in 1862 just outside Jacksonville proper resulted in the first Confederate victory in Florida. However, Union forces captured a Confederate position at the Battle of St. Johns Bluff leading to the Union occupation of Jacksonville in 1862. In February 1864 Union forces left Jacksonville and confronted a Confederate Army at the Battle of Olustee resulting in a Confederate victory. Union forces then retreated to Jacksonville and held the city for the\\n\\nQ: After what battle did Union forces return to and occupy Jacksonville for the rest of the war?\\n\\nA:',\n",
              "   'question': 'After what battle did Union forces return to and occupy Jacksonville for the rest of the war?'},\n",
              "  {'answers': ['Germany', 'Germany', 'Germany'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' The Neckar meets the Rhine at the city of Mainz.',\n",
              "   'generated_answer_probs': [0.9597183864528318,\n",
              "    0.5969724583922652,\n",
              "    0.9999967093467143,\n",
              "    0.5477502741525375,\n",
              "    0.9996212005126488,\n",
              "    0.9991936573690832,\n",
              "    0.9999940877054777,\n",
              "    0.4071798659830795,\n",
              "    0.2260132620035278,\n",
              "    0.7283653298072711,\n",
              "    0.9996418226108421,\n",
              "    0.6480285661737822,\n",
              "    0.9989846836827634,\n",
              "    0.9767024412927379],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' Neck',\n",
              "    'ar',\n",
              "    ' meets',\n",
              "    ' the',\n",
              "    ' Rh',\n",
              "    'ine',\n",
              "    ' at',\n",
              "    ' the',\n",
              "    ' city',\n",
              "    ' of',\n",
              "    ' Main',\n",
              "    'z',\n",
              "    '.'],\n",
              "   'generated_probs': [0.9597183864528318,\n",
              "    0.5969724583922652,\n",
              "    0.9999967093467143,\n",
              "    0.5477502741525375,\n",
              "    0.9996212005126488,\n",
              "    0.9991936573690832,\n",
              "    0.9999940877054777,\n",
              "    0.4071798659830795,\n",
              "    0.2260132620035278,\n",
              "    0.7283653298072711,\n",
              "    0.9996418226108421,\n",
              "    0.6480285661737822,\n",
              "    0.9989846836827634,\n",
              "    0.9767024412927379],\n",
              "   'generated_text': ' The Neckar meets the Rhine at the city of Mainz.',\n",
              "   'generated_tokens': [' The',\n",
              "    ' Neck',\n",
              "    'ar',\n",
              "    ' meets',\n",
              "    ' the',\n",
              "    ' Rh',\n",
              "    'ine',\n",
              "    ' at',\n",
              "    ' the',\n",
              "    ' city',\n",
              "    ' of',\n",
              "    ' Main',\n",
              "    'z',\n",
              "    '.'],\n",
              "   'id': '572f65e9b2c2fd14005680cc',\n",
              "   'prediction': ' The Neckar meets the Rhine at the city of Mainz.',\n",
              "   'prompt': 'Title: Rhine\\n\\nBackground: river islands occur, locally known as \"Rheinauen\". The Rhine is the longest river in Germany. It is here that the Rhine encounters some more of its main tributaries, such as the Neckar, the Main and, later, the Moselle, which contributes an average discharge of more than . Northeastern France drains to the Rhine via the Moselle; smaller rivers drain the Vosges and Jura Mountains uplands. Most of Luxembourg and a very small part of Belgium also drain to the Rhine via the Moselle. As it approaches the Dutch border, the Rhine has an annual mean discharge of and an average\\n\\nQ: Where does the Rhine encounter it\\'s tributary the Neckar? \\n\\nA:',\n",
              "   'question': \"Where does the Rhine encounter it's tributary the Neckar? \"},\n",
              "  {'answers': ['HO', 'HO', 'HO', 'HO', 'HO'],\n",
              "   'em': 0,\n",
              "   'f1': 0.25,\n",
              "   'generated_answer': \" Dalton's erroneous formula for water was HO.\",\n",
              "   'generated_answer_probs': [0.576984982312957,\n",
              "    0.9343891347741693,\n",
              "    0.8688393834249972,\n",
              "    0.9996308584495138,\n",
              "    0.985375732727157,\n",
              "    0.9998926402734679,\n",
              "    0.9865027952709144,\n",
              "    0.6549441592726404,\n",
              "    0.9365192425549599],\n",
              "   'generated_answer_tokens': [' Dalton',\n",
              "    \"'s\",\n",
              "    ' erroneous',\n",
              "    ' formula',\n",
              "    ' for',\n",
              "    ' water',\n",
              "    ' was',\n",
              "    ' HO',\n",
              "    '.'],\n",
              "   'generated_probs': [0.576984982312957,\n",
              "    0.9343891347741693,\n",
              "    0.8688393834249972,\n",
              "    0.9996308584495138,\n",
              "    0.985375732727157,\n",
              "    0.9998926402734679,\n",
              "    0.9865027952709144,\n",
              "    0.6549441592726404,\n",
              "    0.9365192425549599],\n",
              "   'generated_text': \" Dalton's erroneous formula for water was HO.\",\n",
              "   'generated_tokens': [' Dalton',\n",
              "    \"'s\",\n",
              "    ' erroneous',\n",
              "    ' formula',\n",
              "    ' for',\n",
              "    ' water',\n",
              "    ' was',\n",
              "    ' HO',\n",
              "    '.'],\n",
              "   'id': '571c7d55dd7acb1400e4c0c6',\n",
              "   'prediction': \" Dalton's erroneous formula for water was HO.\",\n",
              "   'prompt': 'Title: Oxygen\\n\\nBackground: \"The Botanic Garden\" (1791) by Erasmus Darwin, grandfather of Charles Darwin. John Dalton\\'s original atomic hypothesis presumed that all elements were monatomic and that the atoms in compounds would normally have the simplest atomic ratios with respect to one another. For example, Dalton assumed that water\\'s formula was HO, giving the atomic mass of oxygen was 8 times that of hydrogen, instead of the modern value of about 16. In 1805, Joseph Louis Gay-Lussac and Alexander von Humboldt showed that water is formed of two volumes of hydrogen and one volume of oxygen; and by 1811 Amedeo Avogadro had arrived\\n\\nQ: What was Dalton\\'s erroneous formula for water?\\n\\nA:',\n",
              "   'question': \"What was Dalton's erroneous formula for water?\"},\n",
              "  {'answers': ['denoted scalar quantities',\n",
              "    'scalar quantities',\n",
              "    'denoted scalar quantities',\n",
              "    'scalar quantities',\n",
              "    'scalar quantities'],\n",
              "   'em': 1,\n",
              "   'f1': 1.0,\n",
              "   'generated_answer': ' Scalar quantities.',\n",
              "   'generated_answer_probs': [0.3916848956773906,\n",
              "    0.9991184345373554,\n",
              "    0.9232463810974106,\n",
              "    0.5899731804381848],\n",
              "   'generated_answer_tokens': [' Scal', 'ar', ' quantities', '.'],\n",
              "   'generated_probs': [0.3916848956773906,\n",
              "    0.9991184345373554,\n",
              "    0.9232463810974106,\n",
              "    0.5899731804381848],\n",
              "   'generated_text': ' Scalar quantities.',\n",
              "   'generated_tokens': [' Scal', 'ar', ' quantities', '.'],\n",
              "   'id': '57376828c3c5551400e51eba',\n",
              "   'prediction': ' Scalar quantities.',\n",
              "   'prompt': 'Title: Force\\n\\nBackground: precise operational definitions that are consistent with direct observations and compared to a standard measurement scale. Through experimentation, it is determined that laboratory measurements of forces are fully consistent with the conceptual definition of force offered by Newtonian mechanics. Forces act in a particular direction and have sizes dependent upon how strong the push or pull is. Because of these characteristics, forces are classified as \"vector quantities\". This means that forces follow a different set of mathematical rules than physical quantities that do not have direction (denoted scalar quantities). For example, when determining what happens when two forces act on\\n\\nQ: What physical quantities do not have direction?\\n\\nA:',\n",
              "   'question': 'What physical quantities do not have direction?'},\n",
              "  {'answers': ['1935', '1930', '1935'],\n",
              "   'em': 0,\n",
              "   'f1': 0.2222222222222222,\n",
              "   'generated_answer': ' The occupation of allies would leave Rhineland in 1930.',\n",
              "   'generated_answer_probs': [0.8274906838347776,\n",
              "    0.8248701903976667,\n",
              "    0.8689295649444919,\n",
              "    0.9532114153604503,\n",
              "    0.9844341656372594,\n",
              "    0.9976795150973536,\n",
              "    0.9502955951462624,\n",
              "    0.9998512717111487,\n",
              "    0.9999980234482534,\n",
              "    0.6294935574137926,\n",
              "    0.7975403818950484,\n",
              "    0.7777245782601947],\n",
              "   'generated_answer_tokens': [' The',\n",
              "    ' occupation',\n",
              "    ' of',\n",
              "    ' allies',\n",
              "    ' would',\n",
              "    ' leave',\n",
              "    ' Rh',\n",
              "    'in',\n",
              "    'eland',\n",
              "    ' in',\n",
              "    ' 1930',\n",
              "    '.'],\n",
              "   'generated_probs': [0.8274906838347776,\n",
              "    0.8248701903976667,\n",
              "    0.8689295649444919,\n",
              "    0.9532114153604503,\n",
              "    0.9844341656372594,\n",
              "    0.9976795150973536,\n",
              "    0.9502955951462624,\n",
              "    0.9998512717111487,\n",
              "    0.9999980234482534,\n",
              "    0.6294935574137926,\n",
              "    0.7975403818950484,\n",
              "    0.7777245782601947],\n",
              "   'generated_text': ' The occupation of allies would leave Rhineland in 1930.',\n",
              "   'generated_tokens': [' The',\n",
              "    ' occupation',\n",
              "    ' of',\n",
              "    ' allies',\n",
              "    ' would',\n",
              "    ' leave',\n",
              "    ' Rh',\n",
              "    'in',\n",
              "    'eland',\n",
              "    ' in',\n",
              "    ' 1930',\n",
              "    '.'],\n",
              "   'id': '57300a9a04bcaa1900d77064',\n",
              "   'prediction': ' The occupation of allies would leave Rhineland in 1930.',\n",
              "   'prompt': \"Title: Rhine\\n\\nBackground: Rhineland was subject to the Treaty of Versailles. This decreed that it would be occupied by the allies, until 1935 and after that, it would be a demilitarised zone, with the German army forbidden to enter. The Treaty of Versailles and this particular provision, in general, caused much resentment in Germany and is often cited as helping Adolf Hitler's rise to power. The allies left the Rhineland, in 1930 and the German army re-occupied it in 1936, which was enormously popular in Germany. Although the allies could probably have prevented the re-occupation, Britain and France were not inclined to do\\n\\nQ: When would the occupation of allies leave Rhineland?\\n\\nA:\",\n",
              "   'question': 'When would the occupation of allies leave Rhineland?'},\n",
              "  {'answers': ['recanted 41 sentences',\n",
              "    'recanted 41 sentences',\n",
              "    'recanted 41 sentences'],\n",
              "   'em': 0,\n",
              "   'f1': 0.28571428571428575,\n",
              "   'generated_answer': ' Luther needed to recant 41 sentences from his writings, including the \"Ninety',\n",
              "   'generated_answer_probs': [0.5976175727840892,\n",
              "    0.9857896863293178,\n",
              "    0.9999918236884262,\n",
              "    0.9896656076115599,\n",
              "    0.9998769065366221,\n",
              "    0.9028320807001643,\n",
              "    0.6334900092902485,\n",
              "    0.662088994037166,\n",
              "    0.998844908032894,\n",
              "    0.9774538094487304,\n",
              "    0.8769221491925209,\n",
              "    0.9705898543819234,\n",
              "    0.990890486332807,\n",
              "    0.9944546405847846,\n",
              "    0.966833223833787,\n",
              "    0.9999953989891847],\n",
              "   'generated_answer_tokens': [' Luther',\n",
              "    ' needed',\n",
              "    ' to',\n",
              "    ' rec',\n",
              "    'ant',\n",
              "    ' 41',\n",
              "    ' sentences',\n",
              "    ' from',\n",
              "    ' his',\n",
              "    ' writings',\n",
              "    ',',\n",
              "    ' including',\n",
              "    ' the',\n",
              "    ' \"',\n",
              "    'Nin',\n",
              "    'ety'],\n",
              "   'generated_probs': [0.5976175727840892,\n",
              "    0.9857896863293178,\n",
              "    0.9999918236884262,\n",
              "    0.9896656076115599,\n",
              "    0.9998769065366221,\n",
              "    0.9028320807001643,\n",
              "    0.6334900092902485,\n",
              "    0.662088994037166,\n",
              "    0.998844908032894,\n",
              "    0.9774538094487304,\n",
              "    0.8769221491925209,\n",
              "    0.9705898543819234,\n",
              "    0.990890486332807,\n",
              "    0.9944546405847846,\n",
              "    0.966833223833787,\n",
              "    0.9999953989891847],\n",
              "   'generated_text': ' Luther needed to recant 41 sentences from his writings, including the \"Ninety',\n",
              "   'generated_tokens': [' Luther',\n",
              "    ' needed',\n",
              "    ' to',\n",
              "    ' rec',\n",
              "    'ant',\n",
              "    ' 41',\n",
              "    ' sentences',\n",
              "    ' from',\n",
              "    ' his',\n",
              "    ' writings',\n",
              "    ',',\n",
              "    ' including',\n",
              "    ' the',\n",
              "    ' \"',\n",
              "    'Nin',\n",
              "    'ety'],\n",
              "   'id': '56f81537aef2371900625db4',\n",
              "   'prediction': ' Luther needed to recant 41 sentences from his writings, including the \"Ninety',\n",
              "   'prompt': 'Title: Martin Luther\\n\\nBackground: referring to the Czech reformer and heretic burned at the stake in 1415. From that moment, he devoted himself to Luther\\'s defeat. On 15 June 1520, the Pope warned Luther with the papal bull (edict) \"Exsurge Domine\" that he risked excommunication unless he recanted 41 sentences drawn from his writings, including the \"Ninety-five Theses\", within 60 days. That autumn, Johann Eck proclaimed the bull in Meissen and other towns. Karl von Miltitz, a papal nuncio, attempted to broker a solution, but Luther, who had sent the Pope a copy of \"On the Freedom of a Christian\" in October, publicly set\\n\\nQ: What did Luther need to do to avoid excommunication? \\n\\nA:',\n",
              "   'question': 'What did Luther need to do to avoid excommunication? '},\n",
              "  {'answers': ['Bert Bolin', 'Bert Bolin', 'Bert Bolin'],\n",
              "   'em': 0,\n",
              "   'f1': 0,\n",
              "   'generated_answer': ' Rajendra K. Pachauri was the first chair of the IPCC.',\n",
              "   'generated_answer_probs': [0.9453527468963299,\n",
              "    0.99994127619731,\n",
              "    0.9818438033539879,\n",
              "    0.9987438190566515,\n",
              "    0.9917377009756119,\n",
              "    0.999995638343512,\n",
              "    0.9999943242451071,\n",
              "    0.6168769424155981,\n",
              "    0.9950952159299516,\n",
              "    0.9722525725246745,\n",
              "    0.9932830512291301,\n",
              "    0.9929050978025529,\n",
              "    0.9940121951880192,\n",
              "    0.9755905949104811,\n",
              "    0.9776757156713138],\n",
              "   'generated_answer_tokens': [' Raj',\n",
              "    'endra',\n",
              "    ' K',\n",
              "    '.',\n",
              "    ' P',\n",
              "    'ach',\n",
              "    'auri',\n",
              "    ' was',\n",
              "    ' the',\n",
              "    ' first',\n",
              "    ' chair',\n",
              "    ' of',\n",
              "    ' the',\n",
              "    ' IPCC',\n",
              "    '.'],\n",
              "   'generated_probs': [0.9453527468963299,\n",
              "    0.99994127619731,\n",
              "    0.9818438033539879,\n",
              "    0.9987438190566515,\n",
              "    0.9917377009756119,\n",
              "    0.999995638343512,\n",
              "    0.9999943242451071,\n",
              "    0.6168769424155981,\n",
              "    0.9950952159299516,\n",
              "    0.9722525725246745,\n",
              "    0.9932830512291301,\n",
              "    0.9929050978025529,\n",
              "    0.9940121951880192,\n",
              "    0.9755905949104811,\n",
              "    0.9776757156713138],\n",
              "   'generated_text': ' Rajendra K. Pachauri was the first chair of the IPCC.',\n",
              "   'generated_tokens': [' Raj',\n",
              "    'endra',\n",
              "    ' K',\n",
              "    '.',\n",
              "    ' P',\n",
              "    'ach',\n",
              "    'auri',\n",
              "    ' was',\n",
              "    ' the',\n",
              "    ' first',\n",
              "    ' chair',\n",
              "    ' of',\n",
              "    ' the',\n",
              "    ' IPCC',\n",
              "    '.'],\n",
              "   'id': '57293bc91d0469140077919e',\n",
              "   'prediction': ' Rajendra K. Pachauri was the first chair of the IPCC.',\n",
              "   'prompt': 'Title: Intergovernmental Panel on Climate Change\\n\\nBackground: the resignation of Rajendra K. Pachauri in February 2015. The previous chairs were Rajendra K. Pachauri, elected in May 2002; Robert Watson in 1997; and Bert Bolin in 1988. The chair is assisted by an elected bureau including vice-chairs, working group co-chairs, and a secretariat. The IPCC Panel is composed of representatives appointed by governments and organizations. Participation of delegates with appropriate expertise is encouraged. Plenary sessions of the IPCC and IPCC Working groups are held at the level of government representatives. Non Governmental and Intergovernmental Organizations may be allowed to attend as observers. Sessions of the IPCC Bureau, workshops,\\n\\nQ: Who was the first chair of the IPCC?\\n\\nA:',\n",
              "   'question': 'Who was the first chair of the IPCC?'},\n",
              "  {'answers': [\"highest 'social efficiency'\",\n",
              "    \"highest 'social efficiency'\",\n",
              "    'the races of highest \\'social efficiency\\'\"',\n",
              "    \"of highest 'social efficiency\",\n",
              "    'races of highest \\'social efficiency\\'\"'],\n",
              "   'em': 0,\n",
              "   'f1': 0.16666666666666666,\n",
              "   'generated_answer': ' Hobson wanted all races to develop the world.',\n",
              "   'generated_answer_probs': [0.8037524622358815,\n",
              "    0.9999676210642091,\n",
              "    0.7181835729358363,\n",
              "    0.867630713609151,\n",
              "    0.9939134893104656,\n",
              "    0.9962471420395201,\n",
              "    0.9957431218013527,\n",
              "    0.9971123104195554,\n",
              "    0.9995615360934063,\n",
              "    0.8487540825900288],\n",
              "   'generated_answer_tokens': [' Hob',\n",
              "    'son',\n",
              "    ' wanted',\n",
              "    ' all',\n",
              "    ' races',\n",
              "    ' to',\n",
              "    ' develop',\n",
              "    ' the',\n",
              "    ' world',\n",
              "    '.'],\n",
              "   'generated_probs': [0.8037524622358815,\n",
              "    0.9999676210642091,\n",
              "    0.7181835729358363,\n",
              "    0.867630713609151,\n",
              "    0.9939134893104656,\n",
              "    0.9962471420395201,\n",
              "    0.9957431218013527,\n",
              "    0.9971123104195554,\n",
              "    0.9995615360934063,\n",
              "    0.8487540825900288],\n",
              "   'generated_text': ' Hobson wanted all races to develop the world.',\n",
              "   'generated_tokens': [' Hob',\n",
              "    'son',\n",
              "    ' wanted',\n",
              "    ' all',\n",
              "    ' races',\n",
              "    ' to',\n",
              "    ' develop',\n",
              "    ' the',\n",
              "    ' world',\n",
              "    '.'],\n",
              "   'id': '5730876a396df9190009617b',\n",
              "   'prediction': ' Hobson wanted all races to develop the world.',\n",
              "   'prompt': 'Title: Internationalism (politics)\\n\\nBackground: Kingdom, and the League of Nations, which was formed after World War I. The former was envisioned as a permanent forum for political multilateral negotiations, while the latter was an attempt to solve the world\\'s security problems through international arbitration and dialogue. J. A. Hobson, a Gladstonian liberal who became a socialist after the Great War, anticipated in his book \"Imperialism\" (1902) the growth of international courts and congresses which would hopefully settle international disputes between nations in a peaceful way. Sir Norman Angell in his work \"The Great Illusion\" (1910) claimed that the world was united by trade, finance,\\n\\nQ:  J. A. Hobson wanted which races to develop the world?\\n\\nA:',\n",
              "   'question': ' J. A. Hobson wanted which races to develop the world?'},\n",
              "  {'answers': ['Professional and labor organizations',\n",
              "    'Professional and labor organizations',\n",
              "    'Professional and labor organizations'],\n",
              "   'em': 0,\n",
              "   'f1': 0.4210526315789474,\n",
              "   'generated_answer': ' Professional and labor organizations may limit the supply of workers which results in higher demand and',\n",
              "   'generated_answer_probs': [0.6322483899344716,\n",
              "    0.978349957694219,\n",
              "    0.9974040795440156,\n",
              "    0.9982222179299438,\n",
              "    0.529305028436446,\n",
              "    0.9946283325806299,\n",
              "    0.9995269663157279,\n",
              "    0.9982646556542197,\n",
              "    0.999889182660695,\n",
              "    0.9997615699789565,\n",
              "    0.9677135160524537,\n",
              "    0.9992470633991262,\n",
              "    0.9999630912911431,\n",
              "    0.985864071896446,\n",
              "    0.9998755935391256,\n",
              "    0.9996248964689272],\n",
              "   'generated_answer_tokens': [' Professional',\n",
              "    ' and',\n",
              "    ' labor',\n",
              "    ' organizations',\n",
              "    ' may',\n",
              "    ' limit',\n",
              "    ' the',\n",
              "    ' supply',\n",
              "    ' of',\n",
              "    ' workers',\n",
              "    ' which',\n",
              "    ' results',\n",
              "    ' in',\n",
              "    ' higher',\n",
              "    ' demand',\n",
              "    ' and'],\n",
              "   'generated_probs': [0.6322483899344716,\n",
              "    0.978349957694219,\n",
              "    0.9974040795440156,\n",
              "    0.9982222179299438,\n",
              "    0.529305028436446,\n",
              "    0.9946283325806299,\n",
              "    0.9995269663157279,\n",
              "    0.9982646556542197,\n",
              "    0.999889182660695,\n",
              "    0.9997615699789565,\n",
              "    0.9677135160524537,\n",
              "    0.9992470633991262,\n",
              "    0.9999630912911431,\n",
              "    0.985864071896446,\n",
              "    0.9998755935391256,\n",
              "    0.9996248964689272],\n",
              "   'generated_text': ' Professional and labor organizations may limit the supply of workers which results in higher demand and',\n",
              "   'generated_tokens': [' Professional',\n",
              "    ' and',\n",
              "    ' labor',\n",
              "    ' organizations',\n",
              "    ' may',\n",
              "    ' limit',\n",
              "    ' the',\n",
              "    ' supply',\n",
              "    ' of',\n",
              "    ' workers',\n",
              "    ' which',\n",
              "    ' results',\n",
              "    ' in',\n",
              "    ' higher',\n",
              "    ' demand',\n",
              "    ' and'],\n",
              "   'id': '5727ed2e3acd2414000df005',\n",
              "   'prediction': ' Professional and labor organizations may limit the supply of workers which results in higher demand and',\n",
              "   'prompt': 'Title: Economic inequality\\n\\nBackground: there is a relative shortage of workers for the particular position. Professional and labor organizations may limit the supply of workers which results in higher demand and greater incomes for members. Members may also receive higher wages through collective bargaining, political influence, or corruption. These supply and demand interactions result in a gradation of wage levels within society that significantly influence economic inequality. Polarization of wages does not explain the accumulation of wealth and very high incomes among the 1%. Joseph Stiglitz believes that \"It is plain that markets must be tamed and tempered to make sure they work to\\n\\nQ: Who works to get workers higher compensation?\\n\\nA:',\n",
              "   'question': 'Who works to get workers higher compensation?'}],\n",
              " 'macro_f1': 0.3069870267959624}"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zero_shot_openqa_results_gpt3['macro_f1']"
      ],
      "metadata": {
        "id": "oxBN_LUMglQ-",
        "outputId": "f4e6e6c7-5d3a-4d50-88e8-926a39b23616",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3069870267959624"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "outblNTaYre2"
      },
      "source": [
        "## Homework questions\n",
        "\n",
        "Please embed your homework responses in this notebook, and do not delete any cells from the notebook. (You are free to add as many cells as you like as part of your responses.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKs0WQwzkTxl"
      },
      "source": [
        "### Few-shot OpenQA with no context [2 points]\n",
        "\n",
        "In the section [Open QA with no context](#Open-QA-with-no-context) above, we simply prompted our LM with a question string and looked at what came back. This is arguably unfair to the LM, since we didn't convey anything about our intentions.\n",
        "\n",
        "For a fairer assessment of what the LM alone can do, we should move to the few-shot setting by giving the model a few examples of what we have in mind. The idea here is to create prompts that look like this:\n",
        "\n",
        "   ```   \n",
        "   Q: What is pragmatics?\n",
        "\n",
        "   A: The study of language use\n",
        "\n",
        "   Q: Who is Bert?\n",
        "\n",
        "   A: Bert is one of the Muppets.\n",
        "\n",
        "   Q: What was Stanford University founded?\n",
        "   \n",
        "   A: \n",
        "   ```\n",
        "   \n",
        "This question asks you to write a function for creating such prompts, using SQuAD training examples, and a second function for evaluating this approach. The goal is to have a no context baseline for the other few-shot approaches we are considering.\n",
        "\n",
        "__Task 1___: Complete the function `build_few_shot_no_context_prompt` so that it builds prompts like the above. You can use `test_build_few_shot_no_context_prompt` to check that your function is returning prompts in the desired format.\n",
        "\n",
        "__Task 2__: Complete the function `evaluate_few_shot_no_context` so that you can evaluate this approach. You can use `test_evaluator` to check that your function is performing the desired kind of evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r51ZvoLikTxl"
      },
      "outputs": [],
      "source": [
        "def build_few_shot_no_context_prompt(question, train_exs, joiner=\"\\n\\n\"):\n",
        "    \"\"\"No context few-shot OpenQA prompts.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    question : str   \n",
        "    train_exs : iterable of SQuAD train examples. These can be \n",
        "        obtained via a random sample \n",
        "        from `squad_train` as defined above.\n",
        "    joiner : str\n",
        "        The character to use to join pieces of the prompt into \n",
        "        a single str.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    str, the prompt\n",
        "\n",
        "    \"\"\"\n",
        "    ##### YOUR CODE HERE\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVpgV_WhkTxl"
      },
      "outputs": [],
      "source": [
        "def test_build_few_shot_no_context_prompt(func):\n",
        "    train_exs = [\n",
        "        SquadExample(0, \"T1\", \"Q1\", \"C1\", [\"A1\"]),\n",
        "        SquadExample(1, \"T2\", \"Q2\", \"C2\", [\"A2\"]),\n",
        "        SquadExample(2, \"T3\", \"Q3\", \"C3\", [\"A3\"])]\n",
        "    question = \"My Q\"\n",
        "    result = func(question, train_exs, joiner=\"\\n\")\n",
        "    expected = \"\"\n",
        "    tests = [\n",
        "        (1, \"\\n\", 'Q: C1\\nA: A1\\nQ: My Q\\nA:'),                \n",
        "        (1, \"\\n\\n\", 'Q: C1\\n\\nA: A1\\n\\nQ: My Q\\n\\nA:'),\n",
        "        (2, \"\\n\", 'Q: C1\\nA: A1\\nQ: C2\\nA: A2\\nQ: My Q\\nA:')]\n",
        "    err_count = 0       \n",
        "    for n_context, joiner, expected in tests:\n",
        "        result = func(question, train_exs[: n_context], joiner=joiner)\n",
        "        if result != expected:\n",
        "            err_count +=1 \n",
        "            print(f\"Error:\\n\\nExpected:\\n\\n{expected}\\n\\nGot:\\n\\n{result}\")    \n",
        "    if err_count == 0:\n",
        "        print(\"No errors detected in `build_few_shot_no_context_prompt`\")     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGkCrGUEkTxl"
      },
      "outputs": [],
      "source": [
        "test_build_few_shot_no_context_prompt(build_few_shot_no_context_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9f_UY4AkTxm"
      },
      "outputs": [],
      "source": [
        "def evaluate_few_shot_no_context(\n",
        "        examples,\n",
        "        squad_train,\n",
        "        batch_size=20,\n",
        "        n_context=2,\n",
        "        joiner=\"\\n\\n\",\n",
        "        gen_func=run_eleuther):\n",
        "    \"\"\"Evaluate a few-shot OpenQA with no context approach \n",
        "    defined by `build_few_shot_no_context_prompt` and `gen_func`.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    examples : iterable of SQuAD train examples\n",
        "        Presumably a subset of `squad_dev` as defined above.\n",
        "    squad_train : iterable of SQuAD train examples\n",
        "    batch_size : int\n",
        "        Number of examples to send to `gen_func` at once.\n",
        "    n_context : n\n",
        "        Number of examples to use from `squad_train`.\n",
        "    joiner : str\n",
        "        Used by `build_few_shot_open_qa_prompt` to join segments\n",
        "        of the prompt into a single str.\n",
        "    gen_func : either `run_eleuther` or `run_gpt3`\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dict as determined by `evaluate` above.\n",
        "\n",
        "    \"\"\"\n",
        "    # A list of strings that you build and feed into `gen_func`.\n",
        "    prompts = []\n",
        "\n",
        "    # A list of dicts that you get from `gen_func`.\n",
        "    gens = []\n",
        "\n",
        "    # Iterate through the examples in batches:\n",
        "    for i in range(0, len(examples), batch_size):\n",
        "        # Sample some SQuAD training examples to use with\n",
        "        # `build_few_shot_no_context_prompt` and `ex.question`,\n",
        "        # run the resulting prompt through `gen_func`, and\n",
        "        # add your prompts and results to `prompts` and `gens`.\n",
        "\n",
        "        ##### YOUR CODE HERE\n",
        "\n",
        "\n",
        "\n",
        "    # Return value from a call to `evalaute`, with `examples`\n",
        "    # as provided by the user and the `prompts` and `gens`\n",
        "    # you built:\n",
        "    return evaluate(examples, prompts, gens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5_Z8CjlkTxm"
      },
      "outputs": [],
      "source": [
        "def test_evaluator(func):\n",
        "    examples = [SquadExample(0, \"T1\", \"Q1\", \"C1\", [\"A1\"])]    \n",
        "    squad_train = [SquadExample(0, \"sT1\", \"sQ1\", \"sC1\", [\"sA1\"])] \n",
        "    \n",
        "    def gen_func(*prompts):\n",
        "        return [{\n",
        "            \"generated_answer\": \"Constant output\", \n",
        "            \"generated_answer_tokens\": [\"Constant\", \"output\"], \n",
        "            \"generated_answer_probs\": [0.1, 0.2]}]\n",
        "    \n",
        "    batch_size = 1    \n",
        "    n_context = 1    \n",
        "    joiner = \"\\n\"\n",
        "    result = func(\n",
        "        examples, \n",
        "        squad_train, \n",
        "        batch_size=1, \n",
        "        n_context=1, \n",
        "        joiner=joiner, \n",
        "        gen_func=gen_func)\n",
        "    expected_keys = {'em_per', 'examples', 'macro_f1'}\n",
        "    result_keys = set(result.keys())     \n",
        "    if expected_keys != result_keys:\n",
        "        print(f\"Unexpected keys in result. \"\n",
        "              f\"Expected: {expected_keys}; Got: {result_keys}\")\n",
        "        return\n",
        "    expected_ex_keys = {\n",
        "        'f1', 'id', 'em', 'generated_answer_tokens', 'generated_answer_probs',\n",
        "        'prediction', 'generated_answer', 'question', 'answers'}\n",
        "    result_ex_keys = set(result[\"examples\"][0].keys())\n",
        "    if expected_ex_keys != result_ex_keys:\n",
        "        print(f\"Unexpected keys in result['examples']. \"\n",
        "              f\"Expected: {expected_ex_keys}; Got: {result_ex_keys}\")\n",
        "        return\n",
        "    print(\"No errors detected in `evaluate_few_shot_open_qa`\")  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJGWjjq_kTxm"
      },
      "outputs": [],
      "source": [
        "test_evaluator(evaluate_few_shot_no_context)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2mx3Z4HYre2"
      },
      "source": [
        "### Few-shot OpenQA [2 points]\n",
        "\n",
        "In the section [Few-shot QA](Few-shot-QA) above, we used SQuAD training examples to build prompts that we hope will help the model infer our intended semantics for the prompts themselves. When we moved to the open formulation of the problem, in [Open QA with ColBERT retrieval](Open-QA-with-ColBERT-retrieval), we forced the model to deal with prompts that lack these context clues. This is a \"zero-shot\" formulation of the problem. The goal of this homework problem is to improve that system so that it truly supports few-shot OpenQA.\n",
        "\n",
        "__Task 1__: Complete the function `build_few_shot_open_qa_prompt` so that it builds prompts from a question, a passage, and a sample of SQuAD training examples. You can use `test_build_few_shot_open_qa_prompt` to check that your function is returning prompts in the desired format.\n",
        "\n",
        "__Task 2__: Complete the function `evaluate_few_shot_open_qa` so that you can evaluate this approach. You can use `test_evaluator` from above to check that your function is performing the desired kind of evaluation.\n",
        "\n",
        "We will be checking only that the tests pass. We will not be evaluating the quality of the results you obtain using this code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUuZ5l3gYre2"
      },
      "outputs": [],
      "source": [
        "def build_few_shot_open_qa_prompt(question, passage, train_exs, joiner=\"\\n\\n\"):\n",
        "    \"\"\"Few-shot OpenQA prompts.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    question : str\n",
        "    passage : str\n",
        "        Presumably something retrieved via search.\n",
        "    train_exs : iterable of SQuAD train examples\n",
        "        These can be obtained via a random sample from \n",
        "        `squad_train` as defined above.\n",
        "    joiner : str\n",
        "        The character to use to join pieces of the prompt \n",
        "        into a single str.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    str, the prompt\n",
        "\n",
        "    \"\"\"\n",
        "    ##### YOUR CODE HERE\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vgeNwTu4Yre2"
      },
      "outputs": [],
      "source": [
        "def test_build_few_shot_open_qa_prompt(func):\n",
        "    train_exs = [\n",
        "        SquadExample(0, \"T1\", \"Q1\", \"C1\", [\"A1\"]),\n",
        "        SquadExample(1, \"T2\", \"Q2\", \"C2\", [\"A2\"]),\n",
        "        SquadExample(2, \"T3\", \"Q3\", \"C3\", [\"A3\"])]            \n",
        "    question = \"My Q\"    \n",
        "    passage = \"Title | target passage\"    \n",
        "    tests = [\n",
        "        (1, \"\\n\", ('Title: T1\\nBackground: Q1\\nQ: C1\\nA: A1\\n'\n",
        "                   'Title: Title\\nBackground: target passage\\nQ: My Q\\nA:')),\n",
        "        (1, \"\\n\\n\", ('Title: T1\\n\\nBackground: Q1\\n\\nQ: C1\\n\\nA: A1\\n\\n'\n",
        "                     'Title: Title\\n\\nBackground: target passage\\n\\nQ: My Q\\n\\nA:')),\n",
        "        (2, \"\\n\", ('Title: T1\\nBackground: Q1\\nQ: C1\\nA: A1\\nTitle: T2\\n'\n",
        "                   'Background: Q2\\nQ: C2\\nA: A2\\nTitle: Title\\n'\n",
        "                   'Background: target passage\\nQ: My Q\\nA:'))]\n",
        "    err_count = 0       \n",
        "    for n_context, joiner, expected in tests:\n",
        "        result = func(question, passage, train_exs[: n_context], joiner=joiner)\n",
        "        if result != expected:\n",
        "            err_count +=1 \n",
        "            print(f\"Error:\\n\\nExpected:\\n\\n{expected}\\n\\nGot:\\n\\n{result}\")    \n",
        "    if err_count == 0:\n",
        "        print(\"No errors detected in `build_few_shot_open_qa_prompt`\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lK991-2AYre3"
      },
      "outputs": [],
      "source": [
        "test_build_few_shot_open_qa_prompt(build_few_shot_open_qa_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRhoMeEGYre3"
      },
      "outputs": [],
      "source": [
        "def evaluate_few_shot_open_qa(\n",
        "        examples,\n",
        "        squad_train,\n",
        "        batch_size=20,\n",
        "        n_context=2,\n",
        "        joiner=\"\\n\\n\",\n",
        "        gen_func=run_eleuther):\n",
        "    \"\"\"Evaluate a few-shot OpenQA approach defined by \n",
        "    `build_few_shot_open_qa_prompt` and `gen_func`.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    examples : iterable of SQuAD train examples\n",
        "        Presumably a subset of `squad_dev` as defined above.\n",
        "    squad_train : iterable of SQuAD train examples\n",
        "    batch_size : int\n",
        "        Number of examples to send to `gen_func` at once.\n",
        "    joiner : str\n",
        "        Used by `build_few_shot_open_qa_prompt` to join segments\n",
        "        of the prompt into a single str.\n",
        "    gen_func : either `run_eleuther` or `run_gpt3`\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dict as determined by `evaluate` above.\n",
        "\n",
        "    \"\"\"\n",
        "    # A list of strings that you build and feed into `gen_func`.\n",
        "    prompts = []\n",
        "\n",
        "    # A list of dicts that you get from `gen_func`.\n",
        "    gens = []\n",
        "\n",
        "    # Iterate through the examples in batches:\n",
        "    for i in range(0, len(examples), batch_size):\n",
        "        # Use the `searcher` defined above to get passages\n",
        "        # using `ex.question` as the query, and use your\n",
        "        # `build_few_shot_open_qa_prompt` to build prompts.\n",
        "\n",
        "        ##### YOUR CODE HERE\n",
        "\n",
        "\n",
        "\n",
        "    # Return value from a call to `evalaute`, with `examples`\n",
        "    # as provided by the user and the `prompts` and `gens`\n",
        "    # you built:\n",
        "    return evaluate(examples, prompts, gens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "beEyy_eOYre3"
      },
      "outputs": [],
      "source": [
        "test_evaluator(evaluate_few_shot_open_qa)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXNI9BRNYre3"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXeQzplkYre3"
      },
      "source": [
        "### Answer scoring [2 points]\n",
        "\n",
        "We have so far been assuming that the top-ranked passage retrieved by ColBERT should be used in the prompt and that the single answer returned by the LM is our prediction. It may be possible to improve on this by scoring answers using the ColBERT scores and the probabilities returned by the LM. This question asks you to explore a basic approach to such scoring. The core scoring function:\n",
        "\n",
        "$$\n",
        "\\textbf{score}_{\\text{prompt-func}}(\\textrm{answer}, \\textrm{passage}, \\textrm{question}) = \n",
        "P(\\textrm{passage} \\mid \\textrm{question}) \\cdot \n",
        "P(\\textrm{answer} \\mid \\text{prompt-func}(\\textrm{question}, \\textrm{passage}) ) \n",
        "$$\n",
        "\n",
        "where we estimate the two conditional probabilities as follows:\n",
        "\n",
        "* $P(\\textrm{passage} \\mid \\textrm{question})$ is defined only for the top $k$ passages and defined by the softmax of the top $k$ scores returned by the retriever.\n",
        "\n",
        "* $P(\\textrm{answer} \\mid \\text{prompt-func}(\\textrm{question}, \\textrm{passage}))$ is simply the product of the per-token probabilities of the generated answer given the prompt determined by $\\text{prompt-func}(\\textrm{question}, \\textrm{passage})$. These values can be extracted from the return values of both `run_eleuther` and `run_gpt3` using the key `\"generated_answer_probs\"`. (Your prompt function might of course have other arguments not represented here.)\n",
        "\n",
        "__Your task__: Implement this scoring function for an individual example. The two required pieces are `get_passages_with_scores` and `answer_scoring`. Starter code for each is below, and each has a unit test you can run to check your work.\n",
        "\n",
        "(With this implemented, it is easy to create a new prediction function that uses the $\\textrm{answer}$ from the highest-scoring $\\textrm{answer}/\\textrm{passage}$ pair as the prediction for input $\\textrm{question}$. You are not required to implement such a prediction function, but you might do this as part of [your original system](#Your-original-system-[3-points]).)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7PhfMNsYre3"
      },
      "outputs": [],
      "source": [
        "def get_passages_with_scores(question, k=5):\n",
        "    \"\"\"Pseudo-probabilities from the retriever.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    question : str\n",
        "    k : int\n",
        "        Number of passages to retrieve.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    passages (list of str), passage_probs (np.array)\n",
        "\n",
        "    \"\"\"\n",
        "    # Use the `searcher` to get `k` passages for `questions`:\n",
        "    ##### YOUR CODE HERE\n",
        "\n",
        "\n",
        "\n",
        "    # Softmax normalize the scores and convert the list to\n",
        "    # a NumPy array:\n",
        "    ##### YOUR CODE HERE\n",
        "\n",
        "\n",
        "\n",
        "    # Get the passages as a list of texts:\n",
        "    ##### YOUR CODE HERE\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vqCNOtMYre4"
      },
      "outputs": [],
      "source": [
        "def test_get_passages_with_scores(func):\n",
        "    question = \"What is linguistics?\"        \n",
        "    passages, passage_probs = get_passages_with_scores(question, k=2)    \n",
        "    if len(passages) != len(passage_probs):\n",
        "        print(\"`get_passages_with_scores` should return equal length \"\n",
        "              \"lists of passages and passage probabilities.\")\n",
        "        return\n",
        "    if len(passages) != 2:\n",
        "        print(f\"`get_passages_with_scores` should return `k` passages. Yours returns {len(passages)}\")\n",
        "        return\n",
        "    if not all(isinstance(psg, str) for psg in passages):\n",
        "        print(\"The first return argument should be a list of passage strings.\")\n",
        "        return\n",
        "    if not all(isinstance(p, (float, np.float32, np.float64)) for p in passage_probs): \n",
        "        print(\"The second return argument should be a list of floats.\")\n",
        "        return \n",
        "    print(\"No errors detected in `get_passages_with_scores`\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfsb4pyHYre4"
      },
      "outputs": [],
      "source": [
        "test_get_passages_with_scores(get_passages_with_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwQVdCb6Yre4"
      },
      "outputs": [],
      "source": [
        "def answer_scoring(passages, passage_probs, prompts, gen_func=run_eleuther):\n",
        "    \"\"\"Implements our basic scoring strategy.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    passages : list of str\n",
        "    passage_probs : list of float\n",
        "    prompts : list of str\n",
        "    gen_func : either `run_eleuther` or `run_gpt3`\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    list of pairs (score, dict), sorted with the largest score first.\n",
        "    `dict` should be the return value of `gen_func` for an example.\n",
        "\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    for passage, passage_prob, prompt in zip(passages, passage_probs, prompts):\n",
        "        # Run `gen_func` on [prompt] (crucially, the singleton list here),\n",
        "        # and get the dictionary `gen` from the singleton list `gen_func`\n",
        "        # returns, and then use the values to score `gen` according to our\n",
        "        # scoring method.\n",
        "        #\n",
        "        # Be sure to use \"generated_answer_probs\" for the scores.\n",
        "        ##### YOUR CODE HERE\n",
        "\n",
        "\n",
        "\n",
        "    # Return `data`, sorted with the highest scoring `(score, gen)`\n",
        "    # pair given first.\n",
        "    ##### YOUR CODE HERE\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JD7d8ucgYre4"
      },
      "outputs": [],
      "source": [
        "def test_answer_scoring(func):\n",
        "    passages = [\n",
        "        \"Pragmatics is the study of language use.\", \n",
        "        \"Phonology is the study of linguistic sound systems.\"]\n",
        "    passage_probs = [0.75, 0.25]\n",
        "    prompts = passages\n",
        "    \n",
        "    def gen_func(*prompts):\n",
        "        return [{\n",
        "            \"generated_answer\": \"Constant output\", \n",
        "            \"generated_answer_tokens\": [\"Constant\", \"output\"], \n",
        "            \"generated_answer_probs\": [0.1, 0.2]}]\n",
        "    \n",
        "    data = func(passages, passage_probs, prompts, gen_func=gen_func)\n",
        "    \n",
        "    if not all(len(x) == 2 for x in data):\n",
        "        print(\"`answer_scoring` should return a list of pairs (score, gen)\")\n",
        "        return \n",
        "    if not isinstance(data[0][0], (float, np.float32, np.float64)):\n",
        "        print(\"The first member of each pair in `data` should be a score (type `float`).\")\n",
        "        return    \n",
        "    if not isinstance(data[0][1], dict):\n",
        "        print(\"The second member of each pair in `data` should be a dict \" \n",
        "              \"created by running `gen_func` on a single example.\")\n",
        "        return    \n",
        "    if data[0][0] != max([x for x, y in data]):\n",
        "        print(\"`answer_scoring` should sort its data with the highest score first.\")\n",
        "        return \n",
        "    \n",
        "    print(\"No errors detected in `answer_scoring`\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QWwwDzvBYre4"
      },
      "outputs": [],
      "source": [
        "test_answer_scoring(answer_scoring)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUcdfU9SYre4"
      },
      "outputs": [],
      "source": [
        "def answer_scoring_demo(question):\n",
        "    \"\"\"Example usage for answer_scoring. Here we extract the top-scoring\n",
        "    results, which can then be used in an evaluation.\"\"\"    \n",
        "    passages, passage_probs = get_passages_with_scores(question)\n",
        "    prompts = [build_zero_shot_openqa_prompt(question, psg) for psg in passages]\n",
        "    data = answer_scoring(passages, passage_probs, prompts)\n",
        "    # Top-scoring answer string:\n",
        "    return data[0][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gyyyk2itkTxq"
      },
      "outputs": [],
      "source": [
        "answer_scoring_demo(\"How long is Moby Dick?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmURWvoJYre4"
      },
      "source": [
        "### Your original system [3 points]\n",
        "\n",
        "This question asks you to design your own few-shot OpenQA system. All of the code above can be used and modified for this, and the requirement is just that you try something new that goes beyond what we've done so far. \n",
        "\n",
        "Terms for the bake-off:\n",
        "\n",
        "* You can make free use of SQuAD and other publicly available data.\n",
        "* The LM must be an autoregressive language model. No trained QA components can be used. Our list of preallowed models are those available via the OpenAI API whose names begin with \"text\" and the Eluether models \"gpt-neo-125M\", \"gpt-neo-1.3B\", \"gpt-neo-2.7B\", and \"gpt-j-6B\". If you would like to use a model outside of this set, please check with the teaching team first.\n",
        "\n",
        "Here are some ideas for the original system:\n",
        "\n",
        "* We have so far sampled randomly from the SQuaD train set to create few-shot prompts. One might instead sample passages that have some connection to the target question.\n",
        "\n",
        "* We have used actual SQuAD training examples to build contexts. These might be different in meaningful ways from the passages in our corpus. An alternative is to use the SQuAD question–answer pairs to retrieve passages that contain the answer and use the resulting question–answer–passage triple when building prompts.\n",
        "\n",
        "* There are a lot of parameters to our LMs that we have so far ignored. Exploring different values might lead to better results. The `temperature` parameter is highly impactful for our task.\n",
        "\n",
        "* We have distributed a fixed index of 100K passages. These cover SQuAD plus our bake-off data, but there might still be value in creating a different/expanded index. There is starter code for indexing data with ColBERT [here](https://github.com/stanford-futuredata/ColBERT/blob/new_api/docs/intro.ipynb).\n",
        "\n",
        "* [Khattab et al. (2021a)](https://aclanthology.org/2021.tacl-1.55/) fine-tune the retriever through a handful of successive rounds, using weak supervision from the QA dataset. This is an ambitious direction that could quickly build to an original project, as the role of retriever training is under-explored so far in the context of few-shot OpenQA.\n",
        "\n",
        "* In our \"Answer scoring\" question, we don't normalize scores by answer length. Such normalization might be fairer to long answers and so seems worth adding.\n",
        "\n",
        "* Our \"Answer scoring\" question is inspired by the Retrieval Augmented Generation (RAG) model of [Lewis et al. 2020](https://arxiv.org/abs/2005.11401). Their model fully marginalizes over $k$ retrieved passages to create a proper model of $P(\\textrm{answer} \\mid \\textrm{question})$. Implementing this requires having the probabilities for the prompts. For GPT-3, these can be obtained with `echo=False`, which will lead you to have to make changes to the output processing of `run_gpt3`. For the Eleuther models, one needs to do another call to the model forward function. Here is some starter code that could be used to begin modifying `run_eleuther`:\n",
        "\n",
        "   ```\n",
        "    prompt_logits = eleuther_model(prompt_ids).logits                \n",
        "    prompt_probs = prompt_logits.softmax(-1)                                   \n",
        "    prompt_probs = torch.gather(prompt_probs, 2, prompt_ids[:, :, None]).squeeze(-1)\n",
        "    prompt_probs = [list(prompt_prob.numpy()) for p in prompt_probs]\n",
        "   ```\n",
        "\n",
        "__Original system instructions__:\n",
        "\n",
        "In the cell below, please provide a brief technical description of your original system, so that the teaching team can gain an understanding of what it does. This will help us to understand your code and analyze all the submissions to identify patterns and strategies. \n",
        "\n",
        "We also ask that you report the best macro F1 score your system got during development on `dev_exs` [as defined above](#SQuAD-dev-sample), just to help us understand how systems performed overall.\n",
        "\n",
        "Please review the descriptions in the following comment and follow the instructions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9pfDIrPYre4"
      },
      "outputs": [],
      "source": [
        "# PLEASE MAKE SURE TO INCLUDE THE FOLLOWING BETWEEN THE START AND STOP COMMENTS:\n",
        "#   1) Textual description of your system.\n",
        "#   2) The code for your original system.\n",
        "#   3) The score achieved by your system in place of MY_NUMBER.\n",
        "#        With no other changes to that line.\n",
        "#        You should report your score as a decimal value <=1.0\n",
        "# PLEASE MAKE SURE NOT TO DELETE OR EDIT THE START AND STOP COMMENTS\n",
        "\n",
        "# NOTE: MODULES, CODE AND DATASETS REQUIRED FOR YOUR ORIGINAL SYSTEM\n",
        "# SHOULD BE ADDED BELOW THE 'IS_GRADESCOPE_ENV' CHECK CONDITION. DOING\n",
        "# SO ABOVE THE CHECK MAY CAUSE THE AUTOGRADER TO FAIL.\n",
        "\n",
        "# START COMMENT: Enter your system description in this cell.\n",
        "# My peak score was: MY_NUMBER\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "    pass\n",
        "\n",
        "# STOP COMMENT: Please do not remove this comment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zS3G0Ss7Yre4"
      },
      "source": [
        "## Bake-off [1 point]\n",
        "\n",
        "For the bake-off, you simply need to be able to run your system on the file \n",
        "\n",
        "```data/openqa/cs224u-openqa-test-unlabeled.txt```\n",
        "\n",
        "The following code should download it for you if necessary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zb1rod3DkTxr"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(os.path.join(\"data\", \"openqa\", \"cs224u-openqa-test-unlabeled.txt\")):\n",
        "    !mkdir -p data/openqa\n",
        "    !wget https://web.stanford.edu/class/cs224u/data/cs224u-openqa-test-unlabeled.txt -P data/openqa/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFvy_6LmkTxr"
      },
      "source": [
        "If the above fails, you can just download https://web.stanford.edu/class/cs224u/data/cs224u-openqa-test-unlabeled.txt and place it in `data/openqa`.\n",
        "\n",
        "This file contains only questions. The starter code below will help you structure this. It writes a file \"cs224u-openqa-bakeoff-entry.json\" to the current directory. That file should be uploaded as-is. Please do not change its name."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GyttYJxoYre4"
      },
      "outputs": [],
      "source": [
        "def create_bakeoff_submission():\n",
        "    filename = os.path.join(\"data\", \"openqa\", \"cs224u-openqa-test-unlabeled.txt\")\n",
        "    \n",
        "    # This should become a mapping from questions (str) to response\n",
        "    # dicts from your system.\n",
        "    gens = {} \n",
        "        \n",
        "    with open(filename) as f:\n",
        "        questions = f.read().splitlines()\n",
        "    \n",
        "    # `questions` is the list of questions you need to evaluate your system on.\n",
        "    # Put whatever code you need to in here to evaluate your system.\n",
        "    # All you need to be sure to do is create a list of dicts with at least\n",
        "    # the keys of the dicts returned by `run_gpt` and `run_eleuther`.\n",
        "    # Add those dicts to `gens`.\n",
        "    #\n",
        "    # Here is an example where we just do \"Open QA with no context\",\n",
        "    # for an \"original system\" that would not earn any credit (since\n",
        "    # it is not original!):\n",
        "    for question in questions:\n",
        "        gens[question] = run_eleuther([question])[0]\n",
        "        \n",
        "    # Quick tests we advise you to run: \n",
        "    # 1. Make sure `gens` is a dict with the questions as the keys:\n",
        "    assert all(q in gens for q in questions)\n",
        "    # 2. Make sure the values are dicts and have the key we will use:\n",
        "    assert all(isinstance(d, dict) and \"generated_answer\" in d for d in gens.values())\n",
        "            \n",
        "    # And finally the output file:\n",
        "    with open(\"cs224u-openqa-bakeoff-entry.json\", \"wt\") as f:\n",
        "        json.dump(gens, f, indent=4)    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6d6EsfM5kTxs"
      },
      "outputs": [],
      "source": [
        "create_bakeoff_submission()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmS5WxuukTxs"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6IR6qr3ckTxs"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "PmURWvoJYre4",
        "zS3G0Ss7Yre4"
      ],
      "machine_shape": "hm",
      "name": "My hw_openqa_solved.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "a99ac6d2deb03d0b7ced3594556c328848678d7cea021ae1b9990e15d3ad5c49"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0052cafd45474bfaaf2356a809b8ab8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_746831b8b3b24f79b05eab1ede2931d7",
            "max": 1007,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_093bf95cbcc9471c9788e4b5e53e74ac",
            "value": 1007
          }
        },
        "00ee280de0df457ab2927172e86589a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "06101e7ee98b4df49564b6584c68fadc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_383379fe15b94faf8b41e8f275d671e4",
              "IPY_MODEL_32b1008c4e8f4e7682c031b30bf389c4",
              "IPY_MODEL_e2301a6c44144aecadfd64fb2fcbf9a1"
            ],
            "layout": "IPY_MODEL_b0feee66ceaf4132a76d5cc8176e1183"
          }
        },
        "093bf95cbcc9471c9788e4b5e53e74ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e8a97bab2294583bf0ebf2cb469b404": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "170b400de66c4da4af17b5a567b2d326": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "271abe49dc054863a07a7d4dea6c0865": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28a095b67fdb4e64849114da743a211b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d2aabaf53864d229a24aa4351cde250": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d330683ae74434586f39a079ed602cd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d3531fa44f8443b8bf6db4ce70c28bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3515c902ab94a57b523e3d5dd1afb10",
            "placeholder": "​",
            "style": "IPY_MODEL_f85bc8c52a5347f6a6e82504b9eebad8",
            "value": " 446k/446k [00:00&lt;00:00, 626kB/s]"
          }
        },
        "2d384da8922040e7a85b99c68aeb8e1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d70ee10baac34852afabb6c5fe377d32",
            "placeholder": "​",
            "style": "IPY_MODEL_28a095b67fdb4e64849114da743a211b",
            "value": "Downloading: 100%"
          }
        },
        "2f7e8f2f019f4110b6ff3d2cb1194207": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b995d2d434884b95a6ed27ca35f0701e",
            "max": 898669,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_65dbec85c4c440dc87a2fe83f2c0c6de",
            "value": 898669
          }
        },
        "31e5a2f3fc6044ac8a08c5286338307e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32b1008c4e8f4e7682c031b30bf389c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbd037a19b0245f3ae0bea1a42e126da",
            "max": 357,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_00ee280de0df457ab2927172e86589a9",
            "value": 357
          }
        },
        "3539f428334a48dcbbeb93fd65fd567e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d77e4365e28049ecaef374394eed15ef",
            "placeholder": "​",
            "style": "IPY_MODEL_e97b339812294939be5d6d9870bcbb79",
            "value": " 560/560 [00:00&lt;00:00, 8.81kB/s]"
          }
        },
        "3603bdf6e1cd4a92be658847cd05d140": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "383379fe15b94faf8b41e8f275d671e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31e5a2f3fc6044ac8a08c5286338307e",
            "placeholder": "​",
            "style": "IPY_MODEL_3ddcad33566f44c4886629e1b09f0163",
            "value": "Downloading: 100%"
          }
        },
        "39d2bfb749e64f1f895e5a46f9fee71f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ddcad33566f44c4886629e1b09f0163": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "482d529f86864da49a84b7634c164b4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_882329f06a884864aed2bbb3ad767bfe",
            "placeholder": "​",
            "style": "IPY_MODEL_2d2aabaf53864d229a24aa4351cde250",
            "value": " 0.98k/0.98k [00:00&lt;00:00, 37.0kB/s]"
          }
        },
        "488959fbdb9c4fe999284e4d09e094c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c89addfe272a44d8adc56424f95459f3",
            "max": 526017373,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_73a63281463b47c09aba00b2e086cd71",
            "value": 526017373
          }
        },
        "5040f8d0972c4e1b885394b67fdc964b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5912f66fcd664f5193c2912559c34572": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b3a6c7f95ff4bcfb6a0f6a53e31c363": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bad75932665486dab40377b41dcae7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f094894e4434ec1b8f3035953a54561": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_850c7b8b9a7348b7a717b6949c19d975",
            "placeholder": "​",
            "style": "IPY_MODEL_5bad75932665486dab40377b41dcae7e",
            "value": "Downloading: 100%"
          }
        },
        "5f28af2204f44951af30da8ff19607c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9affd2c86dab4c1287d858a12bdca36f",
              "IPY_MODEL_2f7e8f2f019f4110b6ff3d2cb1194207",
              "IPY_MODEL_a0b543ae60ae4d8c89bc65fb5e9c2655"
            ],
            "layout": "IPY_MODEL_b32f26847ed74c338b6a1154b1cbf025"
          }
        },
        "60fc978c38de4b7380486c3628a80580": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f094894e4434ec1b8f3035953a54561",
              "IPY_MODEL_b3ca85c21bc54756a79f47c2a1bd3bf2",
              "IPY_MODEL_3539f428334a48dcbbeb93fd65fd567e"
            ],
            "layout": "IPY_MODEL_0e8a97bab2294583bf0ebf2cb469b404"
          }
        },
        "64b8a98caa574e05898dfab287daaebc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65dbec85c4c440dc87a2fe83f2c0c6de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "66d57124c640469aae66a6e4104a87a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5912f66fcd664f5193c2912559c34572",
            "placeholder": "​",
            "style": "IPY_MODEL_170b400de66c4da4af17b5a567b2d326",
            "value": " 502M/502M [00:32&lt;00:00, 15.5MB/s]"
          }
        },
        "704775c94eef4ca08e575e08cf6e7549": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2d384da8922040e7a85b99c68aeb8e1e",
              "IPY_MODEL_0052cafd45474bfaaf2356a809b8ab8f",
              "IPY_MODEL_482d529f86864da49a84b7634c164b4f"
            ],
            "layout": "IPY_MODEL_e8152eb7d946460ba1ee26697acd1f28"
          }
        },
        "73a63281463b47c09aba00b2e086cd71": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "746831b8b3b24f79b05eab1ede2931d7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7693bba999da4a5aa00f8b80b93033ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64b8a98caa574e05898dfab287daaebc",
            "placeholder": "​",
            "style": "IPY_MODEL_39d2bfb749e64f1f895e5a46f9fee71f",
            "value": "Downloading: 100%"
          }
        },
        "78a391fb49444ef5a982e7cceafa9d56": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "850c7b8b9a7348b7a717b6949c19d975": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "882329f06a884864aed2bbb3ad767bfe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dda0783b61e4fa0b15b067a3edde7ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffb346b2be2744568c17588151c53978",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c2a9aa86e8c94b38b917584a56d8eb81",
            "value": 456318
          }
        },
        "91f38f5c3ccb4195b610db621fc17a85": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9affd2c86dab4c1287d858a12bdca36f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b077e97c40c14df7b24b3b4de5c1c325",
            "placeholder": "​",
            "style": "IPY_MODEL_3603bdf6e1cd4a92be658847cd05d140",
            "value": "Downloading: 100%"
          }
        },
        "9ebc962deaf241409e2f7807ce42d352": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0b543ae60ae4d8c89bc65fb5e9c2655": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ebc962deaf241409e2f7807ce42d352",
            "placeholder": "​",
            "style": "IPY_MODEL_e78bad9898274b59b2b187668e3cf86a",
            "value": " 878k/878k [00:01&lt;00:00, 1.21MB/s]"
          }
        },
        "a7df7dfb55a9475692c3f4cc52619613": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c3ddf5db64aa4914b0a56b749ce504ee",
              "IPY_MODEL_488959fbdb9c4fe999284e4d09e094c4",
              "IPY_MODEL_66d57124c640469aae66a6e4104a87a6"
            ],
            "layout": "IPY_MODEL_91f38f5c3ccb4195b610db621fc17a85"
          }
        },
        "b077e97c40c14df7b24b3b4de5c1c325": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0feee66ceaf4132a76d5cc8176e1183": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b32f26847ed74c338b6a1154b1cbf025": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3ca85c21bc54756a79f47c2a1bd3bf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b3a6c7f95ff4bcfb6a0f6a53e31c363",
            "max": 560,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5040f8d0972c4e1b885394b67fdc964b",
            "value": 560
          }
        },
        "b4ee18523e4f4c369b2464abd406057e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b995d2d434884b95a6ed27ca35f0701e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c17cfaba919740b2a0737f6467e401a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7693bba999da4a5aa00f8b80b93033ce",
              "IPY_MODEL_8dda0783b61e4fa0b15b067a3edde7ed",
              "IPY_MODEL_2d3531fa44f8443b8bf6db4ce70c28bf"
            ],
            "layout": "IPY_MODEL_2d330683ae74434586f39a079ed602cd"
          }
        },
        "c2a9aa86e8c94b38b917584a56d8eb81": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c3515c902ab94a57b523e3d5dd1afb10": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3ddf5db64aa4914b0a56b749ce504ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d27d7971acee4e5ba6d532e743be97f2",
            "placeholder": "​",
            "style": "IPY_MODEL_78a391fb49444ef5a982e7cceafa9d56",
            "value": "Downloading: 100%"
          }
        },
        "c89addfe272a44d8adc56424f95459f3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d27d7971acee4e5ba6d532e743be97f2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d70ee10baac34852afabb6c5fe377d32": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d77e4365e28049ecaef374394eed15ef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2301a6c44144aecadfd64fb2fcbf9a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4ee18523e4f4c369b2464abd406057e",
            "placeholder": "​",
            "style": "IPY_MODEL_271abe49dc054863a07a7d4dea6c0865",
            "value": " 357/357 [00:00&lt;00:00, 12.1kB/s]"
          }
        },
        "e78bad9898274b59b2b187668e3cf86a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8152eb7d946460ba1ee26697acd1f28": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e97b339812294939be5d6d9870bcbb79": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f85bc8c52a5347f6a6e82504b9eebad8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fbd037a19b0245f3ae0bea1a42e126da": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffb346b2be2744568c17588151c53978": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}